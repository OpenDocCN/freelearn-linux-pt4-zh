<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Design and Deployment Considerations</h1>
                </header>
            
            <article>
                
<p><span><span>Now that we have</span></span> provided a comprehensive overview of the different components of VMware Horizon in the first couple of chapters, in this chapter, we are going to concentrate on how to put those components to use by introducing you to some of the design and deployment techniques that you need to consider when undertaking your VMware Horizon project.</p>
<p>First, we are going to discuss techniques that you can use to prove the technology and understand how it needs to work inside your business, starting with how to assess your current environment and then how to use this information to design your Horizon deployment.</p>
<p>Once you fully understand what it is you need to achieve for the business, we will then take a deeper dive into the design elements of your Horizon solution, including, but not limited to, ESXi host design, memory and CPU allocations for virtual desktops, storage considerations, clients, and other best practices and tips.</p>
<p>We are going to look at both the business and the technical elements of a project, and then discuss each one and see how it fits into the overall project. To make this easier and more logical, we will break these down into three distinct project phases, as shown in the following diagram:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/bd58431e-8c73-4027-a2a3-b277f417c402.png"/></div>
<p>In the following sections, we are going to explore and discuss these three phases in more detail.</p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li class="mce-root">Phase I – Project definition</li>
<li class="mce-root">Phase II – Proving the technology</li>
<li class="mce-root">Phase III – Designing a production environment</li>
<li class="mce-root">Technology choices</li>
<li>Horizon View pod and block architecture</li>
<li>Cloud Pod Architecture</li>
<li>vSphere design for Horizon View</li>
<li>Horizon View design specifics</li>
<li>Supporting infrastructure design</li>
<li>Printing</li>
<li>Thin clients and other endpoint devices</li>
<li>Desktop design considerations</li>
<li>Example solution scenario</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Phase I – Project definition</h1>
                </header>
            
            <article>
                
<p>In this first phase, we are going to look at how you can approach a project. Phase one is broken down into four individual steps, as shown in the following diagram:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/3809e88b-a1f7-4289-8a45-f89ef7952eb0.png" style=""/></div>
<p>Let's look at each individual step in more detail, starting with the business drivers and understanding what your business requirements look like.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 1 – Identifying business drivers – understanding your needs and requirements</h1>
                </header>
            
            <article>
                
<p>Before you jump headlong into your Horizon project, take a step back and ensure that you start to document what you are trying to achieve. Often, it can be very easy to get carried away with all the new, shiny, technological aspects of the solution, such as the installation and configuration of new hardware and software, which means that the end goal is either lost or is not relevant to the business.</p>
<p>It may be an obvious point to make, but the key to identifying the business drivers is to really understand what you want to evaluate. By this, we mean, is it a strategic decision based on the need to transform your organization with new working initiatives, or is there a more compelling event, such as the end of life of an operating system or application? It may even simply be the need to reduce costs. Whatever the case, you need to get that nailed down, written up, and documented on day one so that the project has meaning and direction, and even more importantly, provides a baseline to refer to when it comes to reviewing time in order to gauge whether the project has been successful.</p>
<p>Start by writing a document of requirements that lists the business needs, the current problems you need to solve, the vision, and any compromises and assumptions. As you progress through your project, you should regularly refer to this document to keep yourself focused on the end goal.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 2 – Building the business case</h1>
                </header>
            
            <article>
                
<p>Once you have defined the drivers behind an initiative or the compelling event that's kicked off the project, and also understood the high-level objectives, the next stage is to start building the business case around these. This requires you to go to the next level of detail and start drilling into the specific areas the solution needs to address. To do this, you need to understand the business strategy and then identify the key stakeholders for the project. You can then start to define the high-level requirements of each of the areas identified as drivers and start to define user segmentation. For example, you can look at what different user types you have, how they work today, and what they need going forward. At the end of the day, it will be the end users that decide whether the project is a success, not you! This leads us into the next section, which is the assessment phase.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 3 – Assessment</h1>
                </header>
            
            <article>
                
<p>Once you have built and validated your business case against your strategy and identified that there is a requirement for a new way of delivering a desktop environment, then the next stage is to run an assessment. Although often called a desktop assessment, what you are actually doing is on-boarding an end user so that you can map their entire life cycle through infrastructure<span>—</span>not just today, but by continuously monitoring them to ensure that they continue to have the best user experience possible as they move through the OS, app migrations, and updates.</p>
<p>So, what do we mean by an assessment, or in this instance, how do we on-board end users so that we can assess and monitor them throughout their working life cycle? What exactly is involved? It comes down to several things that we are looking for. This includes examining your current desktop landscape by gathering key metrics so that you can understand what is currently being delivered, to whom it is being delivered, and more importantly, how resource-intensive it is. The assessment is designed to build a complete and accurate picture of what the current end user environment looks like.</p>
<p>It's not just about an inventory report<span>—</span>you need to understand exactly what the end users are doing, and how they are working. Some of the key metrics we are looking for include the following:</p>
<ul>
<li>Which users are using which applications (when, from where, and how often?)</li>
<li>Resource consumption (CPU, memory, disk, and network are key)</li>
<li>Unsuitable applications/use cases for remote delivery or VDI</li>
<li>Which client operating systems are being used?</li>
<li>Hardware inventory of existing devices</li>
<li>Machine boot times and login process breakdown</li>
<li>Current delivery methods (RDSH, XenApp, VDI, physical PCs, and so on)</li>
<li>User profile details</li>
</ul>
<p>What you are ultimately looking to achieve is the creation of a baseline of what your environment looks like today. Then, as you move into defining the success criteria and proving the technology, you have a baseline as a reference point to demonstrate how you have improved current functionality and delivered on both the business case and strategy.</p>
<p>If you have deployed a VDI solution already, and this new project is for something like a migration, or upgrading, then you should have most of this data available. However, if this was a while ago, then it's worth re-running the assessment so that you have up-to-date data, especially around the applications in your environment. Ideally, you would have been monitoring the infrastructure continuously from day one to help plan for such events.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">User experience and desktop analysis tools</h1>
                </header>
            
            <article>
                
<p>There are several different third-party, complementary products on the market that you can use to conduct the analysis. You are often able to use the services of a partner to assist with this process to help you understand the information and data that's been gathered.</p>
<p>One of the most popular solutions is the Liquidware Stratusphere solution. Stratusphere not only provides you with a detailed breakdown of the current user environment, with highlights such as a detailed breakdown of the login process, consumption reports, and a score to easily identify which users are virtualization candidates<span>—</span>it also provides that complete end user life cycle picture.</p>
<p>Stratusphere takes the baseline data and then uses that to continuously monitor the <span>end user experience so that you can ensure that your VDI solution is optimized, as shown in the following screenshot. We will discuss this in more detail later in this book:</span></p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/9dc86a13-cacd-4ae7-b117-10c06254a77a.png"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign"><span>Stratusphere monitor the end user experience</span></div>
<p>One thing to ensure is that the assessment solution is designed specifically for measuring desktops and not servers. The two technologies, although both virtualization technologies, are completely different, and while you could probably use desktop assessment software to plan your server virtualization project, it simply would not work the other way around.</p>
<p>As well as actually collecting the assessment data, there are several other points that you should take into consideration and look at. This will help you understand what some of the raw assessment data is telling you. For example, it might tell you that a specific user is unsuitable to have a virtual desktop due to the number of resources it consumes; however, when you speak to them, you may find that whatever they are doing isn't going to be relevant in VDI.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Understanding what do your users really do</h1>
                </header>
            
            <article>
                
<p>Working in an IT department will often give you a good level of understanding of the tasks that users undertake and the software that they use to achieve these tasks daily. However, this can usually be a lot more complex than it might first appear. By undertaking a desktop assessment, you gather a more granular level of understanding about the processes, applications, and experience your end users are getting from their existing desktops. This will likely include the applications they use, and those that they don't use, including the installed versions and capacity and performance requirements, as well as user experience metrics, such as login times and application load times.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Applications</h1>
                </header>
            
            <article>
                
<p>Understanding your current applications is a key part of the assessment phase. Not only could this impact end user productivity—after all, it's the apps that keep the users working<span>—</span><span>it</span> will also impact many other areas when it comes to design, including the number of pools, pool design, application virtualization, and, potentially, whether the desktop that gets assigned to the user can be non-persistent or whether you need to allocate a persistent desktop.</p>
<p>In some environments, you may well have legacy apps still running, and it's important to understand this as these apps may not be able to run in a virtual desktop environment and would, therefore, stall or derail your project completely. Often, when moving to virtual desktops, you would move from an older operating system as part of the project<span>—</span>which again would cause issues with application compatibility.</p>
<p>With the metrics gathered from the assessment, you will be able to fully understand the current situation of your desktop estate. It's not uncommon to find many disparate versions of software, meaning potential security risks, and in other cases, key applications crashing on a regular basis. This information will help you build a business case for change and help you prioritize your rollout to the users with the biggest security holes or the worst user experience.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Performance</h1>
                </header>
            
            <article>
                
<p>Without actual performance metrics, it will be near on impossible to size your virtual desktops. If you don't have this data, then it will be likely that your desktops will be sized in one of two ways. The first would be by oversizing your desktops. Oversizing often occurs when virtualizing as it is so simple to configure a virtual machine that we sometimes get carried away and start adding more CPU and memory than we really need. The result is that we need more infrastructure to resource this and so the costs goes up. This also happens when we guesstimate the size of the desktop, and then add ten or twenty percent on top of that, just in case. Pushing the costs up could mean that the project is not financially viable.</p>
<p>The flipside would be to undersize your desktops, potentially causing performance issues and a poor end user experience. If you then base your infrastructure on this lower spec and you end up having to add more resources, it may be a difficult conversation to secure more budget to increase the spec of the host servers or even add more servers.</p>
<p>This is one to watch out for if you are looking at a Desktop as a Service solution. On paper, the desktops look like they're good value for money, maybe costing somewhere around $30 to $50 per month. But after you have signed on the dotted line and your end users start ramping up and consuming more resources, the costs start to ramp up too. We have seen many a customer invoice with a much larger monthly payment than budgeted for because of taking low-spec desktops.</p>
<p>By performing a desktop assessment, you will understand what the performance looks like throughout the working day. How many resources are being consumed, and when? You are likely to see many dips and spikes throughout the day, such as login storms, AV scans, logoff storms, and other metrics, such as increased internet usage during lunch breaks.</p>
<p>If you work in an education environment, you might see many login and logoff storms during the day. It is important to understand this, as you will need to ensure that your solution is designed to meet these requirements. This information can be used to help guide you when sizing the relevant desktop pools, but bear in mind that, potentially, you are going to be making changes to the desktops between the assessment phase and deploying VDI desktops. This may be something such as migrating from Windows 7 to Windows 10, or the upgrade of an application. In these cases, the assessment will have been performed on the previous version of the operating system and therefore may not give you 100% accurate information on the resources required. Some third-party assessment tools can take care of this and allow you to model "what if" type scenarios.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">End user experience</h1>
                </header>
            
            <article>
                
<p>Above all else, what matters is user experience, which is the measurement of how good or how poor the end user's experience of using their virtual desktop is. When you undertake a server virtualization project, if done correctly, the users will probably not even realize it has happened.</p>
<p>With a desktop virtualization or any other EUC-type project that is very focused on the end users, it is more likely that they will realize a change has happened, and you need to ensure that this is a positive experience for the project to be a success. To do this, you need to almost get inside the head of the users to see exactly how they use the environment today. The measurements of user experience will be wide, varied, and often subjective, but will include elements such as boot time, application load time, login time, page load time, app failures, and finally, how intuitive it is to use. This is something that assessment tools are unlikely to tell you.</p>
<p>As you are progressing through the <strong>proof of concept</strong> (<span><strong>POC</strong>)</span>, pilot, and tuning processes, you need to ensure that the user experience is constantly improving. Failing to take end user experience into consideration will result in a definite failure of the project. To do this, you need to be interactive with the end user community.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Floor walks, interviews, and department champions</h1>
                </header>
            
            <article>
                
<p>As we outlined previously, while performing desktop assessments and gathering data on your environment are important parts of any EUC project, they should not replace the need to interact with your users. The benefit of human involvement is that you can pick up elements that simply would not be possible with software alone.</p>
<p>Start by simply walking through your office, noting what the users are doing, what applications they are using, what accessories, how many screens, whether they are using laptops or PCs, and so on.</p>
<p>Once you have this high level of understanding, consider booking meetings with key business leaders in each department to understand their needs, requirements, and the problems they have with their desktops today. You should also start considering who your department champions are going to be.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">What are department champions?</h1>
                </header>
            
            <article>
                
<p>If you are going to make a list of the key considerations from this book, then department champions should be high on your list. A department champion is an end user who is going to be the go-to person within the department for everything to do with their department's desktop, design, testing, and support. They don't need to be IT experts, but they should have a desire to help you improve the overall desktop experience. You should work with these champions to help with the design of their desktops, as they will be your first port of call for testing, and then testing again after you have listened to and implemented any of the feedback.</p>
<p>By working with a department champion, you will have a sponsor within the department. They will have a sense of pride over what is being rolled out and will be there to help you shape the desktop and be the user on your side to help explain why certain decisions have been made.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 4 – Defining the success criteria</h1>
                </header>
            
            <article>
                
<p>The key objective in defining the success criteria is to document what a good solution should look like for the project to succeed and become production-ready.</p>
<p>You need to clearly define the elements that need to function correctly to move from <span>POC</span> to POT and then into a pilot phase, before finally deploying into production. You need to fully document what these elements are and get the end users or other project stakeholders to sign up to them. It's almost like creating a statement of work with a clearly defined list of tasks. If you don't have any success criteria in place, then you should not start the testing!</p>
<p>Another important factor is to ensure that during this phase of the project, the success criteria don't start to grow beyond the original scope, which is commonly known as "scope creep." This means that any additional elements should not get added to the success criteria, or at least not without discussing them first. It may well transpire that something key was missed; however, if you have conducted your assessment thoroughly, this shouldn't happen. This is another reason for having the success criteria in place, otherwise you won't know what is on the list, and the list will never end with things continually being added.</p>
<p>Another thing that works well at this stage is to, once again, involve the end users. Set up a steering committee or advisory panel by selecting people from different departments to act as sponsors within their area of business. Actively involve them in the testing phases but get them on board early to get their input in shaping the solution from the outset.</p>
<p>Too many projects fail when a user tries something that didn't work. However, the thing that they tried is not actually a relevant use case or something that is used by the business as a critical line of business app, and therefore shouldn't derail the project.</p>
<p>I once saw a VDI project failing due to the unresponsiveness of the mouse when using Microsoft Paint. This knocked the project way off course while the issue was investigated. In the end, it was shown that Paint was not used by anyone, and so was totally irrelevant to the business or use case. However, it still ended up burning precious cycles while the team tried to enhance performance. As this customer had no success criteria defined beforehand, it was difficult to move the project on. If there had of been a list and this application was not on that list, then it could simply be ignored, and the project could have moved on.</p>
<p>If we have a set of success criteria defined up front that the end users have signed up to, anything outside that criteria is not in scope. If it's not defined in the document, it should be disregarded as not being part of what success should look like.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Phase II – Proving the technology</h1>
                </header>
            
            <article>
                
<p>In this section, we are going to discuss the approach to proving that the technology is fit for purpose. This is another very important piece of work that needs to be successfully completed once you have completed Phase I and is somewhat different to how you would typically approach an IT project. This is the same approach you should take for any end user computing type of project.</p>
<p>As we discussed previously, the starting point is to focus on the end users rather than the IT department. After all, these are the people that will be using the applications daily and know what they need to get their jobs done. Rather than giving them what you think they need, why not ask them what they really need and then, within reason, deliver their requirements. As the saying goes, don't try and fit a square peg into a round hole, as no matter how hard you try, it's just never going to fit.</p>
<p>First and foremost, you need to design the solution around the requirements of the end user rather than spending time and money on building an infrastructure only to find out at the end of the project that it doesn't deliver what the users require.</p>
<p>Once the previous steps have been discussed and documented, you should be able to build a picture around what's driving the project. You will understand what you are trying to achieve/deliver and, based upon hard and fast facts from the assessment phase, be able to work on what success should look like. From there, you can then move into testing the technology in some shape or form.</p>
<p><span>There are three distinct roads we can take within the testing cycle, and it might be the case</span> that you don't need all of them. In fact, it is usually best to jump straight to the last one if you can and look at deploying a pilot to save time and cost, and get the end users engaged early. The three stages we are talking about are as follows:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/237dd66a-1f99-4f84-b5c6-1cbac5a2cea7.png" style=""/></div>
<p>In the following sections, we are going to briefly cover what each of these stages mean and why you may or may not need them.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Proof of concept (POC)</h1>
                </header>
            
            <article>
                
<p>A POC typically refers to a partial solution, which is often built and installed on any old hardware kicking about the IT department. In terms of end user testing, a POC usually involves a small number of users, who are typically those in the IT teams, acting in business roles to establish whether the solution satisfies some aspect of the purpose it was designed for and is fit for purpose.</p>
<p>At the end of the POC, one of two things tend to happen. Firstly, nothing happens as it's just the IT department playing with technology and there wasn't a real business driver in the first place. This is usually down to not having a defined business case. In a similar way, by not having any success criteria, it will also fail, as you don't know exactly what you are setting out to prove.</p>
<p>The second outcome is that the project moves into a pilot phase, which we will discuss in a later section. You could consider moving directly into this phase and bypassing the POC altogether<span>—</span>after all, the vendor has already proved the concept, and to be honest if it's a production-ready solution that you can buy off the shelf today, then there is nothing conceptual about it. Maybe a demonstration of the technology would suffice and using a demo environment over a longer period would show you enough of how the technology works. Most vendors these days have a cloud-based test environment that can be used for prospective customers.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Proof of technology (POT)</h1>
                </header>
            
            <article>
                
<p>In contrast to POC, the objective of POT is to determine whether the proposed solution or technology will integrate into your existing environment and therefore demonstrate compatibility. POT should highlight any technical problems that are specific to your environment, such as how your bespoke systems might integrate. Similar to POC, POT is typically run by the IT department and no business users are usually involved. A POT is purely a technical validation exercise.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Pilot</h1>
                </header>
            
            <article>
                
<p>A pilot refers to what is almost a small-scale rollout of the solution, in a production-like environment, to be tested by real end users. The scope may be limited by the number of users who can access the pilot system, the business processes affected, or the business partners involved. The purpose of a pilot is to test whether the system is working as it was designed to, while limiting business exposure and risk. It should also touch real users so that you can gauge their feedback from what might ultimately become a live, production solution.</p>
<p>This is a critical step in achieving success as the end users are the people that will use the systems daily, and are the reason why you should set up some form of working group so that you can gather their feedback. This would also mitigate project failure, as the solution may deliver everything the IT department could ever wish for, but when it goes live, and the first user logs on and reports a bad experience or performance, you may as well have not bothered.</p>
<p>The pilot should be carefully scoped, sized, and implemented, which breaks down nicely into the following four steps toward a successful pilot, as shown in the following workflow diagram:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/81edd764-6003-4fff-a422-f4573ac3363d.png"/></div>
<p>Let's have a look at these steps in a bit more detail.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 1 – Pilot design</h1>
                </header>
            
            <article>
                
<p>The pilot infrastructure should be designed on the same hardware platforms that the production solution is going to be deployed on. For example, the same servers and storage should be used. This takes into account any anomalies between platforms and configuration differences that could affect things such as scalability, or more importantly, performance.</p>
<p>Even at the pilot stage, design is key, and you should make sure that you consider production design, even at this stage. Why? Basically, we do this because many pilot solutions end up going straight into production and more and more users get added above and beyond those that have been scoped for the pilot. It's great going live with the solution and not having to go back and rebuild it, but when you start to scale by adding more users and applications, you might have some issues due to the initial sizing, given that it was meant to be a pilot. It may sound obvious, but often with a successful pilot you just keep going, with end users continuing to work and IT adding more and more users. Well, until it breaks! If it's only ever going to be a pilot, that's fine, but keep this in mind and bear this in mind<span>—</span>if you are planning on taking the pilot straight into production, design it for production right at the very start.</p>
<p>It is always useful to work from a prerequisite document to understand the different elements that need to be taken into consideration in the design. Design elements include the following:</p>
<ul>
<li>Hardware sizing (servers<span>—</span>CPU, memory, and consolidation ratios)</li>
<li>Pool design (based on user segmentation)</li>
<li>Storage design (local SSD, SAN, and acceleration technologies)</li>
<li>Image creation (rebuild from scratch and optimize for VDI)</li>
<li>Network design (load balancing and external access)</li>
<li>Antivirus considerations</li>
<li>Application delivery (delivering virtually and/or layering versus installing in the base image)</li>
<li>User profile management</li>
<li>Persistent or non-persistent desktop user assignments</li>
<li>Linked Clone, Full Clone, or Instant Clone desktop builds</li>
</ul>
<p>Once you have all of this information, you can start to deploy the pilot environment.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 2 – Deploying the pilot</h1>
                </header>
            
            <article>
                
<p>In the deployment phase of the pilot, you are going to start building out the infrastructure, deploying the test users, and building the OS images. After this, you will start the testing phase.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 3 – Testing the pilot</h1>
                </header>
            
            <article>
                
<p>During the testing phase, you need to work closely with the end users and your sponsors, showing them the solution and how it works, closely monitoring the users, and assessing the solution as it's being used. This allows you to keep in contact with the users and give them the opportunity to continually provide real-time feedback. This, in turn, allows you to answer questions and adjust and make enhancements on the fly rather than waiting until the end of the project, only to be told it didn't work or they just simply didn't understand something.</p>
<p>This then leads us onto the last section, reviewing the pilot.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Step 4 – Reviewing the pilot</h1>
                </header>
            
            <article>
                
<p>This final stage sometimes tends to get forgotten. You have deployed the solution, the users have been testing it, and then it ends there for whatever reason. However, there is one very important last thing to do to enable you to move into production.</p>
<p>You need to measure user experience and the IT department's experience against the success criteria that you set out at the start of this process. You need to get customer sign-off and agreement that you have successfully met all of the objectives and requirements. If this is not the case, you need to understand the reasons why. Have you missed something in the use case, have the user requirements changed, or is it simply a perception issue?</p>
<p>Whatever the case, you need to cycle around the process again. Go back to the use case, understand and reevaluate the user requirements (what it is that is seemingly failing or not behaving as expected), and then tweak the design or make the required changes and get the users to test the solution again.</p>
<p>You need to continue this process, repeating again and again until you get acceptance and sign-off, otherwise you will not get to the final solution deployment phase.</p>
<p>When the project has been signed off after a successful pilot test, there is no reason why you cannot deploy the technology in production. However, it is useful to come back and revisit this occasionally to ensure that nothing has changed.</p>
<p>Now that we have talked about how to prove the technology and successfully demonstrated that it delivers against both your business case and your user requirements, in the following sections, we are going to start looking at designing a production environment.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Phase III – Designing a production environment</h1>
                </header>
            
            <article>
                
<p>Now that you have proved that the solution works within your environment, you can take all of the findings from both the assessment and the pilot phases and start building out a design for production. In this section, we are going to cover the main considerations for a successful design and discuss the general rules of thumb and best practices, before moving on to the specifics of sizing the storage requirement, scalability, availability, and how to architect the solution.</p>
<p>Before we do that, we are going to look at a few different example scenarios that could have been highlighted during the assessment and pilot phases, and look at which technology you should consider deploying.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technology choices</h1>
                </header>
            
            <article>
                
<p>With VMware Horizon, there is no one-product-fits-all solution to meet the needs of your end users, so it is important to consider the use cases carefully and match the different use cases to the different technologies that are available within the VMware Horizon portfolio. Once you have collected key information from assessments and user interaction, you will be able to make some technology solutions around which elements of the solution are going to deliver end user requirements. Choices include whether you should deliver full VDI desktops or published desktops, and how to deliver applications with ThinApp or App Volumes. You also need to consider third-party solutions, and how they are going to integrate. These technology decisions will influence your final design.</p>
<p>In the following sections, we will discuss some sample scenarios and the likely technology decisions that will enable you to deliver a working solution.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Use case example – Scenario 1</h1>
                </header>
            
            <article>
                
<p>In this example, the end users are based in a call center that operates 24/7 and use a Windows desktop to access a customer relationship database log. They are also using a web browser to access an intranet page. These users work set hours in a shift pattern of three shifts per day across the call center, and they all work from hot desks, utilizing whichever desk and devices are available at the time they start their shift.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Solution recommendation</h1>
                </header>
            
            <article>
                
<p>This would seem to be the ideal scenario for a Horizon View VDI desktop. However, with such a simple use case, it would make more sense to deliver these desktops using the Horizon View hosted desktop feature, which is done by using Microsoft RDS. This would allow for greater levels of consolidation and potential cost savings as you would only need to deliver enough sessions to cover one of the three shifts.</p>
<p>If they did not require any of the functionality of the underlying operating system, then you could just publish the CRM client app and a browser to allow them access to the intranet.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Use case example – Scenario 2</h1>
                </header>
            
            <article>
                
<p>There are several engineering users who currently use a laptop, both online and offline. When offline, they will be utilizing bespoke software to program machinery. Often, this work is carried out in areas of poor mobile signal and no Wi-Fi. They rarely come into the office, but do work from home once or twice a week, where they have good internet access. They also need access to a job allocation system when they have access to the internet. At the time of writing this book, this is accessed via connecting to a work VPN and running a Windows client application on their laptops. They would like to be able to adopt iPads or smartphones to access the job allocation system, but are restricted by the need to use the Windows client.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Solution recommendation</h1>
                </header>
            
            <article>
                
<p>This scenario highlights the exact type of user that does not suit a VDI desktop alone. Previously, if you had tried to make VDI work in this scenario, it would have led to a poor user experience, given the lack of connectivity. With the diversity now available in the Horizon Suite, you can use individual components to deliver a solution that can be seamless to the user and offer them a genuine productivity advantage.</p>
<p>In this scenario, you would be looking to centralize and manage laptop images using VMware Mirage. This would allow you to not only store a copy of the devices locally in the case of failure or loss, but it would also allow you to update and deliver new software when a connection to the Mirage server is available over the internet.</p>
<p>However, there is a key requirement, and that is that you need to access an online application in the form of a job allocation system. You could, of course, deliver this in the same way as it is delivered today, but you could also consider delivering this with Horizon View as a published application. This would give you the advantage of this application being accessible through a variety of devices, without the complexity of a second desktop that VDI would bring. You could also consider AirWatch by VMware to manage iPad and smartphone devices and add a layer of security.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Use case example – Scenario 3</h1>
                </header>
            
            <article>
                
<p>In this scenario, you have a marketing department with 10 users, all using desktop PCs with dual screens running Windows 7. These desktops are typically running the same apps, but each desktop also has a few individual applications that have been installed by IT for users over the years. They are now looking to start making use of several SaaS applications and services such as WebEx and would also like to have the ability to work from home.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Solution recommendation</h1>
                </header>
            
            <article>
                
<p>With the end of support for Windows 7 rapidly approaching, you are going to want to move these users to Windows 10. As such, you are going to want to check the compatibility of their applications with the new operating system version, and where possible, try and standardize the applications as much as possible without affecting the user. Where there are applications that don't support the latest operating system, you could see whether VMware ThinApp would allow them to be virtualized and run on the new operating system. As the user has no offline requirements and they actually need to be online for the SaaS apps, this would seem like a good fit for VDI, and as there is a large commonality across the desktops, you should try and see how a non-persistent <span>Linked Clone</span> pool would work for these users.</p>
<p>You could deliver these common applications by installing them in the base image and then delivering the individual bespoke applications where possible using App Volumes. Additionally, you should look at Workspace ONE for delivering a unified workspace, from where they can access all apps and desktops from a single web-based portal.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Use case example – Scenario 4</h1>
                </header>
            
            <article>
                
<p>There's a small CAD and engineering department with 10 users utilizing Autodesk AutoCAD products. Their last purchase was a year ago, and was for five workstations with high-end graphics cards for half of their users. The users must be able to install their own software, and they also keep a lot of data locally while they are working on designs.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Solution recommendation</h1>
                </header>
            
            <article>
                
<p>There are several options for this scenario. With Horizon and NVIDIA GRID graphics cards, it is likely that you would be able to offer these users a good experience using a virtual desktop machine. With AutoCAD, it is likely that the users will need access to a GPU, and so you need to look closely at the graphics requirements and match them to a vGPU profile or deliver a dedicated GPU with vDGA.</p>
<p>Since half of the workstations have recently been refreshed, you would likely recommend that these be kept in use until they are due to be replaced, but maybe use Horizon Mirage for data protection and to manage updates and software rollouts. When machines are due to be replaced, you could now consider replacing them with thin clients.</p>
<p>For the remaining users, you could consider virtual desktop machines that are persistent as they are saving a lot of local data and are installing their own apps. You could also consider non-persistent desktops and use App Volumes and the Writable Volume feature for them so that they can save data and install apps. Once you move to VDI for everyone, then it gives you the option for remote working.</p>
<p>It is recommended that this scenario is heavily tested during the POC and pilot stages so that you fully understand the type of graphics card required, along with the CPU and memory resources.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Conclusions</h1>
                </header>
            
            <article>
                
<p>The scenarios that we have given demonstrate that there is no one-size-fits-all solution that can be deployed over diverse businesses requirements. If you were to try and shoehorn some of these scenarios into a single solution, it would result in a poor user experience. With the Horizon Suite, you are not only able to have commonality across the solutions for the users and administrators, but are also able to offer a diverse range of solutions to meet the differing and diverse requirements of the end users.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Preparing for production</h1>
                </header>
            
            <article>
                
<p>You now have all of the necessary information about the current environment, business requirements, and goals, and have considered the different scenarios to meet the needs of the end users. You can now consider what the production environment will look like. This is where things start to get serious. You have tested your solution, proved the concept, piloted with a subset of your users, built a business case, and signed it off. Now is the time to start rolling out to your agreed user base.</p>
<p>This will happen in several ways, but initially, it's worth starting this slowly and gathering momentum over time. By gathering momentum in this way, you can guarantee success, and less tuning is required along the way. The big bang approach will end in a world of pain, both for the users and for you when you have so many things to consider when looking at issues.</p>
<p>In the next section, we are going to look at designing for production deployment.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Horizon View pod and block architecture</h1>
                </header>
            
            <article>
                
<p>We are going to start by discussing the core concept of a Horizon View design: <strong>the</strong> <strong>pod and block reference architecture.</strong> This provides the underpinnings to all Horizon View deployments.</p>
<p>The Horizon View pod and block architecture provide you with a reference architecture that can support up to 10,000 users. This is achieved by taking a modular approach to infrastructure deployment by creating separate Horizon View blocks that are designed to support up to 2,000 users each. These contain all the infrastructure components that are required to support and run those 2,000 virtual desktop machines.</p>
<p>The management components are also deployed as a module called the management block, as well as hosts components such as the Connection Servers and Security Servers.</p>
<p>The blocks then scale up in multiples of 2,000 until they reach the limit of 10,000 (five blocks). This configuration of five blocks is called a pod and gives you one large, unified virtual desktop environment to manage.</p>
<p>If you were to then introduce the Cloud Pod Architecture into the mix, you could scale even further<span>—</span>up to 200,000 users in total!</p>
<p>Now, you might be reading this thinking, "I only have 500 desktops to create in my environment, so this pod and block architecture does not matter to me," but I would urge you to carry on and understand the design principle, since it's core to understanding how to deploy Horizon View.</p>
<p>If you are creating a VDI solution for 500 desktops, you will still be utilizing the concepts within the pod and block architecture but on a smaller scale, as you will only be creating one pod that contains a single block. However, if you want to add DR into the mix, then this is based on this architecture. The following diagram depicts an individual Horizon View block:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/8e696297-362b-437c-9368-450341443c99.png" style=""/></div>
<p>As we mentioned previously, the management block contains all of the Horizon View infrastructure components, such as the <strong>Connection Servers</strong> and <strong>Security Servers</strong> that support the desktop blocks. This is depicted in the following diagram:</p>
<p class="mce-root"/>
<div class="CDPAlignCenter CDPAlign"><img src="assets/27585389-cd39-42a5-817a-3b879945e622.png" style=""/></div>
<p>If you are starting out with one block in your pod, you will want to ensure that you still have at least two View Connection Servers for resilience.</p>
<div class="packt_infobox">VMware does not support the configuration of blocks across a WAN link as the JMS that's utilized for communication is very susceptible to network latency. However, from Horizon 6 onward, VMware added support for the Cloud Pod Architecture, which allows you to further scale out and provide high availability across multiple sites.</div>
<p>Within each desktop block, as well as having several ESXi hosts of enough capacity to be able to accommodate the number of virtual desktop machines, there is also a vCenter Server to manage these virtual desktop machines. In addition, there are a couple of other components that are not depicted.</p>
<p>You will also need a View Composer server instance for deploying Linked Clone virtual desktop machines, along with a supporting SQL database that will host the View Composer database and the V<span>iew</span> <span>E</span>vents <span>database. This should be made highly available and should also be backed up as the Composer database keeps track of all the virtual desktop machines that are built. The final requirement is a shared storage platform that can either be exclusive to the block or shared across multiple blocks.</span></p>
<p>It's worth pointing out that, as of VMware View 5.2, it is possible to scale a block up to 10,000 users when there are multiple Connection Servers being used to overcome the 2,000-connection limit of View Connection Servers. However, this would result in a large, single point of failure in the vCenter Server itself. You should consider this risk to your business should vCenter fail and design your architecture accordingly to mitigate any failures. Would you really want to bring down 10,000 users all at once?</p>
<div class="packt_infobox">It would be recommended by VMware that, where possible, you limit your pods to 2,000 users to limit the risk of failure.</div>
<p>With a single vCenter Server, you will also be limited to the number of concurrent operations that you are able to undertake. This will be of major significance, for example, when powering up large numbers of desktops or recomposing a large number of desktop pools. If you have multiple vCenter Servers, you will be able to further increase the number of parallel operations that could happen across the vCenter Servers rather than the serial nature of a single vCenter Server.</p>
<p>Inside the pod, the Horizon View Connection Servers are configured in a cluster, and they replicate their data using Microsoft's lightweight directory services and the <strong>Java Message Service</strong> (<strong>JMS</strong>). VMware recommends a limit of seven View Connection Servers in a single pod. These are installed as one per block, plus two additional blocks for availability and/or external connectivity.</p>
<p>The following diagram shows the high-level overview of the Horizon View block and pod architecture, complete with the management block. When implemented in a production environment, the users would connect to the View Connection Servers, Security Servers, or Access Point appliance via third-party load balancers:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/b5e7a900-b07e-4e8f-8753-557b8bef0a22.png" style=""/></div>
<p>In the next section, we are going to look at how you can extend pods over multiple sites to allow for disaster recovery scenarios, and how to scale beyond the 10,000-user limit by configuring your environment with the Cloud Pod Architecture.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Cloud Pod Architecture</h1>
                </header>
            
            <article>
                
<p>In the latest Horizon 7 release, the Cloud Pod Architecture extends on the scalability and feature set from the previous version. You can now federate up to 25 pods across 10 sites, allowing you to deliver a single desktop solution for up to 200,000 users.</p>
<p>When connecting multiple pods in this manner, you will be able to entitle users across pools on both pods and sites. So, if you have currently scaled past a single pod, either for scaling on one site or to deliver a Horizon View environment on multiple sites, you can now administer users through a global user entitlement layer. You can also deliver DR to your virtual desktops, in the event of failure, through the global user entitlement layer.</p>
<p>You can also configure the scope to set whether View shows a user's resources based only being local to them, on the same site but across pods, or in all pods across both sites. The following diagram depicts the Cloud Pod Architecture:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/146dfd01-d23b-41de-857f-dd94d6b4b6e3.png"/></div>
<p>Microsoft Active Directory Lightweight Service and the new <strong>View Interpod API</strong> (<strong>VIPA</strong>) are used for interpod communications. VIPA is enabled when you enable the Cloud Pod Architecture from the command line on the View Connection Servers and is used when virtual desktops are launched to send health information and to find existing desktops.</p>
<p>By default, when a user connects to Horizon View, and they have a global entitlement, there will be a preference applied by the global entitlement to utilize virtual desktops at the local site rather than across a secondary site where possible. However, this is fully customizable by the administrator when creating the global entitlement.</p>
<p>With the scope configuration options, you can specify where the View Connection Server looks for virtual desktops or hosted applications to satisfy a request from the global entitlement. You can configure the following:</p>
<ul>
<li><strong>All sites</strong>: View will look for virtual desktops or hosted applications on any pod within the federation</li>
<li><strong>Within a site</strong>: View will look for virtual desktops or hosted applications that are only on pods that are in the same site as the pod that the user is connected to</li>
<li><strong>Within a pod</strong>: View will look for virtual desktops or hosted applications that are only in the pod that the user is connected to</li>
</ul>
<p>In addition to these scopes, you can configure an option called <strong>home site.</strong> This allows you to configure a site that acts as the end user's default site and when the user logs in, the View Connection Server will look for virtual desktops in that user's home site.</p>
<p>Along with configuring the Cloud Pod Architecture, you will need to utilize third-party load balancing technologies to allow the benefits of this technology to be seamless to the end users. However, this gives us a way of unifying our multiple View deployments that would have been separate entities previously. We will look at how this is configured in later chapters.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">vSphere design for Horizon View</h1>
                </header>
            
            <article>
                
<p>Now that we have looked at some of the reference architectures, it's time to turn our attention to some of the components that are part of that architecture, namely our vSphere virtualization platform, and look at some of the high-level considerations for your design.</p>
<p>In this book, we aren't going into the intricacies of how to install and configure ESXi hosts. However, we will briefly discuss the recommendations on how you should configure vCenter Server, as well as the hosts and clusters for your Horizon environment.</p>
<p>It is technically possible to run your Horizon View and virtual server environments from one set of infrastructures, with one vCenter Server, and one or more ESXi clusters. By doing this, you could create several points of contention and a lot of difficulty during the time of upgrades.</p>
<p>As we discussed previously, there are two infrastructure areas when it comes to Horizon View: the management block that runs the vCenter Server, View Composers, and View Connection Servers, and so on, and the second one, which runs the virtual desktops themselves. The recommendation is that these two components are separated physically on different ESXi hosts and clusters, minimizing any risk of there being performance issues with the server components during heavy use periods or large desktop provisioning processes. From a licensing perspective, this is covered, as it is included with Horizon is the vSphere for desktop entitlement, which allows you to deploy as many ESXi hosts and vCenter Servers as you need to support your environment.</p>
<p>You should also run the Horizon View components on a different vCenter Server from your production vSphere environment. Separating the Horizon View components onto a separate vCenter Server will mean fewer clashes of priorities and prerequisites when it comes to upgrading either environment.</p>
<p>You should also run the Horizon View components on a different vCenter Server from your production vSphere environment. Separating the Horizon View components onto a separate vCenter Server will mean less clashes of priorities and prerequisites when it comes to upgrading either environment. The following diagram shows an example of how your virtual environments could be designed:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/da3f9eb4-5f4c-49b9-b6dc-57104a6b49dd.png" style=""/></div>
<p>In the following section, we are going to look at the maximum values that can be configured.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Configuration maximums</h1>
                </header>
            
            <article>
                
<p>When building any VDI infrastructure, you very quickly and easily hit the configuration maximums that have been set by the product vendors. When it comes to vSphere and vCenter Server, there are a few maximums that you should be aware of.</p>
<div class="packt_infobox">To check out the latest configuration maximums for VMware vSphere, see the following link: <a href="https://configmax.vmware.com/guest">https://configmax.vmware.com/guest</a>.</div>
<p>You should also keep in mind that the Horizon View has specific maximums. We will discuss those later in this chapter. Don't forget that these maximums are not goals to try and hit, but maximum limits. When designing your architecture, you should also keep in mind the risk of losing an individual component such as a vCenter Server or a View Connection Server.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">ESXi host servers</h1>
                </header>
            
            <article>
                
<p>In this section, we are going to cover some recommendations on the sizing and quantities of host servers that might be required to host and support your infrastructure.</p>
<p><span>As with any virtual infrastructure, you need to ensure that redundancy is built-in as standard. This means ensuring that your chosen servers have redundant power supplies,</span> RAID hard disks, or mirrored SD cards for ESXi, and multiple network cards for network failovers in the case of a card or switch failure.</p>
<p>You also need to look at how many hosts are likely to be required to support your environment, and then add the relative amount of hosts to allow for the N+ capacity that you require. In most environments, this will be N+1, meaning that you will have the number of hosts you require to run your virtual desktops, plus one additional host to allow for a host failure. This ensures that any outage does not impact your end users.</p>
<div class="packt_infobox"><span>Remember that you are effectively going to be</span> sizing <span>for two different environment profiles; one will host the management block infrastructure, and the other will host the virtual desktop machines.</span></div>
<p>In the next section, we are going to cover some of the generic points that you should consider for your design.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">CPU and memory requirements for ESXi</h1>
                </header>
            
            <article>
                
<p>The next thing we are going to look at is CPU and memory configurations and recommendations.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Overcommitting CPU and memory resources</h1>
                </header>
            
            <article>
                
<p>As a rule of thumb, never overcommit memory in a VDI environment. This can have many negative knock-on effects if memory is not granted when required, which will ultimately affect the end user experience.</p>
<p>When it comes to CPUs, while it would be nice to also not to have an overcommitment, this would simply not be affordable. CPU overcommitment, if done carefully and not pushed too far, can usually be allowed with little to no effect on the end users. However, the question is, how far is not too far? This will generally depend on the type of workload you are running within your environment. If you look at various resources on the internet, you will find different answers to this question, with some claiming figures of more than 10 <strong>virtual CPUs</strong> (<strong>vCPUs</strong>) per physical core. The only true way to find out what is going to be acceptable in your environment is by reviewing the CPU Ready figure; you can review this metric via vCenter, ESXTOP, or similar tools. When reviewing the CPU Ready figures, you should initially be looking to ensure that you are keeping CPU Ready below 5% per vCPU for the desktops in your environment. Your environment might be able to accept CPU Ready higher than 5%, but this should only be after testing during your POC and pilot stages. Generally, if CPU Ready is as high as 10% per vCPU, the environment is going to struggle enough so that it affects user experience considerably.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">CPU and memory sizing</h1>
                </header>
            
            <article>
                
<p>The number of hosts that are required for your Horizon View infrastructure is usually dictated by the number of desktops required, the amount of CPU and RAM these desktops require, what overcommit ratio you can allow for the CPU within your infrastructure, and how much CPU and memory you can physically fit into your chosen host servers.</p>
<p>Taking that into consideration, you should be looking to include the amount of memory and CPU cores across the infrastructure that allows you to balance these in a cost-effective way without too much wastage.</p>
<p>When selecting your host server platform, you should also consider what effect it would have on the business if that one host was to fail. As such, sometimes, you might consider hosts with two physical CPUs to be a better design decision than having four physical CPUs, especially as the number of cores per CPU continues to increase.</p>
<p>This may well become a financial consideration as well as a technical one, and introduces the scale-up or scale-out argument of should you have fewer, larger servers, or spread the load across more, lower spec servers.</p>
<p>Within your calculations, ensure that you are considering the overheads that the ESXi hypervisor requires to be able to run your virtual machines, as well as memory to be dedicated as graphics memory to virtual machines if required.</p>
<p>The following table details some typical overhead values (in MB) that are required per VM:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/7d2bf389-d22e-41dc-86ea-c68bff69fca6.png" style=""/></div>
<p>Next, we will look at the networking considerations.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Networking</h1>
                </header>
            
            <article>
                
<p>There are generally two considerations for networking in your ESXi hosts, which is whether to use 1 Gbps or 10 Gbps NICs. You could always consider a 40-Gbps network as well. No matter what, you will always want to ensure that you have at least two multiport network cards to separate your traffic, which will allow the resilient network design that you require. Regarding the speed of the network that you require, this will depend on the VM LAN traffic within your infrastructure, and that completely depends on your use case.</p>
<p>If you are streaming a lot of HD media into your VDI desktops, then 10 or 40 Gbps may well be required. Whatever the case, ensure that you really understand the network requirements, as getting this wrong will result in a poor end user experience.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Graphics</h1>
                </header>
            
            <article>
                
<p>A lot of information has already been covered regarding the hardware and software graphics offload and accelerating options in <a href="5d942e5b-dda5-4e5a-8278-62a64210aeef.xhtml" target="_blank">Chapter 2</a>, <em><span>Understanding Horizon 7 Architecture and Components</span>.</em></p>
<p>The requirements for graphics in your environment should be carefully considered and tested during the POC and pilot stages of your project. You should consider all of the elements we mentioned in the previous chapter, and then decide what is required with regard to PCI cards in your ESXi hosts. The requirement for PCI cards for graphics acceleration or offloading will affect the hardware you choose for your ESXi hosts due to the limitations of some of these cards with regard to power and cooling, along with the number of PCIe slots available.</p>
<div class="packt_infobox"><span>NVIDIA</span> publishes a list of supported servers, with the number of cards that can be configured into specific servers. This list can be found by clicking on the following link: <a href="http://www.nvidia.com/object/grid-partners.html">http://www.nvidia.com/object/grid-partners.html</a>. <a href="http://www.nvidia.com/object/grid-partners.html"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Storage</h1>
                </header>
            
            <article>
                
<p>We could probably write a whole book on storage considerations, designs, and options regarding your VDI environment. Along with the network, storage is probably among the most important areas to get right. The most obvious reason is that you don't want to end up with insufficient storage for your planned rollout, and secondly, failure to specify a storage solution that is going to meet your performance requirements will leave you with unhappy users and a failed project. This is particularly key when deploying <span>Linked Clone</span> desktops, as we will now discuss.</p>
<p>When it comes to storage, we need to look at two aspects: performance and capacity.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Storage capacity</h1>
                </header>
            
            <article>
                
<p>Your first consideration will be how much storage space you need for your Horizon View environment. You will need to consider where the relative elements of your virtual infrastructure are to be located. The first and easy bit is going to be totalling the required space for any server components. Often, the server components will live on the same storage device as the rest of your virtual infrastructure, and the desktops will live on a dedicated storage device. However, this is not compulsory and will depend on the type of storage you are utilizing and the levels of separation you desire. You will then need to understand the required storage for your desktops based upon the technologies being used to deploy the desktops, such as Linked Clones, Full Clones, or Instant Clones, not forgetting to include persistent disks for user data if you plan on using them.</p>
<p>An important point to remember is to think beyond just the virtual desktops. If you are planning on delivering apps with App Volumes, then you will also need space to store App Stacks.</p>
<p>With Linked Clones, you need to understand the growth of the <span>Linked Clone</span> between the refresh and recompose operations. The following diagram gives an example of some areas for consideration regarding storage for a typical desktop pool that's utilizing Linked Clones and persistent disks:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/0f78a924-094d-432e-9505-292d413299ce.png" style=""/></div>
<p>The replica from which a <span>Linked Clone</span> originates needs to be located on fast storage, either local to the host server or via a SAN. To enable this in Horizon View, you can choose the location of where the replica should live, and one of the recommendations is that the replica sits on fast storage, such as local SSD, for example.</p>
<p>The recommendation is that during your POC and pilot stages, you collect this type of storage usage information. Once you have this information, you will be able to use a spreadsheet to create a model to predict storage utilization, and then you can grow your environment. The following table depicts a sample Excel spreadsheet outlining the storage requirement across three desktop pools:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/51cc6d05-492e-4f41-8f50-fceb6e1c9e73.png"/></div>
<p>During the POC, we have been able to understand the capacity that's required per desktop for the <span>Linked Clone</span>s. This is a key component for understanding the overall capacity required for the solution moving forward.</p>
<p>This now leads to the other part of the storage story, that is, storage performance.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Storage performance</h1>
                </header>
            
            <article>
                
<p>Once you have worked out how much capacity you require for your Horizon View environment, you can start considering your performance needs. As always, it is recommended that you understand your performance requirements during the POC and pilot stages and use this to size your storage. When examining your virtual environment, you are looking to keep the read and write latency as low as possible to guarantee a good user experience. The amount of latency that's acceptable will depend greatly on the workload of your users and the tolerances of the applications they are using. However, keeping your average latency as low as 25 ms will often deliver a good user experience for your users.</p>
<p>The question is, how do you ensure that you can deliver this type of performance? The first thing to look at would be to deploy some form of storage acceleration technology to drive the IOPS requirements. Horizon View also has its own integrated solution called the <strong>View Storage Accelerator</strong> (<strong>VSA</strong>) or <strong>Content-Based Read Cache</strong> (<strong>CBRC</strong>). This feature allows you to allocate up to 2 GB of memory from the underlying ESXi host server, which can be used as a cache for the most commonly read blocks. As we are talking about booting up desktop operating systems, the same blocks are required, and since these can be retrieved from memory, the process is accelerated.</p>
<div class="packt_infobox">Remember that CBRC is not required when using Instant Clones.</div>
<p>Another solution is to use <strong>View Composer Array Integration</strong> (<strong>VCAI</strong>), which allows built <span>Linked Clone</span><span>s to be offloaded to the storage array and its native snapshot mechanism, rather than having to take CPU cycles from the host server.</span></p>
<p> </p>
<div class="packt_infobox">Instant Clones does not support VCAI.</div>
<p class="mce-root">There are also several other third-party solutions that resolve the storage performance bottleneck and increase the overall storage I/O. These are software-defined solutions such as ThinScale ThinIO, or hardware-based solutions such as deploying an all-flash array. So, the question is, how many IOPS do you need?</p>
<p>As with the question of how many virtual desktop machines can you configure per core, the answer to the IOPS question is also "it depends!". If you read some of the guides and white papers on the subject, you will probably see something like Windows 7 needing 20 to 25 IOPS. That might be correct for a steady state, but what about for peak disk activity? The only way you will know the answer to how many IOPS you need is by analyzing your assessment report data.</p>
<p>The following graph depicts a sample storage environment, which shows a sample workload as the desktops are booted. Users log in and then continue to use the desktops. On the vertical axis, you can see the IOPS, and on the horizontal axis, you can see time.</p>
<p class="mce-root"/>
<p>As you can see, the boot storm is heavily read-intensive, with the login storm and steady state being heavily write-intensive. You need to size accordingly and based on your assessment data:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/cfb9f9e2-efb4-4ba4-b5b8-c25a88373371.png"/></div>
<p>While the desktop may well drive 25 IOPS, what about any applications running on that desktop? How many IOPS will the application require? You don't want to find out the answer to this after you have deployed your solution.</p>
<p>There is also the debate around the split of IOPS between read and write. It is often quoted that the split is 80:20, with 80 writes and 20 reads, but this again will be dependent on your environment and the actual answer will be in your assessment data. It may well transpire that you have 70:30 or even 60:40.</p>
<p>As the IOPS requirements are a key part to the sizing exercise and can have a hit on the virtual desktop machine's performance, you need to get this right, so let's take a closer look at some actual sizing calculations.</p>
<p>One thing that gets forgotten when sizing is the RAID penalty or IOPS penalty when writing to the disks. This means that, for every read operation, there will be multiple write operations occurring, depending on the RAID level being used.</p>
<p>For our example, let's take RAID 5, which has a write penalty of 4, and you need to deliver 200 IOPS with a 60:40 read/write ratio. To calculate this, you can use the following formula:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/1e609379-a41e-4f1e-84fd-0065612b9888.png" style=""/></div>
<p>Going back to our example, the calculation would look something like the following:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/6959fb99-8383-4aa8-9af8-afb71bed20c0.png" style=""/></div>
<p>In this example, you would need to configure a RAID 5 array that could deliver the 600 IOPS that is required.</p>
<p>Once you understand what performance and capacity you require for your VDI environment, you can browse the market to find a suitable solution that will work for you.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Horizon View design specifics</h1>
                </header>
            
            <article>
                
<p>Now that we have looked at some of the more general elements of your infrastructure, and the vSphere platform that is going to support your environment, it's now time to turn your attention to the Horizon View-specific components of the infrastructure.</p>
<p>Let's start by looking at the requirements of those components before looking at sizing the actual VDI desktops themselves.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Horizon View Connection Server</h1>
                </header>
            
            <article>
                
<p>The View Connection Server is a Windows Server with Horizon View installed as an application. In this instance, the application would be that of the View Connection Server role. This server would be hosted as a virtual machine on the management block, and has a recommended configuration, as shown in the following table:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/679fe476-c2c6-44ee-a18b-d1bdf7f2bd57.png"/></div>
<p>As we have touched on previously, if this is purely for a POC or pilot with a limited number of users, you can lower the specification to maybe two vCPUs and 4 GB of memory. You can't resize this afterwards, which is the reason why you should size appropriately should you want to move straight into production without reinstalling.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Horizon View Replica Server</h1>
                </header>
            
            <article>
                
<p>The View Replica Server is essentially the same as the View Connection Server, as it acts as a backup to the main Connection Server. As such, it should be sized in the same way as the View Connection Server.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Horizon View Security Server</h1>
                </header>
            
            <article>
                
<p>As with the Replica Server, the Security Server is just another role of the Connection Server, meaning that it should be sized in the same way as these components.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Horizon View Enrolment Server</h1>
                </header>
            
            <article>
                
<p>Again, the Enrolment Server is another role of the Connection Server, meaning that it should be sized the same as these components.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Horizon View Composer</h1>
                </header>
            
            <article>
                
<p>The View Composer is slightly different from the Connection Server roles. It can either be installed on the same server that vCenter Server is running on or as a standalone server. You would typically install it as standalone server for performance or if you are using the vCenter Server Appliance. The configuration recommendations for View Composer are detailed in the following table:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/539249b7-d57e-482c-999a-8a749910cdd0.png"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">vCenter Servers</h1>
                </header>
            
            <article>
                
<p>With the latest version of Horizon View, you can manage all 10,000 users with a single vCenter Server. However, that is probably not the best way of doing it, as you have no failover should your vCenter Server fail. The configuration recommendations for vCenter Server are detailed in the following table:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/0a39fc75-253b-4f24-a061-8df75dbc26c6.png"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">VMware Access Point</h1>
                </header>
            
            <article>
                
<p>The VMware Access Point is a Linux-based appliance and not a Windows application. Therefore, it gets deployed via the vCenter Server. As an appliance, the configuration is fixed, and the recommendation is not to change it. You will need enough free resources to host it, as detailed in the following table:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/0d584913-a97c-4fae-a0fc-1d61973d0c91.png" style=""/></div>
<p>In the next section, we will look at the configuration maximums for the Horizon View components.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Configuration maximums</h1>
                </header>
            
            <article>
                
<p>Alongside the configuration maximums we listed earlier in this chapter for vSphere, you need to be aware of the specific configuration maximums for Horizon View. We have listed some of the more important ones to consider in the following table:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/c5a1eb0b-ae6c-4228-97a3-9c2e8ba6bc37.png"/></div>
<p>In the following sections, we'll look at the other supporting infrastructures that are required to host the virtual desktop machines, starting with the networking requirements.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Networking</h1>
                </header>
            
            <article>
                
<p>Network optimization is important for giving the users a great experience, as this is how their virtual desktop machine is going to be delivered. You need to consider a couple of different factors when sizing the network.</p>
<p>First, you need to look back at your different use cases, paying close attention to where your end users will be connecting from, and whether they are connecting over a LAN, WAN, or the internet. Although there is nothing you can do from a network perspective for internet users, you can configure policies that limit some of the features and capabilities that could potentially consume more bandwidth.</p>
<p>On the subject of bandwidth, let's take a closer look at the things you need to think about.</p>
<p>When it comes to bandwidth, the question of how much bandwidth is required often pops up in conversation, and again the answer depends on what your end users are doing that, in turn, will determine how much they would consume. This is something that the assessment data will tell you, but VMware has published some guideline figures, which are shown in the following table:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/9d298925-5c4c-412b-90ca-93f25430cee5.png"/></div>
<p>The figures in the previous table refer to the bandwidth requirements overall, but depending on the bandwidth that's available, this will also dictate the audio bandwidth and ultimately the audio quality. This is outlined in the following table:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/6d2e5dc9-2b0d-4f64-b1b7-e73bf5b9cb39.png"/></div>
<p>Note that if you can't provide at least the minimum bandwidth requirements for audio, it will be disabled for that session.</p>
<p>You can, however, make configuration changes to enhance the end user's experience. The PCoIP protocol is completely configurable via the use of a Windows group policy so that you can tune the user experience accordingly. We will cover more on how to tune and optimize the virtual desktop machines in <a href="8ebc54c4-3812-46fe-9534-fe38b78804a9.xhtml" target="_blank">Chapter 10</a>, <em>Fine-Tuning the End User Experience</em>.</p>
<p>There are two other considerations when looking at networking for your View. The first is the latency of the connection.</p>
<p>We previously discussed bandwidth and what is required for the different use cases, but latency can also have a big impact on the end user experience. Typically, the maximum tolerance is anything between 250 milliseconds and 300 milliseconds for acceptable performance. Anything above this may well work, but could result in a degraded user experience, but this would depend on the use case. For example, a basic office worker may work fine when compared with a heavy user. Again, this is information you would determine from your pilot with the end users.</p>
<p>The second is load balancing between Connection Servers, which we will discuss in the next section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Load balancing</h1>
                </header>
            
            <article>
                
<p>Another requirement for Horizon View is the need to use load balancers between View Connection Servers, both for internal and external connections. This not only allows you to scale your solution but also offers high availability, should there be a failure.</p>
<p>It should be noted that there is no load balancer functionality included within Horizon View. As such, you will require third-party load balancers. It is possible to make use of Microsoft <strong>Network Load Balancing</strong> (<strong>NLB</strong>) on small scale and <span>POC</span> deployments, but as your solution starts moving on from POC to the pilot stage, you should consider the need for dedicated physical or virtual load balancers.</p>
<p>When selecting a load balancer, you need to ensure that it is able to offer session persistence. This ensures that the connected user is already directed to the same View Connection Server or View Security Server during their session. You should also ensure that the load balancing solution that is implemented is highly available. The following diagram shows how a typical load balancing solution for Horizon View could be configured:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/a3cfb32d-880a-46c4-aaa1-33a3578e515f.png" style=""/></div>
<p>As you can see, there are multiple VMware Horizon Connection Servers being configured for internal and external connections. The internal Connection Servers are load balanced behind an HA pair of load balancers. Externally, there are also two View Connection Servers, each paired with a dedicated View Security Server. The View Security Servers are then load balanced using a dedicated HA pair of load balancers. There's also the optional Access Point that you could deploy in place of the View Security Servers.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Remote Desktop Session Host (RDSH) design considerations</h1>
                </header>
            
            <article>
                
<p>Since Horizon View 6, VMware has supported Microsoft RDS as a means of delivering hosted desktop sessions rather than full virtual desktop machines. Hosted desktops have full support for PCoIP, whereas previously, while session-based desktops had been supported, they were only supported using RDP as the delivery protocol.</p>
<p>Along with the support for RDS as a desktop source, you also use RDS servers to present published applications to your users. This is referred to as Horizon View Hosted Applications. We will cover hosted desktop sessions and hosted applications in <a href="0eba1087-348f-4f36-a0af-3a4d8b80f7c9.xhtml" target="_blank"/><a href="0eba1087-348f-4f36-a0af-3a4d8b80f7c9.xhtml" target="_blank">Chapter 11</a>, <em>Delivering Published Apps with Horizon 7</em>, and <a href="https://www.packtpub.com/sites/default/files/downloads/Delivering_Published_Desktops_with_Horizon_7.pdf">Chapter 18</a>, <em>Delivering Published Desktops with Horizon 7</em>. In those chapters, we will look at installing and configuring these features, but for now, let's concentrate on the design considerations for RDS-based environments.</p>
<p>Horizon View uses the concept of farms to place hosts that provide a common set of applications or desktops for users. When you are creating applications or desktop pools, you will point them at the specific farms that you have created. A farm might contain anywhere between 1 and 200 RDS hosts.</p>
<p>With Horizon View, the RDS servers are able to be either physical or virtual. An important point to consider when designing your RDS servers in a virtual environment is to ensure that you do not over commit virtual CPUs to the underlying physical CPUs. In the following diagram, we will try and illustrate why:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/9f1a0ae4-e758-4a9f-8a79-c4c05cf2858c.png"/></div>
<p>With VDI, you can achieve good levels of consolidation by over-allocating virtual CPUs to physical cores. With RDS, you can achieve good levels of consolidation by over-allocating users to physical or virtual cores. If you over-allocate virtual CPUs to physical CPUs, it will ultimately result in poor performance for your end users. As ever, you don't want to place memory over-allocation into the design as standard.</p>
<p>If you are utilizing RDS for published applications, you need to consider the design regarding application deployment. Will all of your applications be deployed on one server farm, or are there going to be separate server farms for different applications? You need to consider resources such as CPU, memory, and disk, which are required for each of your RDS servers, depending on their workload.</p>
<p>Consideration regarding how many PCoIP or Blast Extreme connections are required based on your application and desktop design should also be made. In the following diagram, you can see that the end user has a View virtual desktop and is also running an application from <strong>Server Farm A</strong> and another application from <strong>Server Farm B</strong>. In total, this user will be utilizing three connections<span>—</span>one for the View virtual desktop, one for the application from <strong>Server Farm A</strong>, and one for the application from <strong>Server Farm B</strong>. As a result, you will need to be sure that you understand the maximum connections for one View Connection Server and decide how you are going to scale the solution to meet your design needs:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/5fd8ffba-cf7a-4ad6-b542-902f84cb75de.png" style=""/></div>
<p>With RDS, the Connection Server supports a maximum of 150 sessions, based on a configuration of 4 vCPUs and 64 GB of memory.</p>
<p>Please note that you can also use Horizon Workspace ONE to deliver published applications to virtual or physical desktops. Your VDI or RDS desktops could be in a separate View environment to that of your hosted applications.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Supporting infrastructure design</h1>
                </header>
            
            <article>
                
<p><span>Outside of the virtual infrastructure components—and by this we mean the VMware specific components—there are several other components or third-party tools and services that Horizon View is reliant on, which we will discuss in the coming sections.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Database requirements</h1>
                </header>
            
            <article>
                
<p>Microsoft SQL Server or an Oracle database are key components for View Composer and the View Events database, as well as vCenter. Without the View Composer database being available, View is unable to undertake any provisioning or recompose operations. As such, you might wish to consider the availability of the database server and split the environment up as per the block architecture so that you can use multiple database servers at one per block. You should also ensure that you have regular and up-to-date backups of the View Composer database in case of loss or corruption.</p>
<div class="packt_infobox">Horizon View supports several different Microsoft SQL and Oracle databases. The latest support matrix can be found at the following link: <a href="https://bit.ly/2QyH362">https://bit.ly/2QyH362</a>.<a href="https://bit.ly/2QyH362"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">File servers</h1>
                </header>
            
            <article>
                
<p>File servers are often overlooked when it comes to creating a Horizon View environment, but often play a critical role in the overall functionality of the VDI environment.</p>
<p>For example, they will be storing things like ThinApp packages, user profiles, or application layers from App Volumes. First, size your file server for performance, ensure that your file server has enough RAM and CPU to meet user demands, particularly at peak times, and then continue to monitor utilization, and ensure that you add extra capacity as and when it is required.</p>
<p>It's not just about CPU and memory performance<span>—</span>the hard disk performance associated with your file server will also be critical.</p>
<p>With your applications and personas being saved on the file servers, we need to consider the effect of these resources being unavailable when the users are trying to use their desktops. In the case of the layered applications, App Volumes app layers may not attach or might fail midway through the user using an application if the file server goes offline. With the end user's persona stored on a file server, this could have a severe impact on the users accessing their data, or there may be unconsidered effects, such as the application data being unable to load or reduced performance of the desktop.</p>
<p>As such, the availability of file servers needs to be a serious consideration if you plan on using a shared storage device that supports CIFS shares. You could consider storing these files on this device; otherwise, a clustered file server or a DFS share should probably be considered to ensure availability. Of course, these decisions need to be taken alongside the business needs. If your View environment is going to be small initially, and your file server is stored on a virtual environment, the built-in HA functionality might be enough for your requirements.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">IP addressing</h1>
                </header>
            
            <article>
                
<p>Often overlooked in a VDI rollout are IP addressing, subnets, and DHCP requirements. Quite often, in a large company, you are going to use multiple subnets across the business as you separate areas with VLANs. When you slowly start scaling your deployment, it can sometimes be easy to forget that your subnets or DHCP scopes won't be large enough until it is too late, and you run out of IP addresses.</p>
<p>You should consider how you are going to configure your VDI desktops with IP schemes. By default, through the View Administrator, it is only possible to assign each pool with a single network tag. As such, when the desktops are rolled out, they will use the same network tag that the golden image is configured to use. However, it is possible to configure multiple network tags to pools via the View PowerCLI.</p>
<div class="packt_infobox">Horizon 7 supports IPv6, but be aware that when you configure the Horizon View infrastructure components, such as the Connection Server, you must also use either IPv4 or IPv6 and not a mixed mode. Mixing IP versions across the Horizon View components is not supported.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Antivirus</h1>
                </header>
            
            <article>
                
<p><span>Antivirus can often be the nemesis of a good VDI design. If the antivirus solution is not configured in a way that is understanding of the shared nature of the VDI solution, it can often be the cause of large performance issues across the environment.</span></p>
<p>The first consideration with any optimized desktop solution is to ensure that you optimize your antivirus solution to be considerate to the use cases of the users and the applications that they are using. With a VDI solution, you often want to deliver just the right amount of resources to ensure that it meets the users' needs while not over-delivering resources that can have a knock-on effect on the overall cost of the solution. We have personally seen in VDI environments with misconfigured antivirus that double the CPU, RAM, and disk resources are required. Clearly, this could have a massive effect on the cost of the overall solution and, ultimately, your ability to deliver the project on a budget.</p>
<p>Secondly, full desktop scans need to be considered. You need to consider whether full scans are required at all on the desktops if they are being refreshed daily. If full AV scans are a defined requirement, ensure that they are run out of hours and staggered across the desktops. Simultaneously starting scans across all the desktops will affect the RAM, CPU, and the IOPS being consumed, and potentially cause knock-on effects across the environment.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Active Directory Group Policy</h1>
                </header>
            
            <article>
                
<p>As ever, group policy can have a major effect on your desktops, irrespective of whether they are physical or virtual. When designing any EUC solution, there are three main areas you should consider when designing your group policies, namely functionality, lockdown, and performance.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Functionality</h1>
                </header>
            
            <article>
                
<p>Group policy can be your best friend, particularly when implementing non-persistent desktops. Correctly configured, you should be looking to use group policy to configure first-use settings for your desktops and Microsoft applications, alongside the obvious login scripts and mapped drives.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Lockdown</h1>
                </header>
            
            <article>
                
<p>Using group policy to lock down virtual desktops can offer an advantage in a VDI environment, particularly for non-persistent desktops where you don't want users saving documents in areas that won't be redirected, or customizations that probably won't be saved, but there can be downsides. Our advice would be, in a new VDI environment, try not to use the implementation of your new VDI infrastructure as an opportunity to introduce new strict lockdowns while implementing VDI itself. Often, when these kinds of stringent lockdowns are implemented at the same time as VDI, the VDI solution will be blamed for any disruptions or reduction in user experience that's caused by the new lockdowns.</p>
<p>If a new stringent lockdown policy is required, either try to implement it on the physical desktops prior to the migration to VDI or implement the VDI solution first, before introducing the new lockdowns.</p>
<p>You will also find that it can be difficult to troubleshoot where a problem may reside by introducing too many changes at once, particularly when it comes to what users can and can't access. It may be one policy too far.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Performance and management</h1>
                </header>
            
            <article>
                
<p>We aren't going to use this book to write about the A to Z of group policy configuration for optimal performance. There are already several resources on the internet and multiple topics on this subject. However, we recommend that you keep on top of your group policies, ensuring that old unnecessary policies are removed wherever possible. Use a functional design, where you group together GPOs into functional groups but don't take them to the nth degree by creating a GPO per setting. This will ensure ease of management and will reduce performance effects when changes are made.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Key Management Server (KMS)</h1>
                </header>
            
            <article>
                
<p>To ensure seamless license activation between recompose operations of Windows and Office, a Microsoft KMS is imperative to your VDI design. Your desktop will find the KMS via DNS or via manual assignment, which you can preconfigure into the base image and will then be assigned the relevant keys to gain activation.</p>
<p>If you wish to activate Microsoft Office products using the KMS server, you also need to install the Microsoft Office 2013 Volume License Pack on your KMS server. This can be downloaded from the Microsoft Download Center.</p>
<p>Microsoft KMS is quickly and easily configured as a role within Windows Server and earlier versions of Windows. As part of the configuration, you will need your KMS license key from Microsoft. This key will be used during configuration, and your KMS will need to be activated by Microsoft over the web or via the phone. Once the role has been configured, you are ready to start rolling out and activating your desktops with KMS. However, you should be aware that there is a threshold for activations prior to KMS going live of 25 client machines. If you want to give this a try, ensure that your first pool is larger than 25 machines. Once the threshold has been reached, you will be able to activate single machines one at a time, if required.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Printing</h1>
                </header>
            
            <article>
                
<p>Printing is often a tricky subject, and working with any VDI or RDS can often be even more complicated. Included with Horizon View is the ThinPrint technology that allows several configurations when it comes to printing from your desktop pools. We covered ThinPrint in some detail in <a href="5d942e5b-dda5-4e5a-8278-62a64210aeef.xhtml" target="_blank">Chapter 2</a>, <em>Understanding Horizon 7 Architecture and Components</em>.</p>
<p>However, often, the simplest solution across the board is to implement a follow-me printing solution. With a solution such as PaperCut, users print to a virtual follow-me printer. They are then able to release the document to the printer from a localized <strong>Release Station</strong> or compatible printer, which can be explained by the following diagram:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/c7fdf589-2b91-41ac-b756-6b650adb7b0c.png" style=""/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Thin clients and other endpoint devices</h1>
                </header>
            
            <article>
                
<p>We will discuss thin clients and how end users will connect to their VDI desktop in <a href="e1944fcc-6ae9-4db7-b51b-db75e37e01ab.xhtml" target="_blank">Chapter 12</a>, <em>Horizon Client Options</em>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Desktop design considerations</h1>
                </header>
            
            <article>
                
<p>You might think that once you have spent your time considering and designing all of the elements we mentioned earlier that the hard work is over. Realistically, it has only just begun. Your VDI solution, without the desktops, is just a virtual infrastructure, and the design and functionality of the desktops are critical to a successful implementation. There are a great number of choices we need to make around the design for the desktops within Horizon View. This will be affected by the way the users need to use the desktops and is likely to have a knock-on effect on the way you are going to manage the desktops and the resources the desktops require.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Pool design</h1>
                </header>
            
            <article>
                
<p>You will want to design your desktop pools based on the similarities between the desktops, which will ultimately allow you to group desktops together. You should use information that's been collected by the desktop assessment and other sources to start designing how your desktop pools are going to look. While analyzing this data, you are going to look for similarities between the applications and use cases, and make decisions based on information regarding how you will design these pools. To make management and maintenance easier, you should create the smallest number of pools possible, but you also won't want to take this to the nth degree and have thousands of desktops in a pool, as trying to recompose ridiculously large pools with large numbers of virtual desktop machines could be difficult and will likely affect performance. As you can see, it is going to be a very careful balancing act to get the pool design correct.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Sizing the virtual desktop machines</h1>
                </header>
            
            <article>
                
<p>The following table gives a list of some of the recommendations for base desktop sizing, which have been collected from several different VMware documents. Obviously, the resources that are required for the desktops will be greatly affected by the applications being used within the desktops as well:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/c90192f1-0118-4764-b024-7e3d0108a7e5.png"/></div>
<p>In this chapter, we have already covered some of the high-level host server considerations, but now that you have an idea of what desktop resources you need to deploy, you can go to the next level of detail and look at the clock speeds of the CPUs and determine how many hosts you will need, along with the RAM requirements.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Sizing the host server's CPU requirements to run virtual desktops</h1>
                </header>
            
            <article>
                
<p>One of the most frequently asked questions when sizing the servers that are hosting the virtual desktop machines is, how many can I fit on each host server, or how many virtual desktops per core? Well, the answer is, it depends!</p>
<p>First, it depends on the CPU resources that your desktops are going to consume, and the answer to that question will only come from your assessment data.</p>
<p>Second, and more obviously, it will depend on the CPU you configure in the host servers. This is usually chosen on price/performance, as there is usually a CPU that makes more financial sense and the best cost-per-desktop model.</p>
<p>For this section, as we don't have any actual assessment data to work from, we will use some assumptions on the types of users and CPU requirements for each type of user, just to give you an example to work with. The users are then grouped into light usage, medium usage, and heavy usage. We will base our calculations on an industry-standard, rack-mounted server that's been configured with two Intel Xeon E5-2660 v3 CPUs that run at 2.6 GHz and have 10 cores per CPU, giving us a total of 20 cores per host server.</p>
<p>In the example calculations, you will also notice that we have subtracted two of the cores from the total available cores on the host server. The reason for this is that the hypervisor layer (ESXi) also needs CPU resources to run.</p>
<p>The following sections classify a typical user profile and then give an indication of the per-core ratio and how it was calculated.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Light user</h1>
                </header>
            
            <article>
                
<p>Typical utilization is around 300 MHz of CPU resource. It's also worth adding some additional resources to cover any peaks in workload and other tasks such as sounds and USB devices. For this example, we will add 10 percent to the 300 MHz.</p>
<p>The profile of this user type would be somebody working in a call center, an administrator, or the basic web-browser-type user. These desktops might be suspended for long periods of time and have very low utilization, running just one or two light applications. We can work out the CPU requirements with the following quick calculation:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/c437b105-01d3-47de-8561-e84a3299ff4d.png"/></div>
<p>In this user scenario, using the standard sever we described previously, you could host approximately 141 virtual desktop machines, which gives you approximately 17 users per core.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Medium user</h1>
                </header>
            
            <article>
                
<p>Typical utilization is around 500 MHz of CPU resource, plus 10 percent. This type of user would be someone like a data entry personnel, doctors, students, Microsoft Office users, or a help desk operator. These desktops will mainly be used during business/office hours and not heavily utilized. We can work out the CPU requirements with the following quick calculation:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/ab23944d-4b1e-487b-969c-12167ca9dc2c.png"/></div>
<p>In this user scenario, using the standard sever we described previously, you can host approximately 85 virtual desktop machines, giving you five users per core.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Heavy user</h1>
                </header>
            
            <article>
                
<p>Typical utilization is around 750 MHz of CPU resource, plus 10 percent. This type of user would be something like a developer, system administrator, IT worker, database administrator, or engineer. These desktops will more than likely be heavily utilized throughout the day and after normal business hours. They may also be running more graphically intensive or Java-based applications that increase the utilization of the desktop. We can work out the CPU requirements with the following quick calculation:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/e5936c7d-0ea7-4be8-8e9b-f6f0e60f77c0.png"/></div>
<p>In this user scenario, using the standard server we described previously, you can host approximately 65 virtual desktop machines, giving you three users per core.</p>
<p>What we have highlighted in the previous user scenarios is based on assumptions and example use cases. This is where your assessment data becomes critical, as it will tell you the actual resource requirement figures for your own environment.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Sizing the host server's memory requirements to run virtual desktops</h1>
                </header>
            
            <article>
                
<p>Sizing the memory for the servers hosting the virtual desktop machine is somewhat easier than the CPU, although you might need to play a balancing act with the chosen server. The reason for this is that, just because it can accommodate the number of desktops from a CPU perspective, it might not have the memory capacity to serve that number.</p>
<p>If you take a virtual desktop that requires 2 GB of memory and look at the light user scenario from the previous section as an example, you would be hosting 141 virtual desktop machines. That means that the host server will need 282 GB of memory just to host the virtual desktop machine, plus enough memory to run the hypervisor too.</p>
<p>Depending on your choice of server hardware, you might not be able to configure this amount of memory or it might be too expensive, in which case you might end up deploying more, but lower-configuration servers.</p>
<p>Don't forget that when sizing and configuring memory for the virtual desktop machines, never over-commit the memory and set the memory reservation to 100 percent. This stops the swap file from being created, saves storage capacity, and helps performance.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Linked Clone, Instant Clone, or Full Clone</h1>
                </header>
            
            <article>
                
<p>As we have already discussed in <a href="5d942e5b-dda5-4e5a-8278-62a64210aeef.xhtml" target="_blank">Chapter 2</a>, <em>Understanding Horizon 7 Architecture and Components</em>, there are three ways to build virtual desktops from golden images: Linked Clones, Instant Clones, or Full Clones. To recap briefly, Linked Clones are created by replicating a golden image into a thin provisioned replica VM. This VM will be the same size as the used space within the golden image; all reads come from this VM and, no matter how many desktops we have within the pool within limits, each desktop will have a delta disk for writes that will continue to grow until the <span>Linked Clone</span> is recomposed, refreshed, or deleted. With a Full Clone, it does exactly what it says on the tin and will represent a copy of the golden image itself and consume the same amount of space. Finally, Instant Clones essentially take a snapshot of the memory of a running virtual desktop machine.</p>
<p>As such, to save space on our storage device where possible, Linked Clones or Instant Clones are the best options. However, there are a few important use cases where using clones will simply not make sense, such as d<span>esktops where regular refresh or recompose is not possible.</span></p>
<p>As you can see, while clones are possibly the most attractive from the outside and should be able to be widely used, they are not always going to be possible or the right design choice. When your design utilizes full clone desktops, you should be considering your storage design carefully so that it is in-line with this design choice. There are many storage manufacturers that offer re-duplication, compression, and single instance storage that allows you to minimize the storage impact of this type of desktop.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Persistent versus non-persistent</h1>
                </header>
            
            <article>
                
<p>Along with deciding whether you are going to use <span>Linked Clone</span>s or full clones, you will also need to decide whether you are going to use persistent or non-persistent desktops. With persistent desktops, the user is allocated a desktop, either manually or automatically, and will always be directed to that desktop when connecting to their desktop pool. With non-persistent desktops, the users will be directed to any desktop in the given pool. In a lot of designs, Linked Clone and Instant Clone desktops will be configured as non-persistent and Full Clone desktops will be configured as persistent, but this is not always the case and will come down to your own specific use case.</p>
<p>The recommendation would be, wherever possible, to utilize non-persistent desktops that are built on-demand using Linked Clones or Instant Clones. The user's profile would be delivered using View Persona Management/UEM or an AD group policy to configure the desktops. Applications would be delivered using App Volumes. This offers you the easiest way to maintain and refresh the desktops with minimal effect on the users. If your design does not allow this, consider your use case carefully; if you do have to configure persistent desktops due to some value of data or a configuration held within the desktop, consider whether a Full Clone persistent desktop managed by Horizon Mirage for protection and maintenance might be a better approach.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Building a composite desktop</h1>
                </header>
            
            <article>
                
<p>The key to a flexible desktop design is being able to build and customize the desktops in layers. In this context, layers are delivering the individual component parts of the desktop, such as the OS, persona, and applications.</p>
<p>By achieving this, the desktops can not only be more flexible to allow one base image to be used for many more users or pools, but also allow you to configure more Linked Clone or Instant Clone desktop pools. The following screenshot depicts a user's desktop and where all the key elements are being controlled and managed:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/e8a32bef-63ec-45bc-94a0-21c4b7e1608b.png"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Desktop showing key components</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Base layer</h1>
                </header>
            
            <article>
                
<p>Your base layer will consist of an optimized operating system that's been configured to the needs of your business. Agents such as the View agent and AV will be installed into the base image, along with any applications. You will need to decide as to what applications should be installed into the base image and which ones are going to be delivered by other means. Often, the applications that will get installed into the base image will be applications that are used across the organization or a complete pool, such as the Microsoft Office suite. You will also want to consider the nature of the application; if the application is unable to be virtualized with ThinApp since it contains drivers, or integrate with the shell, these applications will also need to be installed in your base image.</p>
<p>You need to get the base image correct, especially if you are using Linked Clones or Instant Clones, otherwise you could end up creating hundreds of desktops very quickly that are configured incorrectly.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Applications</h1>
                </header>
            
            <article>
                
<p>You need to have also built an application delivery strategy. This will detail how each application is going to be delivered to the end user. Some applications will be delivered as part of the base operating system, whereas others may be packaged using ThinApp, or layered in using App Volumes.</p>
<p>There is also the option of Workspace ONE, which would deliver a web-based portal containing additional application delivery methods such as Citrix XenApp or SaaS-based applications.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">User profiles and user environment management</h1>
                </header>
            
            <article>
                
<p>Finally, let's look at delivering the Persona, or a user's profile on top of the desktop. Think of the Persona as everything that makes the desktop personal; for example, application settings, the contents of my documents, and icons on the desktop. There are a number of ways to achieve this, including redirected profiles, group policy, View Persona Management, VMware UEM, and other third-party products, such as Liquidware Labs ProfileUnity. Wherever possible, keeping the solution as simple as possible and not having to combine third-party products is often the easiest way to reduce management overheads. However, depending on the levels of customization needed, you might need to introduce third-party solutions to achieve this level of customization.</p>
<p>With View Persona Management, the users' profiles are redirected by a set of group policies to a dedicated file server. When a user logs into their VDI desktop, elements of the profile are downloaded from the file server to the VDI desktop as they are required. As such, once a file has been called from the profile, it is cached on the local VDI desktop for future use. Any changes to the profile are stored locally on the VDI desktop but periodically uploaded back to the file server.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Disaster recovery and backup</h1>
                </header>
            
            <article>
                
<p>As with any solution, fully understanding the backup and disaster recovery options is highly important. With Horizon View, there are multiple areas where you should understand the backup and recovery options, as well as the options that are available to you if a DR event should occur.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Backup and recovery options</h1>
                </header>
            
            <article>
                
<p>There are several elements that you need to ensure are backed up when it comes to a Horizon View solution, which are as follows:</p>
<ul>
<li>View Connection Servers</li>
<li>View Security Servers</li>
<li>Microsoft Lightweight Directory Service</li>
<li>View Composer Database</li>
<li>vCenter Database</li>
<li>vCenter Server(s)</li>
<li>File servers containing ThinApp, View Persona Data, UEM, and App Stacks</li>
<li>Golden images</li>
<li>Full Clone and persistent desktop images</li>
</ul>
<p>As you can see, there are several areas that you need to ensure are protected on a daily basis, if not more often.</p>
<p>Through the Horizon View Administrator, you can configure the scheduled backup of the LDAP repository and the View Composer Database. These will be backed up to the following location on your View Connection Servers:</p>
<pre class="CommandLineEndPACKT"><strong><span class="CodeInTextPACKT"><span>C:\Program data\VMWare\VDM\backups</span></span></strong></pre>
<p>You should ensure that these backup files are regularly backed up to an external backup solution. We will investigate the configuration and restoration of the View LDAP repository and View Composer Database in <a href="a85150f1-1f32-4c91-87f0-1e8c700b9b96.xhtml">Chapter 4</a>, <em>Installing and Configuring Horizon 7 - Part 1</em>.</p>
<p>It is highly recommended that all server components are protected by some form of backup software solution, such as Veeam Backup and Replication, or VMware Data Protection. As we mentioned previously, you could consider protecting and maintaining your full clones using Horizon Mirage.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Disaster recovery options</h1>
                </header>
            
            <article>
                
<p>Due to the integration of Horizon View with View Composer and vCenter Server, it is not recommended or supported to replicate View environments from production to a DR site. Likewise, Horizon View is not supported for use with VMware SRM. You need to ensure that you design a DR strategy for your Horizon View environment in a different manner. There are several ways you could consider offering DR for View, but let's just cover one of those for now.</p>
<p>First, we need to think of the components that are important to our View environment. Typically, these are things such as the following:</p>
<ul>
<li>User profiles</li>
<li>ThinApp applications or app layers</li>
<li>Golden images</li>
<li>Full Clone desktops</li>
</ul>
<p>If you have these components available at DR, then you can start recovering your View environment at the DR site with relative ease. The DR site will be configured with a dedicated View environment, preconfigured with all the required components such as vCenter Server, View Connection Servers, and View Security Servers. You then need to understand what you need to do to roll out the VDI solution that's been customized for your business needs during a DR event.</p>
<p>As the users' personas, ThinApp applications, and App Volumes AppStacks are all located on a file server, you can consider using technology such as Microsoft's <strong>Distributed FileSystem Replication</strong> (<strong>DFSR</strong>) or similar technology. This allows you to have a copy of this data at both the production and disaster recovery sites.</p>
<p>Once you have your ThinApp packages, AppStacks, and Persona at the DR site, you need to understand how you are going to deliver the desktops. Since the desktops will be rolled out from the golden images, you should consider replicating the golden image from production to DR by utilizing replication that's been integrated into the storage device. You could even do something as primitive as exporting the golden image as an <strong>Open Virtualization Format</strong> (<strong>OVF</strong>) and moving it to the DR site. You are then able to recompose the desktop pools from this golden image at the DR site.</p>
<p>When it comes to full clone desktops, as these are just standard VMs, you could simply consider replicating these directly from the SAN and utilizing SRM to mount them online at the DR site, ready to be added back into Horizon View.</p>
<p>Finally, you should think about how users are going to connect to your DR site in the event of a failure. This could be something as simple as getting the users to connect their client device to a different address, or you could make use of global load balancing technology to redirect the regular URL to the DR site.</p>
<p>As you can see, there isn't a simple solution to building a DR site for your Horizon View solution, but if you break it down to its component level, you can easily configure a solution that will work to deliver the desktops and relevant files for our users, should the need arise. You could also consider utilizing the Cloud Pod Architecture to help enable the cross-site management of users between production and DR, and deploy a global namespace and allow View to direct the user to the appropriate desktop resource.</p>
<p>VMware is also able to deliver desktops as a service as part of their Horizon Air Cloud-Hosted Desktops and Apps service. You could consider utilizing this technology in some way to offer DR for your on-premises Horizon View environment.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Example solution scenario</h1>
                </header>
            
            <article>
                
<p>To finish up this chapter, we wanted to give you an example of a real-life scenario so that you have the opportunity to put all the elements that we've covered in this chapter into action and see how they would all fit together. You will see that we have put together a mock scenario. Read through it and make some notes about the elements that you would be configuring and how you would design the architecture for a production environment.</p>
<p>We are going to build an example design based on a fictitious company called PVO Engineering Inc. and their requirements for deploying a VDI solution. This is shown in the following topology diagram of their current network environment and locations:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/f817ef27-43a9-4a13-9da6-62ba1e092447.png" style=""/></div>
<p>The company has three office locations: an HQ office and two remote sites for the app development teams. To serve these, they have two data centers that are running active/active. Data center A supports the mobile and HQ workers, while data center B supports the app development teams. Each data center can support the entire environment in the event of a data center failure.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">End user requirements</h1>
                </header>
            
            <article>
                
<p>In this example, we have conducted an assessment to gather information on the current user install base of 5,750 users, and we have built up a picture of the types of users and their requirements, along with their location. This is detailed in the following table:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/3d4960d4-03f9-44b6-a29f-038f1c1ad97f.png"/></div>
<p>We now have information on the different types of user and their requirements, and can now start to consider how we are going to deliver the requirements to the end users.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Application developers</h1>
                </header>
            
            <article>
                
<p>In the example scenario, there are two remote development sites, but from the network topology, you can see that they are WAN-based and connect to data center B. They will only use their desktops from within the office and therefore do not require external access.</p>
<p>They do, however, need the ability to install software on their desktops. To deliver this, in this example scenario, we configured a dedicated pool with persistent desktops. The other option would be to configure floating, non-persistent desktops and use App Volumes to deliver Writable Volumes for the users to install their applications onto.</p>
<p>Whichever option you choose, the virtual desktops themselves need to be of a high specification in terms of memory.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Office workers</h1>
                </header>
            
            <article>
                
<p>These end users are your basic task workers and require a basic desktop configuration (2 CPUs and 2 GB memory). They are also perfect candidates for non-persistent virtual desktops. The core Office applications would be installed as part of the base image, with any of the additional applications being delivered via published applications or app layering using App Volumes AppStacks.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Contractors</h1>
                </header>
            
            <article>
                
<p>With contractors, it might be difficult to understand what they are coming into the business to work on, and so since one size doesn't fit all, it's probably best to err on the side of caution when it comes to the configuration. Therefore, we will size for the most intensive role they could perform. In the example scenario, this would be the application development role. That being the case, they will have the same configuration as the internal applications developers; however, they will need external access.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Engineering</h1>
                </header>
            
            <article>
                
<p>There are two teams in the engineering department. Team one are heavy CAD users and design products, and team two create the engineering training material. Team one, therefore, requires a high-end graphics solution to run the CAD software, whereas team two doesn't need quite as many graphics resources; however, they still need substantially more than a standard user would need. The solution for engineering would include NVIDIA accelerated graphics technology, which requires dedicated desktops.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Sales</h1>
                </header>
            
            <article>
                
<p>The sales department follows a similar work pattern to the standard office workers and therefore would use a floating, non-persistent desktop pool. The key difference is that the sales teams would need external access from the internet.</p>
<p>Now that we have the user requirements, we can start to look at creating a pool design based on delivering these use cases.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Desktop pool design</h1>
                </header>
            
            <article>
                
<p>The pool design reflects the use cases, and any similar desktops will be included in a single pool. Based on the information we've gathered, we can start building the pool design, based on the information in the following table:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/1b6b9cf7-c57d-447c-95bf-28068eb3534b.png"/></div>
<p>All the office workers in the design are part of the same desktop pool, along with sales, even though they have different application requirements. We will look at delivering these applications outside of the core virtual desktop machine image using either ThinApp, the Horizon published apps, or App Volumes.</p>
<p>Using the pod and block architecture, we are going to deploy two View pods, one in data center A and the other in data center B. The reason for this is that it makes more sense from a network perspective to have these desktops nearer to the users; however, we will take advantage of the Cloud Pod Architecture since the developers travel between sites, and will configure a global pool for these users. Although in this example we have decided to configure a dedicated pool for the developers, we could deploy floating desktops and use App Volumes to deliver the ability for the developers to install their own software using the Writeable Volumes feature.</p>
<p>Now that we have an idea of the pools, we can start to shape the pod's design and size the management blocks and the desktop hosting blocks. Let's start with the desktop blocks.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Sizing the desktop blocks</h1>
                </header>
            
            <article>
                
<p>In data center A with pod 1, we have 5,500 virtual desktop machines. As there are 2,000 virtual desktop machines supported per block, we would need to configure three blocks with approximately 1,800 virtual desktop machines per block.</p>
<p>In data center B, we have 250 virtual desktop machines, so we only need one block. The next question is, how many servers do we need to host the virtual desktop machines? For this example, we will use the users-per-core figures we previously discussed in this chapter to cover light users for the office and sales workers, and very heavy users for the developers and engineering users. This means that, for office users, we can configure 98 virtual desktop machines per host and, for the very heavy users, we can configure 50 virtual desktop machines per host.</p>
<p>We also need to remember that we have some distinct differences in the host server requirements, as the engineering users require access to hardware-based GPU. This would result in deploying a cluster for each. The number of hosts required for pod 1 could look something like what's shown in the following screenshot. Note that the users per core ratios in these examples are based on servers with two 3-GHz, 10-core CPUs, and user profiles of 300 MHz for light users and 1.1 GHz for power users:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/988a0d14-4b1e-4f0b-be7e-11ddf8c11ba5.png"/></div>
<p>For the GPU-based virtual desktop machines, two configuration options have been used, both using NVIDIA GRID K1 graphics cards and vGPU. The CAD users will use a K180Q profile, and the video users will use a K140Q profile.</p>
<p>There is no DR option for the GRID-enabled servers due to the high cost of the hardware. In the event of a failure, users can continue to work, but with lower graphics capabilities.</p>
<p>Pod 2 in data center B contains just the virtual desktop machines for the application development users and would look something like the following:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/ad528765-3c7e-430f-b4ff-c52ae8d59f2c.png"/></div>
<p>With pod 1, we have exceeded the number of hosts we can support in a cluster, the limit being 32. Therefore, we would deploy two clusters per desktop block with the number of host servers divided across the clusters, while a separate cluster will support the graphics enabled users.</p>
<p>The design is now starting to look like the following diagram:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/35957a8a-093b-47f1-ab44-c0571f963597.png"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Sizing the storage requirements</h1>
                </header>
            
            <article>
                
<p>Using the calculations we detailed previously, you can work out the IOPS requirements you need to deliver. In this example scenario, we will base the calculation on a requirement of 30 IOPS per virtual desktop machine, a 30/70 read/write ratio, a RAID 5 array, and a 10 GB disk capacity. Given those variables, we can work out what the storage requirements are, as shown in the following table:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/59f456b6-4648-479a-be9b-e57e4b216946.png" style=""/></div>
<p>These storage requirements are for hosting the desktops only. If you are using components such as App Volumes, or ThinApp for delivering applications, you will need to think about the capacity and performance requirements to support those environments.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Sizing the management blocks</h1>
                </header>
            
            <article>
                
<p>Once we have configured the desktop blocks and know the pool configuration, we can look at sizing the management blocks to provide the supporting infrastructure. This infrastructure component configuration will look something like what's shown in the following table:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/43b7dcd4-0ea6-4467-8a17-d1c1a7af2fdd.png" style=""/></div>
<p>The final element to look at is the network. You need to assess whether the current network configuration will support the users. If not, then you may need to look at some form of a network upgrade.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Network sizing and requirements</h1>
                </header>
            
            <article>
                
<p>Now that we have our pool design, management and desktop blocks, and the storage requirements, we can look at the network requirements, as shown in the following table:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/5958c7d6-ce8b-425b-b95f-963aa0a6408f.png" style=""/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we have covered some of the essential tasks in designing and building out our Horizon View infrastructure.</p>
<p>We started at a high level, discussing the approach to a VDI project and the different phases to work through to plan and test an environment. The most important of these phases is the assessment phase.</p>
<p>Once we worked through these, we looked at the pod and block reference architecture, before examining the sizing of the key Horizon View components, such as the View Connection Server, View Security Server, and View Composer.</p>
<p>Following on from the management architecture, we looked at some of the considerations for sizing and configuring the virtual desktop machines and the user assignments, before putting all of this together in a high-level example design.</p>
<p>You should now have a methodology for approaching a project, coupled with the knowledge to be able to start sizing an environment that's specific to your end user's requirements.</p>
<p>In the next chapter, we will discuss how to install all of the components that make up the Horizon View solution. We will take a deep dive into installation and follow this process using step-by-step screenshots. By the end of this chapter, we will have a fully functional View infrastructure up and running.</p>


            </article>

            
        </section>
    </body></html>