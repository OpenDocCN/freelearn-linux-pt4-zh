["```\n  {\n    \"healthChecks\": [\n      {\n        \"timeoutSeconds\": 5,\n        \"protocol\": \"HTTP\",\n        \"portIndex\": 0,\n        \"path\": \"/health/cluster\",\n        \"maxConsecutiveFailures\": 0,\n        \"intervalSeconds\": 30,\n        \"gracePeriodSeconds\": 120\n      },\n      {\n        \"timeoutSeconds\": 5,\n        \"protocol\": \"HTTP\",\n        \"portIndex\": 0,\n        \"path\": \"/health/process\",\n        \"maxConsecutiveFailures\": 3,\n        \"intervalSeconds\": 30,\n        \"gracePeriodSeconds\": 120\n      }\n    ],\n    \"id\": \"/cassandra/dev-test\",\n    \"instances\": 1,\n    \"cpus\": 0.5,\n    \"mem\": 512,\n    \"ports\": [0],\n    \"uris\": [\n      \"https://downloads.mesosphere.io/cassandra-mesos/artifacts/0.2.1-SNAPSHOT-608-master-d1c2cf30c8/cassandra-mesos-0.2.1-SNAPSHOT-608-master-d1c2cf30c8.tar.gz\",\n      \"https://downloads.mesosphere.io/java/jre-7u76-linux-x64.tar.gz\"\n    ],\n    \"env\": {\n      \"CASSANDRA_ZK_TIMEOUT_MS\": \"10000\",\n      \"CASSANDRA_HEALTH_CHECK_INTERVAL_SECONDS\": \"60\",\n      \"MESOS_ZK\": \"zk://localhost:2181/mesos\",\n      \"JAVA_OPTS\": \"-Xms256m -Xmx256m\",\n      \"CASSANDRA_CLUSTER_NAME\": \"dev-test\",\n      \"CASSANDRA_ZK\": \"zk://localhost:2181/cassandra-mesos\",\n      \"CASSANDRA_NODE_COUNT\": \"3\",\n      \"CASSANDRA_RESOURCE_CPU_CORES\": \"2.0\",\n      \"CASSANDRA_RESOURCE_MEM_MB\": \"2048\",\n      \"CASSANDRA_RESOURCE_DISK_MB\": \"2048\"\n    },\n    \"cmd\": \"$(pwd)/jre*/bin/java $JAVA_OPTS -classpath cassandra-mesos-framework.jar io.mesosphere.mesos.frameworks.cassandra.framework.Main\"\n  }\n```", "```\n$ curl -X POST -H \"Content-Type: application/json\" -d cassandra-mesos.json http://marathon-machine:8080/v2/apps\n\n```", "```\n--resources='ports:[31000-32000,7000-7001,7199-7199,9042-9042,9160-9160]'\n```", "```\n# name of the cassandra cluster, this will be part of the framework name in Mesos\nCASSANDRA_CLUSTER_NAME=dev-cluster\n\n# Mesos ZooKeeper URL to locate leading master\nMESOS_ZK=zk://localhost:2181/mesos\n\n# ZooKeeper URL to be used to store framework state\nCASSANDRA_ZK=zk://localhost:2181/cassandra-mesos\n\n# The number of nodes in the cluster (default 3)\nCASSANDRA_NODE_COUNT=3\n\n# The number of seed nodes in the cluster (default 2)\n# set this to 1, if you only want to spawn one node\nCASSANDRA_SEED_COUNT=2\n\n# The number of CPU Cores for each Cassandra Node (default 2.0)\nCASSANDRA_RESOURCE_CPU_CORES=2.0\n\n# The number of Megabytes of RAM for each Cassandra Node (default 2048)\nCASSANDRA_RESOURCE_MEM_MB=2048\n\n# The number of Megabytes of Disk for each Cassandra Node (default 2048)\nCASSANDRA_RESOURCE_DISK_MB=2048\n\n# The number of seconds between each health check of the Cassandra node (default 60)\nCASSANDRA_HEALTH_CHECK_INTERVAL_SECONDS=60\n\n# The default bootstrap grace time - the minimum interval between two node starts\n# You may set this to a lower value in pure local development environments.\nCASSANDRA_BOOTSTRAP_GRACE_TIME_SECONDS=120\n\n# The number of seconds that should be used as the mesos framework timeout (default 604800 seconds / 7 days)\nCASSANDRA_FAILOVER_TIMEOUT_SECONDS=604800\n\n# The mesos role to used to reserve resources (default *). If this is set, the framework accepts offers that have resources for that role or the default role *\nCASSANDRA_FRAMEWORK_MESOS_ROLE=*\n\n# A pre-defined data directory specifying where Cassandra should write its data. \n# Ensure that this directory can be created by the user the framework is running as (default. [mesos sandbox]).\n# NOTE:\n# This field is slated to be removed and the framework will be able to allocate the data volume itself.\nCASSANDRA_DATA_DIRECTORY=.\n```", "```\n{\n  \"id\": \"elasticsearch-mesos-scheduler\",\n  \"container\": {\n    \"docker\": {\n      \"image\": \"mesos/elasticsearch-scheduler\",\n      \"network\": \"HOST\"\n    }\n},\n\"args\": [\"--zookeeperMesosUrl\", \"zk://zookeeper-node:2181/mesos\"],\n  \"cpus\": 0.2,\n  \"mem\": 512.0,\n  \"env\": {\n    \"JAVA_OPTS\": \"-Xms128m -Xmx256m\"\n  },\n  \"instances\": 1\n}\n```", "```\n$ curl -k -XPOST -d @elasticsearch.json -H \"Content-Type: application/json\" http://marathon-machine:8080/v2/apps\n\n```", "```\n{\n  \"id\": \"elasticsearch\",\n  \"cpus\": 0.2,\n  \"mem\": 512,\n  \"instances\": 1,\n  \"cmd\": \"java -jar scheduler-0.7.0.jar --frameworkUseDocker false --zookeeperMesosUrl zk://10.0.0.254:2181 --frameworkName elasticsearch --elasticsearchClusterName mesos-elasticsearch --elasticsearchCpu 1 --elasticsearchRam 1024 --elasticsearchDisk 1024 --elasticsearchNodes 3 --elasticsearchSettingsLocation /home/ubuntu/elasticsearch.yml\",\n  \"uris\": [\"https://github.com/mesos/elasticsearch/releases/download/0.7.0/scheduler-0.7.0.jar\"],\n  \"env\": {\n    \"JAVA_OPTS\": \"-Xms256m -Xmx512m\"\n  },\n  \"ports\": [31100],\n  \"requirePorts\": true,\n  \"healthChecks\": [\n    {\n     \"gracePeriodSeconds\": 120,\n      \"intervalSeconds\": 10,\n      \"maxConsecutiveFailures\": 6,\n      \"path\": \"/\",\n      \"portIndex\": 0,\n      \"protocol\": \"HTTP\",\n      \"timeoutSeconds\": 5\n    }\n  ]\n}\n```", "```\n$ curl -k -XPOST -d @elasticsearch.json -H \"Content-Type: application/json\" http://MARATHON_IP_ADDRESS:8080/v2/apps\n\n```", "```\n    --dataDir\n         The host data directory used by Docker volumes in the executors. [DOCKER MODE ONLY]\n         Default: /var/lib/mesos/slave/elasticsearch\n\n    --elasticsearchClusterName\n         Name of the Elasticsearch cluster\n         Default: mesos-ha\n\n    --elasticsearchCpu\n         The amount of CPU resource to allocate to the Elasticsearch instance.\n         Default: 1.0\n\n    --elasticsearchDisk\n         The amount of Disk resource to allocate to the Elasticsearch instance\n         (MB).\n         Default: 1024.0\n\n    --elasticsearchExecutorCpu\n         The amount of CPU resource to allocate to the Elasticsearch executor.\n         Default: 0.1\n\n    --elasticsearchExecutorRam\n         The amount of ram resource to allocate to the Elasticsearch executor\n         (MB).\n         Default: 32.0\n\n    --elasticsearchNodes\n         Number of Elasticsearch instances.\n         Default: 3\n\n    --elasticsearchPorts\n         User specified Elasticsearch HTTP and transport ports. [NOT RECOMMENDED]\n         Default: <empty string>\n\n    --elasticsearchRam\n         The amount of ram resource to allocate to the Elasticsearch instance\n         (MB).\n         Default: 256.0\n\n    --elasticsearchSettingsLocation\n         Path or URL to Elasticsearch yml settings file. [In docker mode file must be in /tmp/config] E.g. '/tmp/config/elasticsearch.yml' or 'https://gist.githubusercontent.com/mmaloney/5e1da5daa58b70a3a671/raw/elasticsearch.yml'\n         Default: <empty string>\n\n    --executorForcePullImage\n         Option to force pull the executor image. [DOCKER MODE ONLY]\n         Default: false\n\n    --executorImage\n         The docker executor image to use. E.g. 'elasticsearch:latest' [DOCKER\n         MODE ONLY]\n         Default: elasticsearch:latest\n\n    --executorName\n         The name given to the executor task.\n         Default: elasticsearch-executor\n\n    --frameworkFailoverTimeout\n         The time before Mesos kills a scheduler and tasks if it has not recovered\n         (ms).\n         Default: 2592000.0\n\n    --frameworkName\n         The name given to the framework.\n         Default: elasticsearch\n\n    --frameworkPrincipal\n         The principal to use when registering the framework (username).\n         Default: <empty string>\n\n    --frameworkRole\n         Used to group frameworks for allocation decisions, depending on the\n         allocation policy being used.\n         Default: *\n\n    --frameworkSecretPath\n         The path to the file which contains the secret for the principal\n         (password). Password in file must not have a newline.\n         Default: <empty string>\n\n    --frameworkUseDocker\n         The framework will use docker if true, or jar files if false. If false, the user must ensure that the scheduler jar is available to all slaves.\n         Default: true\n\n    --javaHome\n         When starting in jar mode, if java is not on the path, you can specify\n         the path here. [JAR MODE ONLY]\n         Default: <empty string>\n\n    --useIpAddress\n         If true, the framework will resolve the local ip address. If false, it\n         uses the hostname.\n         Default: false\n\n    --webUiPort\n         TCP port for web ui interface.\n         Default: 31100\n\n    --zookeeperMesosTimeout\n         The timeout for connecting to zookeeper for Mesos (ms).\n         Default: 20000\n\n    * --zookeeperMesosUrl\n         Zookeeper urls for Mesos in the format zk://IP:PORT,IP:PORT,...)\n         Default: zk://mesos.master:2181\n```", "```\n{\n  \"id\": \"/logstash\",\n  \"cpus\": 1,\n  \"mem\": 1024.0,\n  \"instances\": 1,\n  \"container\": {\n    \"type\": \"DOCKER\",\n    \"docker\": {\n      \"image\": \"mesos/logstash-scheduler:0.0.6\",\n      \"network\": \"HOST\"\n    }\n  },\n  \"env\": {\n    \"ZK_URL\": \"zk://123.0.0.12:5181/logstash\",\n    \"ZK_TIMEOUT\": \"20000\",\n    \"FRAMEWORK_NAME\": \"logstash\",\n    \"FAILOVER_TIMEOUT\": \"60\",\n    \"MESOS_ROLE\": \"logstash\",\n    \"MESOS_USER\": \"root\",\n    \"LOGSTASH_HEAP_SIZE\": \"64\",\n    \"LOGSTASH_ELASTICSEARCH_URL\": \"http://elasticsearch.service.consul:1234\",\n    \"EXECUTOR_CPUS\": \"0.5\",\n    \"EXECUTOR_HEAP_SIZE\": \"128\",\n    \"ENABLE_FAILOVER\": \"false\",\n    \"ENABLE_COLLECTD\": \"true\",\n    \"ENABLE_SYSLOG\": \"true\",\n    \"ENABLE_FILE\": \"true\",\n    \"ENABLE_DOCKER\": \"true\",\n    \"EXECUTOR_FILE_PATH\": \"/var/log/*,/home/jhf/example.log\"\n  }\n}\n```", "```\n$ curl -k -XPOST -d @logstash.json -H \"Content-Type: application/json\" http://MARATHON_IP_ADDRESS:8080/v2/apps\n\n```", "```\n$ sudo echo logstash > /etc/mesos-master/roles\n\n```", "```\nports(logstash):[514-514]\n```", "```\nports(logstash):[25826-25826]\n```", "```\n$ git clone https://github.com/mesos/kibana\n\n```", "```\n$ cd kibana\n$ gradlew jar\n\n```", "```\n$ java -jar /path/to/kibana.jar -zk zk://zookeeper:2181/mesos -v 4.3.1 -es http://es-host:9200\n\n```", "```\n$ git clone https://github.com/mesos/kafka\n$ cd kafka\n$ ./gradlew jar\n\n```", "```\n$ wget https://archive.apache.org/dist/kafka/0.8.2.2/kafka_2.10-0.8.2.2.tgz\n\n```", "```\n$ export MESOS_NATIVE_JAVA_LIBRARY=/usr/local/lib/libmesos.so\n\n```", "```\nstorage=file:kafka-mesos.json\nmaster=zk://master:2181/mesos\nzk=master:2181\napi=http://master:7000\n```", "```\n#Start the kafka scheduler\n$ ./kafka-mesos.sh scheduler\n\n```", "```\n$ ./kafka-mesos.sh broker add 0\n\nbroker added:â€©  id: 0\n active: false\n state: stopped\n resources: cpus:1.00, mem:2048, heap:1024, port:auto\n failover: delay:1m, max-delay:10m\n stickiness: period:10m\n\n```", "```\n$ ./kafka-mesos.sh broker list\n\nbroker:\n id: 0\n active: false\n state: stopped\n resources: cpus:1.00, mem:2048, heap:1024, port:auto\n failover: delay:1m, max-delay:10m\n stickiness: period:10m\n\n```", "```\n$ ./kafka-mesos.sh broker start 0\n\nbroker started:\n id: 0\n active: true\n state: running\n resources: cpus:1.00, mem:2048, heap:1024, port:auto\n failover: delay:1m, max-delay:10m\n stickiness: period:10m, hostname:slave0\n task:\n id: broker-0-d2d94520-2f3e-4779-b276-771b4843043c\n running: true\n endpoint: 192.168.25.62:31000\n attributes: rack=r1\n\n```", "```\n$ sudo apt-get install kafkacat\n\n$ echo \"test\" |kafkacat -P -b \"192.168.25.62:31000\" -t testTopic -p 0\n\n```", "```\n$ kafkacat -C -b \"192.168.25.62:31000\" -t testTopic -p 0 -e\ntest\n\n```", "```\n$ ./kafka-mesos.sh broker add 0..2 --heap 1024 --mem 2048\n\n```", "```\nbrokers added:\n\n id: 0\n active: false\n state: stopped\n resources: cpus:1.00, mem:2048, heap:1024, port:auto\n failover: delay:1m, max-delay:10m\n stickiness: period:10m\n\n id: 1\n active: false\n state: stopped\n resources: cpus:1.00, mem:2048, heap:1024, port:auto\n failover: delay:1m, max-delay:10m\n stickiness: period:10m\n\n id: 2\n active: false\n state: stopped\n resources: cpus:1.00, mem:2048, heap:1024, port:auto\n failover: delay:1m, max-delay:10m\n stickiness: period:10m\n\n```", "```\n$   ./kafka-mesos.sh broker start 0..2\n\nbrokers started:\n\n id: 0\n active: true\n state: running\n resources: cpus:1.00, mem:2048, heap:1024, port:auto\n failover: delay:1m, max-delay:10m\n stickiness: period:10m, hostname:slave0\n task:\n id: broker-0-d2d94520-2f3e-4779-b276-771b4843043c\n running: true\n endpoint: 192.168.25.62:31000\n attributes: rack=r1\n\n id: 1\n active: true\n state: running \n\n id: 2\n active: true\n state: running \n\n```", "```\n$ ./kafka-mesos.sh broker stop 0\n\nbroker stopped:\n id: 0\n active: false\n state: stopped\n resources: cpus:1.00, mem:2048, heap:1024, port:auto\n failover: delay:1m, max-delay:10m\n stickiness: period:10m, hostname:slave0, expires:2015-07-10 15:51:43+03\n\n$ ./kafka-mesos.sh broker update 0 --options log.dirs=/mnt/kafka/broker0\n\nbroker updated:\n id: 0\n active: false\n state: stopped\n resources: cpus:1.00, mem:2048, heap:1024, port:auto\n options: log.dirs=/mnt/kafka/broker0\n failover: delay:1m, max-delay:10m\n stickiness: period:10m, hostname:slave0, expires:2015-07-10 15:51:43+03\n\n```", "```\n$ ./kafka-mesos.sh broker start 0\n\nbroker started:\n id: 0\n active: true\n state: running\n resources: cpus:1.00, mem:2048, heap:1024, port:auto\n failover: delay:1m, max-delay:10m\n stickiness: period:10m, hostname:slave0\n task:\n id: broker-0-d2d94520-2f3e-4779-b276-771b4843043c\n running: true\n endpoint: 192.168.25.62:31000\n attributes: rack=r1\n\n```", "```\n$ ./kafka-mesos.sh broker log 0\n\n```", "```\n$ ./kafka-mesos.sh broker log 0 --name stderr\n\n```", "```\n$ ./kafka-mesos.sh broker log 0 --name server.log\n\n```", "```\n$ ./kafka-mesos.sh broker log 0 --name server.log --lines 200\n\n```", "```\n$ ./kafka-mesos.sh help broker add\nAdd broker\nUsage: broker add <broker-expr> [options]\nOption        Description\n--bind-address        broker bind address (broker0, 192.168.50.*, if:eth1). Default - auto\n--constraints         constraints (hostname=like:master,rack=like:1.*). See below.\n--cpus <Double>       cpu amount (0.5, 1, 2)\n--failover-delay      failover delay (10s, 5m, 3h)\n--failover-max-delay  max failover delay. See failoverDelay.\n--failover-max-tries  max failover tries. Default - none\n--heap <Long>         heap amount in Mb\n--jvm-options         jvm options string (-Xms128m -XX:PermSize=48m)\n--log4j-options       log4j options or file. Examples\n log4j.logger.kafka=DEBUG\\, kafkaAppender\n file:log4j.properties\n--mem <Long>          mem amount in Mb\n--options             options or file. Examples:\n log.dirs=/tmp/kafka/$id,num.io.threads=16\n file:server.properties\n--port                port or range (31092, 31090..31100). Default - auto\n--stickiness-period   stickiness period to preserve same node for broker (5m, 10m, 1h)\n--volume              pre-reserved persistent volume id\n\nGeneric        Options\nOption         Description\n------  -----------\n--api      Api url. Example: http://master:7000broker-expr examples:\n\n 0      - broker 0\n 0,1    - brokers 0,1\n 0..2   - brokers 0,1,2\n 0,1..2 - brokers 0,1,2\n *      - any broker\n\nattribute filtering:\n *[rack=r1]            - any broker having rack=r1\n *[hostname=slave*]    - any broker on host with name starting with 'slave'\n 0..4[rack=r1,dc=dc1]  - any broker having rack=r1 and dc=dc1\n\nconstraint examples:\n like:master     - value equals 'master'\n unlike:master   - value not equals 'master'\n like:slave.*    - value starts with 'slave'\n unique          - all values are unique\n cluster         - all values are the same\n cluster:master  - value equals 'master'\n groupBy         - all values are the same\n groupBy:3       - all values are within 3 different groups\n\n```", "```\n$ ./kafka-mesos.sh help broker start\nStart broker\nUsage: broker start <broker-expr> [options]\nOption     Description\n------     -----------\n--timeout  timeout (30s, 1m, 1h). 0s - no timeout\n\nGeneric  Options\nOption   Description\n------   -----------\n--api    Api url. Example: http://master:7000\n\nbroker    - expr examples:\n 0       - broker 0\n 0,1     - brokers 0,1\n 0..2    - brokers 0,1,2\n 0,1..2  - brokers 0,1,2\n *       - any broker\n\nattribute filtering:\n *[rack=r1]           - any broker having rack=r1\n *[hostname=slave*]   - any broker on host with name starting with 'slave'\n 0..4[rack=r1,dc=dc1] - any broker having rack=r1 and dc=dc1\n\n```", "```\n$ ./kafka-mesos.sh help broker update\n\nUpdate broker\nUsage: broker update <broker-expr> [options]\n\nOption                Description\n------                -----------\n--bind-address        broker bind address (broker0, 192.168.50.*, if:eth1). Default - auto\n--constraints         constraints (hostname=like:master,rack=like:1.*). See below.\n--cpus <Double>       cpu amount (0.5, 1, 2)\n--failover-delay      failover delay (10s, 5m, 3h)\n--failover-max-delay  max failover delay. See failoverDelay.\n--failover-max-tries  max failover tries. Default - none\n--heap <Long>         heap amount in Mb\n--jvm-options         jvm options string (-Xms128m -XX:PermSize=48m)\n--log4j-options       log4j options or file. Examples:\n log4j.logger.kafka=DEBUG\\, kafkaAppender\n file:log4j.properties\n--mem <Long>          mem amount in Mb\n--options             options or file. Examples:\n log.dirs=/tmp/kafka/$id,num.io.threads=16\n file:server.properties\n--port                port or range (31092, 31090..31100). Default - auto\n--stickiness-period   stickiness period to preserve same node for broker (5m, 10m, 1h)\n--volume              pre-reserved persistent volume id\n\nGeneric Options\nOption  Description\n------  -----------\n--api   Api url. Example: http://master:7000\n\nbroker-expr examples:\n 0       - broker 0\n 0,1     - brokers 0,1\n 0..2    - brokers 0,1,2\n 0,1..2  - brokers 0,1,2\n *       - any broker\n\nattribute filtering:\n *[rack=r1]           - any broker having rack=r1\n *[hostname=slave*]   - any broker on host with name starting with 'slave'\n 0..4[rack=r1,dc=dc1] - any broker having rack=r1 and dc=dc1\n\nconstraint examples:\n like:master     - value equals 'master'\n unlike:master   - value not equals 'master'\n like:slave.*    - value starts with 'slave'\n unique          - all values are unique\n cluster         - all values are the same\n cluster:master  - value equals 'master'\n groupBy         - all values are the same\n groupBy:3       - all values are within 3 different groups\n\nNote: use \"\" arg to unset an option\n\n```", "```\n$ ./kafka-mesos.sh help broker stop\n\nStop broker\nUsage: broker stop <broker-expr> [options]\n\nOption     Description\n------     -----------\n--force    forcibly stop\n--timeout  timeout (30s, 1m, 1h). 0s - no timeout\n\nGeneric  Options\nOption   Description\n------   -----------\n--api    Api url. Example: http://master:7000\n\nbroker-expr examples:\n 0      - broker 0\n 0,1    - brokers 0,1\n 0..2   - brokers 0,1,2\n 0,1..2 - brokers 0,1,2\n *      - any broker\nattribute filtering:\n *[rack=r1]           - any broker having rack=r1\n *[hostname=slave*]   - any broker on host with name starting with 'slave'\n 0..4[rack=r1,dc=dc1] - any broker having rack=r1 and dc=dc1\n\n```", "```\n$ ./kafka-mesos.sh help topic add\nAdd topic\nUsage: topic add <topic-expr> [options]\n\nOption                  Description\n------                  -----------\n--broker                <broker-expr>. Default - *. See below.\n--options               topic options. Example: flush.ms=60000,retention.ms=6000000\n--partitions <Integer>  partitions count. Default - 1\n--replicas <Integer>    replicas count. Default - 1\n\ntopic-expr examples:\n t0        - topic t0\n t0,t1     - topics t0, t1\n *         - any topic\n t*        - topics starting with 't'\n\nbroker-expr examples:\n 0      - broker 0\n 0,1    - brokers 0,1\n 0..2   - brokers 0,1,2\n 0,1..2 - brokers 0,1,2\n *      - any broker\n\n```"]