- en: Chapter 8. What Next?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章. 接下来做什么？
- en: In this chapter, we will touch upon some advanced Docker and Core OS topics
    and we will also discuss what is upcoming in CoreOS. For most of the topics, we
    will not go into the details of using or deploying each of the features mentioned
    in this chapter, but will discuss enough so as to be aware of what else is cooking.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论一些高级的Docker和Core OS话题，并且我们还将讨论CoreOS的未来发展。在大多数话题中，我们不会详细介绍如何使用或部署本章中提到的每个功能，而是会提供足够的信息，让你了解即将到来的新特性。
- en: 'This chapter covers the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖以下主题：
- en: Container security
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器安全性
- en: Easy upgrade using CoreUpgrade
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用CoreUpgrade进行轻松升级
- en: User authentication using Dex
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Dex进行用户身份验证
- en: Sysdig
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sysdig
- en: Other container orchestration mechanisms such as Kubernetes, Apache Mesos, and
    Swarm
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他容器编排机制，如Kubernetes、Apache Mesos和Swarm
- en: Docker data volume management
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker数据卷管理
- en: Open Container Project
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开放容器项目
- en: Container security
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 容器安全性
- en: Security is an important aspect of any deployment. There should be security
    in the applications, devices, and network to disallow any unauthorized access.
    There should also be security in the container/docker deployment so as to disallow
    unauthorized access to system resources reserved for the container. We will understand
    how Docker container ensures network and resource isolation and security.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 安全性是任何部署中的重要方面。应用程序、设备和网络应该具备安全性，以防止任何未经授权的访问。容器/docker的部署也应该具备安全性，以防止未经授权的访问系统资源，尤其是那些为容器保留的资源。我们将了解Docker容器如何确保网络和资源隔离以及安全性。
- en: 'Docker uses the namespaces to isolate the container from other containers running
    on the host. There are three important namespaces that take part in providing
    security:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Docker使用命名空间将容器与主机上运行的其他容器隔离开来。参与提供安全性的有三个重要的命名空间：
- en: '**Process namespace**: Each Linux system has a process tree, that is, there
    is an init process with process ID 1, which is also called the root process. This
    root process spawns other daemons and processes as a child process. These daemons
    and processes can then create their own child and so on. It is possible to create
    a child namespace with one of the child as the root process. All the processes
    running in the child namespace don''t have the knowledge of the parent namespace;
    hence, they can''t perform any operations (like signal) on the processes outside
    their namespace.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**进程命名空间**：每个Linux系统都有一个进程树，也就是说，有一个进程ID为1的init进程，它也被称为根进程。这个根进程会生成其他的守护进程和子进程。这些守护进程和进程也可以创建它们自己的子进程，如此类推。可以创建一个子命名空间，并将其中一个进程作为根进程。运行在子命名空间中的所有进程无法了解父命名空间的情况；因此，它们不能对父命名空间之外的进程执行任何操作（如信号操作）。'
- en: '**Network namespace**: Each container has its own network interface that is
    different from the host interface''s. They have their own loop-back interface
    as well. The only way containers can talk to the external world is through the
    bridge network at the host. Bridge network enables communication between different
    namespaces running in the same host or to an address in another host. This ensures
    that the network stack is exclusive to the container, thereby running its own
    IP, TCP, UDP stacks, and so on. Docker has an additional layer of security by
    allowing communication with another Docker by exposing ports or by creating links
    to another container explicitly.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**网络命名空间**：每个容器都有自己的网络接口，与主机接口不同。它们也有自己的环回接口。容器与外部世界通信的唯一方式是通过主机的桥接网络。桥接网络使得同一主机中运行的不同命名空间之间可以通信，或者与另一主机中的地址进行通信。这样可以确保网络栈对容器来说是独占的，从而使其运行自己的IP、TCP、UDP栈等。Docker通过允许与另一个Docker进行通信（通过暴露端口或显式地创建与另一个容器的链接）来增加一层额外的安全性。'
- en: '**Resource namespace**: This ensures that each container has its own resource
    exclusively for its own use. Resource can be dedicated RAM, processors, or a disk
    with its own filesystem. This ensures that the container usage doesn''t cross
    the set limits, thus ensuring that it doesn''t intrude upon the resources being
    allocated to another container.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**资源命名空间**：这确保了每个容器拥有其专用的资源，仅供自己使用。资源可以是专用的RAM、处理器或带有自己文件系统的磁盘。这样可以确保容器的使用不会超出设定的限制，从而确保它不会侵占分配给另一个容器的资源。'
- en: The following figure illustrates the isolation provided by the Docker container.
    As we can see, the service running inside container has its own root process,
    filesystem, and interface which an operation system would normally provide. These
    features are present in almost all of the Linux distributions that Docker uses
    to provide isolation.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了 Docker 容器提供的隔离性。正如我们所见，容器内运行的服务拥有自己的根进程、文件系统和接口，这些是操作系统通常会提供的功能。这些功能几乎存在于
    Docker 用于提供隔离的所有 Linux 发行版中。
- en: '![Container security](img/00039.jpeg)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![容器安全](img/00039.jpeg)'
- en: After isolation, let's discuss security. Docker starts container in non-privilege
    mode. That means containers or applications running inside the container only
    have permissions to perform actions that don't require root privileges. Some examples
    are using a port less than 1024 (though non-privileged docker can use ports that
    are under and above the 1024 range), modifying a file in `/etc,` mounting a filesystem,
    and so on. This ensures that even services in containers are hacked; they can't
    inflict damage on the host and the impact can be limited to that container instance.
    The allowed privileges can be configured and it can be very restrictive, or very
    relaxed based on the environment (trusted or non-trusted) containers are expected
    to work.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 隔离之后，让我们讨论一下安全性。Docker 以非特权模式启动容器。这意味着容器或容器内运行的应用程序仅拥有执行不需要根权限的操作的权限。例如，使用小于
    1024 的端口（尽管非特权 Docker 可以使用 1024 以下和以上的端口）、修改 `/etc` 中的文件、挂载文件系统等。这样可以确保即使容器中的服务被攻击，它们也无法对主机造成损害，影响也仅限于该容器实例。允许的权限可以进行配置，可以根据容器的环境（受信任或不受信任）来设定严格或宽松的限制。
- en: Docker also recommends securing the access to Docker Daemon, which runs as root
    on the host machine. Also, it recommends enabling secure HTTP connections in case
    it is required to administrate a container remotely. Further, the in-built firewalls
    in Linux kernel like `SELinux` can be used to further add restrictions on the
    Docker to set restrictions for using only specific ports and specific protocols
    (only TCP, only UDP, and so on). Also, it is advisable to use other Linux security
    utilities and tools to protect and harden the system.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 还建议保护对 Docker 守护进程的访问，因为它作为根用户在主机上运行。此外，Docker 还建议启用安全的 HTTP 连接，以便在需要远程管理容器时使用。此外，Linux
    内核中内建的防火墙，如 `SELinux`，可以进一步限制 Docker，只允许使用特定的端口和协议（仅 TCP、仅 UDP 等）。同时，建议使用其他 Linux
    安全工具和实用程序来保护和强化系统。
- en: Update and patches – CoreUpdate
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更新和补丁 – CoreUpdate
- en: '`CoreUpdate` is a service available as part of `Premium Manged Service` targeted
    at Enterprise customers who require support and SLA-based support in case they
    face issues with deployment. `CoreUpdate` helps to monitor cluster health, cluster
    software versions, manage updates, and patch deployment.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '`CoreUpdate` 是 `Premium Managed Service` 的一部分，面向需要支持和基于 SLA 的支持的企业客户，以防在部署过程中遇到问题。`CoreUpdate`
    帮助监控集群健康、集群软件版本、管理更新和补丁部署。'
- en: '`CoreUpdates` provides a web interface and a command-line interface to view
    the versions running on each of the `CoreOS` instances and to schedule upgrades
    on them. All instances of the `CoreOS` can be logically distributed into multiple
    application groups, and upgrades can be managed individually for those applications.
    For instance, they can be configured to pick the upgrade/patch from different
    channels like stable/beta/alpha. They can be scheduled at different times and
    can have different metadata, like where to pick the package for upgrade/patch.
    During the upgrade process, progress of the upgrade is displayed and any error/information/warnings
    are displayed to take corrective actions.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '`CoreUpdate` 提供了一个 Web 界面和命令行界面，用于查看每个 `CoreOS` 实例上运行的版本，并对它们进行升级计划。所有的 `CoreOS`
    实例可以逻辑地分配到多个应用程序组中，升级可以单独管理。比如，它们可以配置为从不同的通道（如稳定版、测试版、开发版）获取升级/补丁。可以在不同的时间安排升级，并且可以有不同的元数据，例如，选择从哪个源获取升级/补丁包。在升级过程中，会显示升级进度，任何错误/信息/警告都会显示出来，以便采取纠正措施。'
- en: '`CoreUpdate` also provides a HTTP-based API to integrate software management
    with the developed application.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '`CoreUpdate` 还提供了一个基于 HTTP 的 API，用于将软件管理与开发的应用程序集成。'
- en: Dex
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Dex
- en: All of us have experienced user authentication in multiple ways, like when we
    log in to websites, log in to our computer, log in to social sites, and so on.
    There are a wide variety of authentication systems like local users being managed
    by a system admin for Linux or Microsoft Windows, Enterprise-wide Active Directory,
    or LDAP, or through identity providers such as Google, Outlook, Yahoo!, and Facebook.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们每个人都曾经历过多种用户认证方式，比如在登录网站时、登录计算机时、登录社交网站时等等。有很多种认证系统，例如由系统管理员为 Linux 或 Microsoft
    Windows 管理的本地用户，企业范围的 Active Directory 或 LDAP，或者通过身份提供者如 Google、Outlook、Yahoo!
    和 Facebook 等进行认证。
- en: As an application developer, **Dex** ([https://github.com/coreos/dex](https://github.com/coreos/dex))
    solves the problem of user authentication by providing a ready-to-use standard-based
    implementation and connectors for various authentication systems including local
    authentication. This makes it easier for the developer to concentrate on their
    business logic and trust that authentication is well taken care of.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 作为应用程序开发人员，**Dex** ([https://github.com/coreos/dex](https://github.com/coreos/dex))
    通过提供基于标准的现成实现和适用于各种认证系统（包括本地认证）的连接器，解决了用户认证问题。这使得开发人员可以更加专注于业务逻辑，并且信任认证已经得到妥善处理。
- en: Since Dex implementation is based on standard (**OpenID Connect (OIDC) Core
    spec**), it is language independent as the interfaces are well defined. Use a
    client library conforming to OIDC corresponding to the programming language and
    you are good to go.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Dex 实现基于标准的 (**OpenID Connect (OIDC) 核心规范**)，它是与语言无关的，因为接口已被很好地定义。只需使用符合
    OIDC 的客户端库（对应编程语言），就可以开始使用。
- en: There are different authentication mechanisms that can be used by integrating
    off-the-shelf connectors. If we have to draw a parallel, it is very much like
    a database connector. Currently, two connectors, local and OIDC connector, and
    more are getting developed. With local connector, the user can log in to the system
    using the authentication database maintained by Dex locally, like Linux user IDs
    and passwords. With OIDC connectors, users can be authenticated using another
    OIDC Identity Provider like Google or another `Dex` instance as Dex itself is
    an OIDC identity provider.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种认证机制可以通过集成现成的连接器来使用。如果我们要类比的话，这就像是数据库连接器。目前，已有本地连接器和 OIDC 连接器，更多的连接器正在开发中。使用本地连接器时，用户可以通过
    Dex 本地维护的认证数据库登录系统，如 Linux 用户 ID 和密码。使用 OIDC 连接器时，用户可以通过其他 OIDC 身份提供者（如 Google
    或另一个 `Dex` 实例）进行认证，因为 Dex 本身就是一个 OIDC 身份提供者。
- en: So, if you have a requirement for authentication in your system, explore Dex.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果你的系统需要认证，探索 Dex 可能会有帮助。
- en: sysdig
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: sysdig
- en: We are aware of commonly used debugging tools for Linux to monitor and take
    snapshots of system health. For example, if we want to check whether the machine
    is overloading its CPU or RAM, we use tools like `top` or `vmstat`. If we have
    to capture the packets over the interface, we use `wireshark` or `tcpdump`. Similarly,
    we use `iostat` to monitor the system IO devices.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们都熟悉用于 Linux 的常见调试工具，这些工具可以用来监控和拍摄系统健康状态的快照。例如，如果我们想检查机器是否超负荷使用 CPU 或 RAM，我们会使用
    `top` 或 `vmstat` 等工具。如果我们需要捕获接口上的数据包，我们会使用 `wireshark` 或 `tcpdump`。类似地，我们会使用 `iostat`
    来监控系统的 IO 设备。
- en: '`sysdig` provides integrated support for monitoring all the preceding system
    resources along with providing many more features. And most importantly, in our
    context it provides support for containers. We know that containers run in the
    host OS in separate namespaces. So the processes running inside containers are
    also visible to the native tools, say, for example, `ps`. In a container environment,
    the information related to the application is present in two levels: one at the
    host kernel level, for example process ID as the host kernel sees it, and the
    other at the container level, for example, the process ID inside the container.
    All native Linux tools give a host kernel view leaving it to the user to correlate
    information to find out which information pertains to the container and segregate
    information on a per-container basis. To get information as the container application
    sees it, Docker interfaces/commands are to be used. `sysdig` solves this problem.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '`sysdig`为监控上述所有系统资源提供了集成支持，同时还提供了更多功能。最重要的是，在我们的上下文中，它为容器提供了支持。我们知道，容器在宿主操作系统中运行在不同的命名空间中。因此，运行在容器内的进程对于本机工具（例如`ps`）也是可见的。在容器环境中，应用程序相关的信息存在两个层级：一个是宿主内核层级，例如，宿主内核看到的进程ID；另一个是容器级别，例如容器内的进程ID。所有本机Linux工具提供的是宿主内核视图，用户需要关联信息以找出哪些信息与容器相关，并按容器划分信息。为了获取容器应用程序视角下的信息，需要使用Docker接口/命令。`sysdig`解决了这个问题。'
- en: Let's take a hands-on approach to get a feel of what information `sysdig` provides.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过实践来感受一下`sysdig`提供的信息。
- en: The first step is to install and run `sysdig`. After we start the docker container
    for sysdig, we are taken to a shell where we can run the `sysdig` commands.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是安装并运行`sysdig`。当我们启动用于sysdig的docker容器时，会进入一个shell环境，在这里可以运行`sysdig`命令。
- en: '[PRE0]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Start a Docker container as daemon using the following command:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令以守护进程方式启动Docker容器：
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We will run some example commands to find out container-specific information.
    First, we will list the containers running on the machine both using the `docker
    ps` in another login window and using `sysdig`:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将运行一些示例命令来查找容器的特定信息。首先，我们将在另一个登录窗口使用`docker ps`以及使用`sysdig`列出机器上运行的容器：
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We see here that there are two containers running on the host machine: one
    container is for `sysdig` and the other is the `busybox` we started. Now, we will
    run the corresponding `sysdig` command:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里看到，宿主机上运行了两个容器：一个是`sysdig`容器，另一个是我们启动的`busybox`容器。现在，我们将运行相应的`sysdig`命令：
- en: '[PRE3]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The following command shows the cumulative CPU usage of the containers:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令显示容器的累积CPU使用情况：
- en: '[PRE4]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The output we get is as follows:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到的输出如下：
- en: '![sysdig](img/00040.jpeg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![sysdig](img/00040.jpeg)'
- en: Similarly, we can see a list of processes, its corresponding containers, and
    process ID (as seen by the host and as seen by the container at the global level)
    by using the following command. Note that the `-pc` flag indicates that the information
    is required in the container context. The same command can also be extended by
    providing a container name, and information is displayed only for that container.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，我们可以通过以下命令查看进程列表、其对应的容器和进程ID（主机看到的和容器在全局级别看到的）。请注意，`-pc`标志表示所需的信息是容器上下文中的信息。相同的命令也可以通过提供容器名称来扩展，信息仅显示该容器的内容。
- en: '[PRE5]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The output we get is as follows:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到的输出如下：
- en: '![sysdig](img/00041.jpeg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![sysdig](img/00041.jpeg)'
- en: By now, you would have got an idea of the utility of `sysdig`. Similar to the
    process and CPU information, it can provide a host of other features like monitoring
    networks, network IO, disk usage, trace traffic, and so on. And most of the monitoring
    can be done in a container context also by adding the –`pc` switch.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，您应该已经对`sysdig`的实用性有了一个大致的了解。与进程和CPU信息类似，它还可以提供其他许多功能，比如监控网络、网络IO、磁盘使用、追踪流量等。并且，大部分监控也可以通过添加`-pc`开关在容器上下文中进行。
- en: Competitive container orchestration mechanism
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 竞争性的容器编排机制
- en: 'In this section, we are going to see the other container orchestration mechanism
    currently available in the market. Some of these orchestration mechanisms can
    in fact be complementary to the CoreOS orchestration mechanism. As we have already
    seen in [Chapter 3](part0026_split_000.html#OPEK1-31555e2039a14139a7f00b384a5a2dd8
    "Chapter 3. Creating Your CoreOS Cluster and Managing the Cluster"), *Creating
    Your CoreOS Cluster and Managing the Cluster*, fleet acts as a cluster manager
    in CoreOS and instantiates the docker units/service in any one of the nodes in
    the cluster. Let us discuss the other orchestration mechanisms in detail in this
    chapter. Some of the key container orchestration mechanisms currently available
    are as follows:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨当前市场上其他可用的容器编排机制。其中一些编排机制实际上可以与 CoreOS 编排机制互补。正如我们在[第3章](part0026_split_000.html#OPEK1-31555e2039a14139a7f00b384a5a2dd8
    "第3章：创建你的 CoreOS 集群并管理集群")中已经看到的，*创建你的 CoreOS 集群并管理集群*，fleet 在 CoreOS 中充当集群管理器，并在集群中的任一节点上实例化
    docker 单元/服务。让我们在本章中详细讨论其他编排机制。目前可用的一些主要容器编排机制如下：
- en: Kubernetes
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes
- en: Apache Mesos
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Apache Mesos
- en: Swarm
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Swarm
- en: Kubernetes
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes
- en: '**Kubernetes** is an open source container orchestration infrastructure developed
    by Google for deploying containers or a group of containers in a server cluster.
    Kubernetes provides a way of deploying a group of containers as a single logical
    service. This group of containers has been termed **pod**. Apart from providing
    a mechanism for deploying an application or container, Kubernetes also provides
    way for scheduling, updating, maintaining, and scaling the containers in a cluster.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kubernetes** 是由 Google 开发的开源容器编排基础设施，用于在服务器集群中部署容器或一组容器。Kubernetes 提供了一种将一组容器作为一个逻辑服务进行部署的方式。这个容器组被称为
    **pod**。除了提供应用程序或容器部署的机制外，Kubernetes 还提供了调度、更新、维护和扩展集群中容器的方式。'
- en: 'Kubernetes operates over the pod rather than containers. A pod can contain
    a single container or a group of logically interrelated containers, as described
    earlier. Kubernetes consists of the following components:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 操作的是 pod 而不是容器。一个 pod 可以包含一个容器或一组逻辑上相互关联的容器，如前所述。Kubernetes 由以下组件组成：
- en: Kubernetes master
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 主节点
- en: Kubernetes nodes (Minion)
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 节点（Minion）
- en: Kubernetes pods
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes Pods
- en: Kubernetes services
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 服务
- en: 'The following diagram illustrates the components of Kubernetes:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了 Kubernetes 的组件：
- en: '![Kubernetes](img/00042.jpeg)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![Kubernetes](img/00042.jpeg)'
- en: Kubernetes components overview
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 组件概述
- en: Kubernetes master
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kubernetes 主节点
- en: 'As the name implies, **Kubernetes master** is the master node that controls
    other nodes and pods in the cluster. It is the control plane and provides the
    following services:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 顾名思义，**Kubernetes 主节点**是控制集群中其他节点和 pod 的主节点。它是控制平面，并提供以下服务：
- en: Placement of pods in the server
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pods 在服务器中的部署
- en: Replication control of various pods
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 各种 Pods 的复制控制
- en: Maintaining the state of the containers
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 维护容器的状态
- en: Providing the REST API for controlling the nodes, pods, and so on from the external
    world
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供用于从外部世界控制节点、Pods 等的 REST API
- en: Master Kubernetes runs apiserver, controller manager, and optionally the kubelet
    and proxy servers.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 主 Kubernetes 运行 apiserver、controller manager，并可选地运行 kubelet 和代理服务器。
- en: Kubernetes nodes
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kubernetes 节点
- en: '**Kubernetes nodes** are also called the minion. User applications are deployed
    as a container or docker containers in the minion. The Kubernetes nodes host important
    services of Kubernetes like kubelet and kube-proxy.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kubernetes 节点**也称为 Minion。用户应用程序作为容器或 docker 容器部署在 Minion 中。Kubernetes 节点托管着
    Kubernetes 的重要服务，如 kubelet 和 kube-proxy。'
- en: Kubelet is responsible for managing the pods at the node level. It acts as a
    primary node-agent.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: Kubelet 负责在节点级别管理 Pods。它充当主要的节点代理。
- en: kube-proxy or Kubernetes network proxy is an application that will manage services
    inside the Kubernetes nodes. This is also responsible for providing a kind of
    virtual IP for the application running in the nodes.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: kube-proxy 或 Kubernetes 网络代理是一个应用程序，负责管理 Kubernetes 节点中的服务。它还负责为在节点中运行的应用程序提供虚拟
    IP。
- en: Kubernetes pods
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kubernetes Pods
- en: '**Kubernetes pods** are a group of containers that are logically tightly coupled
    with each other and running inside the same Kubernetes nodes. The containers that
    are part of the same pods share resources like storage, networking, and so on.
    The following represents a pod:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kubernetes Pods** 是一组在逻辑上紧密耦合并运行在同一Kubernetes节点内的容器。属于同一Pod的容器共享存储、网络等资源。以下是一个Pod的表示：'
- en: '[PRE6]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Kubernetes service
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kubernetes服务
- en: '**Kubernetes service** is a group of pods that is running inside the cluster.
    Services provide the vital features that are required for any kind of pods in
    the cluster such as load-balancing, application service discovery, easy deployment,
    and so on. A service is described in JSON representation as follows:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kubernetes服务** 是在集群内运行的一组Pods。服务提供了集群中任何类型的Pods所需的关键功能，如负载均衡、应用服务发现、便捷部署等。服务的描述以JSON格式表示如下：'
- en: '[PRE7]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Now, we have seen the basics of Kubernetes. Let us look into how Kubernetes
    can be used as an orchestration framework for CoreOS docker/Rackt containers.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经了解了Kubernetes的基础知识。接下来，让我们看看Kubernetes如何作为CoreOS docker/Rackt容器的编排框架使用。
- en: CoreOS and Kubernetes
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CoreOS和Kubernetes
- en: Kubernetes can also be used to provide advanced cluster-wide orchestration in
    CoreOS using an etcd distributed key-value store. As Kubernetes is a powerful
    tool for container orchestration, which provides the essential features of a typical
    deployment such as automatic load-balancing, service discovery, and container
    replication, in a CoreOS environment, Kubernetes can be used as a container orchestration
    framework.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes也可以用于通过etcd分布式键值存储在CoreOS中提供高级集群级编排。由于Kubernetes是一个强大的容器编排工具，提供了典型部署所需的基本功能，如自动负载均衡、服务发现和容器复制，因此在CoreOS环境中，Kubernetes可以作为容器编排框架使用。
- en: One node inside the CoreOS cluster can act as a Kubernetes master, wherein you
    can run the apiserver and controller manager. All other nodes in the CoreOS cluster
    can act as a minion, wherein you can install and run kubelet and kube-proxy.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: CoreOS集群中的一个节点可以作为Kubernetes主节点，在其中运行apiserver和controller manager。CoreOS集群中的所有其他节点可以作为minion，在其中安装并运行kubelet和kube-proxy。
- en: Kubernetes can also be used to provide advanced cluster-wide orchestration in
    CoreOS using an etcd distributed key-value store.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes也可以通过etcd分布式键值存储，在CoreOS中提供高级集群级编排。
- en: Apache-Mesos
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Apache-Mesos
- en: '**Apache-Mesos** is a container cluster manager developed for very large clusters
    involving thousands of hosts. Mesos provides a distributed kernel that is running
    across different nodes in the cluster and provides APIs for the application to
    manage resources such as memory, CPU, disk, and scheduling these resources.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**Apache-Mesos** 是为涉及数千个主机的大型集群开发的容器集群管理器。Mesos提供一个分布式内核，跨集群中的不同节点运行，并提供API供应用程序管理资源，如内存、CPU、磁盘等，并调度这些资源。'
- en: 'The major components of Mesos are as follows:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: Mesos的主要组件如下：
- en: Mesos agent
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mesos代理
- en: Mesos master
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mesos主节点
- en: ZooKeeper
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ZooKeeper
- en: Mesos frameworks![Apache-Mesos](img/00043.jpeg)
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mesos框架![Apache-Mesos](img/00043.jpeg)
- en: Mesos component overview
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Mesos组件概述
- en: Mesos master
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Mesos主节点
- en: The **Mesos master** daemon runs in the master node that manages all the slave
    nodes or agents and the Mesos frameworks. The master takes care of sharing the
    resource to the frameworks based on the configured scheduling policy, which can
    either be strict priority or fair sharing.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '**Mesos主节点** 守护进程运行在主节点上，管理所有的从节点或代理以及Mesos框架。主节点根据配置的调度策略（可以是严格优先或公平共享）来处理资源分配给各个框架。'
- en: Mesos agent
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Mesos代理
- en: '**Mesos agent** is responsible for running the actual tasks. The agent reports
    to the master about the availability of the resources, which the master agent
    uses to allocate a particular task or framework to be ran on the agent.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '**Mesos代理** 负责运行实际的任务。代理会向主节点报告资源的可用性，主节点利用这些信息将特定任务或框架分配给代理运行。'
- en: ZooKeeper
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ZooKeeper
- en: In a typical Mesos deployment, there will be more than one master available
    to avoid single point of failure. In these cases, **ZooKeeper** is used to elect
    the leader among the available masters.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在典型的Mesos部署中，会有多个主节点可用，以避免单点故障。在这种情况下，**ZooKeeper** 用于在可用主节点之间选举领导者。
- en: Mesos frameworks
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Mesos框架
- en: '**Mesos frameworks** are the ones that run the tasks in the Mesos agent. The
    framework consists of two components: a scheduler that registers with the master
    and an executor that executes the tasks in the slave node. The master determines
    the number of resources to be allocated for the framework and allocates it to
    the framework. The scheduler picks the resource offered from this list.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '**Mesos 框架** 是在 Mesos 代理节点上运行任务的框架。该框架由两个组件组成：一个注册到主节点的调度器和一个在从节点执行任务的执行器。主节点决定为框架分配的资源数量，并将其分配给框架。调度器从资源列表中选择所提供的资源。'
- en: Swarm
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Swarm
- en: '**Swarm** is a native orchestration mechanism provided by Docker. Like other
    orchestration mechanisms, Swarm also consists of Swarm master and Swarm agent.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swarm** 是 Docker 提供的本地编排机制。像其他编排机制一样，Swarm 也由 Swarm 主节点和 Swarm 代理节点组成。'
- en: '**Swarm master** takes care of orchestrating the docker container to different
    Swarm agents. The master will be running in one or two nodes in the cluster whereas
    the **Swarm agent** will be running in all the nodes in the network.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swarm 主节点** 负责将 Docker 容器编排到不同的 Swarm 代理节点。主节点将在集群中的一个或两个节点上运行，而 **Swarm
    代理节点** 则在网络中的所有节点上运行。'
- en: Docker data volume management
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Docker 数据卷管理
- en: One of the main aspects of the container that we haven't discussed until now
    is the container's data volume management. In this section, we are going to see
    some basic concepts of container data volume management, some of the major problems
    in data volume management, and their solutions.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们直到现在才讨论容器的一个重要方面——容器的数据卷管理。在这一部分，我们将了解一些容器数据卷管理的基本概念、数据卷管理中的主要问题及其解决方案。
- en: 'As you may be aware, the docker container provides two different ways of managing
    the data volumes as:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所知，Docker 容器提供了两种不同的方式来管理数据卷：
- en: Data volumes
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据卷
- en: Data volume containers
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据卷容器
- en: The preceding two mechanisms provide various ways for storing the data in a
    persistent volume, a way to mount a host directory as a data volume, a way to
    mount a host file as a data volume, and so on. This works well until the containers
    are tied to a particular node/server in the cluster.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 前面提到的两种机制提供了多种方式来存储数据持久化卷，包括将主机目录挂载为数据卷、将主机文件挂载为数据卷等。这些方式在容器与集群中特定节点/服务器绑定时效果良好。
- en: '![Docker data volume management](img/00044.jpeg)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![Docker 数据卷管理](img/00044.jpeg)'
- en: Docker data volume management
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 数据卷管理
- en: When the container is moving from one server to another server, the data volume
    should also be moved. Typically, the data volume won't be moved when the container
    is moved from one node to another. This is because the docker/orchestration layer
    manages the containers and data volume separately.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 当容器从一个服务器迁移到另一个服务器时，数据卷也应该一起迁移。通常，当容器从一个节点迁移到另一个节点时，数据卷并不会随之迁移。这是因为 Docker/编排层分别管理容器和数据卷。
- en: Here comes the necessity of managing these two entities together. Flocker provides
    a way of managing both the docker container and docker volume together.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这就需要将这两个实体一起管理。Flocker 提供了一种同时管理 Docker 容器和 Docker 数据卷的方法。
- en: Flocker can be used along with container orchestration mechanisms such as Kubernetes
    and Mesos. Work has been going on to integrate Flocker with CoreOS, though some
    non-production-ready deployments are already available with CoreOS.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: Flocker 可以与容器编排机制如 Kubernetes 和 Mesos 一起使用。虽然与 CoreOS 的集成工作正在进行中，但已经有一些非生产环境的部署可以在
    CoreOS 上使用。
- en: Introduction to Flocker
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Flocker 介绍
- en: '**Flocker** is an open source container data volume manager to manage data
    volumes. In docker, a data volume is tied to a single server. However, in Flocker,
    the data volume, which is also called a dataset, is portable and hence can be
    used with any server in the cluster. Flocker manages the docker container along
    with the data volumes. Hence, when a container is moved from one server to another
    server in the cluster, the corresponding data volume will also be moved.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '**Flocker** 是一个开源容器数据卷管理器，用于管理数据卷。在 Docker 中，数据卷绑定到单个服务器。然而，在 Flocker 中，数据卷（也称为数据集）是可移植的，因此可以与集群中的任何服务器一起使用。Flocker
    管理 Docker 容器及其数据卷。因此，当容器从一个服务器移动到集群中的另一个服务器时，相应的数据卷也会一起移动。'
- en: '![Introduction to Flocker](img/00045.jpeg)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![Flocker 介绍](img/00045.jpeg)'
- en: Flocker cluster architecture
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: Flocker 集群架构
- en: 'The Flocker cluster architecture consists of the following components/services:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: Flocker 集群架构包括以下组件/服务：
- en: Flocker control services
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Flocker 控制服务
- en: Flocker agents
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Flocker 代理
- en: Flocker plugin for Docker
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker 的 Flocker 插件
- en: Flocker control services
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Flocker 控制服务
- en: In Kubernetes, we have Kubernetes master, and similarly the **Flocker control
    service** acts as a master and is installed on a single node in the cluster. It
    exposes the REST API to interface with an external application. This is the brain
    of Flocker and enables the user to monitor the state of the cluster.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 中，我们有 Kubernetes master，同样，**Flocker 控制服务**充当主节点，并安装在集群中的单个节点上。它暴露
    REST API 与外部应用进行接口。这是 Flocker 的大脑，使用户能够监控集群的状态。
- en: Flocker agents
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Flocker 代理
- en: '**Flocker agents** receive the commands from control services and make sure
    that the state of the Flocker agent matches with the desired state. When the local
    state is not matching the desired state, it calculates the actions necessary to
    make the local state match the desired configuration.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '**Flocker 代理**接收来自控制服务的命令，并确保 Flocker 代理的状态与期望状态一致。当本地状态与期望状态不匹配时，它会计算出所需的操作，以使本地状态与期望配置匹配。'
- en: Flocker plugin for Docker
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Docker 的 Flocker 插件
- en: '**Docker''s Flocker plugin** deploys a container along with the data volume
    without worrying about which server in the cluster the data volume is placed.
    Whenever the container is moved from one server to another, the plugin takes care
    of moving the data volume too. This makes sure that the data volume is running
    in any one node in the Flocker cluster.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '**Docker 的 Flocker 插件**会部署容器以及数据卷，而无需担心数据卷位于集群中的哪个服务器。每当容器从一个服务器移动到另一个服务器时，插件会确保数据卷也一起迁移。这确保了数据卷在
    Flocker 集群中的任何节点上运行。'
- en: Open Container Project
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开放容器项目
- en: As the different container technologies are being developed, there is a necessity
    of having a standard container format in order to provide interoperability and
    define the standard for the containers. In order to achieve this, the CoreOS team
    started working on a container standardization mechanism called *App Container*
    to define the standard container image format, runtime environment, and discovery
    protocol, to work toward the goal of a standard, portable shipping container for
    applications.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 随着不同的容器技术的开发，出现了需要标准化容器格式的需求，以提供互操作性并定义容器的标准。为了实现这一目标，CoreOS 团队开始研究一种容器标准化机制，称为
    *App Container*，以定义标准的容器镜像格式、运行时环境和发现协议，朝着标准化、可移植的应用程序运输容器目标迈进。
- en: 'Meanwhile, the **Open Container Project** (**OCP**) was formed by a large group
    of industry leaders to define the standard. The Open Container Project is hosted
    under Linux Foundation. CoreOS App Container also contributes to OCP and the latest
    specification of the OCP project can be found at the following link: [https://github.com/opencontainers/specs](https://github.com/opencontainers/specs)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，**开放容器项目**（**OCP**）由一大批行业领导者组成，旨在定义容器标准。开放容器项目由 Linux 基金会主办。CoreOS 的 App
    Container 也为 OCP 作出了贡献，OCP 项目的最新规范可以通过以下链接找到：[https://github.com/opencontainers/specs](https://github.com/opencontainers/specs)
- en: Summary
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: As CoreOS is a young and very promising operating system, a lot of developments
    are happening on daily basis. One of the major milestones of CoreOS in the recent
    past was that Google and CoreOS jointly announced a new project called Tectonic
    to offer IT infrastructure, which is completely container-based leveraging both
    CoreOS and Kubernetes. Tectonic is a commercial Kubernetes platform that combines
    the CoreOS stack with Kubernetes to bring a Google-style infrastructure to any
    cloud. Companies such as Rackspace, Salesforce, MemSQL, Atlassian, and Pivotal's
    Cloud Foundry have already deployed CoreOS. The future of CoreOS looks very bright
    as CoreOS is aiming to build next-generation IT infrastructure without increasing
    the complexity. As security is one of the major concerns in current IT infrastructure,
    one of the major goals of CoreOS is to enable the companies to run their applications
    securely and reliably in any environment, bringing a promising future for CoreOS.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 CoreOS 是一个年轻且极具潜力的操作系统，许多开发工作每天都在进行。其中一个最近的重大进展是，谷歌与 CoreOS 联合宣布了一项名为 Tectonic
    的新项目，旨在提供完全基于容器的 IT 基础设施，利用 CoreOS 和 Kubernetes 的优势。Tectonic 是一个商业化的 Kubernetes
    平台，将 CoreOS 堆栈与 Kubernetes 结合，为任何云环境提供类似谷歌的基础设施。像 Rackspace、Salesforce、MemSQL、Atlassian
    和 Pivotal 的 Cloud Foundry 等公司已经部署了 CoreOS。CoreOS 的未来非常光明，因为它的目标是构建下一代 IT 基础设施，同时不增加复杂性。由于安全性是当前
    IT 基础设施中的一个主要问题，CoreOS 的主要目标之一是让公司能够在任何环境中安全可靠地运行其应用，带来 CoreOS 光明的未来。
