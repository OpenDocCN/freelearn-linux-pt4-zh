- en: Chapter 8. Mesos Big Data Frameworks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter is a guide to deploy important big data processing frameworks,
    such as Hadoop, Spark, Storm, and Samza, on top of Mesos.
  prefs: []
  type: TYPE_NORMAL
- en: Hadoop on Mesos
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section will introduce Hadoop, explain how to set up the Hadoop stack on
    Mesos, and discuss the problems commonly encountered while setting up the stack.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to Hadoop
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Hadoop was developed by Mike Cafarella and Doug Cutting in 2006 to manage the
    distribution for the Nutch project. The project was named after Doug's son's toy
    elephant.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following modules make up the Apache Hadoop framework:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Hadoop Common**: This has the common libraries and utilities required by
    other modules'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hadoop Distributed File System** (**HDFS**): This is a distributed, scalable
    filesystem capable of storing petabytes of data on commodity hardware'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hadoop YARN**: This is a resource manager to manage cluster resources (similar
    to Mesos)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hadoop MapReduce**: This is a processing model for parallel data processing
    at scale'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MapReduce
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: MapReduce is a processing model using which large amounts of data can be processed
    in parallel on a distributed, commodity hardware-based infrastructure reliably
    and in a fault-tolerant way.
  prefs: []
  type: TYPE_NORMAL
- en: 'The word MapReduce is a combination of the Map and Reduce tasks, which are
    described here:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The Map Task**: In this step, an operation is performed on all the elements
    of the input dataset to transform it as needed (for example applying a filter
    condition)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The Reduce Task**: The next step uses the output generated by the map task
    as its input and applies an aggregate operation on it to generate the final output
    (for example, summing all values)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The scheduling, execution, and monitoring of the tasks is reliably handled by
    the framework without the application programmer having to worry about it.
  prefs: []
  type: TYPE_NORMAL
- en: Hadoop Distributed File System
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Based on **Google Filesystem** or **GFS**, Hadoop Distributed File System (HDFS)
    provides a scalable, distributed filesystem to store large amounts of data in
    a reliable, fault-tolerant way.
  prefs: []
  type: TYPE_NORMAL
- en: HDFS is based on a master/slave architecture, with the master consisting of
    a solitary **NameNode**, which handles the metadata of the filesystem, and single
    or multiple slave nodes, which store the data and are also called **DataNode**.
  prefs: []
  type: TYPE_NORMAL
- en: Each file in HDFS is divided into multiple blocks, with each of these blocks
    being stored in DataNode. NameNode is responsible for maintaining information
    regarding which block is present in which DataNode. Operations such as read/write
    are handled by DataNode along with block management tasks such as the creation,
    removal, and replication of instructions from NameNode.
  prefs: []
  type: TYPE_NORMAL
- en: Interaction is through a shell, where a set of commands can be used to communicate
    with the filesystem.
  prefs: []
  type: TYPE_NORMAL
- en: '![Hadoop Distributed File System](img/B05186_08_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Setting up Hadoop on Mesos
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section will explain how to set up Hadoop on Mesos. An existing Hadoop
    distribution can also be set up on top of Mesos. To run Hadoop on Mesos, our Hadoop
    distribution must contain `Hadoop-Mesos-0.1.0.jar` (the version at the time of
    writing this book). This is required for any Hadoop distribution that uses a protobuf
    version higher than 2.5.0\. We will also set a few configuration properties in
    order to complete the setup, as will be explained subsequently. Note that at the
    time of writing this chapter, YARN and MRv2 are not supported.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s follow the steps mentioned here:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open up the Terminal on your cluster and fire up the following commands to
    set up Hadoop on Mesos:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Once the previous command is executed, it will create the `target/Hadoop-Mesos-0.1.0.jar`
    jar.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'One thing to note here is that if you have an older version of Mesos and need
    to build the jar against this version, then you will have to edit the `pom.xml`
    file with the appropriate version. We can change the following versions in the
    `pom.xml` file:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we can download a Hadoop distribution. As you can see here, we have compiled
    `Hadoop-Mesos jar` with the `hadoop-2.5.0-mr1-cdh5.2.0` version. It can be downloaded
    with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, we need to copy `Hadoop-Mesos-0.1.0.jar` into the Hadoop `share/Hadoop/common/lib`
    directory. This is done as shown here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We now need to update the symlinks of the CHD5 distribution to point to the
    correct version (as it includes both MRv1 and MRv2 (YARN)) using the following
    set of commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'All the configurations are now ready. We can archive and upload the Hadoop
    distribution to our existing Hadoop Distributed File System (HDFS) system, where
    it can be accessed by Mesos. Take a look at the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Once done, we can configure `JobTracker` to launch each `TaskTracker` node
    on Mesos by editing the `mapred-site.xml` file, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: A few properties in the `mapred-site.xml` file are Mesos-specific, such as `mapred.Mesos.master`
    or `mapred.Mesos.executor.uri`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We can now start the `JobTracker` service by including the Mesos native library
    using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: An advanced configuration guide
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: More details regarding the configuration settings in Mesos can be found at [https://github.com/mesos/hadoop/blob/master/configuration.md](https://github.com/mesos/hadoop/blob/master/configuration.md).
  prefs: []
  type: TYPE_NORMAL
- en: Common problems and solutions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The two most common problems encountered while setting up Hadoop on Mesos are:'
  prefs: []
  type: TYPE_NORMAL
- en: Inability to set the Mesos library in the environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Build failures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A solution for both these problems is described here:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Missing the Mesos library in the environment:** We will get an exception
    stack when we forget to set the Mesos library in the environment at the following
    URL: [https://github.com/mesos/hadoop/issues/25](https://github.com/mesos/hadoop/issues/25).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This can be resolved by setting the following environment variables:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**The Maven build failure:** We won''t be able to build the package on some
    occasions due to build failures. One example of a build failure can be found here:
    [https://github.com/mesos/hadoop/issues/64](https://github.com/mesos/hadoop/issues/64).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This can be avoided by removing the older Maven dependencies from the environment
    and rebuilding it.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Here''s an example:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Spark on Mesos
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Apache **Spark** is a powerful open source processing engine built around speed,
    ease of use, and sophisticated analytics. It is currently one of the fastest growing
    big data technologies and is used by several leading companies in production.
  prefs: []
  type: TYPE_NORMAL
- en: Interestingly, Apache Spark was first started as a research project in 2009
    at AmpLab, UC Berkeley, to prove that a distributed processing framework leveraging
    memory resources can run atop Apache Mesos. It was open sourced in 2010, entered
    the Apache incubator in 2013, and became an Apache top-level project in 2014\.
    In its short existence, Apache Spark has managed to capture the attention of the
    developer community and is slowly finding its way into the lexicon of business
    decision makers as well. This, along with the fact that it is now in production
    in over 5000 organizations, speaks volumes about its versatility and utility.
  prefs: []
  type: TYPE_NORMAL
- en: Why Spark
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With earlier distributed parallel computation frameworks such as **Map Reduce**,
    each computation step had to be read from and written to disk. For instance, consider
    the standard word count example of counting the number of occurrences of each
    word that appears in a set of text files. The first step here would be a map task
    that reads the text files from disk (breaking it up into smaller chunks if necessary),
    takes one line from it, splits it into individual words, and then outputs a key
    value pair of `<<word>`,`1>` (note that an intermediate combiner step can add
    the occurrences for each word from each mapper while it is still in memory for
    more efficiency). A number of mappers are spawned across the entire cluster to
    efficiently perform the preceding task in parallel over all the lines from each
    text file. The final output of all these map tasks is written to disk. In the
    next step, the reduce task needs to collect the same words in a single machine
    in order to add them all up and produce the final count. For this, there is a
    shuffle operation that reads the intermediate output generated from the map step
    and ensures that all the output for one word is sent to one and only one reducer.
    After the reduce step, the final output is collected and written to disk.
  prefs: []
  type: TYPE_NORMAL
- en: For iterative workloads, which involve multiple repetitions of the various preceding
    steps, this would lead to a lot of disk I/O. The mappers would read the first
    set of inputs and write out the intermediate output to disk. Then the reducers
    would read the intermediate output from disk and write out their outputs to disk,
    which would then be read by the mappers of stage 2, and so on. Disk reads are
    very slow, and for long, iterative computations, they would often be the bottleneck
    instead of the CPUs. This was one of the basic problems that Spark intended to
    resolve. Many iterative or latency-sensitive applications (interactive querying
    or stream processing, for example) weren't being adequately solved by batch processing
    frameworks such as Map Reduce due to fundamental design constraints. Spark set
    out to solve this problem by coming up with a novel architecture.
  prefs: []
  type: TYPE_NORMAL
- en: To minimize disk I/O, the creators of Spark decided to look at memory as a potential
    alternative. Trends demonstrated that memory cost was falling exponentially with
    each passing year. Affordable memory meant that more memory could be packed into
    commodity servers without bloating up the costs. In order to effectively handle
    the emerging class of business applications, such as iterative machine learning,
    interactive data mining, or stream processing, a memory-based framework also had
    to develop elegant solutions to the common problems of fault tolerance and partition
    control. For example, fault tolerance (or more accurately, high availability)
    can be achieved by replicating data across different machines or by updating the
    state at regular intervals in a database. However, this is a very time-consuming
    approach that utilizes a lot of network bandwidth and would have resulted in much
    slower job execution, something that the framework sought to solve in the first
    place. Partition control and having the flexibility to keep all the data required
    by a task as close to it as possible was also very important as without it, a
    high execution speed could not be achieved.
  prefs: []
  type: TYPE_NORMAL
- en: To tackle all these problems, a new higher-level abstraction called **Resilient
    Distributed Datasets** (**RDDs**) was developed. These new data structures allowed
    programmers to explicitly cache them in memory, place them in the desired partitions
    for optimal performance, and rebuild it based on a blueprint of how it was constructed
    if it is lost. Programmers need to simply write a driver program that encapsulates
    the logical workflow of their application and initiates the execution of the various
    comprising operations in parallel across the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'The two main abstractions that Spark provides are:'
  prefs: []
  type: TYPE_NORMAL
- en: Resilient distributed datasets (or RDDs), as mentioned before
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The processing operations (map, filter, join, for each, collect, and so on)
    have to be applied on these datasets to generate the required output.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: RDDs also permit the application of the same operation/function to multiple
    data points in parallel. By logging the process used to build a dataset (lineage),
    it can effectively reconstruct the dataset at even partition-level granularity
    in case there is a failure by leveraging this stored blueprint.
  prefs: []
  type: TYPE_NORMAL
- en: '![Why Spark](img/B05186_08_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Spark has been shown to be 10 times faster on disk and 100 times faster in-memory
    than MapReduce for certain kinds of applications. It has also brought about a
    drastic reduction in writing the logical workflow itself, with even complex application
    programs now no longer extending beyond a few 100 lines of code instead of 1,000
    and 10,000 lines earlier.
  prefs: []
  type: TYPE_NORMAL
- en: Logistic regression in Hadoop and Spark
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Spark proves to be particularly useful in iterative machine learning, stream
    processing, and interactive querying use cases, in which the enhanced processing
    speeds and ease of programming brought by it is harnessed to drive more and more
    business or organizational value. Source: [http://spark.apache.org](http://spark.apache.org).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Logistic regression in Hadoop and Spark](img/B05186_08_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Spark's generality not only makes it a great fit for the use cases mentioned
    earlier but also for the traditional batch applications. Spark's versatility also
    extends to the fact that it offers rich, expressive APIs in Python, Java, Scala,
    and SQL among others, along with other inbuilt libraries. It is also highly interoperable
    and can work off all standard data storage tools, such as HDFS and Cassandra.
  prefs: []
  type: TYPE_NORMAL
- en: The Spark ecosystem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Spark ecosystem comprises multiple complementary components that are designed
    to work with each other seamlessly. The versatile and general structure of Spark
    allows for specialized libraries geared towards specific workloads to be built
    on top of it, such as **Spark SQL** to query structured data through a SQL interface,
    **MLib** for machine learning, **Spark Streaming** to process data streams in
    motion, and **GraphX** for graph computations. Underpinning each of these components
    is the Spark core engine that defines the basic structure of Spark including its
    core abstraction, the resilient distributed dataset (or RDD).
  prefs: []
  type: TYPE_NORMAL
- en: 'Spark''s design principle of high interoperability and several tightly coupled
    components feeding off a common core has multiple advantages. All the higher-level
    libraries in the ecosystem are directly able to leverage any feature additions
    or improvements made to the base framework. The total cost of ownership reduces
    as only one software stack needs to be set up and maintained instead of having
    multiple disparate systems. It also acts as a unified data analysis stack for
    varied use cases, reducing the overall learning curve and deployment, testing,
    and running cycle. Applications that involve a combination of processing streaming
    data, applying machine learning algorithms, and querying the final output through
    a SQL interface can be easily built using all the different libraries of Spark.
    Moreover, the enhanced speed and lower infrastructure costs provided by Spark
    has unlocked newer use cases as well, ranging from processing streaming data in
    real time to developing applications involving complex machine learning algorithms.
    Source: [http://spark.apache.org](http://spark.apache.org).'
  prefs: []
  type: TYPE_NORMAL
- en: '![The Spark ecosystem](img/B05186_08_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The components of the Spark ecosystem are described in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Spark Core
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Spark Core is the fundamental component that comprises the general execution
    engine and covers the core Spark functionalities. It includes features such as
    memory management, failure recovery, connectivity, or interoperability with different
    storage systems, job scheduling, and rich, expressive APIs (including the one
    that contains the definition for RDDs) to construct application workflows.
  prefs: []
  type: TYPE_NORMAL
- en: Spark SQL
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Spark SQL is the component that allows analysts to use SQL to analyze and query
    structured datasets. It supports multiple data formats, including CSV, Parquet,
    JSON, and AVRO. As mentioned before, the integrated design of Spark also permits
    data engineers to intermingle complex analytics with Spark SQL queries, thus feeding
    the output of one component to others within a unified application through the
    common RDD abstraction.
  prefs: []
  type: TYPE_NORMAL
- en: Another important development in this area was the introduction of the DataFrame
    API (inspired by R and Python DataFrame), which was introduced in Spark 1.3\.
    DataFrames are optimized, table-like, column-organized distributed datasets that
    allow a vast subsection of analysts and data scientists familiar with this concept
    to have the ability to leverage them using Spark. They can be generated from a
    lot of sources, such as structured files, Hive tables, or other RDDs, and can
    be operated upon using a provided DSL or domain-specific language.
  prefs: []
  type: TYPE_NORMAL
- en: Spark Streaming
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Spark Streaming is a component that allows the processing of streaming data
    or data in motion, such as machine logs, server logs, social media feeds, and
    so on in real time. Its model for processing live streams of data is a logical
    extension of how the core API processes batch data. It operates on data in a minibatch
    mode; that is, it collects data for a window of time, applies the processing logic
    on this *minibatch*, then collects the next minibatch, and so on. This makes it
    extremely easy to reuse code written for batch workflows and apply them to a streaming
    data scenario.
  prefs: []
  type: TYPE_NORMAL
- en: MLlib
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Spark comes with a scalable machine learning library containing a rich set of
    distributed algorithms for a wide range of use cases, such as classification,
    clustering, collaborative filtering, decomposition, and regression. It also includes
    a few deeper primitives, such as **gradient descent optimization**.
  prefs: []
  type: TYPE_NORMAL
- en: GraphX
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The GraphX component is useful for operating on and processing graphs (for example,
    social network graphs) through a rich set of operators, such as mapVertices and
    subgraph, as well as standard algorithms for graph analytics (PageRank), community
    detection (triangle counting), and structured prediction (Gibbs sampling). The
    Spark API is extended (similarly to Spark SQL and Spark Streaming) to develop
    directed graphs in which customized properties can be assigned to each edge and
    vertex.
  prefs: []
  type: TYPE_NORMAL
- en: Spark's extendibility has also fostered the development of a multitude of third-party
    packages, connectors, and other libraries that further enhance its utility. Among
    some of the more popular ones are SparkR, launch scripts for different cloud infrastructure
    providers such as GCE developed by Sigmoid, connectors for Redshift and Elasticsearch,
    and a job execution server.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up Spark on Mesos
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section explains how we can run Spark on top of Mesos in detail. Similar
    to the Hadoop setup, we will need the Spark binary package uploaded to a place
    accessible by Mesos and the Spark driver program configured to connect to Mesos.
  prefs: []
  type: TYPE_NORMAL
- en: Another alternative is to install Spark at the same location in all the Mesos
    slaves and set `Spark.Mesos.executor.home` to point to this location.
  prefs: []
  type: TYPE_NORMAL
- en: The following steps can be performed to upload the Spark binary to a location
    accessible by Mesos.
  prefs: []
  type: TYPE_NORMAL
- en: 'Whenever Mesos runs a task on the Mesos slave for the first time, the slave
    must have a Spark binary package to run the Spark Mesos executor backend (which
    comes with Spark). A location that is accessible by Mesos can be HDFS, HTTP, S3,
    and so on. We can download the latest version of Spark Binary from the official
    website by navigating to the following website:'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://spark.apache.org/downloads.html](http://spark.apache.org/downloads.html).'
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, at the time of writing this book, Spark''s latest version is 1.6.0,
    and we can download and upload it to HDFS with the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: In the driver program, we can now give the master URL as the Mesos master URL,
    which will be in the `Mesos://master-host:5050` form for a single master Mesos
    cluster. It could be similar to `Mesos://zk://host1:2181,host2:2181` for a multimaster
    Mesos cluster.
  prefs: []
  type: TYPE_NORMAL
- en: There are two modes of submitting a Spark job to Mesos, which are explained
    in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Submitting jobs in client mode
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The Spark Mesos framework is launched directly on the client machine, and it
    waits for the driver output in client mode. We need to set a few Mesos-specific
    configurations in the `Spark-env.sh` file to interact with Mesos, which are listed
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, when starting a Spark application on the cluster, pass the `Mesos://`
    URL as the master while creating `SparkContext`. Here''s an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Submitting jobs in cluster mode
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the cluster mode, the driver is launched in the cluster, and the client can
    find the results of the driver on the Mesos Web UI. We need to start `MesosClusterDispatcher`
    to use the cluster mode. The script to start `MesosClusterDispatcher` is located
    under the `sbin/start-Mesos-dispatcher.sh` script, which takes in the Mesos master
    URL. We can then submit the jobs to Mesos cluster by specifying the master URL
    to the URL of `MesosClusterDispatcher` (such as `Mesos://dispatcher:7077`). The
    driver status will be available on the Spark cluster Web UI.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Note that the jars or Python files that are passed to Spark-submit should be
    URIs reachable by Mesos slaves, as the Spark driver doesn't automatically upload
    local jars.
  prefs: []
  type: TYPE_NORMAL
- en: An advanced configuration guide
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Spark currently supports two modes to run on Mesos: **coarse-grained** **mode**
    and **fine-grained** **mode**:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Coarse-grained** **mode**: The coarse-grained mode is the default mode, and
    it will launch one long-running Spark task on each Mesos machine and dynamically
    schedule its own minitasks within it. This mode is usually used when we require
    a much lower startup overhead, but it comes with the cost of reserving the Mesos
    resources for the complete duration of the application. We can control the maximum
    number of resources that Spark acquires in the coarse-grained mode by setting
    the `Spark.cores.max` property in `SparkConf`. By default, it acquires all the
    resources available in the cluster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fine-grained** **mode**: In the fine-grained mode, each Spark task runs as
    a separate Mesos task. This allows better sharing of the cluster resources among
    other frameworks at a very fine granularity, where each application gets additional
    or fewer machines as it ramps up and down, depending on the workload. The drawback
    is that it comes with an additional overhead in launching each task. This mode
    is not preferred for low-latency requirements, such as interactive queries or
    serving web requests. To run in the fine-grained mode, we can turn the coarse-grained
    mode off by setting the following property:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Spark configuration properties
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Mesos-specific Spark configuration properties can be found at [http://spark.apache.org/docs/latest/running-on-mesos.html#configuration](http://spark.apache.org/docs/latest/running-on-mesos.html#configuration).
  prefs: []
  type: TYPE_NORMAL
- en: Storm on Mesos
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Storm** is a real-time **distributed data processing system** for processing
    data coming in at high velocities. It can process millions of records per second
    and is particularly useful for applications where millisecond-level latency is
    essential (for example, security threat detection, fraud detection, operational
    monitoring, and so on).'
  prefs: []
  type: TYPE_NORMAL
- en: The Storm architecture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A typical Storm cluster has three types of nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Nimbus or master node**: This is responsible for submitting and distributing
    the computations for execution apart from handling tasks such as launching slave
    nodes and monitoring the execution'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ZooKeeper node**: This is responsible for coordinating the cluster'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Supervisor node**: This is responsible for starting and stopping slave nodes
    based on the instructions sent by the Nimbus node![The Storm architecture](img/B05186_08_05.jpg)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Some important terms used in Storm are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Tuples**: This is an ordered list of elements'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Streams**: This is a sequence of tuples'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Spouts**: These are sources of streams in a computation (for example, the
    Twitter API)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bolts**: These are process input streams and produce output streams'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Topologies**: These are the overall calculation represented visually as a
    network of spouts and bolts, as follows:![The Storm architecture](img/B05186_08_06.jpg)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up Storm on Mesos
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This section explains how we can integrate Storm with the Mesos cluster resource
    manager. Let''s follow the steps mentioned here:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can first explore the Storm on Mesos repository by executing the following
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can now edit the configuration file listed in `conf/Storm.yaml`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Edit the properties according to the cluster that we have and execute the following
    command to start the nimbus:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We need to start the UI on the same machine as the nimbus with the following
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Topologies are submitted to a Storm/Mesos cluster in the exact same way that
    they are submitted to a regular Storm cluster. Storm/Mesos provides resource isolation
    between topologies. So, you don't need to worry about topologies interfering with
    one another.
  prefs: []
  type: TYPE_NORMAL
- en: Running a sample topology
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Once nimbus is running, we can launch one of the Storm-starter topologies with
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Here, we specified the nimbus host and thrift port as parameters.
  prefs: []
  type: TYPE_NORMAL
- en: An advanced configuration guide
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If we want to build the release against a different version of Mesos or Storm,
    then we can use the `build-release.sh` script to download the appropriate version
    by executing the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Here `x.x.x` and `y.y.y` are the appropriate versions of Storm and Mesos that
    we will build against. This command will build a Mesos executor package.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `bin/build-release.sh` script takes in the following subcommands:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Subcommand | Usage |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `main` | This is used to build a Storm package with the Mesos scheduler.
    The output of this command can be used as the package for `mesos.executor.uri`.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `clean` | This attempts to clean the working files and directories created
    when building. |'
  prefs: []
  type: TYPE_TB
- en: '| `downloadStormRelease` | This is a utility function to download the Storm
    release tarball for the targeted Storm release. Set the `MIRROR` environment variable
    to configure the download mirror. |'
  prefs: []
  type: TYPE_TB
- en: '| `mvnPackage` | This runs the Maven targets necessary to build the Storm Mesos
    framework. |'
  prefs: []
  type: TYPE_TB
- en: '| `prePackage` | This prepares the working directories to be able to package
    the Storm Mesos framework and is an optional argument specifying the Storm release
    tarball to package against. |'
  prefs: []
  type: TYPE_TB
- en: '| `package` | This packages the Storm Mesos framework. |'
  prefs: []
  type: TYPE_TB
- en: '| `dockerImage` | This builds a Docker image from the current code. |'
  prefs: []
  type: TYPE_TB
- en: '| `help` | This prints out usage information about the `build-release.sh` script.
    |'
  prefs: []
  type: TYPE_TB
- en: Deploying Storm through Marathon
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can run Storm on Mesos with Marathon easily by setting the `MESOS_MASTER_ZK`
    environment variable to point to our ZooKeeper node of the cluster. The repository
    also includes a script, `bin/run-with-marathon.sh`, which sets the required parameters
    and starts the UI and nimbus. As Storm writes stateful data to the disk, we need
    to make sure that `storm.local.dir config` is set. We can run this from Marathon
    by submitting the following JSON data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'We can save the preceding JSON code as `storm-mesos.json` and send a `curl`
    request to the Marathon API endpoint to deploy with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Reference: [https://github.com/mesos/storm](https://github.com/mesos/storm).'
  prefs: []
  type: TYPE_NORMAL
- en: Samza on Mesos
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Samza is an open source distributed stream processing framework originally
    developed at LinkedIn. It has the following features:'
  prefs: []
  type: TYPE_NORMAL
- en: A simple API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: State management
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fault tolerance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Durability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scalability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pluggability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Processor isolation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important concepts of Samza
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Some concepts in Samza are described in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Streams
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Samza processes streams of data—for example, website clickstreams, server logs,
    or any other event data. Messages can be added and read from a data stream. Multiple
    frameworks can access the same data stream and can partition the data based on
    the keys present in the message.
  prefs: []
  type: TYPE_NORMAL
- en: '![Streams](img/B05186_08_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Jobs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A Samza job is the computation logic that reads data from input streams, applies
    some transformations to it, and outputs the resultant messages to a bunch of output
    streams.
  prefs: []
  type: TYPE_NORMAL
- en: Partitions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Every stream is split into single or multiple partitions. Every partition is
    an ordered sequence of messages.
  prefs: []
  type: TYPE_NORMAL
- en: '![Partitions](img/B05186_08_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Tasks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A job is subdivided into multiple tasks for the parallelism of the computation.
    Every task reads data from a single partition for each input stream of the job.
  prefs: []
  type: TYPE_NORMAL
- en: '![Tasks](img/B05186_08_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Dataflow graphs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Multiple jobs can be composed to develop a dataflow graph, in which the nodes
    are datastreams and the edges are the jobs.
  prefs: []
  type: TYPE_NORMAL
- en: '![Dataflow graphs](img/B05186_08_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Setting up Samza on Mesos
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This topic covers how we can run Samza jobs on a Mesos cluster. We will package
    the Samza jobs in a tarball for the sake of simplicity. Samza also supports packaging
    it in a Docker image.
  prefs: []
  type: TYPE_NORMAL
- en: 'At the time of writing this book, Samza on Mesos is in its early stages and
    hasn''t been tested in a production environment to the best of our knowledge.
    Let''s follow the steps mentioned here to set up Samza on Mesos:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We first need to deploy the `samza-mesos` jar in the environment. For this,
    we can clone the repository and build it with the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Once this is done, we can start importing the Maven dependency to our projects,
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The deployment of Samza through Marathon
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Samza jobs can be deployed through Marathon. Each Samza job is a Mesos framework,
    which creates one Mesos task for each of the Samza containers. It is easier to
    deploy the Samza jobs on Mesos through Marathon, as described here.
  prefs: []
  type: TYPE_NORMAL
- en: 'Samza jobs are usually deployed in a tarball, which should contain the following
    as the top-level directories:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Bin`: This contains the standard Samza distributed shell scripts'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Config`: This should be with your job `.properties` file(s)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Lib`: This contains all the `.jar` files'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, let''s take a look at how we can submit a Samza job to Marathon to deploy
    it on Mesos. The JSON request for the same will look similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Note that here, `mesos.package.path` is the parameter pointing to the Samza
    tarball, which is kept in HDFS.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can save the preceding JSON record to a file called `samza-job.json` and
    submit it to Marathon using the following `curl` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: An advanced configuration guide
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The supported configuration properties are listed at [https://github.com/Banno/samza-mesos](https://github.com/Banno/samza-mesos).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter introduced the reader to some important big data processing frameworks
    and covered topics such as the setup, configuration, and management of these frameworks
    on a distributed infrastructure using Mesos.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will discuss some of the important big data storage
    frameworks that are currently supported by Mesos (either in a beta or production-ready
    state), such as Cassandra, Elasticsearch, and Kafka, and understand how these
    can be set up and configured on Mesos.
  prefs: []
  type: TYPE_NORMAL
