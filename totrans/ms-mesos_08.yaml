- en: Chapter 8. Mesos Big Data Frameworks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章 Mesos大数据框架
- en: This chapter is a guide to deploy important big data processing frameworks,
    such as Hadoop, Spark, Storm, and Samza, on top of Mesos.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章是关于如何在Mesos上部署重要的大数据处理框架（如Hadoop、Spark、Storm和Samza）的指南。
- en: Hadoop on Mesos
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Hadoop on Mesos
- en: This section will introduce Hadoop, explain how to set up the Hadoop stack on
    Mesos, and discuss the problems commonly encountered while setting up the stack.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将介绍Hadoop，解释如何在Mesos上设置Hadoop栈，并讨论设置栈时常遇到的问题。
- en: Introduction to Hadoop
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Hadoop简介
- en: Hadoop was developed by Mike Cafarella and Doug Cutting in 2006 to manage the
    distribution for the Nutch project. The project was named after Doug's son's toy
    elephant.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Hadoop是由Mike Cafarella和Doug Cutting于2006年开发的，用于管理Nutch项目的分发。该项目的名称来源于Doug儿子玩具大象的名字。
- en: 'The following modules make up the Apache Hadoop framework:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 以下模块构成了Apache Hadoop框架：
- en: '**Hadoop Common**: This has the common libraries and utilities required by
    other modules'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Hadoop Common**：包含其他模块所需的公共库和工具。'
- en: '**Hadoop Distributed File System** (**HDFS**): This is a distributed, scalable
    filesystem capable of storing petabytes of data on commodity hardware'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Hadoop分布式文件系统**（**HDFS**）：这是一个分布式、可扩展的文件系统，能够在普通硬件上存储PB级的数据。'
- en: '**Hadoop YARN**: This is a resource manager to manage cluster resources (similar
    to Mesos)'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Hadoop YARN**：这是一个资源管理器，用于管理集群资源（类似于Mesos）。'
- en: '**Hadoop MapReduce**: This is a processing model for parallel data processing
    at scale'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Hadoop MapReduce**：这是一种大规模并行数据处理的模型。'
- en: MapReduce
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: MapReduce
- en: MapReduce is a processing model using which large amounts of data can be processed
    in parallel on a distributed, commodity hardware-based infrastructure reliably
    and in a fault-tolerant way.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: MapReduce是一种处理模型，可以在分布式的普通硬件基础设施上并行处理大量数据，可靠且具有容错能力。
- en: 'The word MapReduce is a combination of the Map and Reduce tasks, which are
    described here:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: MapReduce这个词是Map和Reduce任务的组合，这里描述了它们：
- en: '**The Map Task**: In this step, an operation is performed on all the elements
    of the input dataset to transform it as needed (for example applying a filter
    condition)'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Map任务**：在此步骤中，对输入数据集的所有元素执行操作，根据需要进行转换（例如应用过滤条件）。'
- en: '**The Reduce Task**: The next step uses the output generated by the map task
    as its input and applies an aggregate operation on it to generate the final output
    (for example, summing all values)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Reduce任务**：下一步使用map任务生成的输出作为输入，并对其应用聚合操作，生成最终输出（例如，对所有值求和）。'
- en: The scheduling, execution, and monitoring of the tasks is reliably handled by
    the framework without the application programmer having to worry about it.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 任务的调度、执行和监控由框架可靠地处理，应用程序员无需担心这些问题。
- en: Hadoop Distributed File System
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Hadoop分布式文件系统
- en: Based on **Google Filesystem** or **GFS**, Hadoop Distributed File System (HDFS)
    provides a scalable, distributed filesystem to store large amounts of data in
    a reliable, fault-tolerant way.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 基于**Google文件系统**（**GFS**），Hadoop分布式文件系统（HDFS）提供了一个可扩展、分布式的文件系统，能够以可靠、容错的方式存储大量数据。
- en: HDFS is based on a master/slave architecture, with the master consisting of
    a solitary **NameNode**, which handles the metadata of the filesystem, and single
    or multiple slave nodes, which store the data and are also called **DataNode**.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: HDFS基于主/从架构，主节点由单一的**NameNode**组成，负责处理文件系统的元数据，且一个或多个从节点负责存储数据，并被称为**DataNode**。
- en: Each file in HDFS is divided into multiple blocks, with each of these blocks
    being stored in DataNode. NameNode is responsible for maintaining information
    regarding which block is present in which DataNode. Operations such as read/write
    are handled by DataNode along with block management tasks such as the creation,
    removal, and replication of instructions from NameNode.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: HDFS中的每个文件都被分成多个块，每个块存储在DataNode中。NameNode负责维护关于每个块在哪个DataNode中的信息。像读写操作这样的任务由DataNode处理，同时也负责块管理任务，如根据NameNode的指令进行创建、删除和复制。
- en: Interaction is through a shell, where a set of commands can be used to communicate
    with the filesystem.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 交互通过一个shell进行，在shell中可以使用一组命令与文件系统进行通信。
- en: '![Hadoop Distributed File System](img/B05186_08_01.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![Hadoop分布式文件系统](img/B05186_08_01.jpg)'
- en: Setting up Hadoop on Mesos
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在Mesos上设置Hadoop
- en: This section will explain how to set up Hadoop on Mesos. An existing Hadoop
    distribution can also be set up on top of Mesos. To run Hadoop on Mesos, our Hadoop
    distribution must contain `Hadoop-Mesos-0.1.0.jar` (the version at the time of
    writing this book). This is required for any Hadoop distribution that uses a protobuf
    version higher than 2.5.0\. We will also set a few configuration properties in
    order to complete the setup, as will be explained subsequently. Note that at the
    time of writing this chapter, YARN and MRv2 are not supported.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将解释如何在 Mesos 上设置 Hadoop。现有的 Hadoop 分发包也可以在 Mesos 上进行设置。要在 Mesos 上运行 Hadoop，我们的
    Hadoop 分发包必须包含`Hadoop-Mesos-0.1.0.jar`（本书撰写时的版本）。对于任何使用 protobuf 版本高于 2.5.0 的
    Hadoop 分发包，这都是必需的。我们还需要设置一些配置属性，以完成设置，具体如下所述。请注意，在本章节撰写时，YARN 和 MRv2 尚不支持。
- en: 'Let''s follow the steps mentioned here:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 请按照这里提到的步骤操作：
- en: 'Open up the Terminal on your cluster and fire up the following commands to
    set up Hadoop on Mesos:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开集群中的终端，并运行以下命令以在 Mesos 上设置 Hadoop：
- en: '[PRE0]'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Once the previous command is executed, it will create the `target/Hadoop-Mesos-0.1.0.jar`
    jar.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行前述命令后，将会创建`target/Hadoop-Mesos-0.1.0.jar`文件。
- en: 'One thing to note here is that if you have an older version of Mesos and need
    to build the jar against this version, then you will have to edit the `pom.xml`
    file with the appropriate version. We can change the following versions in the
    `pom.xml` file:'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 需要注意的一点是，如果您使用的是较旧版本的 Mesos，并且需要根据该版本构建 jar，那么您需要编辑 `pom.xml` 文件，选择适当的版本。我们可以在
    `pom.xml` 文件中更改以下版本：
- en: '[PRE1]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now, we can download a Hadoop distribution. As you can see here, we have compiled
    `Hadoop-Mesos jar` with the `hadoop-2.5.0-mr1-cdh5.2.0` version. It can be downloaded
    with the following command:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以下载 Hadoop 分发包。如您所见，我们已使用`hadoop-2.5.0-mr1-cdh5.2.0`版本编译了`Hadoop-Mesos
    jar`。可以通过以下命令下载：
- en: '[PRE2]'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now, we need to copy `Hadoop-Mesos-0.1.0.jar` into the Hadoop `share/Hadoop/common/lib`
    directory. This is done as shown here:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们需要将`Hadoop-Mesos-0.1.0.jar`复制到 Hadoop 的`share/Hadoop/common/lib`目录中。具体操作如下：
- en: '[PRE3]'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We now need to update the symlinks of the CHD5 distribution to point to the
    correct version (as it includes both MRv1 and MRv2 (YARN)) using the following
    set of commands:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在需要更新 CHD5 分发包的符号链接，以指向正确的版本（因为它包含 MRv1 和 MRv2（YARN）），可以使用以下命令：
- en: '[PRE4]'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'All the configurations are now ready. We can archive and upload the Hadoop
    distribution to our existing Hadoop Distributed File System (HDFS) system, where
    it can be accessed by Mesos. Take a look at the following commands:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 所有配置已准备好。我们可以将 Hadoop 分发包归档并上传到现有的 Hadoop 分布式文件系统（HDFS）中，这样 Mesos 就可以访问它。请查看以下命令：
- en: '[PRE5]'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Once done, we can configure `JobTracker` to launch each `TaskTracker` node
    on Mesos by editing the `mapred-site.xml` file, as follows:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成后，我们可以通过编辑`mapred-site.xml`文件来配置`JobTracker`，以便在 Mesos 上启动每个`TaskTracker`节点，如下所示：
- en: '[PRE6]'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: A few properties in the `mapred-site.xml` file are Mesos-specific, such as `mapred.Mesos.master`
    or `mapred.Mesos.executor.uri`.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`mapred-site.xml` 文件中的一些属性是 Mesos 特有的，例如 `mapred.Mesos.master` 或 `mapred.Mesos.executor.uri`。'
- en: 'We can now start the `JobTracker` service by including the Mesos native library
    using the following command:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在可以通过以下命令启动 `JobTracker` 服务，并包括 Mesos 原生库：
- en: '[PRE7]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: An advanced configuration guide
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高级配置指南
- en: More details regarding the configuration settings in Mesos can be found at [https://github.com/mesos/hadoop/blob/master/configuration.md](https://github.com/mesos/hadoop/blob/master/configuration.md).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 有关 Mesos 配置设置的更多详细信息，请参见 [https://github.com/mesos/hadoop/blob/master/configuration.md](https://github.com/mesos/hadoop/blob/master/configuration.md)。
- en: Common problems and solutions
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 常见问题及解决方案
- en: 'The two most common problems encountered while setting up Hadoop on Mesos are:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Mesos 上设置 Hadoop 时最常遇到的两个问题是：
- en: Inability to set the Mesos library in the environment
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无法在环境中设置 Mesos 库
- en: Build failures
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建失败
- en: 'A solution for both these problems is described here:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个问题的解决方案在这里进行了描述：
- en: '**Missing the Mesos library in the environment:** We will get an exception
    stack when we forget to set the Mesos library in the environment at the following
    URL: [https://github.com/mesos/hadoop/issues/25](https://github.com/mesos/hadoop/issues/25).'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**环境中缺少 Mesos 库：** 如果我们忘记在环境中设置 Mesos 库，会在以下网址遇到异常堆栈：[https://github.com/mesos/hadoop/issues/25](https://github.com/mesos/hadoop/issues/25)。'
- en: 'This can be resolved by setting the following environment variables:'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这可以通过设置以下环境变量来解决：
- en: '[PRE8]'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '**The Maven build failure:** We won''t be able to build the package on some
    occasions due to build failures. One example of a build failure can be found here:
    [https://github.com/mesos/hadoop/issues/64](https://github.com/mesos/hadoop/issues/64).'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Maven 构建失败：** 在某些情况下，我们可能无法构建包，因为构建失败。一个构建失败的示例可以在这里找到：[https://github.com/mesos/hadoop/issues/64](https://github.com/mesos/hadoop/issues/64)。'
- en: This can be avoided by removing the older Maven dependencies from the environment
    and rebuilding it.
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以通过从环境中删除较旧的 Maven 依赖项并重新构建来避免这种情况。
- en: 'Here''s an example:'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是一个示例：
- en: '[PRE9]'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Spark on Mesos
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Mesos 上的 Spark
- en: Apache **Spark** is a powerful open source processing engine built around speed,
    ease of use, and sophisticated analytics. It is currently one of the fastest growing
    big data technologies and is used by several leading companies in production.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Apache **Spark** 是一个强大的开源处理引擎，围绕速度、易用性和复杂分析构建。它目前是增长最快的大数据技术之一，并被多家领先公司在生产中使用。
- en: Interestingly, Apache Spark was first started as a research project in 2009
    at AmpLab, UC Berkeley, to prove that a distributed processing framework leveraging
    memory resources can run atop Apache Mesos. It was open sourced in 2010, entered
    the Apache incubator in 2013, and became an Apache top-level project in 2014\.
    In its short existence, Apache Spark has managed to capture the attention of the
    developer community and is slowly finding its way into the lexicon of business
    decision makers as well. This, along with the fact that it is now in production
    in over 5000 organizations, speaks volumes about its versatility and utility.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，Apache Spark 最初是在 2009 年由 UC Berkeley 的 AmpLab 作为一个研究项目启动的，目的是证明一个利用内存资源的分布式处理框架可以在
    Apache Mesos 上运行。它于 2010 年开源，2013 年进入 Apache 孵化器，并于 2014 年成为 Apache 顶级项目。在其短暂的存在期间，Apache
    Spark 成功吸引了开发者社区的关注，并且正在慢慢进入商业决策者的词汇中。此外，它目前已在超过 5000 个组织中投入生产，这充分说明了它的多功能性和实用性。
- en: Why Spark
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么选择 Spark
- en: With earlier distributed parallel computation frameworks such as **Map Reduce**,
    each computation step had to be read from and written to disk. For instance, consider
    the standard word count example of counting the number of occurrences of each
    word that appears in a set of text files. The first step here would be a map task
    that reads the text files from disk (breaking it up into smaller chunks if necessary),
    takes one line from it, splits it into individual words, and then outputs a key
    value pair of `<<word>`,`1>` (note that an intermediate combiner step can add
    the occurrences for each word from each mapper while it is still in memory for
    more efficiency). A number of mappers are spawned across the entire cluster to
    efficiently perform the preceding task in parallel over all the lines from each
    text file. The final output of all these map tasks is written to disk. In the
    next step, the reduce task needs to collect the same words in a single machine
    in order to add them all up and produce the final count. For this, there is a
    shuffle operation that reads the intermediate output generated from the map step
    and ensures that all the output for one word is sent to one and only one reducer.
    After the reduce step, the final output is collected and written to disk.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在早期的分布式并行计算框架（如 **Map Reduce**）中，每个计算步骤都必须从磁盘中读取并写入。例如，考虑一个标准的词频计数示例，计算一组文本文件中每个单词出现的次数。这里的第一步是一个映射任务，它从磁盘读取文本文件（如果需要的话，将其分成更小的块），从中取出一行，将其拆分成单独的单词，然后输出一个键值对
    `<<word>`,`1>`（注意，一个中间合并步骤可以在每个映射器内存中将每个单词的出现次数合并，从而提高效率）。在整个集群中会启动多个映射器，来并行高效地处理来自每个文本文件的所有行。所有这些映射任务的最终输出会写入磁盘。在下一步中，减少任务需要将相同的单词收集到一台机器中，以便将它们全部加起来并生成最终计数。为此，有一个洗牌操作，它读取从映射步骤生成的中间输出，并确保一个单词的所有输出都发送到一个且仅一个
    reducer。经过减少步骤后，最终输出会被收集并写入磁盘。
- en: For iterative workloads, which involve multiple repetitions of the various preceding
    steps, this would lead to a lot of disk I/O. The mappers would read the first
    set of inputs and write out the intermediate output to disk. Then the reducers
    would read the intermediate output from disk and write out their outputs to disk,
    which would then be read by the mappers of stage 2, and so on. Disk reads are
    very slow, and for long, iterative computations, they would often be the bottleneck
    instead of the CPUs. This was one of the basic problems that Spark intended to
    resolve. Many iterative or latency-sensitive applications (interactive querying
    or stream processing, for example) weren't being adequately solved by batch processing
    frameworks such as Map Reduce due to fundamental design constraints. Spark set
    out to solve this problem by coming up with a novel architecture.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 对于涉及多次重复前述步骤的迭代工作负载，这将导致大量的磁盘I/O。映射器将读取第一组输入，并将中间输出写入磁盘。然后，减速器将从磁盘读取中间输出，并将它们的输出写入磁盘，然后由第2阶段的映射器读取，并以此类推。磁盘读取速度非常慢，对于长时间的迭代计算，它们通常会成为瓶颈，而不是CPU。这是Spark旨在解决的基本问题之一。许多迭代或延迟敏感的应用程序（例如交互式查询或流处理）由于基本设计约束，并未得到批处理框架（如Map
    Reduce）充分解决。Spark通过提出一种新颖的架构来解决这个问题。
- en: To minimize disk I/O, the creators of Spark decided to look at memory as a potential
    alternative. Trends demonstrated that memory cost was falling exponentially with
    each passing year. Affordable memory meant that more memory could be packed into
    commodity servers without bloating up the costs. In order to effectively handle
    the emerging class of business applications, such as iterative machine learning,
    interactive data mining, or stream processing, a memory-based framework also had
    to develop elegant solutions to the common problems of fault tolerance and partition
    control. For example, fault tolerance (or more accurately, high availability)
    can be achieved by replicating data across different machines or by updating the
    state at regular intervals in a database. However, this is a very time-consuming
    approach that utilizes a lot of network bandwidth and would have resulted in much
    slower job execution, something that the framework sought to solve in the first
    place. Partition control and having the flexibility to keep all the data required
    by a task as close to it as possible was also very important as without it, a
    high execution speed could not be achieved.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 为了最小化磁盘I/O，Spark的创建者决定将内存视为一个潜在的替代方案。趋势表明，随着每年的过去，内存成本呈指数级下降。经济实惠的内存意味着可以将更多内存打包到商品服务器中，而不会增加成本。为了有效处理新兴的商业应用类别，例如迭代机器学习、交互式数据挖掘或流处理，内存为基础的框架还必须开发出对容错和分区控制常见问题的优雅解决方案。例如，容错（或更精确地说是高可用性）可以通过在不同的机器上复制数据或者在数据库中定期更新状态来实现。然而，这是一种非常耗时的方法，利用了大量的网络带宽，并且会导致作业执行速度大大降低，这正是该框架首先要解决的问题。分区控制和能够尽可能地保持任务所需的所有数据靠近它非常重要，因为没有这一点，就无法实现高执行速度。
- en: To tackle all these problems, a new higher-level abstraction called **Resilient
    Distributed Datasets** (**RDDs**) was developed. These new data structures allowed
    programmers to explicitly cache them in memory, place them in the desired partitions
    for optimal performance, and rebuild it based on a blueprint of how it was constructed
    if it is lost. Programmers need to simply write a driver program that encapsulates
    the logical workflow of their application and initiates the execution of the various
    comprising operations in parallel across the cluster.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决所有这些问题，开发了一种新的更高级别的抽象称为**弹性分布式数据集**（**RDDs**）。这些新的数据结构允许程序员将它们显式地缓存到内存中，将它们放置在所需的分区以获得最佳性能，并且可以根据其构建蓝图重新构建它们，以防数据丢失。程序员只需编写一个驱动程序，封装其应用程序的逻辑工作流，并在集群中并行执行各种组成操作。
- en: 'The two main abstractions that Spark provides are:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: Spark提供的两个主要抽象是：
- en: Resilient distributed datasets (or RDDs), as mentioned before
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 弹性分布式数据集（或RDDs），如前所述。
- en: The processing operations (map, filter, join, for each, collect, and so on)
    have to be applied on these datasets to generate the required output.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 需要在这些数据集上应用处理操作（map、filter、join、for each、collect等），以生成所需的输出。
- en: RDDs also permit the application of the same operation/function to multiple
    data points in parallel. By logging the process used to build a dataset (lineage),
    it can effectively reconstruct the dataset at even partition-level granularity
    in case there is a failure by leveraging this stored blueprint.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: RDD还允许将相同的操作/功能并行地应用于多个数据点。通过记录构建数据集的过程（谱系），它可以有效地在发生故障时，通过利用这个存储的蓝图重新构建数据集，甚至在分区级别进行恢复。
- en: '![Why Spark](img/B05186_08_02.jpg)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![为什么选择Spark](img/B05186_08_02.jpg)'
- en: Spark has been shown to be 10 times faster on disk and 100 times faster in-memory
    than MapReduce for certain kinds of applications. It has also brought about a
    drastic reduction in writing the logical workflow itself, with even complex application
    programs now no longer extending beyond a few 100 lines of code instead of 1,000
    and 10,000 lines earlier.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: Spark已被证明在磁盘上的速度比MapReduce快10倍，在内存中则快100倍，适用于某些类型的应用程序。它还大大减少了编写逻辑工作流的复杂性，即使是复杂的应用程序程序，现在也不再需要超过几百行代码，而不再是之前的1,000行或10,000行。
- en: Logistic regression in Hadoop and Spark
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Hadoop和Spark中的逻辑回归
- en: 'Spark proves to be particularly useful in iterative machine learning, stream
    processing, and interactive querying use cases, in which the enhanced processing
    speeds and ease of programming brought by it is harnessed to drive more and more
    business or organizational value. Source: [http://spark.apache.org](http://spark.apache.org).'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: Spark在迭代式机器学习、流处理和交互式查询等应用场景中特别有用，它通过增强的处理速度和编程简便性，助力驱动越来越多的业务或组织价值。来源：[http://spark.apache.org](http://spark.apache.org)。
- en: '![Logistic regression in Hadoop and Spark](img/B05186_08_03.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![Hadoop和Spark中的逻辑回归](img/B05186_08_03.jpg)'
- en: Spark's generality not only makes it a great fit for the use cases mentioned
    earlier but also for the traditional batch applications. Spark's versatility also
    extends to the fact that it offers rich, expressive APIs in Python, Java, Scala,
    and SQL among others, along with other inbuilt libraries. It is also highly interoperable
    and can work off all standard data storage tools, such as HDFS and Cassandra.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: Spark的通用性不仅使其非常适合前面提到的用例，而且也适用于传统的批处理应用程序。Spark的多功能性还体现在它提供了丰富且表达力强的API，支持Python、Java、Scala和SQL等多种语言，并且拥有其他内置库。它还具有很高的互操作性，能够与所有标准的数据存储工具兼容，如HDFS和Cassandra。
- en: The Spark ecosystem
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Spark生态系统
- en: The Spark ecosystem comprises multiple complementary components that are designed
    to work with each other seamlessly. The versatile and general structure of Spark
    allows for specialized libraries geared towards specific workloads to be built
    on top of it, such as **Spark SQL** to query structured data through a SQL interface,
    **MLib** for machine learning, **Spark Streaming** to process data streams in
    motion, and **GraphX** for graph computations. Underpinning each of these components
    is the Spark core engine that defines the basic structure of Spark including its
    core abstraction, the resilient distributed dataset (or RDD).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Spark生态系统包括多个互补的组件，这些组件旨在无缝协作。Spark的多功能和通用结构使得可以在其基础上构建针对特定工作负载的专用库，如**Spark
    SQL**用于通过SQL接口查询结构化数据，**MLib**用于机器学习，**Spark Streaming**用于处理动态数据流，以及**GraphX**用于图计算。支撑这些组件的是Spark核心引擎，它定义了Spark的基本结构，包括其核心抽象——弹性分布式数据集（或RDD）。
- en: 'Spark''s design principle of high interoperability and several tightly coupled
    components feeding off a common core has multiple advantages. All the higher-level
    libraries in the ecosystem are directly able to leverage any feature additions
    or improvements made to the base framework. The total cost of ownership reduces
    as only one software stack needs to be set up and maintained instead of having
    multiple disparate systems. It also acts as a unified data analysis stack for
    varied use cases, reducing the overall learning curve and deployment, testing,
    and running cycle. Applications that involve a combination of processing streaming
    data, applying machine learning algorithms, and querying the final output through
    a SQL interface can be easily built using all the different libraries of Spark.
    Moreover, the enhanced speed and lower infrastructure costs provided by Spark
    has unlocked newer use cases as well, ranging from processing streaming data in
    real time to developing applications involving complex machine learning algorithms.
    Source: [http://spark.apache.org](http://spark.apache.org).'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: Spark 高度互操作性设计原则以及多个紧密耦合的组件共享一个共同核心的方式具有多种优势。生态系统中的所有高级库都可以直接利用对基础框架所做的任何功能添加或改进。拥有总拥有成本的降低，因为只需要设置和维护一个软件栈，而不是多个独立的系统。它还作为一个统一的数据分析栈，适用于多种使用场景，减少了整体的学习曲线、部署、测试和运行周期。涉及流数据处理、应用机器学习算法和通过
    SQL 接口查询最终输出的应用程序，可以通过使用 Spark 的所有不同库轻松构建。此外，Spark 提供的加速性能和较低的基础设施成本也解锁了新的使用场景，从实时处理流数据到开发涉及复杂机器学习算法的应用程序。来源：[http://spark.apache.org](http://spark.apache.org)。
- en: '![The Spark ecosystem](img/B05186_08_04.jpg)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![Spark 生态系统](img/B05186_08_04.jpg)'
- en: The components of the Spark ecosystem are described in the following sections.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: Spark 生态系统的各个组件在以下章节中进行了描述。
- en: Spark Core
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Spark 核心
- en: Spark Core is the fundamental component that comprises the general execution
    engine and covers the core Spark functionalities. It includes features such as
    memory management, failure recovery, connectivity, or interoperability with different
    storage systems, job scheduling, and rich, expressive APIs (including the one
    that contains the definition for RDDs) to construct application workflows.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: Spark Core 是基础组件，包含了通用执行引擎，并涵盖了 Spark 的核心功能。它包括内存管理、故障恢复、与不同存储系统的连接或互操作性、作业调度以及丰富、表达力强的
    API（包括定义 RDD 的 API）来构建应用程序工作流等功能。
- en: Spark SQL
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Spark SQL
- en: Spark SQL is the component that allows analysts to use SQL to analyze and query
    structured datasets. It supports multiple data formats, including CSV, Parquet,
    JSON, and AVRO. As mentioned before, the integrated design of Spark also permits
    data engineers to intermingle complex analytics with Spark SQL queries, thus feeding
    the output of one component to others within a unified application through the
    common RDD abstraction.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: Spark SQL 是使分析师可以使用 SQL 分析和查询结构化数据集的组件。它支持多种数据格式，包括 CSV、Parquet、JSON 和 AVRO。如前所述，Spark
    的集成设计还允许数据工程师将复杂的分析与 Spark SQL 查询交织在一起，从而通过公共 RDD 抽象将一个组件的输出传递给统一应用程序中的其他组件。
- en: Another important development in this area was the introduction of the DataFrame
    API (inspired by R and Python DataFrame), which was introduced in Spark 1.3\.
    DataFrames are optimized, table-like, column-organized distributed datasets that
    allow a vast subsection of analysts and data scientists familiar with this concept
    to have the ability to leverage them using Spark. They can be generated from a
    lot of sources, such as structured files, Hive tables, or other RDDs, and can
    be operated upon using a provided DSL or domain-specific language.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 该领域的另一个重要发展是引入了 DataFrame API（灵感来自 R 和 Python 的 DataFrame），该 API 于 Spark 1.3
    中引入。DataFrame 是优化的、表格型的、按列组织的分布式数据集，允许大量熟悉此概念的分析师和数据科学家能够在 Spark 中利用它们。它们可以从许多来源生成，如结构化文件、Hive
    表或其他 RDD，并且可以使用提供的领域特定语言（DSL）进行操作。
- en: Spark Streaming
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Spark Streaming
- en: Spark Streaming is a component that allows the processing of streaming data
    or data in motion, such as machine logs, server logs, social media feeds, and
    so on in real time. Its model for processing live streams of data is a logical
    extension of how the core API processes batch data. It operates on data in a minibatch
    mode; that is, it collects data for a window of time, applies the processing logic
    on this *minibatch*, then collects the next minibatch, and so on. This makes it
    extremely easy to reuse code written for batch workflows and apply them to a streaming
    data scenario.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: Spark Streaming 是一个组件，允许实时处理流数据或移动中的数据，如机器日志、服务器日志、社交媒体信息流等。它处理实时数据流的模型是核心 API
    处理批量数据的逻辑扩展。它以小批量模式处理数据；也就是说，它收集一个时间窗口内的数据，在此小批量上应用处理逻辑，然后收集下一个小批量，依此类推。这使得将为批处理工作流编写的代码重用于流数据场景变得非常容易。
- en: MLlib
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: MLlib
- en: Spark comes with a scalable machine learning library containing a rich set of
    distributed algorithms for a wide range of use cases, such as classification,
    clustering, collaborative filtering, decomposition, and regression. It also includes
    a few deeper primitives, such as **gradient descent optimization**.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: Spark 配备了一个可扩展的机器学习库，包含丰富的分布式算法，适用于多种使用场景，如分类、聚类、协同过滤、分解和回归。它还包括一些更深层次的原语，如**梯度下降优化**。
- en: GraphX
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: GraphX
- en: The GraphX component is useful for operating on and processing graphs (for example,
    social network graphs) through a rich set of operators, such as mapVertices and
    subgraph, as well as standard algorithms for graph analytics (PageRank), community
    detection (triangle counting), and structured prediction (Gibbs sampling). The
    Spark API is extended (similarly to Spark SQL and Spark Streaming) to develop
    directed graphs in which customized properties can be assigned to each edge and
    vertex.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: GraphX 组件对于处理图形（例如社交网络图）非常有用，通过一组丰富的操作符，如 mapVertices 和 subgraph，以及用于图形分析（PageRank）、社区检测（三角形计数）和结构预测（吉布斯采样）的标准算法。Spark
    API 被扩展（类似于 Spark SQL 和 Spark Streaming）来开发有向图，其中可以为每个边和顶点分配自定义属性。
- en: Spark's extendibility has also fostered the development of a multitude of third-party
    packages, connectors, and other libraries that further enhance its utility. Among
    some of the more popular ones are SparkR, launch scripts for different cloud infrastructure
    providers such as GCE developed by Sigmoid, connectors for Redshift and Elasticsearch,
    and a job execution server.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: Spark 的可扩展性也促进了大量第三方包、连接器和其他库的发展，进一步增强了其实用性。其中一些更受欢迎的包括 SparkR、由 Sigmoid 开发的用于不同云基础设施提供商（如
    GCE）的启动脚本、用于 Redshift 和 Elasticsearch 的连接器，以及作业执行服务器。
- en: Setting up Spark on Mesos
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Mesos 上设置 Spark
- en: This section explains how we can run Spark on top of Mesos in detail. Similar
    to the Hadoop setup, we will need the Spark binary package uploaded to a place
    accessible by Mesos and the Spark driver program configured to connect to Mesos.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 本节详细解释了如何在 Mesos 上运行 Spark。与 Hadoop 配置类似，我们需要将 Spark 二进制包上传到 Mesos 可访问的位置，并配置
    Spark 驱动程序程序以连接到 Mesos。
- en: Another alternative is to install Spark at the same location in all the Mesos
    slaves and set `Spark.Mesos.executor.home` to point to this location.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种选择是在所有 Mesos 从属节点上安装 Spark，并设置 `Spark.Mesos.executor.home` 指向此位置。
- en: The following steps can be performed to upload the Spark binary to a location
    accessible by Mesos.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤可以用来将 Spark 二进制包上传到一个 Mesos 可访问的位置。
- en: 'Whenever Mesos runs a task on the Mesos slave for the first time, the slave
    must have a Spark binary package to run the Spark Mesos executor backend (which
    comes with Spark). A location that is accessible by Mesos can be HDFS, HTTP, S3,
    and so on. We can download the latest version of Spark Binary from the official
    website by navigating to the following website:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 每当 Mesos 在 Mesos 从属节点上首次运行任务时，从属节点必须拥有一个 Spark 二进制包才能运行 Spark Mesos 执行器后端（该后端随
    Spark 一起提供）。Mesos 可以访问的位置可以是 HDFS、HTTP、S3 等。我们可以通过访问以下网站从官方网站下载最新版本的 Spark 二进制包：
- en: '[http://spark.apache.org/downloads.html](http://spark.apache.org/downloads.html).'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://spark.apache.org/downloads.html](http://spark.apache.org/downloads.html)。'
- en: 'For example, at the time of writing this book, Spark''s latest version is 1.6.0,
    and we can download and upload it to HDFS with the following commands:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在写这本书时，Spark 的最新版本是 1.6.0，我们可以使用以下命令将其下载并上传到 HDFS：
- en: '[PRE10]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: In the driver program, we can now give the master URL as the Mesos master URL,
    which will be in the `Mesos://master-host:5050` form for a single master Mesos
    cluster. It could be similar to `Mesos://zk://host1:2181,host2:2181` for a multimaster
    Mesos cluster.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在驱动程序中，我们现在可以将 master URL 设置为 Mesos master URL，对于单 master Mesos 集群，它将是 `Mesos://master-host:5050`
    的形式。对于多 master Mesos 集群，它可能类似于 `Mesos://zk://host1:2181,host2:2181`。
- en: There are two modes of submitting a Spark job to Mesos, which are explained
    in the following sections.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 向 Mesos 提交 Spark 作业有两种模式，下面的章节将解释这两种模式。
- en: Submitting jobs in client mode
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在客户端模式下提交作业
- en: 'The Spark Mesos framework is launched directly on the client machine, and it
    waits for the driver output in client mode. We need to set a few Mesos-specific
    configurations in the `Spark-env.sh` file to interact with Mesos, which are listed
    here:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: Spark Mesos 框架直接在客户端机器上启动，并且在客户端模式下等待驱动程序的输出。我们需要在 `Spark-env.sh` 文件中设置一些与 Mesos
    交互的 Mesos 特定配置，这些配置列在这里：
- en: '[PRE11]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now, when starting a Spark application on the cluster, pass the `Mesos://`
    URL as the master while creating `SparkContext`. Here''s an example:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在集群上启动 Spark 应用时，创建 `SparkContext` 时将 `Mesos://` URL 作为 master。下面是一个示例：
- en: '[PRE12]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Submitting jobs in cluster mode
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在集群模式下提交作业
- en: In the cluster mode, the driver is launched in the cluster, and the client can
    find the results of the driver on the Mesos Web UI. We need to start `MesosClusterDispatcher`
    to use the cluster mode. The script to start `MesosClusterDispatcher` is located
    under the `sbin/start-Mesos-dispatcher.sh` script, which takes in the Mesos master
    URL. We can then submit the jobs to Mesos cluster by specifying the master URL
    to the URL of `MesosClusterDispatcher` (such as `Mesos://dispatcher:7077`). The
    driver status will be available on the Spark cluster Web UI.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在集群模式下，驱动程序在集群中启动，客户端可以在 Mesos Web UI 上查看驱动程序的结果。我们需要启动 `MesosClusterDispatcher`
    才能使用集群模式。启动 `MesosClusterDispatcher` 的脚本位于 `sbin/start-Mesos-dispatcher.sh`，该脚本需要传入
    Mesos master URL。然后，我们可以通过指定 `MesosClusterDispatcher` 的 URL（例如 `Mesos://dispatcher:7077`）将作业提交到
    Mesos 集群。驱动程序状态将在 Spark 集群 Web UI 上显示。
- en: 'Here''s an example:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个示例：
- en: '[PRE13]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Note that the jars or Python files that are passed to Spark-submit should be
    URIs reachable by Mesos slaves, as the Spark driver doesn't automatically upload
    local jars.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，传递给 Spark-submit 的 jars 或 Python 文件应该是 Mesos slave 可访问的 URI，因为 Spark 驱动程序不会自动上传本地的
    jars。
- en: An advanced configuration guide
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 高级配置指南
- en: 'Spark currently supports two modes to run on Mesos: **coarse-grained** **mode**
    and **fine-grained** **mode**:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: Spark 当前支持两种在 Mesos 上运行的模式：**粗粒度** **模式** 和 **细粒度** **模式**：
- en: '**Coarse-grained** **mode**: The coarse-grained mode is the default mode, and
    it will launch one long-running Spark task on each Mesos machine and dynamically
    schedule its own minitasks within it. This mode is usually used when we require
    a much lower startup overhead, but it comes with the cost of reserving the Mesos
    resources for the complete duration of the application. We can control the maximum
    number of resources that Spark acquires in the coarse-grained mode by setting
    the `Spark.cores.max` property in `SparkConf`. By default, it acquires all the
    resources available in the cluster.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**粗粒度** **模式**：粗粒度模式是默认模式，它会在每个 Mesos 机器上启动一个长时间运行的 Spark 任务，并在其中动态调度自己的子任务。这个模式通常用于需要较低启动开销的场景，但它的代价是需要在应用程序整个持续时间内保留
    Mesos 资源。我们可以通过在 `SparkConf` 中设置 `Spark.cores.max` 属性来控制 Spark 在粗粒度模式下获取的最大资源数量。默认情况下，它会获取集群中所有可用的资源。'
- en: '**Fine-grained** **mode**: In the fine-grained mode, each Spark task runs as
    a separate Mesos task. This allows better sharing of the cluster resources among
    other frameworks at a very fine granularity, where each application gets additional
    or fewer machines as it ramps up and down, depending on the workload. The drawback
    is that it comes with an additional overhead in launching each task. This mode
    is not preferred for low-latency requirements, such as interactive queries or
    serving web requests. To run in the fine-grained mode, we can turn the coarse-grained
    mode off by setting the following property:'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**细粒度** **模式**：在细粒度模式下，每个 Spark 任务都作为一个独立的 Mesos 任务运行。这可以更精细地共享集群资源，在工作负载增加或减少时，每个应用可以获得更多或更少的机器。缺点是每个任务启动时会有额外的开销。此模式不适用于低延迟要求的场景，如交互式查询或
    Web 请求服务。要运行细粒度模式，我们可以通过设置以下属性来关闭粗粒度模式：'
- en: '[PRE14]'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Spark configuration properties
  id: totrans-118
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Spark 配置属性
- en: Mesos-specific Spark configuration properties can be found at [http://spark.apache.org/docs/latest/running-on-mesos.html#configuration](http://spark.apache.org/docs/latest/running-on-mesos.html#configuration).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: Mesos 特定的 Spark 配置属性可以在 [http://spark.apache.org/docs/latest/running-on-mesos.html#configuration](http://spark.apache.org/docs/latest/running-on-mesos.html#configuration)
    中找到。
- en: Storm on Mesos
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Storm on Mesos
- en: '**Storm** is a real-time **distributed data processing system** for processing
    data coming in at high velocities. It can process millions of records per second
    and is particularly useful for applications where millisecond-level latency is
    essential (for example, security threat detection, fraud detection, operational
    monitoring, and so on).'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '**Storm** 是一个实时的 **分布式数据处理系统**，用于处理高速流入的数据。它可以每秒处理数百万条记录，并特别适用于对毫秒级延迟有严格要求的应用（例如，安全威胁检测、欺诈检测、运营监控等）。'
- en: The Storm architecture
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Storm 架构
- en: 'A typical Storm cluster has three types of nodes:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的 Storm 集群包含三种类型的节点：
- en: '**Nimbus or master node**: This is responsible for submitting and distributing
    the computations for execution apart from handling tasks such as launching slave
    nodes and monitoring the execution'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Nimbus 或主节点**：负责提交和分发计算执行，此外还处理启动从节点、监控执行等任务'
- en: '**ZooKeeper node**: This is responsible for coordinating the cluster'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ZooKeeper 节点**：负责协调集群'
- en: '**Supervisor node**: This is responsible for starting and stopping slave nodes
    based on the instructions sent by the Nimbus node![The Storm architecture](img/B05186_08_05.jpg)'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Supervisor 节点**：负责根据 Nimbus 节点发送的指令启动和停止从节点！[Storm 架构](img/B05186_08_05.jpg)'
- en: 'Some important terms used in Storm are:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: Storm 中使用的一些重要术语包括：
- en: '**Tuples**: This is an ordered list of elements'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**元组**：这是一个有序的元素列表'
- en: '**Streams**: This is a sequence of tuples'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**流**：这是一个元组的序列'
- en: '**Spouts**: These are sources of streams in a computation (for example, the
    Twitter API)'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Spouts**：这些是计算中的流源（例如，Twitter API）'
- en: '**Bolts**: These are process input streams and produce output streams'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Bolts**：这些是处理输入流并产生输出流的组件'
- en: '**Topologies**: These are the overall calculation represented visually as a
    network of spouts and bolts, as follows:![The Storm architecture](img/B05186_08_06.jpg)'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**拓扑**：这些是以 spouts 和 bolts 网络形式表示的整体计算，如下所示：![Storm 架构](img/B05186_08_06.jpg)'
- en: Setting up Storm on Mesos
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置 Storm on Mesos
- en: 'This section explains how we can integrate Storm with the Mesos cluster resource
    manager. Let''s follow the steps mentioned here:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 本节解释了如何将 Storm 与 Mesos 集群资源管理器集成。让我们按照这里提到的步骤操作：
- en: 'We can first explore the Storm on Mesos repository by executing the following
    command:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以先通过执行以下命令来探索 Storm on Mesos 仓库：
- en: '[PRE15]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We can now edit the configuration file listed in `conf/Storm.yaml`:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以编辑 `conf/Storm.yaml` 中列出的配置文件：
- en: '[PRE16]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Edit the properties according to the cluster that we have and execute the following
    command to start the nimbus:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据我们集群的配置编辑属性，并执行以下命令以启动 nimbus：
- en: '[PRE17]'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We need to start the UI on the same machine as the nimbus with the following
    command:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要在与 nimbus 相同的机器上启动 UI，使用以下命令：
- en: '[PRE18]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Topologies are submitted to a Storm/Mesos cluster in the exact same way that
    they are submitted to a regular Storm cluster. Storm/Mesos provides resource isolation
    between topologies. So, you don't need to worry about topologies interfering with
    one another.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 拓扑以与常规 Storm 集群相同的方式提交给 Storm/Mesos 集群。Storm/Mesos 提供了拓扑之间的资源隔离，因此，您不必担心拓扑之间的相互干扰。
- en: Running a sample topology
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 运行示例拓扑
- en: 'Once nimbus is running, we can launch one of the Storm-starter topologies with
    the following command:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦 nimbus 启动，我们可以使用以下命令启动其中一个 Storm-starter 拓扑：
- en: '[PRE19]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Here, we specified the nimbus host and thrift port as parameters.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将 nimbus 主机和 thrift 端口指定为参数。
- en: An advanced configuration guide
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一个高级配置指南
- en: 'If we want to build the release against a different version of Mesos or Storm,
    then we can use the `build-release.sh` script to download the appropriate version
    by executing the following command:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想将发布版本构建为不同版本的 Mesos 或 Storm，我们可以使用 `build-release.sh` 脚本，通过执行以下命令下载适当的版本：
- en: '[PRE20]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Here `x.x.x` and `y.y.y` are the appropriate versions of Storm and Mesos that
    we will build against. This command will build a Mesos executor package.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 这里 `x.x.x` 和 `y.y.y` 是我们将要构建的 Storm 和 Mesos 的适当版本。此命令将构建一个 Mesos 执行程序包。
- en: 'The `bin/build-release.sh` script takes in the following subcommands:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '`bin/build-release.sh` 脚本接收以下子命令：'
- en: '| Subcommand | Usage |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| 子命令 | 用法 |'
- en: '| --- | --- |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `main` | This is used to build a Storm package with the Mesos scheduler.
    The output of this command can be used as the package for `mesos.executor.uri`.
    |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| `main` | 用于使用 Mesos 调度器构建 Storm 包。此命令的输出可以用作 `mesos.executor.uri` 的包。 |'
- en: '| `clean` | This attempts to clean the working files and directories created
    when building. |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| `clean` | 尝试清理在构建时创建的工作文件和目录。 |'
- en: '| `downloadStormRelease` | This is a utility function to download the Storm
    release tarball for the targeted Storm release. Set the `MIRROR` environment variable
    to configure the download mirror. |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| `downloadStormRelease` | 这是一个实用程序，用于下载目标 Storm 版本的发行 tar 包。设置 `MIRROR` 环境变量来配置下载镜像。
    |'
- en: '| `mvnPackage` | This runs the Maven targets necessary to build the Storm Mesos
    framework. |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| `mvnPackage` | 运行构建 Storm Mesos 框架所需的 Maven 目标。 |'
- en: '| `prePackage` | This prepares the working directories to be able to package
    the Storm Mesos framework and is an optional argument specifying the Storm release
    tarball to package against. |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| `prePackage` | 准备工作目录，以便能够打包 Storm Mesos 框架，是一个可选参数，指定要打包的 Storm 发行 tar 包。
    |'
- en: '| `package` | This packages the Storm Mesos framework. |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| `package` | 打包 Storm Mesos 框架。 |'
- en: '| `dockerImage` | This builds a Docker image from the current code. |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| `dockerImage` | 从当前代码构建一个 Docker 镜像。 |'
- en: '| `help` | This prints out usage information about the `build-release.sh` script.
    |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| `help` | 输出 `build-release.sh` 脚本的使用信息。 |'
- en: Deploying Storm through Marathon
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过 Marathon 部署 Storm
- en: 'We can run Storm on Mesos with Marathon easily by setting the `MESOS_MASTER_ZK`
    environment variable to point to our ZooKeeper node of the cluster. The repository
    also includes a script, `bin/run-with-marathon.sh`, which sets the required parameters
    and starts the UI and nimbus. As Storm writes stateful data to the disk, we need
    to make sure that `storm.local.dir config` is set. We can run this from Marathon
    by submitting the following JSON data:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过设置 `MESOS_MASTER_ZK` 环境变量，将其指向集群的 ZooKeeper 节点，轻松地在 Mesos 上运行 Storm 并通过
    Marathon 启动。该代码库还包含一个脚本，`bin/run-with-marathon.sh`，它设置了所需的参数并启动了 UI 和 Nimbus。由于
    Storm 会将有状态数据写入磁盘，我们需要确保设置了 `storm.local.dir config`。我们可以通过提交以下 JSON 数据从 Marathon
    中运行：
- en: '[PRE21]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We can save the preceding JSON code as `storm-mesos.json` and send a `curl`
    request to the Marathon API endpoint to deploy with the following command:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将前述 JSON 代码保存为 `storm-mesos.json` 并发送 `curl` 请求到 Marathon API 端点，以使用以下命令进行部署：
- en: '[PRE22]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Reference: [https://github.com/mesos/storm](https://github.com/mesos/storm).'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 参考：[https://github.com/mesos/storm](https://github.com/mesos/storm)。
- en: Samza on Mesos
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Mesos 上运行 Samza
- en: 'Samza is an open source distributed stream processing framework originally
    developed at LinkedIn. It has the following features:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: Samza 是一个开源的分布式流处理框架，最初由 LinkedIn 开发。它具有以下特点：
- en: A simple API
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个简单的 API
- en: State management
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 状态管理
- en: Fault tolerance
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容错
- en: Durability
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 持久性
- en: Scalability
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可扩展性
- en: Pluggability
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可插拔性
- en: Processor isolation
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理器隔离
- en: Important concepts of Samza
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Samza 的重要概念
- en: Some concepts in Samza are described in the following sections.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: Samza 中的一些概念将在以下章节中描述。
- en: Streams
  id: totrans-180
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 流
- en: Samza processes streams of data—for example, website clickstreams, server logs,
    or any other event data. Messages can be added and read from a data stream. Multiple
    frameworks can access the same data stream and can partition the data based on
    the keys present in the message.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: Samza 处理数据流——例如，网站点击流、服务器日志或任何其他事件数据。消息可以添加到数据流中并从中读取。多个框架可以访问同一数据流，并根据消息中存在的键对数据进行分区。
- en: '![Streams](img/B05186_08_07.jpg)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![流](img/B05186_08_07.jpg)'
- en: Jobs
  id: totrans-183
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 任务
- en: A Samza job is the computation logic that reads data from input streams, applies
    some transformations to it, and outputs the resultant messages to a bunch of output
    streams.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: Samza 任务是计算逻辑，它从输入流中读取数据，对数据进行一些转换，并将结果消息输出到多个输出流。
- en: Partitions
  id: totrans-185
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分区
- en: Every stream is split into single or multiple partitions. Every partition is
    an ordered sequence of messages.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 每个流被拆分为一个或多个分区。每个分区是一个有序的消息序列。
- en: '![Partitions](img/B05186_08_08.jpg)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![分区](img/B05186_08_08.jpg)'
- en: Tasks
  id: totrans-188
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 任务
- en: A job is subdivided into multiple tasks for the parallelism of the computation.
    Every task reads data from a single partition for each input stream of the job.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 一个任务被细分为多个子任务，以实现计算的并行性。每个任务从任务的每个输入流的单个分区中读取数据。
- en: '![Tasks](img/B05186_08_09.jpg)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![任务](img/B05186_08_09.jpg)'
- en: Dataflow graphs
  id: totrans-191
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据流图
- en: Multiple jobs can be composed to develop a dataflow graph, in which the nodes
    are datastreams and the edges are the jobs.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 可以组合多个任务来开发数据流图，其中节点是数据流，边是任务。
- en: '![Dataflow graphs](img/B05186_08_10.jpg)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![数据流图](img/B05186_08_10.jpg)'
- en: Setting up Samza on Mesos
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Mesos 上设置 Samza
- en: This topic covers how we can run Samza jobs on a Mesos cluster. We will package
    the Samza jobs in a tarball for the sake of simplicity. Samza also supports packaging
    it in a Docker image.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 本主题介绍了如何在 Mesos 集群上运行 Samza 作业。为了简化，我们将把 Samza 作业打包成 tarball。Samza 也支持将其打包为
    Docker 镜像。
- en: 'At the time of writing this book, Samza on Mesos is in its early stages and
    hasn''t been tested in a production environment to the best of our knowledge.
    Let''s follow the steps mentioned here to set up Samza on Mesos:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写本书时，Samza 在 Mesos 上还处于早期阶段，且据我们所知，尚未在生产环境中进行过测试。让我们按照此处提到的步骤在 Mesos 上设置 Samza：
- en: 'We first need to deploy the `samza-mesos` jar in the environment. For this,
    we can clone the repository and build it with the following commands:'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先需要在环境中部署 `samza-mesos` jar 文件。为此，我们可以克隆仓库并使用以下命令构建：
- en: '[PRE23]'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Once this is done, we can start importing the Maven dependency to our projects,
    as follows:'
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦完成这些设置，我们可以开始将 Maven 依赖项导入到我们的项目中，方法如下：
- en: '[PRE24]'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The deployment of Samza through Marathon
  id: totrans-201
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过 Marathon 部署 Samza
- en: Samza jobs can be deployed through Marathon. Each Samza job is a Mesos framework,
    which creates one Mesos task for each of the Samza containers. It is easier to
    deploy the Samza jobs on Mesos through Marathon, as described here.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: Samza 作业可以通过 Marathon 部署。每个 Samza 作业都是一个 Mesos 框架，它为每个 Samza 容器创建一个 Mesos 任务。正如这里所描述的那样，通过
    Marathon 在 Mesos 上部署 Samza 作业更加简便。
- en: 'Samza jobs are usually deployed in a tarball, which should contain the following
    as the top-level directories:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: Samza 作业通常以 tarball 形式部署，其中应包含以下顶级目录：
- en: '`Bin`: This contains the standard Samza distributed shell scripts'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Bin`：此目录包含标准的 Samza 分布式 Shell 脚本'
- en: '`Config`: This should be with your job `.properties` file(s)'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Config`：此目录应包含你的作业 `.properties` 文件'
- en: '`Lib`: This contains all the `.jar` files'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Lib`：此目录包含所有的 `.jar` 文件'
- en: 'Now, let''s take a look at how we can submit a Samza job to Marathon to deploy
    it on Mesos. The JSON request for the same will look similar to the following:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看一下如何提交 Samza 作业到 Marathon 以便在 Mesos 上部署。相应的 JSON 请求将如下所示：
- en: '[PRE25]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Note that here, `mesos.package.path` is the parameter pointing to the Samza
    tarball, which is kept in HDFS.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`mesos.package.path` 是指向 Samza tarball 的参数，它存储在 HDFS 中。
- en: 'We can save the preceding JSON record to a file called `samza-job.json` and
    submit it to Marathon using the following `curl` command:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将前面的 JSON 记录保存为名为 `samza-job.json` 的文件，并使用以下 `curl` 命令将其提交到 Marathon：
- en: '[PRE26]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: An advanced configuration guide
  id: totrans-212
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 高级配置指南
- en: The supported configuration properties are listed at [https://github.com/Banno/samza-mesos](https://github.com/Banno/samza-mesos).
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 支持的配置属性列出在 [https://github.com/Banno/samza-mesos](https://github.com/Banno/samza-mesos)。
- en: Summary
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: This chapter introduced the reader to some important big data processing frameworks
    and covered topics such as the setup, configuration, and management of these frameworks
    on a distributed infrastructure using Mesos.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 本章向读者介绍了一些重要的大数据处理框架，并涵盖了如何在分布式基础设施上使用 Mesos 设置、配置和管理这些框架等主题。
- en: In the next chapter, we will discuss some of the important big data storage
    frameworks that are currently supported by Mesos (either in a beta or production-ready
    state), such as Cassandra, Elasticsearch, and Kafka, and understand how these
    can be set up and configured on Mesos.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论一些目前 Mesos 支持的重要大数据存储框架（无论是处于测试版还是生产就绪状态），例如 Cassandra、Elasticsearch
    和 Kafka，并了解如何在 Mesos 上进行设置和配置。
