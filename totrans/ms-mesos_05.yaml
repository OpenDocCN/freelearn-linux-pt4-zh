- en: Chapter 5. Mesos Cluster Deployment
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第五章：Mesos 集群部署
- en: This chapter explains how a Mesos cluster can be easily set up and monitored
    using standard deployment and configuration management tools used by system administrators
    and DevOps engineers. We will explain the steps that are required to set up a
    Mesos cluster through Ansible, Puppet, SaltStack, Chef, Terraform, or Cloudformation,
    and how a test environment can be set up using Playa Mesos. We will also talk
    about some standard monitoring tools, such as Nagios and Satellite that are can
    be used to monitor the cluster. We will also discuss some of the common problems
    faced while deploying a Mesos cluster along with their corresponding resolutions.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章讲解了如何使用系统管理员和 DevOps 工程师常用的标准部署和配置管理工具，轻松地设置和监控 Mesos 集群。我们将解释如何通过 Ansible、Puppet、SaltStack、Chef、Terraform
    或 Cloudformation 设置 Mesos 集群的步骤，并介绍如何使用 Playa Mesos 设置测试环境。我们还会讨论一些标准监控工具，例如 Nagios
    和 Satellite，可以用来监控集群。我们还将讨论在部署 Mesos 集群时遇到的一些常见问题以及相应的解决方法。
- en: 'The topics that will be covered are as follows:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: 'Deploying and configuring a Mesos cluster using the following:'
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用以下方法部署和配置 Mesos 集群：
- en: Ansible
  id: totrans-4
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ansible
- en: Puppet
  id: totrans-5
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Puppet
- en: SaltStack
  id: totrans-6
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: SaltStack
- en: Chef
  id: totrans-7
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chef
- en: Terraform
  id: totrans-8
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Terraform
- en: Cloudformation
  id: totrans-9
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cloudformation
- en: Creating test environments using Playa Mesos
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Playa Mesos 创建测试环境
- en: Common deployment issues and solutions
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 常见部署问题及解决方案
- en: 'Monitoring the Mesos cluster using the following:'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用以下工具监控 Mesos 集群：
- en: Nagios
  id: totrans-13
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nagios
- en: Satellite
  id: totrans-14
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Satellite
- en: Deploying and configuring a Mesos cluster using Ansible
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Ansible 部署和配置 Mesos 集群
- en: Ansible is one of the popular infrastructure automation tools commonly used
    by system administrators today and recently acquired by Red Hat. Nodes are managed
    through **Secure Shell** (**SSH**) and require only Python support. Ansible has
    open sourced a lot of playbooks, including an `ansible-mesos` one that we will
    discuss in this section.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Ansible 是一种流行的基础设施自动化工具，当前广泛应用于系统管理员中，并且最近被 Red Hat 收购。节点通过**安全外壳**（**SSH**）进行管理，只需要
    Python 支持。Ansible 已开源了许多剧本，包括我们将在本节中讨论的 `ansible-mesos` 剧本。
- en: The `ansible-mesos` playbook can be used to install and configure a Mesos cluster
    with customized master as well as slave setup options. Currently, it supports
    Ubuntu and CentOS/Red Hat operating system-powered machines. The `ansible-mesos`
    playbook also supports setting specific slave executors and hence can be run with
    native Docker support.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '`ansible-mesos` 剧本可以用于安装和配置 Mesos 集群，并支持自定义的主节点和从节点设置选项。目前，它支持基于 Ubuntu 和 CentOS/Red
    Hat 操作系统的机器。`ansible-mesos` 剧本还支持设置特定的从节点执行器，因此可以与原生 Docker 支持一起运行。'
- en: Installing Ansible
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装 Ansible
- en: Ansible installation is only required on a single machine. It does not require
    a database, nor does it need to keep a daemon running all the time. It uses SSH
    to manage the cluster and requires Python (versions 2.6 or 2.7) to be installed
    on the machine. You can even install Ansible on your laptop or personal computer
    and have it manage the machines running remotely. The machine where Ansible is
    installed is called the **control machine**. At the time of writing this book,
    there is no support for Windows machines. The machines that are controlled by
    the control machine are known as **managed nodes** and require SSH access ability
    from the control machine as well as Python (version 2.4 or later) installed on
    them.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 安装 Ansible 只需要在单台机器上进行。它不需要数据库，也不需要持续运行守护进程。它通过 SSH 来管理集群，并要求机器上安装 Python（版本
    2.6 或 2.7）。你甚至可以在笔记本电脑或个人计算机上安装 Ansible，远程管理其他机器。安装了 Ansible 的机器被称为**控制机器**。在编写本书时，Windows
    机器尚不受支持。受控制的机器称为**受管节点**，需要控制机器的 SSH 访问权限，并且上面也需要安装 Python（版本 2.4 或更高）。
- en: Installing the control machine
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装控制机器
- en: 'We can run Ansible without root access as it doesn''t require you to install
    any additional software or database servers. Execute the following code:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在没有 root 权限的情况下运行 Ansible，因为它不需要安装任何额外的软件或数据库服务器。执行以下代码：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: If everything goes well, then we can see the following output in the Terminal,
    indicating that the installation was successful. After this, we will be able to
    use the Ansible command from the Terminal.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切顺利，我们可以在终端中看到以下输出，表示安装成功。之后，我们将能够在终端中使用 Ansible 命令。
- en: '![Installing the control machine](img/B05186_05_01.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![安装控制机器](img/B05186_05_01.jpg)'
- en: 'By default, Ansible uses the inventory file in `/etc/ansible/hosts`, which
    is an INI-like format and could look similar to the following, for example:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Ansible使用`/etc/ansible/hosts`中的清单文件，该文件采用类似INI格式，可能如下所示：
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Here, the group names are indicated in brackets, which can be used to classify
    the systems that will be controlled.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，组名用括号表示，可用于对将被管理的系统进行分类。
- en: We can also use the command-line option `-i` to point it to a different file
    rather than the one found in `/etc/ansible/hosts`.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用命令行选项`-i`，将其指向不同的文件，而不是`/etc/ansible/hosts`中找到的文件。
- en: Creating an ansible-mesos setup
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建ansible-mesos设置
- en: Ansible executes a playbook composed of roles against a set of hosts, as described
    before in the hosts file, which are organized into groups. For more details, visit
    [http://frankhinek.com/create-ansible-playbook-on-github-to-build-mesos-clusters/](http://frankhinek.com/create-ansible-playbook-on-github-to-build-mesos-clusters/).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: Ansible执行由角色组成的剧本，针对的是如之前在hosts文件中描述的，按组组织的一组主机。更多详情，请访问[http://frankhinek.com/create-ansible-playbook-on-github-to-build-mesos-clusters/](http://frankhinek.com/create-ansible-playbook-on-github-to-build-mesos-clusters/)。
- en: 'First, let''s create a hosts file by pointing to our Mesos master and slave
    nodes via the following:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们通过以下方式创建一个指向Mesos主节点和从节点的hosts文件：
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Here, we created two groups named `mesos_masters` and `mesos_workers` and listed
    the master and slave IP addresses, respectively. For the `mesos_masters` group,
    we will also need to specify the ZooKeeper ID as the cluster will run in high
    availability.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们创建了两个组，分别命名为`mesos_masters`和`mesos_workers`，并列出了主节点和从节点的IP地址。对于`mesos_masters`组，我们还需要指定ZooKeeper
    ID，因为集群将以高可用性运行。
- en: 'In the following steps, we will take a look at how to deploy Mesos on the machines
    listed in the hosts file using Ansible:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的步骤中，我们将看看如何使用Ansible在hosts文件中列出的机器上部署Mesos：
- en: 'Create a `site.yml` file with following content:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个`site.yml`文件，内容如下：
- en: '[PRE3]'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now, we can create a group variable file that will be applicable to all the
    hosts belonging to the cluster, as follows:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以创建一个适用于集群中所有主机的组变量文件，内容如下：
- en: '[PRE4]'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Next, we will put the following contents in all the files:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将在所有文件中放入以下内容：
- en: '[PRE5]'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now, we can create the roles for the Mesos cluster. First, create a roles directory
    via the following command:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以为Mesos集群创建角色。首先，通过以下命令创建一个roles目录：
- en: '[PRE6]'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We can now use the `ansible-galaxy` command to initialize the directory structure
    for this role, as follows:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在可以使用`ansible-galaxy`命令初始化该角色的目录结构，内容如下：
- en: '[PRE7]'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This will create the directory structure as follows:![Creating an ansible-mesos
    setup](img/B05186_05_02.jpg)
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这将创建以下目录结构：![创建一个ansible-mesos设置](img/B05186_05_02.jpg)
- en: 'Now, modify the `mesos/handlers/main.yml` file with following content:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，修改`mesos/handlers/main.yml`文件，内容如下：
- en: '[PRE8]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Next, modify the tasks from the `mesos/tasks/main.yml` file, as follows:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，按以下方式修改`mesos/tasks/main.yml`文件中的任务：
- en: '[PRE9]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This is a standard template to configure the Mesos master slave machines in
    the cluster. This file also specifies the various configurations that are necessary
    to install components such as ZooKeeper. The steps are listed as follows:'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是配置集群中Mesos主从机器的标准模板。该文件还指定了安装ZooKeeper等组件所需的各种配置。步骤如下：
- en: 'Create the ZooKeeper configuration template as follows:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按如下方式创建ZooKeeper配置模板：
- en: '[PRE10]'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Then, add the following content:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，添加以下内容：
- en: '[PRE11]'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Next, enter the following command:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，输入以下命令：
- en: '[PRE12]'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Finally, add the following content:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，添加以下内容：
- en: '[PRE13]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We can now run this playbook to deploy Mesos on the machines listed in the hosts
    file. We only need to change the IP addresses from the hosts file to deploy on
    other machines.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以运行这个剧本，将Mesos部署到hosts文件中列出的机器上。我们只需要更改hosts文件中的IP地址，就能在其他机器上部署。
- en: Deploying and configuring Mesos cluster using Puppet
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Puppet部署和配置Mesos集群
- en: 'This portion will primarily cover how one can deploy a Mesos cluster with the
    Puppet configuration management tool using the ZooKeeper and Mesos modules located
    at the following repositories:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这一部分将主要介绍如何使用Puppet配置管理工具，结合ZooKeeper和Mesos模块，从以下仓库部署Mesos集群：
- en: '[https://github.com/deric/puppet-mesos](https://github.com/deric/puppet-mesos)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://github.com/deric/puppet-mesos](https://github.com/deric/puppet-mesos)'
- en: '[https://github.com/deric/puppet-zookeeper](https://github.com/deric/puppet-zookeeper)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://github.com/deric/puppet-zookeeper](https://github.com/deric/puppet-zookeeper)'
- en: 'Puppet is an open source configuration management tool that runs on Windows,
    Linux, and Mac OS. Puppet Labs was founded by Luke Kanies, who produced the Puppet,
    in 2005\. It is written in Ruby and released as free software under the GNU General
    Public License (GPL) until version 2.7.0 and Apache License 2.0 after that. Using
    this, system administrators can automate the standard tasks that they need to
    run regularly. More information about Puppet can be found at the following location:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: Puppet 是一款开源的配置管理工具，支持在 Windows、Linux 和 Mac OS 上运行。Puppet Labs 由 Luke Kanies
    于 2005 年创立，他也开发了 Puppet。Puppet 是用 Ruby 编写的，并在版本 2.7.0 之前作为 GNU 通用公共许可证（GPL）下的自由软件发布，从那时起采用
    Apache License 2.0。通过使用 Puppet，系统管理员可以自动化他们需要定期执行的标准任务。有关 Puppet 的更多信息，请访问以下位置：
- en: '[https://puppetlabs.com/puppet/puppet-open-source](https://puppetlabs.com/puppet/puppet-open-source)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://puppetlabs.com/puppet/puppet-open-source](https://puppetlabs.com/puppet/puppet-open-source)'
- en: The code will be organized with the profiles and roles pattern, and the node
    data will be stored using Hiera. Hiera is a Puppet tool to perform a key/value
    lookup of the configuration data. It allows a hierarchical configuration of data
    in Puppet, which is difficult to achieve with native Puppet code. Also, it acts
    as a separator of configuration data and code.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 代码将按照配置文件和角色模式进行组织，节点数据将通过 Hiera 存储。Hiera 是一个 Puppet 工具，用于执行配置数据的键/值查找。它允许在
    Puppet 中对数据进行层次化配置，而这在原生 Puppet 代码中是很难实现的。此外，它作为配置数据和代码的分隔器。
- en: At the end of this module, you will have a highly available Mesos cluster with
    three masters and three slaves. Along with this, Marathon and Chronos will also
    be deployed in the same fashion.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在本模块结束时，你将拥有一个高度可用的 Mesos 集群，包含三个主节点和三个从节点。此外，Marathon 和 Chronos 也将以相同的方式部署。
- en: 'We can combine several Puppet modules to manage Mesos and ZooKeeper. Let''s
    perform the following steps:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以结合多个 Puppet 模块来管理 Mesos 和 ZooKeeper。让我们执行以下步骤：
- en: 'First, create a `Puppetfile` with the following content:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，创建一个包含以下内容的 `Puppetfile`：
- en: '[PRE14]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Now, we can write the profiles and roles pattern for both Mesos masters and
    slaves. On the master machines, it will also include managing ZooKeeper, Marathon,
    and Chronos.
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，我们可以为 Mesos 主节点和从节点编写配置文件和角色模式。在主节点上，还将包括管理 ZooKeeper、Marathon 和 Chronos。
- en: 'Create the following role for the masters:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为主节点创建以下角色：
- en: '[PRE15]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Next, create the following role for the slaves:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，为从节点创建以下角色：
- en: '[PRE16]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Now, we can go ahead and create the reusable profiles that match the include
    statements listed before in the roles. The profiles will contain the calls to
    the Mesos and ZooKeeper modules and any other resources that we need to manage.
    One can consider the roles as the business logic and the profiles as the actual
    implementation.
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，我们可以继续创建与之前在角色中列出的 include 语句匹配的可重用配置文件。这些配置文件将包含对 Mesos 和 ZooKeeper 模块的调用以及我们需要管理的任何其他资源。可以将角色视为业务逻辑，而将配置文件视为实际的实现。
- en: 'Create the following profile for ZooKeeper:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为 ZooKeeper 创建以下配置文件：
- en: '[PRE17]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Create the following profile for Mesos masters:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为 Mesos 主节点创建以下配置文件：
- en: '[PRE18]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Next, create the following profile for Mesos slaves:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，为 Mesos 从节点创建以下配置文件：
- en: '[PRE19]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: These are the basic things we need to launch a Mesos cluster. To manage Chronos
    and Marathon, the following profiles will also need to be included.
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这些是启动 Mesos 集群所需的基本内容。为了管理 Chronos 和 Marathon，还需要包含以下配置文件。
- en: 'Create a profile for Chronos, as follows:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照以下方式创建 Chronos 的配置文件：
- en: '[PRE20]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Now, create a profile for Marathon via the following code:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，通过以下代码创建 Marathon 的配置文件：
- en: '[PRE21]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'So far, the roles and profiles don''t contain any information about the machines
    that we will use to set up the cluster. This information will come using Hiera.
    The Hiera data for master would look something similar to this:'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 到目前为止，角色和配置文件中并没有包含我们将用于设置集群的机器的信息。这些信息将通过 Hiera 提供。主节点的 Hiera 数据大致如下所示：
- en: '[PRE22]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: As we are setting up a highly available cluster, the master machines are named
    master 1, master 2, and master 3, respectively.
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于我们正在设置一个高度可用的集群，因此主节点的名称分别为 master 1、master 2 和 master 3。
- en: 'Hiera data for slave would look something similar to the following:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从节点的 Hiera 数据大致如下所示：
- en: '[PRE23]'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Now, we can initiate a Puppet run on each of the machines to install and configure
    Mesos, ZooKeeper, Chronos, and Marathon.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以在每台机器上启动 Puppet 运行，来安装和配置 Mesos、ZooKeeper、Chronos 和 Marathon。
- en: 'The installation of the module is the same as for any Puppet module, as follows:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 模块的安装与任何 Puppet 模块相同，步骤如下：
- en: '[PRE24]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Once executed successfully, we can expect that the Mesos package will be installed
    and the `mesos-master` service will be configured in the cluster.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦执行成功，我们可以预期 Mesos 包会被安装，并且 `mesos-master` 服务会在集群中配置好。
- en: Deploying and configuring a Mesos cluster using SaltStack
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 SaltStack 部署和配置 Mesos 集群
- en: 'The SaltStack platform, or Salt, is a Python-based open source configuration
    management software and a remote execution engine. This module explains how we
    can use SaltStack to install a Mesos cluster with Marathon and a few other tools
    in production. SaltStack is an alternative to Puppet, Ansible, Chef, and others.
    As with the others, it is used to automate the deployment and configuration of
    software on multiple servers. The SaltStack architecture consists of one node
    as the SaltStack master and other nodes as the minions (slaves). There are also
    two different roles: one master role to perform cluster actions and a slave role
    to run the Docker containers.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: SaltStack 平台，或称 Salt，是一个基于 Python 的开源配置管理软件和远程执行引擎。本模块解释了如何使用 SaltStack 在生产环境中安装一个包含
    Marathon 和其他一些工具的 Mesos 集群。SaltStack 是 Puppet、Ansible、Chef 等的替代方案。与其他工具类似，它用于自动化在多个服务器上部署和配置软件。SaltStack
    架构由一个节点作为 SaltStack 主节点，以及其他作为 minion（从节点）的节点组成。还有两种不同的角色：一个主节点角色用于执行集群操作，一个从节点角色用于运行
    Docker 容器。
- en: 'The following packages will be installed for the role master:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 以下软件包将为主节点角色安装：
- en: ZooKeeper
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ZooKeeper
- en: The Mesos master
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mesos 主节点
- en: Marathon
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Marathon
- en: Consul
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Consul
- en: 'The slave role will have the following packages installed:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 从节点角色将安装以下软件包：
- en: The Mesos slave
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mesos 从节点
- en: Docker
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker
- en: cAdvisor (used to export metrics to prometheus)
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: cAdvisor（用于将指标导出到 Prometheus）
- en: Registrator (used to register services with Consul)
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Registrator（用于将服务注册到 Consul）
- en: Weave (provides an overlay network between containers)
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Weave（为容器之间提供覆盖网络）
- en: 'Now, let''s take a look at how these components look in the cluster. The following
    figure shows all these components connected together in the cluster (source: [https://github.com/Marmelatze/saltstack-mesos-test](https://github.com/Marmelatze/saltstack-mesos-test)):'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看这些组件在集群中的样子。下图显示了集群中所有这些组件的连接方式（来源：[https://github.com/Marmelatze/saltstack-mesos-test](https://github.com/Marmelatze/saltstack-mesos-test)）：
- en: '![Deploying and configuring a Mesos cluster using SaltStack](img/B05186_05_03.jpg)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![使用 SaltStack 部署和配置 Mesos 集群](img/B05186_05_03.jpg)'
- en: SaltStack installation
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SaltStack 安装
- en: 'We need to install the Salt-Master to coordinate all the Salt-Minions. SaltStack
    requires the masters to be an odd number. One of these masters can be used as
    the Salt-Master, and the others will then become the minions. Let''s follow the
    steps mentioned here to install SaltStack:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要安装 Salt-Master 来协调所有的 Salt-Minions。SaltStack 要求主节点数量为奇数。这些主节点中的一个可以作为 Salt-Master，其余的将成为
    minions。让我们按照这里提到的步骤安装 SaltStack：
- en: 'Execute the following command to set up the master and minion:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下命令设置主节点和 minion：
- en: '[PRE25]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Edit the `/etc/salt/master` file and change the configurations, as follows:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编辑 `/etc/salt/master` 文件并按如下方式更改配置：
- en: '[PRE26]'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Now restart the master:'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在重启主节点：
- en: '[PRE27]'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Edit the minion configuration file located at `/etc/salt/minion` via the following
    code:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过以下代码编辑位于`/etc/salt/minion`的 minion 配置文件：
- en: '[PRE28]'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Now, edit the `salt-grains` file located at `/etc/salt/grains` by executing
    the following code:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，通过执行以下代码编辑位于 `/etc/salt/grains` 的 `salt-grains` 文件：
- en: '[PRE29]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Then, replace the ID with a numerical value starting from 1; this ID is similar
    to the ZooKeeper ID that we used earlier.
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，将 ID 替换为从 1 开始的数字值；这个 ID 类似于我们之前使用的 ZooKeeper ID。
- en: 'Now, restart the minion via the following command:'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，通过以下命令重启 minion：
- en: '[PRE30]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Public key authentication is used for authentication between the minion and
    the master. Execute the following command to do so:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 公钥认证用于 minion 与主节点之间的认证。执行以下命令进行认证：
- en: '[PRE31]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Once we are done with the preceding steps, we can run SaltStack with the following
    command:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成前面的步骤后，我们可以使用以下命令运行 SaltStack：
- en: '[PRE32]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: If everything is successfully executed, then Mesos services will be up and running
    in the cluster.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切执行成功，则 Mesos 服务将在集群中启动并运行。
- en: Deploying and configuring a Mesos cluster using Chef
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Chef 部署和配置 Mesos 集群
- en: 'Chef is both the name of a company and the name of a configuration management
    tool written in Ruby and Erlang. It uses a pure Ruby domain-specific language
    (DSL) to write system configuration "recipes". This module will explain how to
    install and configure the Apache Mesos master and slave using the Chef cookbook.
    Chef is a configuration management tool to automate large-scale server and software
    application deployments. We will assume that the reader is already familiar with
    Chef. The following repository will be used for reference:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: Chef既是一个公司的名字，也是一个配置管理工具的名称，它是用Ruby和Erlang编写的。Chef使用纯Ruby领域特定语言（DSL）编写系统配置“配方”。本模块将解释如何使用Chef
    cookbook安装和配置Apache Mesos的主从节点。Chef是一个配置管理工具，用于自动化大规模的服务器和软件应用部署。我们假设读者已经熟悉Chef。以下代码库将作为参考：
- en: '[https://github.com/everpeace/cookbook-mesos](https://github.com/everpeace/cookbook-mesos).'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/everpeace/cookbook-mesos](https://github.com/everpeace/cookbook-mesos)'
- en: The Chef cookbook version at the time of writing this book supports the Ubuntu
    and CentOS operating systems. The CentOS version is experimental and is not recommended
    for use in a production environment. Ubuntu 14.04 or higher is required to make
    use of the cgroups isolator or Docker container features. Only Mesos 0.20.0 and
    later supports Docker containerization.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 本书编写时的Chef cookbook版本支持Ubuntu和CentOS操作系统。CentOS版本为实验性版本，不建议在生产环境中使用。需要Ubuntu
    14.04或更高版本才能使用cgroups隔离器或Docker容器功能。只有Mesos 0.20.0及更高版本支持Docker容器化。
- en: 'This cookbook supports installation in both ways—that is, building Mesos from
    source and from the Mesosphere package. By default, this cookbook builds Mesos
    from source. One can switch between the source and Mesosphere by setting the following
    type variable:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这个cookbook支持两种安装方式——即，从源代码构建Mesos和从Mesosphere包构建。默认情况下，此cookbook是从源代码构建Mesos的。可以通过设置以下类型变量在源代码构建和Mesosphere之间切换：
- en: '[PRE33]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Recipes
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配方
- en: 'The following are the recipes used by this cookbook to install and configure
    Mesos:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是此cookbook用于安装和配置Mesos的配方：
- en: '`mesos::default`: This installs Mesos using the source or Mesosphere recipe,
    depending on the type variable discussed before.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mesos::default`：根据之前讨论的类型变量，这将使用源代码或Mesosphere配方安装Mesos。'
- en: '`mesos::build_from_source`: This installs Mesos in the usual way—that is, download
    zip from GitHub, configure, make, and install.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mesos::build_from_source`：这将以通常的方式安装Mesos——即，从GitHub下载zip文件，配置，make，并安装。'
- en: '`mesos::mesosphere`: This variable installs Mesos using Mesosphere''s `mesos`
    package. Along with it, we can use the following variable to install the ZooKeeper
    package.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mesos::mesosphere`：此变量使用Mesosphere的`mesos`包安装Mesos。与此同时，我们可以使用以下变量来安装ZooKeeper包。'
- en: '`node[:mesos][:mesosphere][:with_zookeeper]`'
  id: totrans-143
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`node[:mesos][:mesosphere][:with_zookeeper]`'
- en: '`mesos::master`: This configures the Mesos master and cluster deployment configuration
    files and uses `mesos-master` to start the service. The following are the variables
    associated with the configurations:'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mesos::master`：此配置项用于配置Mesos主节点和集群部署的配置文件，并使用`mesos-master`来启动服务。以下是与这些配置相关的变量：'
- en: '`node[:mesos][:prefix]/var/mesos/deploy/masters`'
  id: totrans-145
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`node[:mesos][:prefix]/var/mesos/deploy/masters`'
- en: '`node[:mesos][:prefix]/var/mesos/deploy/slaves`'
  id: totrans-146
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`node[:mesos][:prefix]/var/mesos/deploy/slaves`'
- en: '`node[:mesos][:prefix]/var/mesos/deploy/mesos-deploy-env.sh`'
  id: totrans-147
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`node[:mesos][:prefix]/var/mesos/deploy/mesos-deploy-env.sh`'
- en: '`node[:mesos][:prefix]/var/mesos/deploy/mesos-master-env.sh`'
  id: totrans-148
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`node[:mesos][:prefix]/var/mesos/deploy/mesos-master-env.sh`'
- en: 'If we select `mesosphere` as the type to build, then the default ":" prefix
    attribute location will be `/usr/local` as the package from Mesosphere installs
    Mesos in this directory. This recipe also configures the upstart files at the
    following locations:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们选择`mesosphere`作为构建类型，则默认的 ":" 前缀属性位置将是`/usr/local`，因为来自Mesosphere的软件包将Mesos安装在这个目录下。此配方还在以下位置配置了upstart文件：
- en: '`/etc/mesos/zk`'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`/etc/mesos/zk`'
- en: '`/etc/defaults/mesos`'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`/etc/defaults/mesos`'
- en: '`/etc/defaults/mesos-master`'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`/etc/defaults/mesos-master`'
- en: Configuring mesos-master
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置mesos-master
- en: 'The `mesos-master` command-line parameters can be used to configure the `node[:mesos][:master]`
    attribute. An example is given here:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '`mesos-master`命令行参数可用于配置`node[:mesos][:master]`属性。以下是一个示例：'
- en: '[PRE34]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The `mesos-master` command will be invoked with the options given in the configuration
    as follows:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '`mesos-master`命令将使用配置中给定的选项进行调用，具体如下：'
- en: '[PRE35]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The `mesos::slave` command provides configurations for the Mesos slave and
    starts the `mesos-slave` instance. We can use the following variable to point
    to the `mesos-slave-env.sh` file:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '`mesos::slave` 命令为 Mesos 从节点提供配置并启动 `mesos-slave` 实例。我们可以使用以下变量来指向 `mesos-slave-env.sh`
    文件：'
- en: '`node[:mesos][:prefix]/var/mesos/deploy/mesos-slave-env.sh`'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`node[:mesos][:prefix]/var/mesos/deploy/mesos-slave-env.sh`'
- en: 'The upstart configuration files for `mesos-slave` are as follows:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '`mesos-slave` 的 upstart 配置文件如下：'
- en: '`/etc/mesos/zk`'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`/etc/mesos/zk`'
- en: '`/etc/defaults/mesos`'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`/etc/defaults/mesos`'
- en: '`/etc/defaults/mesos-slave`'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`/etc/defaults/mesos-slave`'
- en: Configuring mesos-slave
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置 mesos-slave
- en: 'The `mesos-slave` command-line options can be configured using the `node[:mesos][:slave]`
    hash. An example configuration is given here:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '`mesos-slave` 命令行选项可以通过 `node[:mesos][:slave]` 哈希值进行配置。下面是一个配置示例：'
- en: '[PRE36]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The `mesos-slave` command is invoked as follows:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '`mesos-slave` 命令的调用方式如下：'
- en: '[PRE37]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Now, let''s take a look at how we can put all this together in a vagrant file
    and launch a standalone Mesos cluster. Create a `Vagrantfile` with the following
    contents:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看看如何将这些内容结合在一个 vagrant 文件中并启动一个独立的 Mesos 集群。创建一个包含以下内容的 `Vagrantfile`：
- en: '[PRE38]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Now, type in the following command to have a fully functional standalone Mesos
    cluster:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，键入以下命令以启动一个完全功能的独立 Mesos 集群：
- en: '[PRE39]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Deploying and configuring a Mesos cluster using Terraform
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Terraform 部署和配置 Mesos 集群
- en: Terraform is an infrastructure building, changing, and versioning tool to handle
    the existing popular services as well as custom in-house solutions safely and
    efficiently that is owned by HashiCorp and written in Go language. In this module,
    we will first discuss how we can install Terraform, and then, we will consider
    how we can use Terraform to spin up a Mesos cluster.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: Terraform 是一个基础设施构建、变更和版本控制工具，用于安全高效地处理现有的流行服务以及定制的内部解决方案，属于 HashiCorp 公司并使用
    Go 语言编写。在本模块中，我们将首先讨论如何安装 Terraform，然后再讨论如何使用 Terraform 启动一个 Mesos 集群。
- en: Installing Terraform
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装 Terraform
- en: 'Head to [https://www.terraform.io/downloads.html](https://www.terraform.io/downloads.html),
    download the appropriate version for your platform, and unzip it, as follows:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 前往 [https://www.terraform.io/downloads.html](https://www.terraform.io/downloads.html)，下载适合您平台的版本，并解压，如下所示：
- en: '[PRE40]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'You will note that the `terraform` archive is a bunch of binaries once you
    unzip them, which looks similar to the following:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 您会注意到，解压后，`terraform` 压缩包中的文件是一堆二进制文件，类似于以下内容：
- en: '![Installing Terraform](img/B05186_05_04.jpg)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![安装 Terraform](img/B05186_05_04.jpg)'
- en: Now, add the path to the directory in the `PATH` variable so that you can access
    the `terraform` command from any directory.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，将目录路径添加到 `PATH` 变量中，这样您就可以从任何目录访问 `terraform` 命令。
- en: 'If everything goes well, then you can see the usage of `terraform` once you
    execute the `terraform` command in the Terminal:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切顺利，当您在终端执行 `terraform` 命令时，您将看到 `terraform` 的使用：
- en: '![Installing Terraform](img/B05186_05_05.jpg)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![安装 Terraform](img/B05186_05_05.jpg)'
- en: Spinning up a Mesos cluster using Terraform on Google Cloud
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Google Cloud 上使用 Terraform 启动 Mesos 集群
- en: To spin up a Mesos cluster in Google Cloud Engine (GCE) with Terraform, you
    are required to have a JSON key file to authenticate. Head to [https://console.developers.google.com](https://console.developers.google.com)
    and then generate a new JSON key by navigating to the **Credentials** **|** **Service**
    account. A file will then be downloaded, which will be needed later to launch
    machines.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 Google Cloud Engine (GCE) 上使用 Terraform 启动 Mesos 集群，您需要一个 JSON 密钥文件进行身份验证。前往
    [https://console.developers.google.com](https://console.developers.google.com)，然后通过导航到
    **Credentials** **|** **Service** 账户生成一个新的 JSON 密钥。一个文件将被下载，稍后将用于启动虚拟机。
- en: 'We can now create a `terraform` configuration file for our Mesos cluster. Create
    a `mesos.tf` file with the following contents:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以为 Mesos 集群创建一个 `terraform` 配置文件。创建一个包含以下内容的 `mesos.tf` 文件：
- en: '[PRE41]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'As we can note, a few of these configurations can be used to control versions,
    such as:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，其中一些配置可以用来控制版本，例如：
- en: '`mesos_version`: This specifies the version of Mesos'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mesos_version`：这指定了 Mesos 的版本'
- en: '`image`: This is the Linux system image'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image`：这是 Linux 系统镜像'
- en: 'Now, execute the following commands to start the deployment:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，执行以下命令开始部署：
- en: '[PRE42]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Destroying the cluster
  id: totrans-192
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 销毁集群
- en: 'We can execute the following command to destroy the cluster:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以执行以下命令来销毁集群：
- en: '[PRE43]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Deploying and configuring a Mesos cluster using Cloudformation
  id: totrans-195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Cloudformation 部署和配置 Mesos 集群
- en: 'In this module, we will discuss how we can use Cloudformation scripts to launch
    a Mesos cluster on Amazon AWS. Before jumping into it, first make sure you install
    and configure aws-cli on the machines where you want to launch the cluster. Take
    a look at the instructions from the following repository to set up aws-cli:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在本模块中，我们将讨论如何使用 Cloudformation 脚本在 Amazon AWS 上启动 Mesos 集群。在开始之前，请确保在希望启动集群的机器上安装并配置了
    aws-cli。从以下存储库查看说明来设置 aws-cli：
- en: '[https://github.com/aws/aws-cli](https://github.com/aws/aws-cli).'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/aws/aws-cli](https://github.com/aws/aws-cli)。'
- en: The next thing that we need after setting up aws-cli is the `cloudformation-zookeeper`
    template for an exhibitor-managed ZooKeeper cluster.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置 aws-cli 后，我们需要的下一步是 `cloudformation-zookeeper` 模板用于管理由 Exhibitor 管理的 ZooKeeper
    集群。
- en: Setting up cloudformation-zookeeper
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置 cloudformation-zookeeper
- en: 'We first need to clone the following repository as it contains the JSON file
    that has the parameters, descriptors, and configuration values:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先需要克隆以下存储库，因为它包含了具有参数、描述符和配置值的 JSON 文件：
- en: '[PRE44]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Log in to the AWS console and open up the following ports for security group:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 登录 AWS 控制台，并为安全组打开以下端口：
- en: 'SSH Port: 22'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SSH 端口：22
- en: 'ZooKeeper Client Port: 2181'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ZooKeeper 客户端端口：2181
- en: 'Exhibitor HTTP Port: 8181'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Exhibitor HTTP 端口：8181
- en: 'We can now use `aws-cli` to launch the cluster using the following command:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用 `aws-cli` 命令来启动集群：
- en: '[PRE45]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Using cloudformation-mesos
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 cloudformation-mesos
- en: 'You can clone the project repository from the following URL:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从以下网址克隆项目存储库：
- en: '[PRE46]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'The project primarily includes three templates in the JSON format, which defines
    the parameters, configurations, and descriptors, as follows:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 该项目主要包括三个 JSON 格式的模板，定义了参数、配置和描述，如下所示：
- en: '`mesos-master.json`: This is used to launch a set of Mesos masters, which run
    Marathon in an autoscaling group.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mesos-master.json`：用于启动一组运行 Marathon 的 Mesos 主节点的模板，在自动扩展组中运行。'
- en: '`mesos-slave.json`: Similar to the preceding one, this launches a set of Mesos
    slaves in an autoscaling group.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mesos-slave.json`：与前述相似，这会在自动扩展组中启动一组 Mesos 从节点。'
- en: '`mesos.json`: This creates both the `mesos-master` and `mesos-slave` stacks
    from the corresponding templates, which were listed previously. This is the general
    template used to launch a Mesos cluster.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mesos.json`：此文件从先前列出的对应模板创建 `mesos-master` 和 `mesos-slave` 两个堆栈。这是用于启动 Mesos
    集群的通用模板。'
- en: 'A few configurable properties from `master.json` are listed as follows:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '`master.json` 中列出了一些可配置属性：'
- en: '[PRE47]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '`MasterInstanceCount` and `MasterQuorumCount` control the number of master
    machines that are required in the cluster. Take a look at the following code:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '`MasterInstanceCount` 和 `MasterQuorumCount` 控制集群中所需的主节点数量。查看以下代码：'
- en: '[PRE48]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Similarly, `SlaveInstanceCount` is used to control the number of slave instances
    in the cluster.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，`SlaveInstanceCount` 用于控制集群中从节点实例的数量。
- en: 'Cloudformation updates the autoscaling groups, and Mesos then transparently
    handles the scaling up by adding more nodes and scaling down by removing nodes.
    Take a look:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: Cloudformation 更新自动扩展组，Mesos 通过增加和减少节点来透明地处理扩展。详见：
- en: '[PRE49]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: We can also use the `InstanceType` configuration property for both the master
    (`MasterInstanceType`) and slave (`SlaveInstanceType`) to control the size of
    the machine in the AWS cloud.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用 `InstanceType` 配置属性来控制 AWS 云中主节点 (`MasterInstanceType`) 和从节点 (`SlaveInstanceType`)
    的机器大小。
- en: 'Again, in the security group that we created earlier, open up the following
    ports for Mesos communication:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，在我们之前创建的安全组中，为 Mesos 通信打开以下端口：
- en: 'Mesos master port: 5050'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mesos 主节点端口：5050
- en: 'Marathon port : 8080'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Marathon 端口：8080
- en: 'Once we configure the values in the `mesos-master.json`, `mesos-slave.json`
    files, we can upload these files into S3 using the following command:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `mesos-master.json` 和 `mesos-slave.json` 文件中配置值后，我们可以使用以下命令将这些文件上传到 S3：
- en: '[PRE50]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'We can now use aws-cli to launch our Mesos cluster with the following command:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用 aws-cli 命令来启动我们的 Mesos 集群：
- en: '[PRE51]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Creating test environments using Playa Mesos
  id: totrans-230
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Playa Mesos 创建测试环境
- en: 'Apache Mesos test environments can be quickly created using Playa Mesos. You
    can take a look at the official repository from the following URL:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Playa Mesos 可快速创建 Apache Mesos 测试环境。你可以从以下网址查看官方存储库：
- en: '[https://github.com/mesosphere/playa-mesos](https://github.com/mesosphere/playa-mesos).'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/mesosphere/playa-mesos](https://github.com/mesosphere/playa-mesos)。'
- en: Before using this project, make sure in your environment that you install and
    configure VirtualBox, Vagrant, and an Ubuntu machine image that contains Mesos
    and Marathon preinstalled.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用此项目之前，请确保在您的环境中安装并配置了 VirtualBox、Vagrant 和包含预装 Mesos 和 Marathon 的 Ubuntu
    镜像。
- en: Installations
  id: totrans-234
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装
- en: Follow the below instructions to get started with Playa Mesos
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下说明开始使用 Playa Mesos
- en: '**Install VirtualBox**: You can navigate to [https://www.virtualbox.org/wiki/Downloads](https://www.virtualbox.org/wiki/Downloads)
    and download and install the appropriate version for your environment'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安装 VirtualBox**：您可以访问 [https://www.virtualbox.org/wiki/Downloads](https://www.virtualbox.org/wiki/Downloads)
    下载并安装适合您环境的版本。'
- en: '**Install Vagrant**: You can use the methods described in the *Installing Aurora*
    section of [Chapter 4](ch04.html "Chapter 4. Service Scheduling and Management
    Frameworks"), *Service Scheduling and Management Frameworks*, to get started with
    Vagrant'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安装 Vagrant**：您可以参考 [第 4 章](ch04.html "第 4 章 服务调度与管理框架") 中 *安装 Aurora* 部分所描述的方法来开始使用
    Vagrant。'
- en: '**Playa**: You can clone the repository with the following command:'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Playa**：您可以使用以下命令克隆仓库：'
- en: '[PRE52]'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: If everything goes well, we will be able to see the Mesos master Web UI by pointing
    the browser to `10.141.141.10:5050` and the Marathon Web UI from `10.141.141.10:8080`.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切顺利，我们可以通过将浏览器指向 `10.141.141.10:5050` 来查看 Mesos master Web UI，并通过 `10.141.141.10:8080`
    查看 Marathon Web UI。
- en: 'Once the machine is started, then we can use `ssh` to log in to the machine
    with the following command:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦机器启动，我们可以使用 `ssh` 登录到机器，命令如下：
- en: '[PRE53]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'We can also use the following command to halt and terminate the test environment:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用以下命令来停止并终止测试环境：
- en: '[PRE54]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Apart from this, if you wish to tweak the configurations a bit, then you can
    do this by editing the `config.json` file located at the root of the `playa-mesos`
    repository.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 除此之外，如果您希望稍微调整配置，您可以通过编辑位于 `playa-mesos` 仓库根目录的 `config.json` 文件来进行。
- en: 'We can use the following configuration properties in the `config.json` file:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在 `config.json` 文件中使用以下配置属性：
- en: '`platform`: This is the virtualization platform. We will use VirtualBox, although
    VMware Fusion and VMware workstation can also be used.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`platform`：这是虚拟化平台。我们将使用 VirtualBox，虽然 VMware Fusion 和 VMware Workstation 也可以使用。'
- en: '`box_name`: This is the name of the vagrant instance.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`box_name`：这是 Vagrant 实例的名称。'
- en: '`base_url`: This is the base URL where Vagrant images are stored.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`base_url`：这是 Vagrant 镜像存储的基本 URL。'
- en: '`ip_address`: This is the private network IP address of the VM.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ip_address`：这是虚拟机的私有网络 IP 地址。'
- en: '`mesos_release`: This parameter is optional, which specifies the version of
    Mesos. This should be the full string returned by `apt-cache policy mesos`. An
    example would be `0.22.1-1.0.ubuntu1404`.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mesos_release`：此参数是可选的，指定 Mesos 的版本。它应为 `apt-cache policy mesos` 返回的完整字符串。例如：`0.22.1-1.0.ubuntu1404`。'
- en: '`vm_ram`: This is the memory allocated to the Vagrant VM.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vm_ram`：这是分配给 Vagrant 虚拟机的内存。'
- en: '`vm_cpus`: This is the number of cores allocated to the Vagrant VM.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vm_cpus`：这是分配给 Vagrant 虚拟机的核心数量。'
- en: 'We can create a sample `config.json` file by putting up all these configuration
    parameters, and it would look similar to the following:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过将所有这些配置参数放在一起，创建一个示例 `config.json` 文件，文件内容如下：
- en: '[PRE55]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: As you can note here, we allocated 2,040 MB memory and two cores, and the machine
    will run on the `10.141.141.10` IP address.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，我们分配了 2040 MB 的内存和两个核心，且机器将运行在 `10.141.141.10` 的 IP 地址上。
- en: Monitoring the Mesos cluster using Nagios
  id: totrans-257
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Nagios 监控 Mesos 集群
- en: Monitoring is a vital part of keeping the infrastructure up and running. Mesos
    integrates well with the existing monitoring solutions and has plugins for most
    monitoring solutions, such as **Nagios**. This module will give you a walkthrough
    of how to install Nagios on your cluster and enable monitoring to send you e-mail
    alerts whenever something goes wrong in your cluster.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 监控是保持基础设施正常运行的关键部分。Mesos 与现有的监控解决方案集成良好，并且有适用于大多数监控解决方案的插件，例如 **Nagios**。本模块将指导您如何在集群上安装
    Nagios，并启用监控功能，在集群出现故障时通过电子邮件向您发送警报。
- en: Installing Nagios 4
  id: totrans-259
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装 Nagios 4
- en: 'The first thing we need to do before installing Nagios is to add an Nagios
    user to the system from which the Nagios process can run and send out alerts.
    We can create a new user and a new usergroup for Nagios by executing the following
    commands:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 在安装 Nagios 之前，我们需要做的第一件事是为 Nagios 进程添加一个 Nagios 用户，该进程可以运行并发送警报。我们可以通过执行以下命令来创建一个新用户和一个新用户组：
- en: '[PRE56]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: Here, we created a user, Nagios, and a user group, `nagcmd`, which is assigned
    to the user Nagios in the third command listed before.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们创建了一个用户Nagios和一个用户组`nagcmd`，该组分配给Nagios用户，如前面列出的第三个命令所示。
- en: 'Now, install the dependency packages with the following command:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，使用以下命令安装依赖包：
- en: '[PRE57]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Once the dependencies are installed and the user is added, we can start downloading
    and installing `nagios` by executing the following commands:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 安装依赖项并添加用户后，我们可以开始通过执行以下命令下载并安装`nagios`：
- en: '[PRE58]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Once `nagios` is installed, we can install the `nagios` plugin by downloading
    and building it by issuing the following commands:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦`nagios`安装完成，我们可以通过下载并构建来安装`nagios`插件，执行以下命令：
- en: '[PRE59]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Once the plugins are installed, we can install **NRPE** (**Nagios Remote Plugin
    Executor**) to take status updates from remote machines. It can be installed by
    executing the following commands:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 插件安装完成后，我们可以安装**NRPE**（**Nagios远程插件执行器**）以从远程机器获取状态更新。可以通过执行以下命令进行安装：
- en: '[PRE60]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'For security reasons, edit the file located at `/etc/xinetd.d/nrpe` with the
    following content:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 出于安全原因，请编辑`/etc/xinetd.d/nrpe`文件，内容如下：
- en: '[PRE61]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Replace the IP address with our `nagios` server IP address so that only our
    `nagios` server is able to make remote calls. Once this is done, save the file
    and exit and then restart the `xintend` service by executing the following command:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 用我们的`nagios`服务器IP地址替换文件中的IP地址，以确保只有我们的`nagios`服务器可以进行远程调用。完成后，保存文件并退出，然后执行以下命令重启`xintend`服务：
- en: '[PRE62]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Now that `nagios` is installed, we can configure the contact e-mail addresses
    to which the notifications will be sent by editing the following file:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 现在`nagios`已安装，我们可以通过编辑以下文件来配置接收通知的联系电子邮件地址：
- en: '[PRE63]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Find and replace the following line with your own e-mail address:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 找到并将以下行替换为您自己的电子邮件地址：
- en: '[PRE64]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Add a user to `nagios` so that we can log in from the browser and see the activities
    by executing the following command. Here, we used `nagiosadmin` as the username
    and password, as follows:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 通过执行以下命令，添加一个用户到`nagios`，以便我们可以从浏览器登录并查看活动。在这里，我们使用`nagiosadmin`作为用户名和密码，如下所示：
- en: '[PRE65]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Now, restart the `nagios` service by issuing the following command:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，通过执行以下命令重启`nagios`服务：
- en: '[PRE66]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'We can now log in to the `nagios` admin panel by accessing the following URL
    from the browser:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以通过从浏览器访问以下URL登录`nagios`管理面板：
- en: '`http://MachineIP/nagios`'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: '`http://MachineIP/nagios`'
- en: '`MachineIP` is the IP address of the machine on which we installed `nagios`,
    and it will prompt you with an authentication form in which you can give the username
    and password as `nagiosadmin`.'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '`MachineIP`是我们安装了`nagios`的机器的IP地址，它会提示您输入认证表单，您可以在其中输入用户名和密码`nagiosadmin`。'
- en: '![Installing Nagios 4](img/B05186_05_06.jpg)'
  id: totrans-286
  prefs: []
  type: TYPE_IMG
  zh: '![安装Nagios 4](img/B05186_05_06.jpg)'
- en: 'Upon authentication, you will reach the Nagios home page. To view which hosts
    are being monitored by Nagios, click on the **Hosts** link present on the left-hand
    side, as shown in the following screenshot (source: [https://www.digitalocean.com/community/tutorials/how-to-install-nagios-4-and-monitor-your-servers-on-ubuntu-14-04](https://www.digitalocean.com/community/tutorials/how-to-install-nagios-4-and-monitor-your-servers-on-ubuntu-14-04)):'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 认证通过后，您将进入Nagios主页。要查看Nagios监控的主机，点击左侧的**Hosts**链接，如下图所示（来源：[https://www.digitalocean.com/community/tutorials/how-to-install-nagios-4-and-monitor-your-servers-on-ubuntu-14-04](https://www.digitalocean.com/community/tutorials/how-to-install-nagios-4-and-monitor-your-servers-on-ubuntu-14-04)）：
- en: '![Installing Nagios 4](img/B05186_05_07.jpg)'
  id: totrans-288
  prefs: []
  type: TYPE_IMG
  zh: '![安装Nagios 4](img/B05186_05_07.jpg)'
- en: Now, we will discuss how we can use NRPE to monitor the nodes in our Mesos cluster.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将讨论如何使用NRPE监控Mesos集群中的节点。
- en: The following section will add a machine to Nagios to monitor, and we can repeat
    the same steps to add as many machines as required. For the time being, we will
    choose the Mesos master node to be monitored, and it will trigger an e-mail if
    the disk usage for a particular drive exceeds the given amount.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的部分将添加一台机器到Nagios进行监控，我们可以重复相同的步骤添加需要的任意多台机器。目前，我们选择监控Mesos主节点，如果某个驱动器的磁盘使用量超过给定值，它将触发电子邮件。
- en: 'Now, on the master machine, install the Nagios plugins and `nrpe-server` with
    the following command:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在主机上，通过以下命令安装Nagios插件和`nrpe-server`：
- en: '[PRE67]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: As mentioned earlier, for security reasons, edit the `/etc/nagios/nrpe.cfg`
    file and put the `nagios` server IP address for communication under the `allowed_hosts`
    property.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，为了安全原因，请编辑`/etc/nagios/nrpe.cfg`文件，并将`nagios`服务器的IP地址放入`allowed_hosts`属性下进行通信。
- en: 'Now, edit the `nrpe` configuration file with the properties to monitor the
    disk usage via the following command:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，使用以下命令编辑 `nrpe` 配置文件，设置监控磁盘使用情况：
- en: '[PRE68]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Then, add the following content:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，添加以下内容：
- en: '[PRE69]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: Here, `server_address` is the IP address of the machine, `allowed_hosts` is
    the `nagios` server address, and the command is the actual command to pull the
    disk usage. We used the `check_disk` plugin that comes with `nagios` and passes
    the arguments to the command as `-w 20%` `-c 10%`. Whenever the server exceeds
    20% disk usage, Nagios will trigger an e-mail alert.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`server_address` 是机器的 IP 地址，`allowed_hosts` 是 `nagios` 服务器的地址，命令是实际用于拉取磁盘使用情况的命令。我们使用了
    `nagios` 自带的 `check_disk` 插件，并将参数传递给命令，分别为 `-w 20%` 和 `-c 10%`。每当服务器的磁盘使用超过 20%
    时，Nagios 会触发电子邮件警报。
- en: 'Once we edit the file, restart the `nrpe` server with the following command:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 编辑文件后，通过以下命令重启`nrpe`服务器：
- en: '[PRE70]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: Now that we have configured the Mesos master to check the disk usage, we also
    need to add this Mesos master to the `nagios` server so that it can keep on checking
    the disk usage and alert the administrators when it exceeds the quota.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经配置了 Mesos 主节点来检查磁盘使用情况，我们还需要将这个 Mesos 主节点添加到 `nagios` 服务器，以便它可以持续检查磁盘使用情况，并在超过配额时提醒管理员。
- en: 'Add a new configuration file on the `nagios` server to monitor, and we can
    add the file in `/usr/local/nagios/etc/servers/`, as follows:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `nagios` 服务器上添加一个新的配置文件进行监控，我们可以将文件添加到 `/usr/local/nagios/etc/servers/`，如下所示：
- en: '[PRE71]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Then, add the following content:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，添加以下内容：
- en: '[PRE72]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: This configuration will keep monitoring the Mesos master machine to check whether
    it is still running. The administrator (or others, as specified in the e-mail
    list) will get an e-mail notification if the Mesos master machine goes down.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 该配置将持续监控 Mesos 主机，检查其是否仍在运行。如果 Mesos 主机宕机，管理员（或邮件列表中指定的其他人员）将收到电子邮件通知。
- en: 'We can also enable the network usage checking by adding the following service:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过添加以下服务来启用网络使用情况检查：
- en: '[PRE73]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'Once we set the configurations for the new host, we need to restart `nagios`
    by executing the following command:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们为新主机设置了配置，就需要通过执行以下命令来重启`nagios`：
- en: '[PRE74]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: We can create new configuration files for slave nodes, as well, by following
    the steps listed previously.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过遵循之前列出的步骤，为从属节点创建新的配置文件。
- en: Monitoring the Mesos cluster using Satellite
  id: totrans-312
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Satellite 监控 Mesos 集群
- en: Satellite is another tool for monitoring Mesos, and the Satellite project is
    maintained by Two Sigma Investments, which is written in Clojure. The Satellite
    master instance monitors the Mesos masters and receives the monitoring information
    from Mesos slaves through the Satellite slaves. For each Mesos master and Mesos
    slave, there exists a Satellite master and slave process, with the `satellite-slave`
    processes sending one type of message to all `satellite-masters` in the cluster.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: Satellite 是另一个用于监控 Mesos 的工具，Satellite 项目由 Two Sigma Investments 维护，使用 Clojure
    编写。Satellite 主实例监控 Mesos 主节点，并通过 Satellite 从属节点接收来自 Mesos 从属节点的监控信息。对于每个 Mesos
    主节点和从属节点，都会有一个 Satellite 主进程和从进程，`satellite-slave` 进程将向集群中的所有 `satellite-master`
    发送一种类型的消息。
- en: Aggregate statistics of the cluster, such as the utilization of resources, the
    number of lost tasks and events specific to the master, such as how many leaders
    are currently active and so on, are usually pulled. Satellite also provides a
    **Representational State Transfer** (**REST)** interface to interact with the
    Mesos master whitelist. Whitelists are text files that contain the list of hosts
    to which the master will consider sending tasks. It also provides a REST interface
    to access the cached Mesos tasks metadata. Satellite itself never caches any of
    this information and only provides an interface to retrieve it if it is cached.
    This is an optional feature, but it is useful if we have persisted tasks metadata
    within Mesos itself.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 集群的汇总统计信息，如资源利用率、丢失的任务数量以及与主节点相关的事件（例如当前有多少个领导节点处于活动状态等），通常是被拉取的。Satellite 还提供了一个**表现状态转移**（**REST**）接口，以与
    Mesos 主节点白名单进行交互。白名单是包含主节点将考虑发送任务的主机列表的文本文件。它还提供了一个 REST 接口，用于访问缓存的 Mesos 任务元数据。Satellite
    本身从不缓存这些信息，只提供一个接口来检索缓存的信息（如果已缓存）。这是一个可选功能，但如果我们在 Mesos 内部持久化了任务元数据，它将非常有用。
- en: 'Satellite adds two additional conceptual whitelists to the mix:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: Satellite 添加了两个额外的概念性白名单：
- en: '**Managed whitelist**: These are the hosts that are are entered automatically'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**托管白名单**：这些是自动输入的主机'
- en: '**Manual whitelist**: If a host is present in this whitelist, then its status
    overrides that in the managed whitelist discussed previously. These are the REST
    endpoints taking the `PUT` and `DELETE` requests.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**手动白名单**：如果某个主机出现在此白名单中，那么它的状态将覆盖前面讨论的受管白名单中的状态。这些是接受 `PUT` 和 `DELETE` 请求的
    REST 端点。'
- en: At intervals, a merge operation actually merges these two into the whitelist
    file.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 在间隔时间内，合并操作实际上会将这两者合并到白名单文件中。
- en: Satellite installation
  id: totrans-319
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 卫星安装
- en: 'Satellite needs to be installed on all the machines that are present in the
    Mesos cluster. We will need to install `satellite-master` on the Mesos master
    machines and the `satellite-slave` on the Mesos slave machines. Run the following
    code:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 卫星需要安装在所有 Mesos 集群中的机器上。我们需要在 Mesos 主机上安装 `satellite-master`，并在 Mesos 从机上安装
    `satellite-slave`。运行以下代码：
- en: '[PRE75]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: The preceding command will create a `jar` in the target directory, which we
    can copy to all the Mesos master machines.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令将在目标目录中创建一个 `jar` 文件，我们可以将其复制到所有 Mesos 主机上。
- en: 'Executing the following command by passing the configuration will run the satellite
    process on the machines:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 通过传递配置执行以下命令，将在机器上运行卫星进程：
- en: '[PRE76]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: Common deployment issues and solutions
  id: totrans-325
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 常见的部署问题及解决方案
- en: 'This module contains a few common issues that are faced while installing or
    setting up the tools and modules described in this chapter:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 本模块包含了一些在安装或设置本章中描述的工具和模块时常遇到的常见问题：
- en: For the Ansible python-setup tools, take a look at the following screenshot:![Common
    deployment issues and solutions](img/B05186_05_08.jpg)
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于 Ansible python-setup 工具，查看以下截图：![常见部署问题及解决方案](img/B05186_05_08.jpg)
- en: 'If your Ansible installation shows the preceding message, then execute the
    following command to resolve it:'
  id: totrans-328
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你的 Ansible 安装显示上述消息，请执行以下命令来解决该问题：
- en: '[PRE77]'
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE77]'
- en: SSH runs on a different port, and `nagios` shows a `connection refused` error.
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: SSH 运行在不同的端口上，`nagios` 显示 `连接被拒绝` 错误。
- en: 'You will get the following exception if you run your `ssh` server on a different
    port:'
  id: totrans-331
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你将 `ssh` 服务器运行在不同的端口上，你将遇到以下异常：
- en: '[PRE78]'
  id: totrans-332
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'This can be fixed by editing the following line from `/etc/nagios/conf.d/services_nagios.cfg`:'
  id: totrans-333
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过编辑 `/etc/nagios/conf.d/services_nagios.cfg` 文件中的以下行可以解决此问题：
- en: '[PRE79]'
  id: totrans-334
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE79]'
- en: Here, we used `6666` as the `ssh` port, rather than `22`, to get rid of the
    error message.
  id: totrans-335
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们使用 `6666` 作为 `ssh` 端口，而不是 `22`，以避免出现错误信息。
- en: Chef fails to unzip packages.
  id: totrans-336
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Chef 无法解压软件包。
- en: 'Sometimes, the Chef setup fails to retrieve the packages and gives the following
    error stack:'
  id: totrans-337
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 有时，Chef 设置无法检索软件包并给出以下错误堆栈：
- en: '[PRE80]'
  id: totrans-338
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'This error shows up when your apt''s key is old. To resolve this issue, you
    need to update the keys by executing the following command:'
  id: totrans-339
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当你的 apt 密钥过期时，可能会出现此错误。要解决此问题，你需要通过执行以下命令来更新密钥：
- en: '[PRE81]'
  id: totrans-340
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: ZooKeeper throws an error "no masters are currently leading".
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ZooKeeper 抛出错误 "没有主节点当前正在领导"。
- en: 'This is a known ZooKeeper error due to the incorrect configuration of the ZooKeeper
    properties. We can resolve this error by editing the ZooKeeper configuration file
    located at `/etc/zookeeper/conf/zoo.cfg` properly. Add the following properties
    beside the server IP listed in the file:'
  id: totrans-342
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是一个已知的 ZooKeeper 错误，源于 ZooKeeper 配置文件的错误配置。我们可以通过正确编辑位于 `/etc/zookeeper/conf/zoo.cfg`
    的 ZooKeeper 配置文件来解决此错误。将以下属性添加到文件中列出的服务器 IP 旁边：
- en: '[PRE82]'
  id: totrans-343
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE82]'
- en: Summary
  id: totrans-344
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: After reading this chapter, you should now be able to use any standard deployment
    tool to launch and configure a Mesos cluster on a distributed infrastructure.
    You would also be able to understand various security, multitenancy, and maintenance
    features supported by Mesos and learn how to implement them for production-grade
    setups.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读完本章后，你现在应该能够使用任何标准部署工具，在分布式基础设施上启动并配置 Mesos 集群。你还将能够理解 Mesos 支持的各种安全性、多租户性和维护功能，并学习如何将它们实现到生产级别的设置中。
- en: In the next chapter, we will explore Mesos frameworks in greater detail. We
    will discuss the various features of frameworks and the process of porting an
    existing framework on Mesos and understand how to develop custom frameworks on
    top of Mesos to address specific applications.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将更详细地探索 Mesos 框架。我们将讨论框架的各种特性、将现有框架移植到 Mesos 上的过程，并了解如何在 Mesos 上开发自定义框架来解决特定的应用需求。
