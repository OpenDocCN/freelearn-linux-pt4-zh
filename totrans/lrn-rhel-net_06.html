<html><head></head><body><div class="chapter" title="Chapter&#xA0;6.&#xA0;File Sharing with NFS" id="aid-1HIT81"><div class="titlepage"><div><div><h1 class="title"><a id="ch06"/>Chapter 6. File Sharing with NFS</h1></div></div></div><p>File sharing with <span class="strong"><strong>Network File System</strong></span> (<span class="strong"><strong>NFS</strong></span>) is the traditional way on Unix and Linux for remote hosts to be able to mount filesystems over a network and interact with them as if they were mounted locally. Although RHEL 7 supports both NFSv3 and NFSv4, there is no longer any support for NFSv2. The RHEL 7 client will default to NFSv4 and falls back to NFSv3 if a connection cannot be established. Using NFSv4 simplifies location of services behind a firewall with only the TCP port <code class="literal">2049</code> required for client access; however, we will demonstrate both the NFSv4 and v3 firewall configurations. During this chapter, the following topics will be covered:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Overview of NFS</li><li class="listitem">Overview of the lab environment</li><li class="listitem">The NFS server configuration</li><li class="listitem">Using <code class="literal">exportfs</code></li><li class="listitem">Hosting NFSv4 behind a firewall</li><li class="listitem">Hosting NFSv3 behind a firewall</li><li class="listitem">The NFS client configuration</li><li class="listitem">Auto-mounting NFS with <code class="literal">autofs</code></li></ul></div><div class="section" title="An overview of NFS"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec46"/>An overview of NFS</h1></div></div></div><p>We have been used to <a id="id219" class="indexterm"/>NFSv4 being included with Red Hat Enterprise Linux 6. RHEL 7 includes additional support for <code class="literal">pNFS</code> (Parallel NFS) with NFSv4.1. <code class="literal">pNFS</code>, providing <a id="id220" class="indexterm"/>security and performance enhancements, which allow more efficient connections to clients behind firewalls and <span class="strong"><strong>Network Address Translation</strong></span> (<span class="strong"><strong>NAT</strong></span>) routers.</p><p>Support for NFSv2 is no longer available, which is no great loss, as it did not support file sizes above 2 GB and was not as robust as version 3 and 4.</p><p>Using NFSv4, mounting and locking protocols are incorporated in a <span class="emphasis"><em>batteries included</em></span> philosophy. This allows the use of just the one TCP port: <code class="literal">2049</code>. However, with NFSv3, we have to use <code class="literal">rpcbind</code> and set static ports for additional services so that a firewall can be configured. This simplifies the firewall configuration, which you will see later, as access only to the TCP port <code class="literal">2049</code> is required.</p><p>Both the server and client tools are installed together from the <code class="literal">nfs-utils</code> package. This package includes tools for <a id="id221" class="indexterm"/>both the NFSv4 and V3 protocols. It also includes other useful tools such as <code class="literal">nfsiostat</code> that can be used to monitor NFS shares usage on an NFS server. To list the contents of an installed package, you can use the <code class="literal">rpm</code> command, as shown in the following command lines that can be run as a standard user:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ rpm -ql nfs-utils #lists all files in the package</strong></span>
<span class="strong"><strong>$ rpm -qd nfs-utils #lists just the documentation files</strong></span>
<span class="strong"><strong>$ rpm -qc nfs-utils #list only the configuration files</strong></span>
<span class="strong"><strong>$ rpm -qi nfs-utils #displays descriptive information on the package</strong></span>
</pre></div></div></div>
<div class="section" title="Overview of the lab environment" id="aid-1IHDQ1"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec47"/>Overview of the lab environment </h1></div></div></div><p>For demonstrations <a id="id222" class="indexterm"/>is this chapter, we will use two virtual machines running in an <a id="id223" class="indexterm"/>
<span class="strong"><strong>Oracle VirtualBox</strong></span> virtualization environment. VirtualBox can be downloaded from <a class="ulink" href="https://www.virtualbox.org/">https://www.virtualbox.org/</a> free of charge and is available for Windows, Mac OS X, Linux, and Solaris hosts.</p><p>The NFS Server will be configured on the RHEL 7.1 host with the IP address of <code class="literal">192.168.10.10</code> and the hostname of <code class="literal">nfshost</code>. The NFS client will be configured on the RHEL 7.1 host with the IP address of <code class="literal">192.168.10.11</code> and the hostname of <code class="literal">nfsclient</code>.</p><p>Both machines were installed with a minimal configuration; we have installed the <code class="literal">nfs-utils</code> package on both hosts, as shown in the following code:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sudo yum install -y nfs-utils</strong></span>
</pre></div><p>Additionally, on the <code class="literal">nfshost</code> host, we have installed the net-tools package so that we can display open ports with the <code class="literal">netstat</code> command. The command to install <code class="literal">net-tools</code> is as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sudo yum install -y net-tools</strong></span>
</pre></div><p>The firewall is running the default setup and is managed with the <code class="literal">firewall-cmd</code> command. To allow NFSv4 connections to <code class="literal">nfshost</code>, we have additionally opened the TCP port <code class="literal">2049</code> using the following commands:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sudo firewall-cmd --add-port=2049/tcp --permanent</strong></span>
<span class="strong"><strong>$ sudo firewall-cmd --reload</strong></span>
</pre></div><div class="note" title="Note"><h3 class="title"><a id="tip18"/>Tip</h3><p>We will cover more on firewall on RHEL 7 later in this chapter and also look at how to use the<code class="literal">firewall-cmd</code> and <code class="literal">firewalld</code> service in detail in <a class="link" title="Chapter 11. Network Security with firewalld" href="part0090.xhtml#aid-2LQIK1">Chapter 11</a>, <span class="emphasis"><em>Network Security with firewalld</em></span>, of this book.</p></div><p>NFS not only uses a firewall to protect the server, but also supports TCP wrappers to control access. The rights to <a id="id224" class="indexterm"/>access a service can be determined by the use of the <code class="literal">/etc/hosts.allow</code> and <code class="literal">/etc/hosts.deny</code> files.</p></div>
<div class="section" title="The NFS server configuration"><div class="titlepage" id="aid-1JFUC2"><div><div><h1 class="title"><a id="ch06lvl1sec48"/>The NFS server configuration</h1></div></div></div><p>To configure the <a id="id225" class="indexterm"/>NFS server, we choose which directories we want to share. The terminology used in NFS to share a directory is <span class="emphasis"><em>to export</em></span> the <a id="id226" class="indexterm"/>directory; therefore, shared directories are known as <span class="strong"><strong>exports</strong></span>.</p><p>To permanently export <a id="id227" class="indexterm"/>a directory, we add the configuration to the /<code class="literal">etc/exports</code> file. This file exists, but will be empty on a new system. The <code class="literal">nfs-server</code> service will read this file on startup to determine which directories should be available to the network client. If <code class="literal">/etc/exports</code> is changed, reloading the <code class="literal">nfs-server</code> service will force the service to reread the file, as shown in the following command line:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sudo systemctl reload nfs-server</strong></span>
</pre></div><p>To display the current exports <a id="id228" class="indexterm"/>on the server, we can use the <code class="literal">exportfs</code> or <code class="literal">showmount</code> command. We will now take a little time to start the required services and create our first simple export.</p><p>Firstly, we will need to start the required services. We can start and enable each service independently, but in the spirit of automation, we will write a simple loop at Command Prompt to save some typing and time. We will use <code class="literal">sudo</code>; your user account will need to be listed within the <code class="literal">sudoers</code> file. Once you are sure that you have access to <code class="literal">sudo</code>, the command will be executed as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>for s in rpcbind nfs-server nfs-lock nfs-idmap ; do</strong></span>
<span class="strong"><strong>  sudo systemctl enable $s</strong></span>
<span class="strong"><strong>  sudo systemctl start $s</strong></span>
<span class="strong"><strong>done</strong></span>
</pre></div><p>If it makes the syntax clearer to you, the following screenshot shows the command as executed on <code class="literal">nfshost</code>:</p><div class="mediaobject"><img src="../Images/image00254.jpeg" alt="The NFS server configuration"/></div><p style="clear:both; height: 1em;"> </p><div class="section" title="Simple exports"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec36"/>Simple exports</h2></div></div></div><p>Without editing the <code class="literal">/etc/exports</code> file, we cannot export anything on the filesystem. As a result, there will be no <a id="id229" class="indexterm"/>output when we display the local exports using <code class="literal">exportfs</code>, as shown in the following command line:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sudo exportfs</strong></span>
</pre></div><p>We will have little luck with the <code class="literal">showmount</code> command, as shown in the following screenshot:</p><div class="mediaobject"><img src="../Images/image00255.jpeg" alt="Simple exports"/></div><p style="clear:both; height: 1em;"> </p><p>As you can see, the <code class="literal">showmount</code> command will show the export list heading, but, of course, the list is empty until we explicitly define some exported directories.</p><div class="note" title="Note"><h3 class="title"><a id="tip19"/>Tip</h3><p>The <code class="literal">showmount</code> command can be used on remote hosts, such as the <code class="literal">nfsclient</code>, to list exported directories, but this will depend on additional services. So, the firewall on <code class="literal">nfshost</code> will need to be configured for NFSv3. We will discuss this later in this chapter.</p></div><p>I accept that sharing nothing, nada, zilch is not the most exciting feature that you will find in this book, at least we have discovered some useful tools such as <code class="literal">exportfs</code> and <code class="literal">showmount</code>. We will now export an existing directory just to get used to NFS. To do this, we will need to edit as root the <code class="literal">/etc/exports</code> file; we can do this using <code class="literal">sudo</code>. You can log in as root directly or with the <code class="literal">su</code> command. We will add the following line to export or share the <code class="literal">/usr/share/doc</code> directory. This is just a simple test. We will add our own directories and content later. For our demonstration, we will stick to using <code class="literal">vi</code> in order to edit the file; however, you are welcome to use your favorite editor:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sudo vi /etc/exports</strong></span>
</pre></div><p>With the file open and without the contents on a new NFS server, we can add the following line to export the <code class="literal">/usr/share/doc</code> directory:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>/usr/share/doc *(ro)</strong></span>
</pre></div><p>Using the <code class="literal">cat</code> command, we can show the filename that we should be editing and the files' content once the edit is complete, as shown in the following screenshot:</p><div class="mediaobject"><img src="../Images/image00256.jpeg" alt="Simple exports"/></div><p style="clear:both; height: 1em;"> </p><p>Having exported a directory, we should be able to see this using <code class="literal">exportfs</code> or <code class="literal">showmount</code>.</p><div class="note" title="Note"><h3 class="title"><a id="tip20"/>Tip</h3><p>The <code class="literal">exportfs</code> command requires administrative access, whereas <code class="literal">showmount</code> does not.</p></div><p>However, before we get ahead of ourselves, we need to recall that the <code class="literal">nfs-server</code> service reads this file when it starts up and is currently running. We can restart this service, but it will be better to reload the service. In this way, there is no need to bring the service down if the remote hosts <a id="id230" class="indexterm"/>currently have mounted exports. Running the following command will reload the service and then display the exports directory or directories:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sudo systemctl reload nfs-server</strong></span>
<span class="strong"><strong>$ sudo exportfs</strong></span>
</pre></div><p>The output from both commands previously listed is now displayed in the following screenshot:</p><div class="mediaobject"><img src="../Images/image00257.jpeg" alt="Simple exports"/></div><p style="clear:both; height: 1em;"> </p><p>When we defined exports, we exported a directory to all hosts denoted with an asterix symbol; any options for the export are included within parenthesis. We specified the export as read only with the inclusion of the <code class="literal">ro</code> option.</p><p>As a simple test, we can now use the <code class="literal">nfsclient</code> host to access this export. From the console of the <code class="literal">nfsclient</code>, we can access the exported directory and mount it to the local <code class="literal">/mnt</code> directory on the <code class="literal">nfsclient</code> using the following command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sudo mount 192.168.10.10:/usr/share/doc /mnt</strong></span>
</pre></div><p>We can use either the IP address or the hostname of the server as long as the hostname is resolvable via DNS, <span class="strong"><strong>mDNS</strong></span> (<span class="strong"><strong>Multicast DNS</strong></span>), or the localhost's file. The end of the server hostname or IP <a id="id231" class="indexterm"/>address must be denoted with a colon.</p><p>We can easily list the contents of the exported directory using the standard <code class="literal">ls</code> command against the <code class="literal">/mnt</code> directory. The <a id="id232" class="indexterm"/>truncated output from the ls command is shown in the following screenshot:</p><div class="mediaobject"><img src="../Images/image00258.jpeg" alt="Simple exports"/></div><p style="clear:both; height: 1em;"> </p></div><div class="section" title="Advanced exports"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec37"/>Advanced exports</h2></div></div></div><p>We have seen how simple <a id="id233" class="indexterm"/>life can be for a Linux system administrator if only simple exporting of directories is all that is needed. However, although this option may fit some directory exports and servers, others may require a little more time and effort.</p><p>The basic directive within the <code class="literal">/etc/exports</code> file is as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>export host(options)</strong></span>
</pre></div><p>The structure of these variables is as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">export</code>: This is the directory on the NFS server being exported or shared</li><li class="listitem"><code class="literal">host</code>: This is the host or network to which the exported directory is shared</li><li class="listitem"><code class="literal">options</code>: These are specific options to be used by a host or network that proceeds the parenthesis</li></ul></div><p>It's also possible to write a single entry to share one export with different options to different hosts or networks, as shown in the following example code:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>export host(options) host(options)</strong></span>
</pre></div><p>Expanding this to actual values in place of the variables a working example to allow read/write access to <code class="literal">192.168.10.11</code> but read-only access to all other hosts, we can examine the following code:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>/usr/share/doc *(ro) 192.168.10.11(rw,sync)</strong></span>
</pre></div><p>Options are comma-separated, and we have additionally added the <code class="literal">sync</code> option in the options for the <code class="literal">nfsclient 192.168.10.11</code>. The <code class="literal">sync</code> option will ensure that writes to this export are written to disk on demand, rather than waiting for write-buffers to be flushed to the disk. Linux uses a system of buffering that promotes the use of dirty-cache buffers. These are written to disk as numbers grow. The <code class="literal">sync</code> option ensures that these buffers are written to the disk immediately. This has a negative impact on performance, but can be more reliable as connections are not always maintained.</p><p>If a single line in the <code class="literal">/etc/exports</code> file becomes too long, then it can be wrapped using the backslash (<code class="literal">\</code>) character. Within a file, each export must be represented with its own individual line. Additional <a id="id234" class="indexterm"/>blank lines are ignored and can be added for readability. Lines may be configured to be ignored by the server if they are commented with the line starting with the hash (<code class="literal">#</code>) character.</p><div class="note" title="Note"><h3 class="title"><a id="tip21"/>Tip</h3><p>If the read/write access is granted to the export and the filesystem is read only to the user, they still have read-only access. If the export is set to read only and the filesystem would normally allow read and write access to the user, they still have read-only access. Quite simply, when combining file and export permissions, the most restrictive permission is effective.</p></div><p>If we are to be 100 percent accurate, the options for an export are optional. If an option is not set, the default option will apply. We can then rewrite the previous example making use of the defaults as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>/usr/share/doc * 192.168.10.11(rw)</strong></span>
</pre></div><p>From the modified example, you should be able to guess correctly that the <code class="literal">ro</code> and <code class="literal">sync</code> default options are no longer explicitly set, but they will still be effective. The effective options for an exported directory can be seen using the <code class="literal">exportfs</code> command with the <code class="literal">-v</code> option, as show in the following command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sudo exportfs -v</strong></span>
</pre></div><p>If an option is not set and displayed in the output of the previous command, then you will see the default option.</p><p>The default options for the NFS server include the following; more details can be found on the <code class="literal">man</code> page:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">ro</code>: This makes the exported filesystem as read only on the remote host.</li><li class="listitem"><code class="literal">sync</code>: The NFS server writes changes to the disk before responding to new requests.</li><li class="listitem"><code class="literal">wdelay</code>: This is used with the <code class="literal">sync</code> option; the NFS server will delay writing to the disk and more writes are anticipated imminently.</li><li class="listitem"><code class="literal">root_squash</code>:The remote users connecting as root or <code class="literal">UID 0</code> are changed to <code class="literal">nfsnobody</code> and as such, we will only be able to collect permissions granted to others. This effectively squashes the permissions of root access remotes, preventing unauthorized root access to exported filesystems.</li></ul></div><p>We will now amend the <code class="literal">/etc/exports</code> file to represent two sets of hosts that we will export to and verify that we can connect from the designated host <code class="literal">192.168.10.11</code>. The export is set to <code class="literal">rw</code>, which supersedes the <code class="literal">ro</code> option set to all hosts with <code class="literal">*</code>. We will use <code class="literal">echo</code> to overwrite the <code class="literal">exports</code> file so that you can see the edit being made through to the file along with other <a id="id235" class="indexterm"/>commands. These commands are listed in the following example with a supporting screenshot to display export options:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sudo bash -c 'echo "/usr/share/doc * 192.168.10.11(rw)" &gt; /etc/exports'</strong></span>
<span class="strong"><strong>$ sudo systemctl reload nfs-server</strong></span>
<span class="strong"><strong>$ sudo exportfs -v</strong></span>
</pre></div><div class="mediaobject"><img src="../Images/image00259.jpeg" alt="Advanced exports"/></div><p style="clear:both; height: 1em;"> </p><p>From the preceding screenshot, we can see that the <code class="literal">192.168.10.11</code> host has read/write access, whereas <code class="literal">&lt;world&gt;</code> or all other hosts have read-only access.</p><div class="note" title="Note"><h3 class="title"><a id="tip22"/>Tip</h3><p>
<span class="strong"><strong>Be cautious with spaces</strong></span>
</p><p>The format of the <code class="literal">/etc/exports</code> file is very precise and no spaces should precede the host/network before the options for that host. The following entries have very different meanings:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>/home server1(rw)</strong></span>
<span class="strong"><strong>#correctly shares /home as read and write to server1</strong></span>
<span class="strong"><strong>/home server1 (rw)</strong></span>
<span class="strong"><strong>#shares the export /home to server1 using the default read-only and to &lt;world&gt; read-write is assigned, the asterisk can be omitted when designating all hosts.</strong></span>
</pre></div></div></div><div class="section" title="Pseudo-root"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec38"/>Pseudo-root</h2></div></div></div><p>As you can see in the <code class="literal">/usr/share/doc</code> current export, it's normal for the complete path of the exported directory to be used when accessing it on the server. It's possible to simplify paths that are <a id="id236" class="indexterm"/>needed to access exported directories using a pseudo-root directory on the server. This is only an option for NFSv4 servers and clients. With the pseudo-root directory in place, we can mount other directories to that path. Let's take a look at this on our <code class="literal">nfshost</code>.</p><p>We will clear the current exported directory. This time, we will set up sharing from scratch with a little thought and planning.</p><p>Firstly, we will create a new directory on <code class="literal">nfshost</code> that will act as the pseudo-root directory:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sudo mkdir -m 1777 /var/exports</strong></span>
</pre></div><p>We can create this directory and set mode or permissions at the same time. Here, we set permissions to all users and include the sticky bit so that users can only delete the files that they own.</p><p>Next, we will overwrite the current exports within the <code class="literal">/etc/exports</code> file with the newly created directory:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sudo bash -c 'echo "/var/exports 192.168.10.11(rw,fsid=0,crossmnt)" &gt; /etc/exports'</strong></span>
<span class="strong"><strong>$ sudo systemctl reload nfs-server</strong></span>
</pre></div><p>These commands are run on <code class="literal">nfshost</code> and shown in the following screenshot:</p><div class="mediaobject"><img src="../Images/image00260.jpeg" alt="Pseudo-root"/></div><p style="clear:both; height: 1em;"> </p><p>There are two new options that we implement here:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">fsid=0</code>: This sets the directory as the root directory of the server when accessed over NFS. In this way, the <code class="literal">/var/export</code> directory is accessed from the remote client as <code class="literal">192.168.10.10:/</code>.</li><li class="listitem"><code class="literal">crossmnt</code>: This is the clever option that we need in order to allow access to directories that are mounted underneath this mount point. To mount directories to this export, we will use the <code class="literal">mount --bind</code> command. This will be covered very shortly.</li></ul></div><p>Setting the export option as read/write enables us to control access using file permissions on the <code class="literal">nfshost</code>. Any user will have full permission to the export when accessing from the <code class="literal">nfsclient</code>, so restrictions will need to be made in the filesystem.</p><p>With the NFS root in place, we can make any directory within the filesystem available after this entry point. We will need to create subdirectories as mount points within the <code class="literal">/var/exports</code> directory and then mount the local targets to these mount points. We will add a central shared directory called <code class="literal">/home/marketing</code> and mount this and the existing <code class="literal">/usr/share/doc</code> directory after the newly created <code class="literal">exports</code> directory. The commands to achieve this are shown in the following command lines:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sudo mkdir -m 1777 /home/marketing</strong></span>
<span class="strong"><strong>$ touch /home/marketing/marketing.doc</strong></span>
<span class="strong"><strong>$ sudo mkdir -m 777 /var/exports/{doc,marketing}</strong></span>
<span class="strong"><strong>$ sudo mount --bind /usr/share/doc /var/exports/doc</strong></span>
<span class="strong"><strong>$ sudo mount --bind /home/marketing /var/exports/marketing</strong></span>
</pre></div><p>The following bullet points <a id="id237" class="indexterm"/>explain the preceding command line steps:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">After working through the list of commands, we first create the central shared directory that we will add after the <code class="literal">/home</code> structure. This may be desired due to partitioning and quota settings that dictate that the marketing directory should be on the <code class="literal">/home</code> partition.</li><li class="listitem">We add a document to this directory so that we are able to view some content.</li><li class="listitem">The third command in the list creates both the doc and marketing directories. We will use these directories as mount points. These directories are created in the <code class="literal">/var/exports</code> NFS root.</li><li class="listitem">The final two commands mount the local directories to their export mount points. In this way, we can easily add any directory to be available directly after /var/exports.</li></ul></div><p>Listing the contents on the <code class="literal">/var/exports/marketing</code> directory should show the file we created in the <code class="literal">/home/marketing</code> directory. Refer to the following screenshot:</p><div class="mediaobject"><img src="../Images/image00261.jpeg" alt="Pseudo-root"/></div><p style="clear:both; height: 1em;"> </p><p>In the same way, looking at the contents of <code class="literal">/var/exports/doc</code> should show the contents of <code class="literal">/usr/share/doc</code>.</p><p>For permanency of local mounts, we will need to add them to the <code class="literal">/etc/fstab</code> file in the following format:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>/originaldir /newdir none bind</strong></span>
</pre></div><p>We will now edit the <code class="literal">fstab</code> file as root and add these two lines to the end of the file to ensure that the mount points are populated during boot:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>/usr/share/doc /var/exports/doc none bind</strong></span>
<span class="strong"><strong>/home/marketing /var/exports/marketing none bind</strong></span>
</pre></div><p>When you return to the <code class="literal">nfsclient</code> system, you will be able test both exports and permissions. The original <code class="literal">/home/marketing</code> directory is writable, whereas the <code class="literal">/usr/share/doc</code> directory is not:</p><p>From the <code class="literal">nfsclient</code> system we can issue the following commands:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sudo mount 192.168.10.10:/ /mnt</strong></span>
<span class="strong"><strong>$ touch /mnt/marketing/file1</strong></span>
<span class="strong"><strong>$ touch /mnt/doc/file1</strong></span>
</pre></div><p>Now the file path is simpler, being <a id="id238" class="indexterm"/>able to access both folders with a single path from the server's NFS root. We should also note that although the exported directory is read/ write, we can write to the <code class="literal">marketing</code> directory using the first <code class="literal">touch</code> command, but the second <code class="literal">touch</code> command will fail as the target filesystem is read only.</p></div></div>
<div class="section" title="Using exportfs to create temporary exports" id="aid-1KEEU1"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec49"/>Using exportfs to create temporary exports</h1></div></div></div><p>It's not always <a id="id239" class="indexterm"/>desirable to create permanent exports within the <code class="literal">/etc/exports</code> file. Should you want to define a new export temporarily, you can use the <code class="literal">exportfs</code> command. As we have already defined the NFS root to be <code class="literal">/var/exports</code>, all directories that we export must be after that structure. Let's temporarily export <code class="literal">/var/export/doc</code> to all hosts. We can do so using the following command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sudo exportfs *:/var/exports/doc</strong></span>
</pre></div><p>On the next restart of <code class="literal">nfs-server</code>, this export will be lost; however, if you need to delete it ahead of this, you can implement the following command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sudo exportfs -u *:/var/exports/doc</strong></span>
</pre></div><p>Should you need to include export options with the temporary export, use the <code class="literal">-o</code> option in a similar manner, as shown in the following command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sudo exportfs *:/var/exports/doc -o ro,all_squash</strong></span>
</pre></div><p>To display the current <a id="id240" class="indexterm"/>exports, you can run <code class="literal">exportfs</code> by itself:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sudo exportfs</strong></span>
</pre></div></div>
<div class="section" title="Hosting NFSv4 behind a firewall" id="aid-1LCVG1"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec50"/>Hosting NFSv4 behind a firewall</h1></div></div></div><p>When you <a id="id241" class="indexterm"/>access the NFS server using v4 of the protocol on both the <a id="id242" class="indexterm"/>client and server, the firewall configuration is quite simple with only the TCP port <code class="literal">2049</code> required to be opened. The default firewall daemon on RHEL 7 is <code class="literal">firewalld</code> and is managed from the command line using <code class="literal">firewall-cmd</code>.</p><p>We have been running the standard firewall for our demonstrations thus far just opening the one additional port <code class="literal">2049</code>, as detailed in the lab overview earlier in this section.</p><p>We can list the current firewall configuration using the following command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sudo firewall-cmd --list-all</strong></span>
</pre></div><p>The output is shown in the following screenshot:</p><div class="mediaobject"><img src="../Images/image00262.jpeg" alt="Hosting NFSv4 behind a firewall"/></div><p style="clear:both; height: 1em;"> </p><p>Should you need to <a id="id243" class="indexterm"/>remove the port setting that we added, this can be done using the following commands:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sudo firewall-cmd --remove-port=2049/tcp --permanent</strong></span>
<span class="strong"><strong>$ sudo firewall-cmd --reload</strong></span>
</pre></div><p>Of course, a client can no longer access the NFS exports. We have the choice of adding ports or service entries. To add a service entry, the port and associated service needs to be defined in the <code class="literal">/etc/services</code> file. This can be easily checked using the <code class="literal">grep</code> command. An example is shown in the following command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ grep 2049 /etc/services</strong></span>
</pre></div><p>We do have an entry for the port <code class="literal">2049</code> and the service is called <code class="literal">nfs</code>. To use the service name in the firewall configuration, you may use the following command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sudo firewall-cmd --add-service=nfs --permanent</strong></span>
<span class="strong"><strong>$ sudo firewall-cmd --reload</strong></span>
<span class="strong"><strong>$ sudo firewall-cmd --list-all</strong></span>
</pre></div><p>This is illustrated <a id="id244" class="indexterm"/>with the following screenshot:</p><div class="mediaobject"><img src="../Images/image00263.jpeg" alt="Hosting NFSv4 behind a firewall"/></div><p style="clear:both; height: 1em;"> </p><p>With the service now allowed in all firewall rules, we can continue to access the NFS export from <code class="literal">nfsclient</code>. If <a id="id245" class="indexterm"/>you want to use tools like <code class="literal">showmount</code> remotely or if you have NFSv3 clients, you will need to open more ports and set some ports statically.</p></div>
<div class="section" title="Hosting NFSv3 behind a firewall"><div class="titlepage" id="aid-1MBG22"><div><div><h1 class="title"><a id="ch06lvl1sec51"/>Hosting NFSv3 behind a firewall</h1></div></div></div><p>If we try to use <a id="id246" class="indexterm"/>the <code class="literal">showmount</code> command from the <code class="literal">nfsclient</code>, we <a id="id247" class="indexterm"/>should be able to list exports on the remote NFS server. The syntax will be as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ showmount -e 192.168.10.10</strong></span>
</pre></div><p>The command and the corresponding error are shown in the following screenshot:</p><div class="mediaobject"><img src="../Images/image00264.jpeg" alt="Hosting NFSv3 behind a firewall"/></div><p style="clear:both; height: 1em;"> </p><p>At this stage, we can choose from the following options:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Pack our bags and go home, perhaps it will be better tomorrow</li><li class="listitem">Google the error</li><li class="listitem">Debug the error ourselves</li></ul></div><div class="section" title="Diagnosing NFSv3 issues"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec39"/>Diagnosing NFSv3 issues</h2></div></div></div><p>Now, Google is <a id="id248" class="indexterm"/>often really good at helping us, but you fail to learn fault-finding techniques, so let's opt out of option 3 and install the <code class="literal">tcpdump</code> command-line packet analyzer so that we can see what is happening. This can be installed on <code class="literal">nfsclient</code> using <code class="literal">yum</code> as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sudo yum install -y tcpdump</strong></span>
</pre></div><p>To capture network traffic between the <code class="literal">nfsclient</code> and the <code class="literal">nfshost</code> and to print port numbers that are being accessed, we can use the following command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sudo tcpdump -nn -i enp0s8 host 192.168.10.10</strong></span>
</pre></div><p>The options to <code class="literal">tcpdump</code> used here are listed as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">-nn</code>: This shows the host IP addresses and port numbers and not their names.</li><li class="listitem"><code class="literal">-i</code>: This is the interface to be used. You will need to use the correct interface name, where we have used <code class="literal">enp0s8</code> as the interface we need to listen on.</li><li class="listitem"><code class="literal">host 192.168.10.10</code>: This displays traffic to and from this host. This is the IP address for the <code class="literal">nfshost</code>.</li></ul></div><p>From another console or the SSH session, try the <code class="literal">showmount</code> command again. While viewing the console where <code class="literal">tcpdump</code> is running, we should try to access the UDP port <code class="literal">111</code> on the server twice and report the error. The output is shown from my system in the following screenshot:</p><div class="mediaobject"><img src="../Images/image00265.jpeg" alt="Diagnosing NFSv3 issues"/></div><p style="clear:both; height: 1em;"> </p><p>The UDP Port <code class="literal">111</code> is not open in the firewall configuration of <code class="literal">nfshost</code>. If you recall, we have just displayed the allowed services and ports for the firewall and <code class="literal">111</code> was not among them.</p><p>Port <code class="literal">111</code> is held open by the <code class="literal">portmapper</code> service run by <code class="literal">rpcbind</code> and shows as the <code class="literal">sunrpc</code> service in the <code class="literal">/etc/services</code> file. We can check this by running <code class="literal">netstat</code> on the <code class="literal">nfshost</code> as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sudo netstat -aunp</strong></span>
</pre></div><p>The options to <code class="literal">netstat</code> used here are listed as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">-a</code>: This shows all and by all; by this we mean listening and established ports</li><li class="listitem"><code class="literal">-u</code>: This displays UDP ports only</li><li class="listitem"><code class="literal">-n</code>: This displays port and network numbers rather than resolving them to names</li><li class="listitem"><code class="literal">-p</code>: This displays the process name holding the port or connection open</li></ul></div><p>To use the <code class="literal">-p</code> option, we must run as root (using <code class="literal">sudo</code>); otherwise, the process column will be left blank.</p><p>The theory behind the <code class="literal">rpcbind</code> service is that it will return the port address so that the required service is running to the requesting client. This is how NFSv3 works and the <code class="literal">showmount</code> command still makes use of this old protocol. The incoming request from <code class="literal">showmount</code> from the remote client asks for the address of the NFS Mount Daemon. This is the service running as the <a id="id249" class="indexterm"/>process: <code class="literal">rpc.mountd</code>. These services can run on dynamically-assigned ports. As such, it requires further configuration to reliably have them allowed through your firewall on a long term basis.</p><p>The pictorial process of <a id="id250" class="indexterm"/>what should be happening with <code class="literal">showmount</code> starts with the request for the <code class="literal">rpc.mountd</code> port, as shown in the following screenshot:</p><div class="mediaobject"><img src="../Images/image00266.jpeg" alt="Diagnosing NFSv3 issues"/></div><p style="clear:both; height: 1em;"> </p><p>We can start by allowing the <code class="literal">rpcbind</code> traffic from the firewall to the <code class="literal">nfshost</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sudo firewall-cmd --add-port=111/udp --permanent</strong></span>
<span class="strong"><strong>$ sudo firewall-cmd --reload</strong></span>
</pre></div><div class="note" title="Note"><h3 class="title"><a id="tip23"/>Tip</h3><p>Don't forget to reload the firewall once you have added the port. It's all too easy to forget to complete this.</p></div><p>Now that we can connect to the <code class="literal">rpcbind portmapper</code> service running on the UDP port <code class="literal">111</code>, we should go a little further. Remember that we are really trying to debug the process and learn some useful <code class="literal">tcpdump</code> analysis tricks. We can repeat the previous exercise running <code class="literal">tcpdump</code> on one console and <code class="literal">showmount</code> on the other (both consoles running on the <code class="literal">nfsclient</code>). The error reported from the <code class="literal">showmount</code> command should be slightly different now. To <a id="id251" class="indexterm"/>illustrate this, the following screenshot shows the current error, where we have the UDP port <code class="literal">111</code> open:</p><div class="mediaobject"><img src="../Images/image00267.jpeg" alt="Diagnosing NFSv3 issues"/></div><p style="clear:both; height: 1em;"> </p><p>So, the error is slightly different now, we now no longer have the error number; however, we can see from the <code class="literal">tcpdump</code> output that we received the reply from the <code class="literal">nfshost</code>. Subsequently, we then try to make a TCP connection back to the host on the port <code class="literal">20048</code>.</p><p>To identify the purpose of this port, we can again use <code class="literal">netstat</code>, but this time, we will replace <code class="literal">-u</code> with <code class="literal">-t</code> because we want to show the TCP ports. As we only need to see listening ports, we can replace <code class="literal">-a</code> with <code class="literal">-l</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sudo netstat -ltnp</strong></span>
</pre></div><p>We should see that the port we are trying to connect to is being held open by <code class="literal">rpc.mountd</code>. Of course, this is not allowed through the firewall.</p><div class="note" title="Note"><h3 class="title"><a id="tip24"/>Tip</h3><p>The port that <code class="literal">rpc.mountd</code> listens on may well be different to the port used on your system, so adjust the exercises to work with your <code class="literal">rpc.mountd</code> port and the port that is being used by your client.</p></div><p>The output from <code class="literal">tcpdump</code> is shown in the following screenshot. We can identify it as TCP traffic by additional <a id="id252" class="indexterm"/>properties, such as the sequence (<code class="literal">seq</code>) and window size (<code class="literal">win</code>), which we have highlighted in the following screenshot:</p><div class="mediaobject"><img src="../Images/image00268.jpeg" alt="Diagnosing NFSv3 issues"/></div><p style="clear:both; height: 1em;"> </p><p>So now we can see that we also require the TCP port <code class="literal">20048</code> to be opened through the firewall on the NFS server; remember that the port may not be the same on your <code class="literal">nfshost</code>; we can remedy this very quickly using <code class="literal">firewall-cmd</code> from <code class="literal">nfshos</code>t again as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sudo firewall-cmd --add-port=20048/tcp --permanent</strong></span>
<span class="strong"><strong>$ sudo firewall-cmd --reload</strong></span>
</pre></div><p>Now, we can return to the <code class="literal">nfsclient</code> as the <code class="literal">showmount</code> command should work correctly now, as shown in the following screenshot:</p><div class="mediaobject"><img src="../Images/image00269.jpeg" alt="Diagnosing NFSv3 issues"/></div><p style="clear:both; height: 1em;"> </p></div><div class="section" title="Using static ports for NFSv3"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec40"/>Using static ports for NFSv3</h2></div></div></div><p>The <code class="literal">portmapper</code> <a id="id253" class="indexterm"/>service is required for services that operate on non-static ports, which include the <code class="literal">rpc.mountd</code> and other NFSv3-based services. While <a id="id254" class="indexterm"/>configuring NFSv4 is simple because we only require access to the TCP port <code class="literal">2049</code> as the only requisite to the firewall, we still need access to more ports with v3 and most of these ports are non-static. Help is at hand though with the <code class="literal">/etc/sysconfig/nfs</code> file, where we can add entries enabling static ports for these services. The configuration is different on the RHEL 6 configuration. This is where search engines can often let you down with outdated documentations. This also includes the RHEL 7 documentation that is not up to date. Here, we show the correct settings that you will need in the <code class="literal">/etc/sysconfig/nfs</code> file to set static ports.</p><p>When you work on <code class="literal">nfshost</code> as root and use a text editor of your choice, you will need to edit the following lines:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>RPCRQUOTADOPTS="-p 30001"</strong></span>
<span class="strong"><strong>LOCKD_TCPPORT=30002</strong></span>
<span class="strong"><strong>LOCKD_UDPPORT=30002</strong></span>
<span class="strong"><strong>RPCMOUNTDOPTS="-p 30003"</strong></span>
<span class="strong"><strong>STATDARG="-p 30004"</strong></span>
</pre></div><p>The ports used are nominal and you should choose ports that are not in use on your system. You can see that some services take the <code class="literal">-p</code> option to specify a port. The <code class="literal">rpc.lockd</code> utility has an actual port configuration. This was the RHEL 6 way of configuring all ports, but has changed on RHEL 7.</p><p>We will need to restart our services, and we can restart them individually or revisit the <code class="literal">for</code> loop that we used earlier. The edited loop is shown in the following code:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>for s in rpcbind nfs-server nfs-lock nfs-idmap ; do</strong></span>
<span class="strong"><strong>  sudo systemctl restart $s</strong></span>
<span class="strong"><strong>done</strong></span>
</pre></div><p>We have now configured <code class="literal">nfshost</code> to use the static ports for these NFS services that will normally cause us an issue with dynamic ports. We still need the UDP port <code class="literal">111</code> configured in the firewall rules to allow access to <code class="literal">portmapper</code>, but we now know the ports that will be returned for other services and that they can be added. The final firewall configuration for NFSv3 using ports that we have configured are listed in the following command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>sudo firewall-cmd --add-port=111/udp --permanent</strong></span>
<span class="strong"><strong>sudo firewall-cmd --add-port=2049/tcp --permanent</strong></span>
<span class="strong"><strong>sudo firewall-cmd --add-port=30001/tcp --permanent</strong></span>
<span class="strong"><strong>sudo firewall-cmd --add-port=30001/udp --permanent</strong></span>
<span class="strong"><strong>sudo firewall-cmd --add-port=30002/tcp --permanent</strong></span>
<span class="strong"><strong>sudo firewall-cmd --add-port=30002/udp --permanent</strong></span>
<span class="strong"><strong>sudo firewall-cmd --add-port=30003/tcp --permanent</strong></span>
<span class="strong"><strong>sudo firewall-cmd --add-port=30003/udp --permanent</strong></span>
<span class="strong"><strong>sudo firewall-cmd --add-port=30004/tcp --permanent</strong></span>
<span class="strong"><strong>sudo firewall-cmd --add-port=30004/udp --permanent</strong></span>
<span class="strong"><strong>sudo firewall-cmd --reload</strong></span>
</pre></div><p>If we want to test the configuration fully with NFSv4, you will need to remove the <code class="literal">crossmnt</code> and <code class="literal">fsid</code> <a id="id255" class="indexterm"/>options from the exiting export definition <a id="id256" class="indexterm"/>because these are v4 options.</p></div><div class="section" title="Configuring the NFS client"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec41"/>Configuring the NFS client</h2></div></div></div><p>When mounting filesystems <a id="id257" class="indexterm"/>from a client, the default protocol implemented is NFSv4 on RHEL 7. We can explicitly set the protocol to v3 or v4, using the <code class="literal">-t</code> option to the mount command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sudo mount -t nfs4 192.168.10.10:/var/exports /mnt  #NFS 4</strong></span>
<span class="strong"><strong>$ sudo mount -t nfs 192.168.10.10:/var/exports /mnt    #NFS 3</strong></span>
</pre></div><p>In the following screenshot, you can see that we are able to connect from <code class="literal">nfsclient</code> using NFSv4 or NFSv3:</p><div class="mediaobject"><img src="../Images/image00270.jpeg" alt="Configuring the NFS client"/></div><p style="clear:both; height: 1em;"> </p><p>Other mount options can be applied with the <code class="literal">-o</code> option to the mount command. You may consider the following command options:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">bg</code>: This backgrounds the mount process</li><li class="listitem"><code class="literal">rsize=xxxx</code>: This specifies the maximum read size request in bytes</li><li class="listitem"><code class="literal">wsize=xxxx</code>: This specifies the maximum write buffer size in bytes</li></ul></div><p>For more NFSv3 and NFSv4 <a id="id258" class="indexterm"/>mount options, these can be read in detail from the appropriate man page, as shown in the following command line:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ man 5 nfs</strong></span>
</pre></div></div></div>
<div class="section" title="Auto-mounting NFS with autofs" id="aid-1NA0K1"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec52"/>Auto-mounting NFS with autofs</h1></div></div></div><p>There is a <a id="id259" class="indexterm"/>client-side service called <code class="literal">autofs</code> that acts as an auto-mount service for both local and remote filesystems. This works with a kernel module and <a id="id260" class="indexterm"/>the user space service; as you enter a directory, the mount is created automatically. The <code class="literal">autofs</code> package needs to be installed along with the <code class="literal">nfs-utils</code> package if NFS mounts are to be made. The auto-mounting feature can work with other remote filesystems, not just NFS. To install <code class="literal">autofs</code>, use the following command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sudo yum install -y autofs</strong></span>
</pre></div><p>With this installed, the default behavior is to use the <code class="literal">/net</code> directory point for the network hosts. We can then access shares or exports on any host that we have access to, and enter a directory that matches the server name or IP address after the <code class="literal">/net</code> directory. We only need to create top level directories and do not need to create subdirectories. We can just change the directories to <code class="literal">/net/192.168.10.10</code> and this directory will be created. Listing the contents of the directory will list the root level of the exports on the <code class="literal">nfshost</code>. This may sound too good to be true, so let's see this in action. First, we will create the directory and then start the service and enable it, as shown in the following command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sudo mkdir /net</strong></span>
<span class="strong"><strong>$ sudo systemctl start autofs</strong></span>
<span class="strong"><strong>$ sudo systemctl enable autofs</strong></span>
</pre></div><p>With this in place, we can simply list the contents of the <code class="literal">/net/192.168.10.10</code> directory. We should see the top level of the export configuration. For us, this is currently the <code class="literal">/var</code> directory and the export directory is <code class="literal">/var/export</code>. If we have more top level directories exported, they too will show. The <code class="literal">/net/192.168.10.10</code> directory is created automatically and the default timeout for <code class="literal">autofs</code> is 300 seconds or 5 minutes. After 5 minutes of inactivity, a filesystem that is mounted will be automatically unmounted and the directory will <a id="id261" class="indexterm"/>disappear until it's needed again. This is a typical safe value; however, a specific timeout can be configured. We will see this later.</p><p>The following screenshot shows the four commands executed in order and the listing of the the temporary automount directory:</p><div class="mediaobject"><img src="../Images/image00271.jpeg" alt="Auto-mounting NFS with autofs"/></div><p style="clear:both; height: 1em;"> </p><p>Auto-mounting directories on the client as they are required reduces the overhead on both the client and server, which is a really effective way of generating mounts. To define our own mounts points, we can edit the <code class="literal">/etc/auto.master</code> configuration file. We will add a top level directory as before.</p><p>In <code class="literal">/etc/auto.master</code> file, we will add the following command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>/corp /etc/auto.corp --timeout=600</strong></span>
</pre></div><p>This setting in the <code class="literal">auto.master</code> file tells the <code class="literal">autofs</code> service that when entering the <code class="literal">/corp</code> directory, the <a id="id262" class="indexterm"/>configuration can be read from the <code class="literal">/etc/auto.corp</code> file. Additionally, we have doubled the default timeout to 10 minutes for this auto-mount. We will need to create the top-level directory as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sudo mkdir /corp</strong></span>
</pre></div><p>The configuration file for this directory should look similar to this in our case:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>redhat -fstype=nfs4,rsize=4096,wsize=4096 192.168.10.10:/var/exports</strong></span>
</pre></div><p>With this entry, we will <a id="id263" class="indexterm"/>be able to see the contents of the server export while entering the <code class="literal">/corp/redhat</code> directory. We do not create the <code class="literal">redhat</code> subdirectory. Before testing, you will need to restart the <code class="literal">autofs</code> service:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>$ sudo systemctl restart autofs</strong></span>
</pre></div><p>Now, we can access the <code class="literal">/corp</code> directory and it will be empty. This is shown in the following screenshot:</p><div class="mediaobject"><img src="../Images/image00272.jpeg" alt="Auto-mounting NFS with autofs"/></div><p style="clear:both; height: 1em;"> </p><p>If we now access the <a id="id264" class="indexterm"/>
<code class="literal">redhat</code> directory, this does not show yet; we will <a id="id265" class="indexterm"/>be able to list the contents of the server's export. This is shown in the following screenshot:</p><div class="mediaobject"><img src="../Images/image00273.jpeg" alt="Auto-mounting NFS with autofs"/></div><p style="clear:both; height: 1em;"> </p><p>I have been using this for years; it's still one of the most magical experiences on Linux.</p></div>
<div class="section" title="Summary" id="aid-1O8H61"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec53"/>Summary</h1></div></div></div><p>I hope that you have found this chapter both intense and useful. There has been a lot of content to cover that has been made complicated by the need to cover both NFSv4 and NFSv3. Similar to most technologies, legacy clients need to be supported for some time. The great advantage this gave us was diagnosing firewall issues and using <code class="literal">tcpdump</code> in anger.</p><p>The main point with NFS and firewalling is to use NFSv4 wherever possible because we then only need to open the one static port: the TCP port <code class="literal">2049</code>. For NFSv3, we need to assign static ports and often need to open both UDP and TCP ports to each protocol, depending on the client that connects.</p><p>Finishing the chapter on <code class="literal">autofs</code> is a real high note because this is so simple and effective to use, auto-creating directories and mounting them as required. What more could we wish for!</p><p>In the next chapter, we will stay with file sharing, but investigate sharing to Windows systems using Samba 4.</p></div></body></html>