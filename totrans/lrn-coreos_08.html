<html><head></head><body>
<div id="page" style="height:0pt"/><div class="book" title="Chapter&#xA0;8.&#xA0;What Next?" id="1DOR01-31555e2039a14139a7f00b384a5a2dd8"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch08" class="calibre1"/>Chapter 8. What Next?</h1></div></div></div><p class="calibre9">In this chapter, we will touch upon some advanced Docker and Core OS topics and we will also discuss what is upcoming in CoreOS. For most of the topics, we will not go into the details of using or deploying each of the features mentioned in this chapter, but will discuss enough so as to be aware of what else is cooking.</p><p class="calibre9">This chapter covers the following topics:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Container security</li><li class="listitem">Easy upgrade using CoreUpgrade</li><li class="listitem">User authentication using Dex</li><li class="listitem">Sysdig</li><li class="listitem">Other container orchestration mechanisms such as Kubernetes, Apache Mesos, and Swarm</li><li class="listitem">Docker data volume management</li><li class="listitem">Open Container Project</li></ul></div></div>

<div class="book" title="Chapter&#xA0;8.&#xA0;What Next?" id="1DOR01-31555e2039a14139a7f00b384a5a2dd8">
<div class="book" title="Container security"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_1"><a id="ch08lvl1sec42" class="calibre1"/>Container security</h1></div></div></div><p class="calibre9">Security is<a id="id351" class="calibre1"/> an important aspect of any deployment. There should be security in the applications, devices, and network to disallow any unauthorized access. There should also be security in the container/docker deployment so as to disallow unauthorized access to system resources reserved for the container. We will understand how Docker container ensures network and resource isolation and security.  </p><p class="calibre9">Docker uses the namespaces to isolate the container from other containers running on the host. There are <a id="id352" class="calibre1"/>three important namespaces that take part in providing security:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre2">Process namespace</strong></span>: Each<a id="id353" class="calibre1"/> Linux system has a process tree, that is, there is an init process with process ID 1, which is also called the root process. This root process spawns other daemons and processes as a child process. These daemons and processes can then create their own child and so on. It is possible to create a child namespace with one of the child as the root process. All the processes running in <a id="id354" class="calibre1"/>the child namespace don't have the <a id="id355" class="calibre1"/>knowledge of the parent namespace; hence, they can't perform any operations (like signal) on the processes outside their namespace.</li><li class="listitem"><span class="strong"><strong class="calibre2">Network namespace</strong></span>: Each container has its own network interface that is different<a id="id356" class="calibre1"/> from the host interface's. They have their own loop-back interface as well. The only way containers can talk to the external world is through the bridge network at the host. Bridge network enables communication between different namespaces running in the same host or to an address in another host. This ensures that the network stack is exclusive to the container, thereby running its own IP, TCP, UDP stacks, and so on. Docker has an additional layer of security by allowing communication with another Docker by exposing ports or by creating links to another container explicitly.</li><li class="listitem"><span class="strong"><strong class="calibre2">Resource namespace</strong></span>: This ensures that each container has its own resource exclusively<a id="id357" class="calibre1"/> for its own use. Resource can be dedicated RAM, processors, or a disk with its own filesystem. This ensures that the container usage doesn't cross the set limits, thus ensuring that it doesn't intrude upon the resources being allocated to another container.</li></ul></div><p class="calibre9">The <a id="id358" class="calibre1"/>following figure illustrates the isolation provided by the Docker container. As we can see, the service running inside container has its own root process, filesystem, and interface which an operation system would normally provide. These features are present in almost all of the Linux distributions that Docker uses to provide isolation.</p><div class="mediaobject"><img src="../images/00039.jpeg" alt="Container security" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre9">After<a id="id359" class="calibre1"/> isolation, let's discuss security. Docker starts container in non-privilege mode. That means containers or applications running inside the container only have permissions to perform actions that don't require root privileges. Some examples are using a port less than 1024 (though non-privileged docker can use ports that are under and above the 1024 range), modifying a file in <code class="email">/etc, </code>mounting a filesystem, and so on. This ensures that even services in containers are hacked; they can't inflict damage on the host and the impact can be limited to that container instance. The allowed privileges can be configured and it can be very restrictive, or very relaxed based on the environment (trusted or non-trusted) containers are expected to work. </p><p class="calibre9">Docker also recommends securing the access to Docker Daemon, which runs as root on the host machine. Also, it recommends enabling secure HTTP connections in case it is required to <a id="id360" class="calibre1"/>administrate a container remotely. Further, the in-built firewalls in Linux kernel like <code class="email">SELinux</code> can be used to further add restrictions on the Docker to set restrictions for using only specific ports and specific protocols (only TCP, only UDP, and so on). Also, it is advisable to use other Linux security utilities and tools to protect and harden the system.</p></div></div>
<div class="book" title="Update and patches &#x2013; CoreUpdate" id="1ENBI1-31555e2039a14139a7f00b384a5a2dd8"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch08lvl1sec43" class="calibre1"/>Update and patches – CoreUpdate</h1></div></div></div><p class="calibre9">
<code class="email">CoreUpdate</code> is <a id="id361" class="calibre1"/>a service available as part of <code class="email">Premium Manged Service</code> targeted at Enterprise customers who require support and SLA-based support in case they face issues with deployment. <code class="email">CoreUpdate</code> helps to monitor cluster health, cluster software versions, manage updates, and patch deployment.</p><p class="calibre9">
<code class="email">CoreUpdates</code> provides a web interface and a command-line interface to view the versions running on each of the <code class="email">CoreOS</code> instances and to schedule upgrades on them. All instances of the <code class="email">CoreOS</code> can be logically distributed into multiple application groups, and upgrades can be managed individually for those applications. For instance, they can be configured to pick the upgrade/patch from different channels like stable/beta/alpha. They can be scheduled at different times and can have different metadata, like where to pick the package for upgrade/patch. During the upgrade process, progress of the upgrade is displayed and any error/information/warnings are displayed to take corrective actions.</p><p class="calibre9">
<code class="email">CoreUpdate</code> also provides a HTTP-based API to integrate software management with the developed application.</p></div>
<div class="book" title="Dex" id="1FLS41-31555e2039a14139a7f00b384a5a2dd8"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch08lvl1sec44" class="calibre1"/>Dex</h1></div></div></div><p class="calibre9">All of us<a id="id362" class="calibre1"/> have experienced user authentication in multiple ways, like when we log in to websites, log in to our computer, log in to social sites, and so on. There are a wide variety of authentication systems like local users being managed by a system admin for Linux or Microsoft Windows, Enterprise-wide Active Directory, or LDAP, or through identity providers such as Google, Outlook, Yahoo!, and Facebook.</p><p class="calibre9">As an application <a id="id363" class="calibre1"/>developer, <span class="strong"><strong class="calibre2">Dex</strong></span> (<a class="calibre1" href="https://github.com/coreos/dex">https://github.com/coreos/dex</a>) solves the problem of user authentication by providing a ready-to-use standard-based implementation and connectors for various authentication systems including local authentication. This makes it easier for the developer to concentrate on their business logic and trust that authentication is well taken care of.</p><p class="calibre9">Since Dex implementation is based on standard (<span class="strong"><strong class="calibre2">OpenID Connect (OIDC) Core spec</strong></span>), it is <a id="id364" class="calibre1"/>language independent as the interfaces are well defined. Use a client library conforming to OIDC corresponding to the programming language and you are good to go.</p><p class="calibre9">There <a id="id365" class="calibre1"/>are different authentication mechanisms that can be used by integrating off-the-shelf connectors. If we have to draw a parallel, it is very much like a database connector.  Currently, two connectors, local and OIDC connector, and more are getting developed. With local connector, the user can log in to the system using the authentication database maintained by Dex locally, like Linux user IDs and passwords. With OIDC connectors, users can be authenticated using another OIDC Identity Provider like Google or another <code class="email">Dex</code> instance as Dex itself is an OIDC identity provider.</p><p class="calibre9">So, if you have a requirement for authentication in your system, explore Dex.</p></div>
<div class="book" title="sysdig" id="1GKCM1-31555e2039a14139a7f00b384a5a2dd8"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch08lvl1sec45" class="calibre1"/>sysdig</h1></div></div></div><p class="calibre9">We are<a id="id366" class="calibre1"/> aware of commonly used debugging tools for Linux to monitor and take snapshots of system health. For example, if we want to check whether the machine is overloading its CPU or RAM, we use tools like <code class="email">top</code> or <code class="email">vmstat</code>. If we have to capture the packets over the interface, we use <code class="email">wireshark</code> or <code class="email">tcpdump</code>. Similarly, we use <code class="email">iostat</code> to monitor the system IO devices.</p><p class="calibre9">
<code class="email">sysdig</code> provides integrated support for monitoring all the preceding system resources along with providing many more features. And most importantly, in our context it provides support for containers. We know that containers run in the host OS in separate namespaces. So the processes running inside containers are also visible to the native tools, say, for example, <code class="email">ps</code>. In a container environment, the information related to the application is present in two levels: one at the host kernel level, for example process ID as the host kernel sees it, and the other at the container level, for example, the process ID inside the container. All native Linux tools give a host kernel view leaving it to the user to correlate information to find out which information pertains to the container and segregate information on a per-container basis. To get information as the container application sees it, Docker interfaces/commands are to be used. <code class="email">sysdig</code> solves this problem.</p><p class="calibre9">Let's take a hands-on approach to get a feel of what information <code class="email">sysdig</code> provides. </p><p class="calibre9">The first step is to install and run <code class="email">sysdig</code>. After we start the docker container for sysdig, we are taken to  a shell where we can run the <code class="email">sysdig</code> commands.  </p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">Vagrant ssh core-01</strong></span>
<span class="strong"><strong class="calibre2">docker pull sysdig/sysdig</strong></span>
<span class="strong"><strong class="calibre2">docker run -i -t --name sysdig --privileged -v /var/run/docker.sock:/host/var/run/docker.sock -v /dev:/host/dev -v /proc:/host/proc:ro -v /boot:/host/boot:ro -v /lib/modules:/host/lib/modules:ro -v /usr:/host/usr:ro sysdig/sysdig</strong></span>
</pre></div><p class="calibre9">Start a Docker container as daemon using the following command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">/usr/bin/docker run –d --name busybox busybox /bin/sh -c "while true; do echo Hello World; sleep 60; done"</strong></span>
</pre></div><p class="calibre9">We will<a id="id367" class="calibre1"/> run some example commands to find out container-specific information. First, we will list the containers running on the machine both using the <code class="email">docker ps</code> in another login window and using <code class="email">sysdig</code>:</p><div class="informalexample"><pre class="programlisting">docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES
f71277abf37c        busybox             "/bin/sh -c 'while tr"   4 seconds ago       Up 3 seconds                            busybox
d21a39a0668f        sysdig/sysdig       "/docker-entrypoint.s"   5 minutes ago       Up 5 minutes                            sysdig</pre></div><p class="calibre9">We see here that there are two containers running on the host machine: one container is for <code class="email">sysdig</code> and the other is the <code class="email">busybox</code> we started. Now, we will run the corresponding <code class="email">sysdig</code> command:</p><div class="informalexample"><pre class="programlisting">sysdig -c lscontainers
container.type container.image container.name      container.id
-------------- --------------- ------------------- ------------
docker         busybox         busybox             f74777abf37c
docker         sysdig/sysdig   sysdig              d2da79a0668f</pre></div><p class="calibre9">The following command shows the cumulative CPU usage of the containers:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">sysdig -c topcontainers_cpu</strong></span>
</pre></div><p class="calibre9">The output we get is as follows:</p><div class="mediaobject"><img src="../images/00040.jpeg" alt="sysdig" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre9">Similarly, we can see a list of processes, its corresponding containers, and process ID (as seen by the host and as seen by the container at the global level) by using the following command. Note that the <code class="email">-pc</code> flag indicates that the information is required in the container <a id="id368" class="calibre1"/>context. The same command can also be extended by providing a container name, and information is displayed only for that container.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong class="calibre2">sysdig -pc -c topconns</strong></span>
</pre></div><p class="calibre9">The output we get is as follows:</p><div class="mediaobject"><img src="../images/00041.jpeg" alt="sysdig" class="calibre11"/></div><p class="calibre12"> </p><p class="calibre9">By now, you would have got an idea of the utility of <code class="email">sysdig</code>. Similar to the process and CPU information, it can provide a host of other features like monitoring networks, network IO, disk usage, trace traffic, and so on. And most of the monitoring can be done in a <a id="id369" class="calibre1"/>container context also by adding the –<code class="email">pc</code> switch.</p></div>

<div id="page" style="height:0pt"/><div class="book" title="Competitive container orchestration mechanism"><div class="book" id="1HIT82-31555e2039a14139a7f00b384a5a2dd8"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch08lvl1sec46" class="calibre1"/>Competitive container orchestration mechanism</h1></div></div></div><p class="calibre9">In this <a id="id370" class="calibre1"/>section, we are going to see the other container orchestration mechanism currently available in the market. Some of these orchestration mechanisms can in fact be complementary to the CoreOS orchestration mechanism. As we have already seen in <a class="calibre1" title="Chapter 3. Creating Your CoreOS Cluster and Managing the Cluster" href="part0026_split_000.html#OPEK1-31555e2039a14139a7f00b384a5a2dd8">Chapter 3</a>, <span class="strong"><em class="calibre10">Creating Your CoreOS Cluster and Managing the Cluster</em></span>, fleet acts as a cluster manager in CoreOS and instantiates the docker units/service in any one of the nodes in the cluster. Let us discuss the other orchestration mechanisms in detail in this chapter. Some of the key container orchestration mechanisms currently available are as follows:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Kubernetes</li><li class="listitem">Apache Mesos</li><li class="listitem">Swarm</li></ul></div></div>

<div class="book" title="Competitive container orchestration mechanism">
<div class="book" title="Kubernetes"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch08lvl2sec38" class="calibre1"/>Kubernetes</h2></div></div></div><p class="calibre9">
<span class="strong"><strong class="calibre2">Kubernetes</strong></span> is<a id="id371" class="calibre1"/> an open source <a id="id372" class="calibre1"/>container orchestration infrastructure developed by Google for deploying containers or a group of containers in a server cluster. Kubernetes provides a way of deploying a group of containers as a single logical service. This group <a id="id373" class="calibre1"/>of containers has been termed <span class="strong"><strong class="calibre2">pod</strong></span>. Apart from providing a mechanism for deploying an application or container, Kubernetes also provides way for scheduling, updating, maintaining, and scaling the containers in a cluster.</p><p class="calibre9">Kubernetes operates over the pod rather than containers. A pod can contain a single container or a group of logically interrelated containers, as described earlier. Kubernetes consists of the <a id="id374" class="calibre1"/>following components:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Kubernetes master</li><li class="listitem">Kubernetes nodes (Minion)</li><li class="listitem">Kubernetes pods</li><li class="listitem">Kubernetes services</li></ul></div><p class="calibre9">The following diagram illustrates the components of Kubernetes:</p><div class="mediaobject"><img src="../images/00042.jpeg" alt="Kubernetes" class="calibre11"/><div class="caption"><p class="calibre14">Kubernetes components overview</p></div></div><p class="calibre12"> </p><div class="book" title="Kubernetes master"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch08lvl3sec40" class="calibre1"/>Kubernetes master</h3></div></div></div><p class="calibre9">As the <a id="id375" class="calibre1"/>name implies, <span class="strong"><strong class="calibre2">Kubernetes master</strong></span> is the master<a id="id376" class="calibre1"/> node that controls other nodes and pods in the cluster. It is the control plane and provides the following services:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Placement of pods in the server</li><li class="listitem">Replication control of various pods</li><li class="listitem">Maintaining the state of the containers</li><li class="listitem">Providing the REST API for controlling the nodes, pods, and so on from the external world</li></ul></div><p class="calibre9">Master Kubernetes runs apiserver, controller manager, and optionally the kubelet and proxy servers.</p></div><div class="book" title="Kubernetes nodes"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch08lvl3sec41" class="calibre1"/>Kubernetes nodes</h3></div></div></div><p class="calibre9">
<span class="strong"><strong class="calibre2">Kubernetes nodes</strong></span> are also called the minion. User applications are deployed as a container<a id="id377" class="calibre1"/> or docker containers in the minion. The Kubernetes<a id="id378" class="calibre1"/> nodes host important services of Kubernetes like kubelet and kube-proxy.</p><p class="calibre9">Kubelet is responsible for managing the pods at the node level. It acts as a primary node-agent.</p><p class="calibre9">kube-proxy or Kubernetes network proxy is an application that will manage services inside the Kubernetes nodes. This is also responsible for providing a kind of virtual IP for the application running in the nodes.</p></div><div class="book" title="Kubernetes pods"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch08lvl3sec42" class="calibre1"/>Kubernetes pods</h3></div></div></div><p class="calibre9">
<span class="strong"><strong class="calibre2">Kubernetes pods</strong></span> are<a id="id379" class="calibre1"/> a group of containers that are logically <a id="id380" class="calibre1"/>tightly coupled with each other and running inside the same Kubernetes nodes. The containers that are part of the same pods share resources like storage, networking, and so on. The following represents a pod:</p><div class="informalexample"><pre class="programlisting">apiVersion: v1
kind: Pod
metadata:
  name: backend-app
  labels:
    app: backend-app
    version: v1
    role=backend
spec:
  containers:
  - name: javaapp
    image: kingston/javaapp
    ports:
    - containerPort: 443
    volumeMounts:
    - mountPath: /volumes/logs
      name: logs
  - name: logapp
    image: kingston/logapp:v1.1.3
    ports:
    - containerPort: 9999
    volumeMounts:
    - mountPath: /logs
      name: logs
  - name: monitor
    image: kingston/monitor:v1.5.6
    ports:
    - containerPort: 1234</pre></div></div><div class="book" title="Kubernetes service"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch08lvl3sec43" class="calibre1"/>Kubernetes service</h3></div></div></div><p class="calibre9">
<span class="strong"><strong class="calibre2">Kubernetes service</strong></span> is a group of pods that is running inside the cluster. Services provide<a id="id381" class="calibre1"/> the vital features that are required for any kind <a id="id382" class="calibre1"/>of pods in the cluster such as load-balancing, application service discovery, easy deployment, and so on. A service is described in JSON representation as follows:</p><div class="informalexample"><pre class="programlisting">{
    "kind": "Service",
    "apiVersion": "v1",
    "metadata": {
        "name": "Web Frontend Service"
    },
    "spec": {
        "selector": {
            "app": "webapp",
            "role": "frontend"
        },
        "ports": [
            {
                "name": "http"
                "protocol": "TCP",
                "port": 80,
                "targetPort": 80
            }
        ]
    }
}</pre></div><p class="calibre9">Now, we have seen the basics of Kubernetes. Let us look into how Kubernetes can be used as an orchestration framework for CoreOS docker/Rackt containers.</p></div></div></div>

<div class="book" title="Competitive container orchestration mechanism">
<div class="book" title="CoreOS and Kubernetes"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch08lvl2sec39" class="calibre1"/>CoreOS and Kubernetes</h2></div></div></div><p class="calibre9">Kubernetes<a id="id383" class="calibre1"/> can <a id="id384" class="calibre1"/>also be used to provide advanced cluster-wide orchestration in CoreOS using an etcd distributed key-value store. As Kubernetes is a powerful tool for container orchestration, which provides the essential features of a typical deployment such as automatic load-balancing, service discovery, and container replication, in a CoreOS environment, Kubernetes can be used as a container orchestration framework.</p><p class="calibre9">One node inside the CoreOS cluster can act as a Kubernetes master, wherein you can run the apiserver and controller manager. All other nodes in the CoreOS cluster can act as a minion, wherein you can install and run kubelet and kube-proxy.</p><p class="calibre9">Kubernetes can also be used to provide advanced cluster-wide orchestration in CoreOS using an etcd distributed key-value store.</p></div></div>

<div id="page" style="height:0pt"/><div class="book" title="Apache-Mesos" id="1IHDQ1-31555e2039a14139a7f00b384a5a2dd8"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch08lvl1sec47" class="calibre1"/>Apache-Mesos</h1></div></div></div><p class="calibre9">
<span class="strong"><strong class="calibre2">Apache-Mesos</strong></span> is<a id="id385" class="calibre1"/> a container cluster manager developed for very large clusters involving thousands of hosts. Mesos provides a distributed kernel that is running across different nodes in the cluster and provides APIs for the application to manage resources such as memory, CPU, disk, and scheduling these resources.</p><p class="calibre9">The major<a id="id386" class="calibre1"/> components of Mesos are as follows:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Mesos agent</li><li class="listitem">Mesos master</li><li class="listitem">ZooKeeper</li><li class="listitem">Mesos frameworks<div class="mediaobject"><img src="../images/00043.jpeg" alt="Apache-Mesos" class="calibre11"/><div class="caption"><p class="calibre14">Mesos component overview</p></div></div><p class="calibre15"> </p></li></ul></div></div>

<div class="book" title="Apache-Mesos" id="1IHDQ1-31555e2039a14139a7f00b384a5a2dd8">
<div class="book" title="Mesos master"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch08lvl2sec40" class="calibre1"/>Mesos master</h2></div></div></div><p class="calibre9">The <span class="strong"><strong class="calibre2">Mesos master</strong></span> daemon runs in the master node that manages all the slave nodes or agents <a id="id387" class="calibre1"/>and the Mesos frameworks. The master takes care of sharing the resource to the frameworks based on the configured scheduling policy, which can either be strict priority or fair sharing.</p></div></div>

<div class="book" title="Apache-Mesos" id="1IHDQ1-31555e2039a14139a7f00b384a5a2dd8">
<div class="book" title="Mesos agent"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch08lvl2sec41" class="calibre1"/>Mesos agent</h2></div></div></div><p class="calibre9">
<span class="strong"><strong class="calibre2">Mesos agent</strong></span> is<a id="id388" class="calibre1"/> responsible for running the actual tasks. The agent reports to the master about the availability of the resources, which the master agent uses to allocate a particular task or framework to be ran on the agent.</p></div></div>

<div class="book" title="Apache-Mesos" id="1IHDQ1-31555e2039a14139a7f00b384a5a2dd8">
<div class="book" title="ZooKeeper"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_3"><a id="ch08lvl2sec42" class="calibre1"/>ZooKeeper</h2></div></div></div><p class="calibre9">In a<a id="id389" class="calibre1"/> typical Mesos deployment, there will be more than one master available to avoid single point of failure. In these cases, <span class="strong"><strong class="calibre2">ZooKeeper</strong></span> is used to elect the leader among the available masters.</p></div></div>

<div class="book" title="Apache-Mesos" id="1IHDQ1-31555e2039a14139a7f00b384a5a2dd8">
<div class="book" title="Mesos frameworks"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_4"><a id="ch08lvl2sec43" class="calibre1"/>Mesos frameworks</h2></div></div></div><p class="calibre9">
<span class="strong"><strong class="calibre2">Mesos frameworks</strong></span> are the ones that run the tasks in the Mesos agent. The framework consists<a id="id390" class="calibre1"/> of two components: a scheduler that registers with the master and an executor that executes the tasks in the slave node. The master determines the number of resources to be allocated for the framework and allocates it to the framework. The scheduler picks the resource offered from this list.</p></div></div>
<div class="book" title="Swarm" id="1JFUC1-31555e2039a14139a7f00b384a5a2dd8"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch08lvl1sec48" class="calibre1"/>Swarm</h1></div></div></div><p class="calibre9">
<span class="strong"><strong class="calibre2">Swarm</strong></span> is a<a id="id391" class="calibre1"/> native orchestration mechanism provided by Docker. Like other orchestration mechanisms, Swarm also consists of Swarm master and Swarm agent. </p><p class="calibre9">
<span class="strong"><strong class="calibre2">Swarm master</strong></span> takes<a id="id392" class="calibre1"/> care of orchestrating the docker container to different Swarm agents. The master will be running in one or two nodes in the cluster <a id="id393" class="calibre1"/>whereas the <span class="strong"><strong class="calibre2">Swarm agent</strong></span> will be running in all the nodes in the network. </p></div>

<div id="page" style="height:0pt"/><div class="book" title="Docker data volume management" id="1KEEU1-31555e2039a14139a7f00b384a5a2dd8"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch08lvl1sec49" class="calibre1"/>Docker data volume management</h1></div></div></div><p class="calibre9">One <a id="id394" class="calibre1"/>of the main aspects of the container that we haven't discussed until now is the container's data volume management. In this section, we are going to see some basic concepts of container data volume management, some of the major problems in data volume management, and their solutions.</p><p class="calibre9">As you may be aware, the docker container provides two different ways of managing the data volumes as:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Data volumes  </li><li class="listitem">Data volume containers</li></ul></div><p class="calibre9">The preceding two mechanisms provide various ways for storing the data in a persistent volume, a way to mount a host directory as a data volume, a way to mount a host file as a data volume, and so on. This works well until the containers are tied to a particular node/server in the cluster.</p><div class="mediaobject"><img src="../images/00044.jpeg" alt="Docker data volume management" class="calibre11"/><div class="caption"><p class="calibre14">Docker data volume management</p></div></div><p class="calibre12"> </p><p class="calibre9">When the<a id="id395" class="calibre1"/> container is moving from one server to another server, the data volume should also be moved. Typically, the data volume won't be moved when the container is moved from one node to another. This is because the docker/orchestration layer manages the containers and data volume separately.</p><p class="calibre9">Here comes the necessity of managing these two entities together. Flocker provides a way of managing both the docker container and docker volume together.</p><p class="calibre9">Flocker can be used along with container orchestration mechanisms such as Kubernetes and Mesos. Work has been going on to integrate Flocker with CoreOS, though some non-production-ready deployments are already available with CoreOS. </p></div>

<div class="book" title="Docker data volume management" id="1KEEU1-31555e2039a14139a7f00b384a5a2dd8">
<div class="book" title="Introduction to Flocker"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch08lvl2sec44" class="calibre1"/>Introduction to Flocker</h2></div></div></div><p class="calibre9">
<span class="strong"><strong class="calibre2">Flocker</strong></span> is<a id="id396" class="calibre1"/> an open source container data volume<a id="id397" class="calibre1"/> manager to manage data volumes. In docker, a data volume is tied to a single server. However, in Flocker, the data volume, which is also called a dataset, is portable and hence can be used with any server in the cluster. Flocker manages the docker container along with the data volumes. Hence, when a container is moved from one server to another server in the cluster, the corresponding data volume will also be moved.</p><div class="mediaobject"><img src="../images/00045.jpeg" alt="Introduction to Flocker" class="calibre11"/><div class="caption"><p class="calibre14">Flocker cluster architecture</p></div></div><p class="calibre12"> </p><p class="calibre9">The <a id="id398" class="calibre1"/>Flocker cluster architecture consists <a id="id399" class="calibre1"/>of the following components/services:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Flocker control services</li><li class="listitem">Flocker agents</li><li class="listitem">Flocker plugin for Docker</li></ul></div><div class="book" title="Flocker control services"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch08lvl3sec44" class="calibre1"/>Flocker control services</h3></div></div></div><p class="calibre9">In <a id="id400" class="calibre1"/>Kubernetes, we have Kubernetes master, and similarly the <span class="strong"><strong class="calibre2">Flocker control service</strong></span> acts as a master and is installed on a single node in the cluster. It <a id="id401" class="calibre1"/>exposes the REST API to interface with an external application. This is the brain of Flocker and enables the user to monitor the state of the cluster.</p></div><div class="book" title="Flocker agents"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch08lvl3sec45" class="calibre1"/>Flocker agents</h3></div></div></div><p class="calibre9">
<span class="strong"><strong class="calibre2">Flocker agents</strong></span> receive <a id="id402" class="calibre1"/>the commands from control services and make sure that the state of the Flocker agent matches with the desired state. When the local state is not matching the desired state, it calculates the actions necessary to make the local state match the desired configuration.</p></div><div class="book" title="Flocker plugin for Docker"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch08lvl3sec46" class="calibre1"/>Flocker plugin for Docker</h3></div></div></div><p class="calibre9">
<span class="strong"><strong class="calibre2">Docker's Flocker plugin</strong></span> deploys a container along with the data volume without worrying<a id="id403" class="calibre1"/> about which server in the cluster the data volume is placed. Whenever the container is moved from one server to another, the plugin takes care of moving the data volume too. This makes sure that the data volume is running in any one node in the Flocker cluster.</p></div></div></div>
<div class="book" title="Open Container Project" id="1LCVG1-31555e2039a14139a7f00b384a5a2dd8"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch08lvl1sec50" class="calibre1"/>Open Container Project</h1></div></div></div><p class="calibre9">As the different <a id="id404" class="calibre1"/>container technologies are being developed, there is a necessity of having a standard container format in order to provide interoperability and define the standard for the containers. In order to achieve this, the CoreOS team started working on a container standardization mechanism called <span class="strong"><em class="calibre10">App Container</em></span> to define the standard container image format, runtime environment, and discovery protocol, to work toward the goal of a standard, portable shipping container for applications.</p><p class="calibre9">Meanwhile, the <span class="strong"><strong class="calibre2">Open Container Project</strong></span> (<span class="strong"><strong class="calibre2">OCP</strong></span>) was formed by a large group of industry leaders to define the standard. The Open Container Project is hosted under Linux Foundation. CoreOS App Container also contributes to OCP and the latest specification of the OCP <a id="id405" class="calibre1"/>project can be found at the following link: <a class="calibre1" href="https://github.com/opencontainers/specs">https://github.com/opencontainers/specs</a>
</p></div>
<div class="book" title="Summary" id="1MBG21-31555e2039a14139a7f00b384a5a2dd8"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch08lvl1sec51" class="calibre1"/>Summary</h1></div></div></div><p class="calibre9">As CoreOS is a young and very promising operating system, a lot of developments are happening on daily basis. One of the major milestones of CoreOS in the recent past was that Google and CoreOS jointly announced a new project called Tectonic to offer IT infrastructure, which is completely container-based leveraging both CoreOS and Kubernetes. Tectonic is a commercial Kubernetes platform that combines the CoreOS stack with Kubernetes to bring a Google-style infrastructure to any cloud. Companies such as Rackspace, Salesforce, MemSQL, Atlassian, and Pivotal's Cloud Foundry have already deployed CoreOS. The future of CoreOS looks very bright as CoreOS is aiming to build next-generation IT infrastructure without increasing the complexity. As security is one of the major concerns in current IT infrastructure, one of the major goals of CoreOS is to enable the companies to run their applications securely and reliably in any environment, bringing a promising future for CoreOS.</p></div></body></html>