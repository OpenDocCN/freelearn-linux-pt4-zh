<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Summarizing Logs with AWK</h1>
                </header>
            
            <article>
                
<p>In the previous chapter, we talked about regular expressions and we saw how to use them to empower <kbd>sed</kbd> and AWK. In this chapter, we will discuss some practical examples of using AWK.</p>
<p>One of the tasks that AWK is really good at is filtering data from log files. These log files may be many lines in length, perhaps 250,000 or more. I have worked with data with over a million lines. AWK can process these lines quickly and effectively. As an example, we will work with a web server access log with 30,000 lines to show how effective and well-written AWK code can be. As we work our way through the chapter, we will also see different log files and review some of the techniques that we can employ with the <kbd>awk</kbd> command and the AWK programming language to help with the reporting and administration of our services. In this chapter, we will cover the following topics:</p>
<ul>
<li>HTTPD log file format</li>
<li>Displaying data from web logs</li>
<li>Displaying the highest ranking client IP addresses</li>
<li>Displaying the browser data</li>
<li>Working with email logs</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>The source code for this chapter can be downloaded from here:</p>
<p><a href="https://github.com/PacktPublishing/Mastering-Linux-Shell-Scripting-Second-Edition/tree/master/Chapter12">https://github.com/PacktPublishing/Mastering-Linux-Shell-Scripting-Second-Edition/tree/master/Chapter12</a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The HTTPD log file format</h1>
                </header>
            
            <article>
                
<p>When working with any file, the first task is to become familiar with the file schema. In simple terms, we need to know what is represented by each field and what is used to delimit the fields. We will be working with the access log file from an Apache HTTPD web server. The location of the log file can be controlled from the <kbd>httpd.conf</kbd> file. The default log file location on a Debian-based system is <kbd>/var/log/apache2/access.log</kbd>; other systems may use the <kbd>httpd</kbd> directory in place of <kbd>apache2</kbd>.</p>
<p>The <kbd>log</kbd> file is already in the code bundle, so you can download it and use it directly.</p>
<p>Using the <kbd>tail</kbd> command, we can display the end of the <kbd>log</kbd> file. Although, to be fair, the use of <kbd>cat</kbd> will do just as well with this file, as it will have just a few lines:</p>
<pre><strong>$ tail /var/log/apache2/access.log</strong>  </pre>
<p class="mce-root">The output of the command and the contents of the file are shown in the following screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/9b3f97e4-b874-4381-89a5-3f60d78dd4e8.png" style="width:45.17em;height:8.83em;"/></div>
<p class="mce-root">The output does wrap a little onto the new lines, but we do get a feel of the layout of the log. We can also see that even though we feel that we access just one web page, we are in fact accessing two items: the <kbd>index.html</kbd> and the <kbd>ubuntu-logo.png</kbd>. We also failed to access the <kbd>favicon.ico</kbd> file. We can see that the file is space separated. The meaning of each of the fields is laid out in the following table:</p>
<table class="table">
<tbody>
<tr>
<td>
<p><strong>Field</strong></p>
</td>
<td>
<p><strong>Purpose</strong></p>
</td>
</tr>
<tr>
<td>
<p>1</p>
</td>
<td>
<p>Client IP address.</p>
</td>
</tr>
<tr>
<td>
<p>2</p>
</td>
<td>
<p>Client identity as defined by RFC 1413 and the <kbd>identd</kbd> client. This is not read unless <kbd>IdentityCheck</kbd> is enabled. If it is not read, the value will be with a hyphen.</p>
</td>
</tr>
<tr>
<td>
<p>3</p>
</td>
<td>
<p>The user ID of the user authentication if enabled. If authentication is not enabled, the value will be a hyphen.</p>
</td>
</tr>
<tr>
<td>
<p>4</p>
</td>
<td>
<p>The date and time of the request in the format of <kbd>day/month/year:hour:minute:second offset</kbd>.</p>
</td>
</tr>
<tr>
<td>
<p>5</p>
</td>
<td>
<p>The actual request and method.</p>
</td>
</tr>
<tr>
<td>
<p>6</p>
</td>
<td>
<p>The return status code, such as <kbd>200</kbd> or <kbd>404</kbd>.</p>
</td>
</tr>
<tr>
<td>
<p>7</p>
</td>
<td>
<p>File size in bytes.</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p>Even though these fields are defined by Apache, we have to be careful. The time, date, and time zone is a single field and is defined within square braces; however, there are additional spaces inside the field between that data and the time zone. To ensure that we print the complete time field if required, we need to print both <kbd>$4</kbd> and <kbd>$5</kbd>. This is shown in the following command example:</p>
<pre><strong>$ awk ' { print $4,$5 } ' /var/log/apache2/access.log</strong>  </pre>
<p>We can view the command and the output it produces in the following screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/71c919e5-13bb-4764-9402-d54f64c1d840.png" style="width:39.08em;height:5.92em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Displaying data from web logs</h1>
                </header>
            
            <article>
                
<p>We have already had a preview of how we can use AWK to view the log files from the Apache web server; however, we will now move onto our demonstration file that has greater and more varied content.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Selecting entries by date</h1>
                </header>
            
            <article>
                
<p>Having seen how we can display the date, we should perhaps look at how we print entries from just one day. To do this, we can use the match operator in <kbd>awk</kbd>. This is denoted by the tilde or squiggly line, if you prefer. As we only need the date element, there is no need for us to use both the date and time zone field. The following command shows how to print entries from September 10, 2014:</p>
<pre><strong>$ awk ' ( $4 ~ /10\/Sep\/2014/ ) ' access.log</strong>  </pre>
<p>For completeness, this command and partial output is shown in the following screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-344 image-border" src="assets/1cd97c0b-241d-484c-9072-4fb73de7885e.png" style="width:41.92em;height:6.33em;"/></div>
<p>The round brackets or parentheses embrace the range of lines that we are looking for and we have omitted the main block, which ensures that we print the complete matching lines from the range. There is nothing stopping us from further filtering on the fields to print from the matching lines. For example, if we want to print out just the client IP address that is being used to access the web server, we can print field <kbd>1</kbd>. This is shown in the following command example:</p>
<pre><strong>$ awk ' ( $4 ~ /10\/Sep\/2014/ ) { print $1 } ' access.log</strong>  </pre>
<p>If we want to be able to print the total number of accesses on a given date, we could pipe the entries through to the <kbd>wc</kbd> command. This is demonstrated in the following:</p>
<pre><strong>$ awk ' ( $4 ~ /10\/Sep\/2014/ ) { print $1 } ' access.log | wc -l</strong>  </pre>
<p>However, if we want to use <kbd>awk</kbd> to do this for us, this will be more efficient than starting a new process and we can count the entries. If we use the built-in variable <kbd>NR</kbd>, we can print entire lines in the files, not just those within the range. It is best to increment our own variable in the main block instead of matching the range for each line. The <kbd>END</kbd> block can be implemented to print the <kbd>count</kbd> variable we use. The following command line acts as an example:</p>
<pre><strong>$ awk ' ( $4 ~ /10\/Sep\/2014/ ) { print $1; COUNT++ }  END { print COUNT }' access.log</strong>  </pre>
<p>The output of the count from both <kbd>wc</kbd> and the internal counter will give us <kbd>16205</kbd> as a result from the demonstration file. We should use the variable increment within the main block if we want to count and nothing else:</p>
<pre><strong>$ awk ' ( $4 ~ /10\/Sep\/2014/ ) { COUNT++ }  END { print COUNT }' access.log</strong>  </pre>
<p>We can see this in the following output:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-345 image-border" src="assets/5a3b0cfe-80b4-4adf-b946-15e89e22cd86.png" style="width:50.67em;height:3.50em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summarizing 404 errors</h1>
                </header>
            
            <article>
                
<p>The status code of the request page is shown in field <kbd>9</kbd> of the log. The <kbd>404</kbd> status will represent the page not found error on the server. I am sure we have all seen that in our browsers at some stage. This may be indicative of a misconfigured link on your site or just produced by a browser searching for the icon image to display in tabbed browsers for the page. You can also identify potential threats to your site by requests looking for standard pages that may give access to additional information on PHP driven sites, such as WordPress.</p>
<p>Firstly, we can solely print the status of the request:</p>
<pre><strong>$ awk '{ print $9 } ' access.log</strong>  </pre>
<p>We can now extend the code a little as well as ourselves and just print the <kbd>404</kbd> errors:</p>
<pre><strong>$ awk ' ( $9 ~ /404/ ) { print $9 } ' access.log</strong>  </pre>
<p>We can extend this a little further by printing both the status code and the page that was being accessed. This will need us to print field <kbd>9</kbd> and field <kbd>7</kbd>. Simply put, this will be as shown in the following code:</p>
<pre><strong>$ awk ' ( $9 ~ /404/ ) { print $9, $7 } ' access.log</strong>  </pre>
<p>Many of these failed accessed pages will be duplicated. To summarize these records, we can use the command pipeline to achieve this with the <kbd>sort</kbd> and <kbd>uniq</kbd> commands:</p>
<pre><strong>$ awk ' ( $9 ~ /404/ ) { print $9, $7 } ' access.log | sort -u</strong> </pre>
<p>To use the <kbd>uniq</kbd> command, the data must be pre-sorted; hence, we use the <kbd>sort</kbd> command to prepare the data.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summarizing HTTP access codes</h1>
                </header>
            
            <article>
                
<p>It is time for us to leave the pure command line and start working with the AWK control files. As always, when the complexity of the required result set increases, we see an increase in the complexity of the <kbd>awk</kbd> code. We will create a <kbd>status.awk</kbd> file in our current directory. The file should look similar to the following file:</p>
<pre>{ record[$9]++ } 
END { 
for (r in record) 
print r, " has occurred ", record[r], " times." }  </pre>
<p>First, we will strip down the main code block and this is very simple and sparse. This is a simple way to count each unique occurrence of a status code. Instead of using a simple variable, we feed this into an array. The array in this case is called a record. An array is a multi-values variable and the slots in the array are known as keys. So we will have a collection of variables stored in the array. For example, we expect to see entries for <kbd>record[200]</kbd> and <kbd>record[404]</kbd>. We populate each key with their occurrence count. Each time we find a <kbd>404</kbd> code, we increment the count that is stored in the associated key:</p>
<pre>{ record[$9]++ } </pre>
<p>In the <kbd>END</kbd> block, we create the summary information using a <kbd>for</kbd> loop to print out each key and value from the array:</p>
<pre>END { 
for (r in record) 
print r, " has occurred ", record[r], " times." } </pre>
<p>To run this, the associated command line will be similar to the following:</p>
<pre><strong>$ awk -f status.awk access.log</strong> </pre>
<p>To view the command and output, we have included the following screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-346 image-border" src="assets/979b1d94-c4a5-47df-a82e-101b6c030214.png" style="width:24.75em;height:11.00em;"/></div>
<p>We can take this further and focus on the <kbd>404</kbd> errors. You could, of course, choose any of the status codes. We can see from the results that we have <kbd>4382 404</kbd> status codes. To summarize these <kbd>404</kbd> codes, we will copy the <kbd>status.awk</kbd> to a new file named <kbd>404.awk</kbd>. We can edit the <kbd>404.awk</kbd> adding an <kbd>if</kbd> statement to work only on the <kbd>404</kbd> codes. The file should be similar to the following code:</p>
<pre>{ if ( $9 == "404" ) 
    record[$9,$7]++ } 
END { 
for (r in record) 
print r, " has occurred ", record[r], " times." } </pre>
<p>If we execute the code with the following command:</p>
<pre><strong>$ awk -f 404.awk access.log</strong>  </pre>
<p>The output will be similar to the following screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-347 image-border" src="assets/a26e123c-4f6c-49d1-a770-3e239e236898.png" style="width:25.42em;height:9.08em;"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Resources hits</h1>
                </header>
            
            <article>
                
<p>You can check how many times a specific page or a resource was requested using AWK:</p>
<pre><strong>$ awk '{print $7}' access.log | sort | uniq -c | sort -rn</strong> </pre>
<p>The preceding command will sort the requested resources from the highest requested resource to the lowest:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/407e25dc-56a9-4b51-bffb-34a501f600ae.png" style="width:41.08em;height:22.92em;"/></div>
<p>The resources could be images, text files, or CSS files.</p>
<p>If you want to look at the requested PHP files, you can use <kbd>grep</kbd> to get PHP files only:</p>
<pre><strong>$ awk ' ($7 ~ /php/) {print $7}' access.log | sort | uniq -c | sort -nr</strong>  </pre>
<div class="CDPAlignCenter CDPAlign"><img src="assets/029c03ca-516f-449d-a193-880605109e0e.png" style="width:39.58em;height:24.92em;"/></div>
<p>Alongside each page, there is the number of hits.</p>
<p>You can grab any statistics from the <kbd>log</kbd> file and get unique values and sort them the same way.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Identify image hotlinking</h1>
                </header>
            
            <article>
                
<p>As we talk about resources, there is a problem that you may face, which is image hotlinking. It's about using your images from other servers by linking to them. This behavior of image hotlinking can leak your bandwidth.</p>
<p>And since we are talking about AWK, we will see how to use AWK to find out how it is using our images:</p>
<pre><strong>$ awk -F\" '($2 ~ /\.(png|jpg|gif)/ &amp;&amp; $4 !~ /^https:\/\/www\.yourdomain\.com/){print $4}' access.log | sort | uniq -c | sort</strong></pre>
<p>Note that you can prevent image hotlinking by a small <kbd>.htaccess</kbd> file if you are using Apache, by checking if the referrer is not your domain:</p>
<pre>RewriteEngine on 
RewriteCond %{HTTP_REFERER} !^$ 
RewriteCond %{HTTP_REFERER} !^https://(www\.)yourdomain.com/.*$ [NC] 
RewriteRule \.(gif|jpg|jpeg|bmp|png)$ - [F] </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Displaying the highest ranking IP address</h1>
                </header>
            
            <article>
                
<p>You should now be aware of some the powers of <kbd>awk</kbd> and how immense the language structure is in itself. The data we have been able to produce from the 30,000 line file is truly powerful and easily extracted. We just need to replace the field we have used before with <kbd>$1</kbd>. This field represents the client IP address. If we make use of the following code, we will be able to print each IP Address and also the number of times it has been used to access the web server:</p>
<pre>{ ip[$1]++ } 
END { 
for (i in ip) 
print i, " has accessed the server ", ip[i], " times." } </pre>
<p>We want to be able to extend this to show only the highest ranking IP address, the address that has been used the most to access the site. The work, again, will mainly be in the <kbd>END</kbd> block and will make use of a comparison against the current highest ranking address. The following file can be created and saved as <kbd>ip.awk</kbd>:</p>
<pre>{ ip[$1]++ } 
END { 
for (i in ip) 
    if ( max &lt; ip[i] ) { 
        max = ip[i] 
        maxnumber = i } 
 
print i, " has accessed ", ip[i], " times." } </pre>
<p>We can see the output of the command in the following screenshot. Part of the client IP address has been obscured as it is from my public web server:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-348 image-border" src="assets/b821d655-ea19-4f24-8550-2dd28c60b366.jpg" style="width:25.50em;height:5.08em;"/></div>
<p>The functionality of the code comes from within the <kbd>END</kbd> block. On entering the <kbd>END</kbd> block, we run into a <kbd>for</kbd> loop. We iterate through each entry in the <kbd>ip</kbd> array. We use the conditional <kbd>if</kbd> statement to see whether the current value that we are iterating through is higher than the current maximum. If it is, this becomes the new highest entry. When the <kbd>loop</kbd> has finished, we print the IP address that has the highest entry.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Displaying the browser data</h1>
                </header>
            
            <article>
                
<p>The browser that is used to access the website is contained within the log file in field <kbd>12</kbd>. It may be interesting to display the list of browsers used to access your site. The following code will assist you in displaying the list of accesses by the reported browser:</p>
<pre>{ browser[$12]++ } 
END { 
    for ( b in browser ) 
        print b, " has accessed ", browser[b], " times." 
    } </pre>
<p>You can see how we can create little plugins to <kbd>awk</kbd> with these files and adjust the field and array names to suit. The output is shown in the following screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-349 image-border" src="assets/8c801f02-d3dc-4623-8779-435026722d5a.png" style="width:30.08em;height:15.92em;"/></div>
<p>Interestingly, we see that Mozilla 4 and 5 make up the majority of the requesting client. We see that Mozilla 4 is listed here <kbd>1713</kbd> times. The Mozilla/5.0 entry here is malformed with an extra double quote. It appears later with 27,000 accesses.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Working with email logs</h1>
                </header>
            
            <article>
                
<p>We have worked with logs from the Apache HTTP web server. The reality is that we can apply the same ideals and methodology to any log file. We will take a look at Postfix mail logs. The mail log holds all activity from the SMTP server and we can then see who has been sending emails to whom. The log file is usually located at <kbd>/var/log/mail.log</kbd>. I will access this on my Ubuntu 15.10 server that has a local email delivery. All this means is that the STMP server is listening only to the localhost interface of <kbd>127.0.0.1</kbd>.</p>
<p>The log format will change a little depending on the type of message. For example, <kbd>$7</kbd> will contain <kbd>from</kbd> logs on outbound messages, whereas inbound messages will contain <kbd>to</kbd>.</p>
<p>If we want to list all the inbound messages to the SMTP server, we can use the following command:</p>
<pre><strong>$ awk '  ( $7 ~ /^to/ ) ' /var/log/mail.log</strong>  </pre>
<p>As the string <kbd>to</kbd> is very short, we can add identification to it by ensuring that the field begins with <kbd>to</kbd> using the <kbd>^</kbd>. The command and output is shown in the following screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-350 image-border" src="assets/2b73c3f8-6754-47d5-8092-c7885c69ab43.png" style="width:48.25em;height:4.58em;"/></div>
<p>It will be easy to extend the <kbd>to</kbd> or <kbd>from</kbd> searches to also include usernames. We can see the format of the delivered or received mail. Working with the same template we used with the Apache logs, we can easily display the highest recipient or sender.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>We now have some heavy ammunition behind our text processing and we can begin to understand just how powerful AWK can be. Working with real data is particularly useful in gauging the performance and accuracy of our searches. Having begun working with simple Apache entries on the newly installed Ubuntu 15.10 Apache web server, we soon migrated to the larger sample data from a live web server. With 30,000 lines, this file gives us some real meat to work with and in no time, we were able to produce credible reports. We closed up the return to the Ubuntu 15.10 server to analyze the Postfix SMTP logs. We can see that we can very much drag and drop the technology that we have previously used into the new log files.</p>
<p>Next up, we stick with AWK and look at how we can report on the <kbd>lastlog</kbd> data and on flat XML files.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Questions</h1>
                </header>
            
            <article>
                
<ol>
<li>Which field in the <kbd>access_log</kbd> file contains the IP address?</li>
<li>What is the command used to count the lines processed by AWK?</li>
<li>How do you get IP addresses of unique visitors from the Apache access log file?</li>
<li>How do you get the most visited PHP page from the Apache access log file?</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Further reading</h1>
                </header>
            
            <article>
                
<p>Please see the following for further reading relating to this chapter:</p>
<ul>
<li><a href="https://httpd.apache.org/docs/1.3/logs.html"><span class="URLPACKT">https://httpd.apache.org/docs/1.3/logs.html</span></a></li>
</ul>


            </article>

            
        </section>
    </body></html>