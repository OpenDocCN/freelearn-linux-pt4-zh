- en: Chapter 6. Measuring and Increasing Performance
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Up to this point, we have created an active/passive cluster, added several resources
    to it, and tested its failover capabilities. We also discussed how to troubleshoot
    common issues. The final step in our journey consists of measuring and increasing
    the performance of our cluster as it has been installed so far—as far as the services
    running on it are concerned.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: In addition, we will provide the overall instructions to convert your A/P cluster
    into an A/A one.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Setting up a sample database
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In order to properly test our MariaDB database server, we need a database populated
    with sample data. For this reason, we will use the Employees database, developed
    by Patrick Crews and Giuseppe Maxia and provided by Oracle Corporation under a
    Creative Commons Attribution-Share Alike 3.0 Unported License. It provides a very
    large dataset (~160 MB and ~4 million records) spread over six tables, which will
    be ideal for our performance tests.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The Creative Commons Attribution-Share Alike 3.0 Unported License, available
    at [http://creativecommons.org/licenses/by-sa/3.0/](http://creativecommons.org/licenses/by-sa/3.0/),
    grants us the following freedoms regarding the Employees database:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '*Share: This lets us copy and redistribute the material in any medium or format*'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '*Adapt: This lets us remix, transform, and build upon the material*'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '*for any purpose, even commercially.*'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '*The licensor cannot revoke these freedoms as long as you follow the license
    terms.*'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: Downloading and installing the Employees database
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s proceed with downloading and installing the database using the following
    steps:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: To download the Employees table, go to [https://launchpad.net/test-db/](https://launchpad.net/test-db/)
    and grab the link for the tarball of the latest stable release (at the time of
    writing this book, it is v1.0.6), as shown in the following screenshot:![Downloading
    and installing the Employees database](img/00067.jpeg)
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Then, download it to the node on which the database server is running (in our
    case, it is `node01`). To do so, you will need to install two packages named `wget`
    and `bzip2` first, using the following command:'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-15
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then, extract/unarchive its contents in your current working directory:'
  id: totrans-16
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This will create a subdirectory named `employees_db`, where the main installation
    script (`employees.sql`) resides, as can be seen in the output of the following
    two commands:'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Next, use the following command to connect to the cluster database server we
    set up and configured in [Chapter 4](part0030_split_000.html#SJGS1-1d2c6d19b9d242db82da724021b51ea0
    "Chapter 4. Real-world Implementations of Clustering"), *Real-world Implementations
    of Clustering* (note that you will be prompted to enter the password for the root
    MariaDB user):'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This will also install the employees database and load the corresponding information
    into its tables:'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`departments`'
  id: totrans-23
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`employees`'
  id: totrans-24
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dept_emp`'
  id: totrans-25
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dept_manager`'
  id: totrans-26
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`titles`'
  id: totrans-27
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`salaries`'
  id: totrans-28
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  id: totrans-29
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: After you are done setting up the sample database, feel free to perform a forced
    failover to verify that the resources and the database, along with their tables
    and records, become available in the current passive node. Review chapter 4 to
    recall instructions if you need.
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Due to the high volume of data being loaded into the database, it is to be
    expected that the installation may take around a minute or two to complete. While
    we are at it, we will see the progress of the import process: the database structure
    and the storage engine are instantiated, then the tables are created, and finally,
    they are populated with data, as shown here:'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Downloading and installing the Employees database](img/00068.jpeg)'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'We can verify by logging into the database server and issuing these commands
    to first list all databases. Then, switch to the recently installed Employees
    database, and use it for the subsequent queries:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The output should be similar to the one shown in the preceding screenshot.![Downloading
    and installing the Employees database](img/00069.jpeg)
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Before we proceed with the actual performance tests (measuring general performance
    before and after a failover event), feel free to investigate those tables (and
    the fields they contain) using the `DESCRIBE` statement. Then browse the records
    with the `SELECT` statement, as shown here:'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The result can be seen in the following screenshot:![Downloading and installing
    the Employees database](img/00070.jpeg)
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once you have taken some time to become acquainted with the structure of the
    database, we are ready to proceed with the tests.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: Introducing initial cluster tests
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In addition, for the actual performance tests, you should note that MariaDB
    comes with several database-related utilities that can come in handy for a variety
    of administration tasks. One of them is `mysqlshow`, which returns complete information
    about databases and tables in one quick command.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: 'Its generic syntax is as follows:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'So, we could use the following command to display the description for the titles
    table in the `employees` database:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Note
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can list the complete set of utilities that are included in your MariaDB
    installation using the `ls /bin | grep mysql` command. Each of those tools has
    a corresponding manual page, which can be invoked from the command line as usual.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: We will use another of the tools that are included by MariaDB to see how our
    database server performs when placed under significant load. The tool is `mysqlslap`,
    a diagnostic program designed to emulate client load for a MariaDB/MySQL server
    and to report the timing of each stage. It works as if multiple clients are accessing
    the server simultaneously.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: 'Before executing the actual commands that we will use in the following tests,
    we will introduce a few of the flags available for `mysqlslap`:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '`--create-schema`: This command specifies the database in which we will run
    the tests'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--query`: This is a string (or alternatively, a file) containing the `SELECT`
    statements used to retrieve data'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--query`：这是一个字符串（或者说是一个文件），其中包含用于检索数据的`SELECT`语句'
- en: '`--delimiter`: This command allows you to specify a delimiter to separate multiple
    queries in the same string in `--query`'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--delimiter`：此命令允许你指定一个分隔符，用来分隔`--query`中同一字符串中的多个查询'
- en: '`--concurrency`: This command is the number of simultaneous connections to
    simulate'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--concurrency`：此命令表示模拟的并发连接数'
- en: '`--iterations`: This is the number of times to run the tests'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--iterations`：这是运行测试的次数'
- en: '`--number-of-queries`: This command limits each client (refer to `--concurrency`)
    to that amount of queries'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--number-of-queries`：此命令限制每个客户端（参见`--concurrency`）的查询数量'
- en: In addition, there are other switches listed in the manual page for `mysqlslap`
    that you can use if you want.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，`mysqlslap`手册页中列出了其他你可以使用的开关，如果你愿意的话。
- en: That said, we will run the following tests against the database server in our
    cluster.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 也就是说，我们将在集群中的数据库服务器上运行以下测试。
- en: Test 1 – retrieving all fields from all records
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试 1 – 检索所有记录的所有字段
- en: 'In this first test, we will perform a rather simple query that consists of
    retrieving all fields from all records in the employees table. We will simulate
    `10` concurrent connections and make `50` queries overall. This will result in
    clients running `5` queries each (50/10 = 5):'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一个测试中，我们将执行一个相当简单的查询，内容是从员工表中检索所有记录的所有字段。我们将模拟`10`个并发连接，总共进行`50`次查询。这将导致每个客户端运行`5`次查询（50/10
    = 5）：
- en: '[PRE8]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'After a couple of minutes, you will be able to see output similar to the one
    shown in the following screenshot. Although here we list the result of an isolated
    test, you may want to perform this operation several times on your own and write
    down the results for a later comparison. However, if you choose to do so, make
    sure that the query results are not cached by running the following command in
    your MariaDB server session after each run:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 几分钟后，你将能够看到类似以下截图中的输出。虽然这里列出了一个独立测试的结果，但你可能希望自己多次执行此操作并记录结果以供后续对比。然而，如果你选择这样做，请确保查询结果没有被缓存，在每次运行后，运行以下命令清除
    MariaDB 服务器会话中的缓存：
- en: '[PRE9]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![Test 1 – retrieving all fields from all records](img/00071.jpeg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![测试 1 – 检索所有记录的所有字段](img/00071.jpeg)'
- en: Test 2 – performing JOIN operations
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试 2 – 执行 JOIN 操作
- en: 'In this second test, we will do a `JOIN` operation between the employees and
    salaries tables (a more realistic example) and modify the number of connections,
    queries, and iterations a bit:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个第二个测试中，我们将执行一个`JOIN`操作，将员工表和薪资表进行连接（一个更现实的例子），并稍微调整连接数、查询数和迭代次数：
- en: '[PRE10]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'In the following screenshot, we can see an expected increase in the time it
    took to run the queries this time:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下截图中，我们可以看到这次运行查询所花费的时间有所增加，这是预期中的结果：
- en: '![Test 2 – performing JOIN operations](img/00072.jpeg)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![测试 2 – 执行 JOIN 操作](img/00072.jpeg)'
- en: Before proceeding further, feel free to play around with the number of connections,
    iterations, and queries, or with the query itself. Based on these values, you
    may knock the database server down. That is to be expected at some point, since
    we have been building our infrastructure and examples on a virtual machine-based
    cluster. For this reason, you may want to increase the processing resources on
    each node's Virtualbox configuration to the extent of the available capacity,
    or consider acquiring real hardware to set up your cluster.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，可以随意调整连接数、迭代次数和查询，或者修改查询本身。根据这些值，你可能会使数据库服务器崩溃。这在某些时候是可以预期的，因为我们构建基础设施和示例时使用的是基于虚拟机的集群。因此，你可能希望在每个节点的
    VirtualBox 配置中增加处理资源，尽可能利用可用容量，或者考虑购买真实硬件来搭建集群。
- en: Note
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Database administration and optimization are topics out of the scope of this
    book. It is strongly recommended that you also take these subjects into account
    before moving the cluster to a production environment. Since the performance of
    the database and web servers can be optimized separately through their corresponding
    settings, in this book, we will focus our efforts on analyzing and improving the
    availability of these resources (which we have named `dbserver` and `webserver`
    respectively) using their respective configuration files and internal settings.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: Performing a failover
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will now force a failover by stopping the cluster functionality on the node
    where all the resources are currently running (`node01`) so that they will move
    to `node02`. Here, we will perform tests 1 and 2, and we expect to see a similar
    behavior to what we saw earlier. It is important to keep in mind that during a
    failover, data is not encrypted automatically. If you have concerns about sensitive
    data being failed over an unsecured connection, you should take the necessary
    precaution to use encryption either at the filesystem or at the Logical Volume
    level. Before we do this, however, we must keep in mind that moving a sensitive
    resource, such as a database server, around a cluster constantly may negatively
    impact the availability of such resource. For this reason, we will want it to
    remain in the node where it is active unless in the case that there is an actual
    node shutdown. The concept of resource stickiness does exactly this: it allows
    us to instruct all cluster resources to either fall back to their original node
    when it becomes available again after an outage, or to remain where they are currently
    active. The following syntax is used to specify the default value for all resources:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The higher the value, the more the resource will prefer to stay where it is.
    By default, Pacemaker uses `0` as value, which tells the cluster that it is desired
    (and optimal) to move the resource around in the case of failover. To specify
    the stickiness of a specific resource, use the following syntax to set the stickiness
    for a specific resource:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Let''s assume that you use `INFINITY` as the value in the preceding command:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: (Where you need to replace `resource_id` with the actual resource identification)
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, both the default stickiness for all resources and for the resource identified
    by `resource_id` will be set to `INFINITY`. That being said, let''s now perform
    the failover. Take note of the current node and resource status by using the following
    command:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Then, stop the cluster by using the following command:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Then, verify that all resources have been properly started on the other node.
    If not, troubleshoot using the tools explained in [Chapter 5](part0041_split_000.html#173721-1d2c6d19b9d242db82da724021b51ea0
    "Chapter 5. Monitoring the Cluster Health"), *Monitoring the Cluster Health*.
    Finally, proceed to run tests 1 and 2 on `node02`.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: The results in our present case are explained here.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: 'For test 1, refer to the following screenshot:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: '![Performing a failover](img/00073.jpeg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
- en: Summarizing results of test 1 on both nodes
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: 'For our convenience, let''s put both results in the following for a quick comparison:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '| TEST 1 [seconds] | Node01 | Node02 |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
- en: '| Average, all queries | 20.770 | 20.179 |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
- en: '| Minimum, all queries | 20.242 | 19.930 |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
- en: '| Maximum, all queries | 21.298 | 20.428 |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
- en: 'On the other hand, for test 2, the following screenshot and the next table
    show the details:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '![Performing a failover](img/00074.jpeg)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
- en: Summarizing results of test 2 on both nodes
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '| TEST 2 [seconds] | Node01 | Node02 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
- en: '| Average, all queries | 40.008 | 39.084 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
- en: '| Minimum, all queries | 38.713 | 38.779 |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
- en: '| Maximum, all queries | 41.304 | 39.389 |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
- en: As you can see, the results are very similar in both cases, which confirms that
    the failover did not affect the performance of the database server running on
    top of our cluster. While it is true that the failover did not improve performance
    either, we can see that the availability of the resource during a failover has
    been confirmed with a negative impact on the functionality of the cluster.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: Measuring and improving performance
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You will recall from earlier chapters that by definition, a resource is a service
    that is made highly available by the cluster. Every resource is assigned what
    is called a **resource agent**, an external shell script that manages the actual
    resource for the cluster, independently of how those services would be managed
    by systemd if they were left to its care. Thus, the actual operation of the resource
    is transparent to the cluster, since it is being managed by the resource agent.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: Resource agents are found inside `/usr/lib/ocf/resource.d`, so feel free to
    take a look at them to become better acquainted with their structure. In most
    circumstances, you will not need to modify them, but work on the specific resources'
    configuration files, as we shall see. You will recall from earlier chapters that
    adding a cluster resource involved using an argument of the `standard:provider:resource_agent`
    form (`ocf:heartbeat:mysql`, for example).You can also view the complete list
    of resource standards and providers with `pcs resource standards` and `pcs resource
    providers` respectively. Additionally, you can view the available agents for each
    `standard:provider` pair with `pcs resource agents standard:provider`.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: Apache's configuration and settings
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When the Apache web server is first installed, by default, it comes with several
    modules in the form of **Dynamic Shared Objects** (**DSOs**) that extend its functionality.
    The downside is that some of them may consume resources unnecessarily if they
    remain loaded and your applications don't' use them. As you can probably guess,
    this may lead to performance loss over time.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: 'In CentOS 7, you can view the list of currently loaded and shared modules with
    `httpd -M`. The following output is truncated for the sake of brevity, but should
    be very similar in your case:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: A careful inspection of the module list and solid knowledge of what your applications
    actually needs will help you define which modules are not needed, and thus, they
    can be unloaded for the time being.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: 'Look at the following line in `/etc/httpd/conf/httpd.conf`:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This line indicates that Apache will look in the `conf.modules.d` directory
    for instructions to load module inside `.conf` files. For example, in the standard
    installation, `00-base.conf` contains ~70 `LoadModule` directives that point to
    DSOs inside /`etc/httpd/modules`. It is in these `.conf` files that you can enable
    or disable (by prepending each `LoadModule` directive with a `#` symbol, thus
    commenting that line) Apache modules. Note that this must be performed on both
    nodes.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: Loading and disabling modules
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the following screenshot, `userdir_module` modules, `version_module`, and
    `vhost_alias_module` are loaded, whereas `buffer_module`, `watchdog_module`, and
    `heartbeat_module` are disabled through `00-base.conf`:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: '![Loading and disabling modules](img/00075.jpeg)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
- en: 'For example, in order to disable the `userdir` module, comment the corresponding
    `LoadModule` directive in `/etc/httpd/conf.modules.d/00-base.conf` on both nodes:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Restart the cluster resource on the node where it is currently active:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Placing limits on the number of Apache processes and children
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In order for Apache to be able to handle as many simultaneous requests as needed,
    but preventing it from consuming more RAM than you can afford for your application(s),
    you need to set the `MaxRequestWorkers` (called `MaxClients` before version 2.3.13)
    directive to an appropriate value based mostly on the available physical memory
    that can be allotted in your specific environment. Note that if this value is
    set too high, you may bring the web server (and the resource altogether) to its
    knees.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, setting it to an appropriate value, which is calculated based
    on the memory usage of each Apache process compared to the allotted RAM, will
    allow the web server to respond to that many requests at once. If the number of
    requests surpasses the capacity of the server, the extra requests will be served
    once the first ones have already been served, thus avoiding the resource from
    hanging for all connections.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: For further details, refer to the Apache MPM Common directives documentation
    at [http://httpd.apache.org/docs/2.4/mod/mpm_common.html](http://httpd.apache.org/docs/2.4/mod/mpm_common.html).
    Keep in mind that Apache fine-tuning is out of the scope of this book, and the
    actions mentioned here are generally not enough for production use.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: Database resource
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since you will seldom use a web server without an accompanying database server,
    you also need to look on that side of things to improve performance. Here are
    some basic things you will want to look at.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: Creating indexes
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A database containing tables of hundreds of thousands or million of records
    can quickly become a performance bottleneck when a typical `SELECT-FROM-WHERE`
    statement is made to retrieve a specific record. Going through every row in a
    table to accomplish this is considered highly inefficient as it is performed at
    the hard disk level.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: With indexes, the operation is performed in memory instead of disk, and records
    can be automatically sorted so that it's faster to find the one we want because
    an index only contains the actual sorted data and a link to the original data
    record. In addition, we can create an index for each column we need to sort by,
    so using indexes becomes a handy tool to improve performance.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: 'To begin, exit your MariaDB session and run test 3 to measure performance without
    indexes:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Now, let''s create indexes on the `emp_no` field in the employees and salaries
    tables since we will use them in our `WHERE` clause, and then perform test 3 again.
    Perform these steps:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: 'First, log in to the database server using the following command:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Then, issue the following commands from the MariaDB shell:'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: After that, exit the MariaDB shell and run the test again to compare performance.
    The results are shown in the following screenshots and summarized against the
    previous example (without indexes) in the next table:![Creating indexes](img/00076.jpeg)
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, let''s look at the results of the same test, but this time using indexes:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '![Creating indexes](img/00077.jpeg)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
- en: Summarizing results of test 2 with and without indexes on node01
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: '| TEST 3 (in seconds) | Node01 (without indexes) | Node01 (with indexes) |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
- en: '| Average, all queries | 0.043 | 0.038 |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
- en: '| Minimum, all queries | 0.035 | 0.037 |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
- en: '| Maximum, all queries | 0.055 | 0.046 |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
- en: The preceding screenshots demonstrate that creating indexes on searchable fields
    will improve performance as it will prevent the server from having to go through
    all rows before returning the results.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: Using query cache
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In a MariaDB database server, the results of `SELECT` queries are stored in
    a query cache so that when the exact same operation is performed again, the results
    can be returned faster. This is precisely the case in most modern websites where
    similar queries are made over and over again (high-read and low-write environments).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: So, how does this happen at the server level? If an incoming query is not found
    in the cache, it will be processed normally and then stored, along with its result
    set, in the query cache. Otherwise, the results are pulled from the cache, which
    makes it possible to complete the operation much faster than if it was processed
    normally.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: 'In MariaDB, the query cache is enabled by default (`SHOW VARIABLES LIKE ''query''query''_cache_type'';`),
    but its size is set to zero (`SHOW VARIABLES LIKE ''query''query''_cache_size'';`),
    as indicated in the following screenshot:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: '![Using query cache](img/00078.jpeg)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
- en: 'For this reason, we need to set the query cache size variable to an appropriate
    value according to the use of our application. In the following screenshot, this
    variable is set to 100 KB (`SET GLOBAL query_cache_size = 102400;`), and we can
    see that the query cache size has been updated accordingly:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: '![Using query cache](img/00079.jpeg)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
- en: Note that the right value for the query cache size will depend largely, if not
    entirely, on the needs of your specific case. Setting it too high will result
    in performance degradation as the system will have to allocate extra resources
    to manage a large cache. On the other hand, setting it to a very low value will
    cause at least some repeated queries to be processed normally and not be cached.
    In the preceding example, we allocated 100 KB of data as cache to store queries
    and their corresponding results.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: For further details, refer to the MariaDB documentation ([https://mariadb.com](https://mariadb.com)),
    specifically to the *Managing MariaDB/Optimization and tuning* section.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The MariaDB documentation contains very helpful information to tune a database
    server starting from the ground up (all the way from the operating system level
    through query optimization). Other tools to increase performance and stability
    are MySQL tuner ([http://mysqltuner.com/](http://mysqltuner.com/)), MySQL Tuning
    Primer ([https://launchpad.net/mysql-tuning-primer](https://launchpad.net/mysql-tuning-primer)),
    and phpMyAdmin Advisor ([https://www.phpmyadmin.net/](https://www.phpmyadmin.net/)).
    The last tool is available in the **Status** tab of a standard phpMyAdmin installation.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: Moving to an A/A cluster
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you will recall from the introduction of [Chapter 3](part0023_split_000.html#LTSU2-1d2c6d19b9d242db82da724021b51ea0
    "Chapter 3. A Closer Look at High Availability"), *A Closer Look at High Availability*,
    A/A clusters tend to provide higher availability as several nodes are actively
    running applications at the same time (which, by the way, requires that the necessary
    data for those applications be available simultaneously on all cluster members).
    The downside is that if one or more nodes go offline, the remaining ones are assigned
    extra processing load, thus negatively impacting the overall performance of the
    cluster.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: That being said, let's examine briefly the required steps to convert our current
    A/P cluster to an A/A one. Make sure a STONITH resource has been defined (refer
    to chapter 3 for further details).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: 'Enable STONITH resource by using the following command:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Install the additional software that will be needed for this:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: As opposed to a traditional journaling filesystem such as `ext4` (which we have
    used for our filesystems up until this point in the book), you will need a way
    to ensure that all nodes are granted simultaneous access to the same block storage.
    **Global File System 2** (also known as **GFS2**) provides such a feature through
    its command-line tools, which are included in the `gfs2-utils` package.
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In addition, the `dlm` package will install the **Distributed Lock Manager**
    (also known as **DLM**), a requirement in cluster filesystems to synchronize access
    to shared resources. Add (and clone) the Distributed Lock Manager as a cluster
    resource of the `ocf` class, pacemaker provider, and `controld` class:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Now, push the newly created resource to the CIB:'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Choose a replicated storage resource and create a `gfs2` filesystem on top of
    its associated device node.
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For example, let''s use the `/dev/drbd0` device we created in [Chapter 4](part0030_split_000.html#SJGS1-1d2c6d19b9d242db82da724021b51ea0
    "Chapter 4. Real-world Implementations of Clustering"), *Real-world Implementations
    of Clustering*. We will need to unmount it from the node with the DRBD primary
    role (most likely, `node01`) before we can create a `gfs2` filesystem on it:'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Here, as you can see in the following screenshot, `MyCluster` is the original
    name of our cluster, `Web` is a random name, and the `-j` flag is used to indicate
    that the filesystem will use two journals (in this case one for each node - you
    will want to change this number if your cluster consists in more nodes). Finally,
    the `-p` option tells us that we are going to use the DLM provided by the kernel:'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Moving to an A/A cluster](img/00080.jpeg)'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'You will also need to change the `fstype` option of the `web_fs` resource from
    `ext4` (the original filesystem used when we first created it in [Chapter 4](part0030_split_000.html#SJGS1-1d2c6d19b9d242db82da724021b51ea0
    "Chapter 4. Real-world Implementations of Clustering"), *Real-world Implementations
    of Clustering*) to `gfs2` in the PCS resource configuration:'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'It is important to note that if the cluster attempts to start `web_fs` before
    `dlm-clone`, we will run into an issue (we cannot mount a `gfs2` filesystem if
    the `dlm` functionality is not present). Thus, we need to add colocation and ordering
    constraints so that `web_fs` will always start on the node where `dlm-clone` starts:'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '`anddlm-clone` will be started before `web_fs`.'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The `pcs constraint` order `dlm-clone` then `web_fsClone` the virtual IP address
    resource.
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Cloning the IP address will allow us to effectively use resources on both nodes,
    but at the same time, any given packet will be sent to only one node (thus, implementing
    a basic load-balancing method in our cluster):'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To do this, we will save the cluster configuration to a file named `load_balancing_cfg`
    and update such file with the :'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'You will notice from the pcs resource help that the clone operation allows
    you to specify certain options. In the following lines, `clone-max` specifies
    the number of nodes that host the `virtual_ip` resource (2 in this case), whereas
    clone-node-max indicates the number of resource instances each node is allowed
    to run. Next, `globally-unique` instructs the resource agent that each node is
    distinct from the rest and thus, handles distinct traffic as well. Finally, `clusterip_hash=sourceip`
    tells us that the packet''s source IP address will be used to decide which node
    gets to process which request:'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The next steps consists of cloning the filesystem and Apache and/or MariaDB
    resources. Note that in order to allow two primaries in a DRBD device so that
    you can serve content from both at the same time, you will need to set the allow-two-primaries
    directive to yes (`allow-two-primaries yes;`) in the net section of the resource
    configuration file (`/etc/drbd.d/drbd0.res`, for example):'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Once again, save the current CIB to a local file and add the clone resource
    information. In the next example, we will use `web_fs`, `web_drbd_clone` and `webserver`:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Now, `web_drbd` should be allowed to serve both instances as primary or master:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Then, activate the new configuration:'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Last but not least, you need to keep in mind that you will need to set the value
    of the resource stickiness to `0` in order for it to return an instance to its
    original node after a failover. To do so, refer to the *Performing a failover*
    section this same chapter.
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can now proceed to force a failover as usual, and test the resource availability.
    Unfortunately, this is not possible in a Virtualbox environment as I have explained
    previously. However, it's entirely possible if you are able to build your cluster
    with real hardware and an actual STONITH device.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this last chapter, we set up a couple of performance testing tools for the
    example services that you need to make highly available in your cluster, and provided
    a few suggestions to optimize their performance separately as well. Note that
    those suggestions are not intended to represent an exhaustive list of tuning methods,
    but a starting point instead. We have also provided the overall instructions so
    that you can convert an A/P cluster into an A/A one.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: Finally, keep in mind that this book was written using virtual machines instead
    of specialized hardware. Thus, we have run into some associated limitations, such
    as the lack for real STONITH devices that would otherwise have allowed us to actually
    demonstrate the functionalities of an A/A cluster. However, the principles outlined
    in this book will undoubtedly be a guide to set up your own clusters, whether
    you are experimenting with virtual machines as well or using real hardware.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: Best of success in your endeavors!
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
