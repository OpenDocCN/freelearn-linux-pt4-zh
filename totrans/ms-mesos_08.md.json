["```\n    # Install snappy-java package if not alr\n    eady installed.\n    $ sudo apt-get install libsnappy-dev\n\n    # Clone the repository\n    $ git clone https://github.com/Mesos/Hadoop\n\n    $ cd Hadoop\n\n    # Build the Hadoop-Mesos-0.1.0.jar\n    $ mvn package\n\n    ```", "```\n      <!-- runtime deps versions -->\n      <commons-logging.version>1.1.3</commons-logging.version>\n      <commons-httpclient.version>3.1</commons-httpclient.version>\n    <Hadoop-client.version>2.5.0-mr1-cdh5.2.0</Hadoop-client.version>\n      <Mesos.version>0.23.1</Mesos.version>\n      <protobuf.version>2.5.0</protobuf.version>\n      <metrics.version>3.1.0</metrics.version>\n      <snappy-java.version>1.0.5</snappy-java.version>\n    ```", "```\n    $ wget \n    http://archive.cloudera.com/cdh5/cdh/5/hadoop-2.5.0-cdh5.2.0.tar.gz\n    # Extract the contents\n    $ tar zxf hadoop-2.5.0-cdh5.2.0.tar.gz\n\n    ```", "```\n    $ cp hadoop-Mesos-0.1.0.jar hadoop-2.5.0-cdh5.2.0/share/hadoop/common/lib/\n\n    ```", "```\n    $ cd hadoop-2.5.0-cdh5.2.0\n    $ mv bin bin-mapreduce2\n    $ mv examples examples-mapreduce2 \n    $ ln -s bin-mapreduce1 bin\n    $ ln -s examples-mapreduce1 examples\n\n    $ pushd etc\n    $ mv hadoop hadoop-mapreduce2\n    $ ln -s hadoop-mapreduce1 Hadoop\n    $ popd\n    $ pushd share/hadoop\n    $ rm mapreduce\n    $ ln -s mapreduce1 mapreduce\n    $ popd \n\n    ```", "```\n    $ tar czf hadoop-2.5.0-cdh5.2.0.tar.gz hadoop-2.5.0-cdh5.2.0\n    $ hadoop fs -put hadoop-2.5.0-cdh5.2.0.tar.gz /hadoop-2.5.0-cdh5.2.0.tar.gz\n\n    ```", "```\n    <property>\n      <name>mapred.job.tracker</name>\n      <value>localhost:9001</value>\n    </property>\n\n    <property>\n      <name>mapred.jobtracker.taskScheduler</name>\n      <value>org.apache.Hadoop.mapred.MesosScheduler</value>\n    </property>\n\n    <property>\n      <name>mapred.Mesos.taskScheduler</name>\n      <value>org.apache.Hadoop.mapred.JobQueueTaskScheduler</value>\n    </property>\n\n    <property>\n      <name>mapred.Mesos.master</name>\n      <value>localhost:5050</value>\n    </property>\n\n    <property>\n      <name>mapred.Mesos.executor.uri</name>\n      <value>hdfs://localhost:9000/Hadoop-2.5.0-cdh5.2.0.tar.gz</value>\n    </property>\n    ```", "```\n    $ MESOS_NATIVE_LIBRARY=/path/to/libMesos.so Hadoop jobtracker\n\n    ```", "```\n    $ export MESOS_NATIVE_LIBRARY=/usr/local/lib/libMesos.so\n    $ export MESOS_NATIVE_JAVA_LIBRARY=/usr/local/lib/libMesos.so\n\n    ```", "```\n    $ mv ~/.m2 ~/.mv_back\n    $ mvn package\n\n    ```", "```\n$ wget http://d3kbcqa49mib13.cloudfront.net/spark-1.6.0-bin-hadoop2.6.tgz\n$ hadoop fs -put spark-1.6.0-bin-hadoop2.6.tgz /\n\n```", "```\nexport MESOS_NATIVE_JAVA_LIBRARY=<path to libMesos.so>\nexport SPARK_EXECUTOR_URI=<URL of Spark-1.6.0.tar.gz uploaded above>\n\n```", "```\nval conf = new SparkConf().setMaster(\"Mesos://HOST:5050\").setAppName(\"My app\").set(\"Spark.executor.uri\", \"<path to Spark-1.6.0.tar.gz uploaded above>\")\nval sc = new SparkContext(conf)\n```", "```\n./bin/Spark-submit \\\n  --class org.apache.Spark.examples.SparkPi \\\n  --master Mesos://207.184.161.138:7077 \\\n  --deploy-mode cluster\n  --supervise\n  --executor-memory 20G \\\n  --total-executor-cores 100 \\\n  http://path/to/examples.jar \\\n  1000\n```", "```\n    conf.set(\"Spark.Mesos.coarse\", \"false\")\n    ```", "```\n    $ git clone https://github.com/Mesos/Storm\n    $ cd Storm\n\n    ```", "```\n      # Please change these for your cluster to reflect your cluster settings\n      # -----------------------------------------------------------\n      Mesos.master.url: \"zk://localhost:2181/Mesos\"\n      Storm.zookeeper.servers:\n      - \"localhost\"\n      # -----------------------------------------------------------\n\n      # Worker resources\n      topology.Mesos.worker.cpu: 1.0\n\n      # Worker heap with 25% overhead\n      topology.Mesos.worker.mem.mb: 512\n      worker.childopts: \"-Xmx384m\"\n\n      # Supervisor resources\n      topology.Mesos.executor.cpu: 0.1\n      topology.Mesos.executor.mem.mb: 500 # Supervisor memory, with 20% overhead\n      supervisor.childopts: \"-Xmx400m\"\n\n    # The default behavior is to launch the 'logviewer' unless 'autostart' is false. If you enable the logviewer, you'll need to add memory overhead to the executor for the logviewer.\n\n      logviewer.port: 8000\n      logviewer.childopts: \"-Xmx128m\"\n      logviewer.cleanup.age.mins: 10080\n      logviewer.appender.name: \"A1\"\n      supervisor.autostart.logviewer: true\n\n    # Use the public Mesosphere Storm build. Please note that it won't work with other distributions. You may want to make this empty if you use `Mesos.container.docker.image` instead.\n      # Mesos.executor.uri: \"file:///usr/local/Storm/Storm-Mesos-0.9.6.tgz\"\n\n    # Alternatively, use a Docker image instead of URI. If an image is specified, Docker will be used instead of Mesos containers.\n      Mesos.container.docker.image: \"Mesosphere/Storm\"\n\n      # Use Netty to avoid ZMQ dependencies\n      Storm.messaging.transport: \"backtype.Storm.messaging.netty.Context\"\n      Storm.local.dir: \"Storm-local\"\n\n      # role must be one of the Mesos-master's roles defined in the --roles flag\n      Mesos.framework.role: \"*\"\n      Mesos.framework.checkpoint: true\n      Mesos.framework.name: \"Storm\"\n\n    # For setting up the necessary Mesos authentication see Mesos authentication page and set the Mesos-master flags --credentials, --authenticate, --acls, and --roles.\n\n      Mesos.framework.principal: \"Storm\"\n\n      # The \"secret\" phrase cannot be followed by a NL\n\n      Mesos.framework.secret.file: \"Storm-local/secret\"\n\n      #Mesos.allowed.hosts:\n        - host1\n      #Mesos.disallowed.hosts:\n        - host1\n    ```", "```\n    $ bin/Storm-Mesos nimbus\n\n    ```", "```\n    $ bin/Storm ui\n\n    ```", "```\n$ ./bin/Storm jar -c nimbus.host=10.0.0.1 -c nimbus.thrift.port=32001 examples/Storm-starter/Storm-starter-topologies-0.9.6.jar Storm.starter.WordCountTopology word-count\n\n```", "```\nSTORM_RELEASE=x.x.x MESOS_RELEASE=y.y.y bin/build-release.sh\n\n```", "```\n{\n  \"id\": \"storm-nimbus\",\n  \"cmd\": \"./bin/run-with-marathon.sh\",\n  \"cpus\": 1.0,\n  \"mem\": 1024,\n  \"ports\": [0, 1],\n  \"instances\": 1,\n  \"container\": {\n    \"type\": \"DOCKER\",\n    \"docker\": {\n      \"image\": \"mesosphere/storm\",\n      \"network\": \"HOST\",\n      \"forcePullImage\":true\n    }\n  },\n  \"healthChecks\": [\n    {\n      \"protocol\": \"HTTP\",\n      \"portIndex\": 0,\n      \"path\": \"/\",\n      \"gracePeriodSeconds\": 120,\n      \"intervalSeconds\": 20,\n      \"maxConsecutiveFailures\": 3\n    }\n  ]\n}\n```", "```\n$ curl -X POST -H \"Content-Type: application/json\" -d storm-mesos.json http://marathon-machine:8080/v2/apps\n\n```", "```\n    $ git clone https://github.com/Banno/samza-mesos\n    $ cd samza-mesos\n    $ mvn clean install\n\n    ```", "```\n    <dependency>\n      <groupId>eu.inn</groupId>\n      <artifactId>samza-mesos</artifactId>\n      <version>0.1.0-SNAPSHOT</version>\n    </dependency>\n    ```", "```\n{\n  \"id\": \"samza-jobs.my-job\", /Job ID/\n  \"uris\": [\n    \"hdfs://master-machine/my-job.tgz\" /Job Resource/\n  ],\n  \"cmd\": \"bin/run-job.sh --config-path=file://$PWD/config/my-job.properties --config=job.factory.class=eu.inn.samza.mesos.MesosJobFactory --config=mesos.master.connect=zk://zookeeper-machine:2181/mesos --config=mesos.package.path=hdfs://master-machine/my-job.tgz --config=mesos.executor.count=1\", /Job Properties/\n  \"cpus\": 0.1,\n  \"mem\": 64, /Resources/\n  \"instances\": 1,\n  \"env\": {\n    \"JAVA_HEAP_OPTS\": \"-Xms64M -Xmx64M\"\n  }\n}\n```", "```\n$ curl -X POST -H \"Content-Type: application/json\" -d samza-job.json http://marathon-machine:8080/v2/apps\n\n```"]