- en: Chapter 5. Virtualization and Cloud Computing inside the Ubuntu Server
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Virtualization and Cloud computing are some of the hottest topics in system
    administration communities nowadays. They give system administrators the possibility
    to run more servers on the same hardware and use resources in a reliable manner.
    The Cloud concept, which is already based on virtualization, provides much more
    benefits, especially via security and new business models such as SaaS, PaaS,
    and IaaS.
  prefs: []
  type: TYPE_NORMAL
- en: 'Ubuntu provides a good set of virtualization and Cloud computing platforms.
    In this chapter, we will have a look at how the Ubuntu Server handles the most
    well known platforms:'
  prefs: []
  type: TYPE_NORMAL
- en: In the first section, we will focus on virtualization. We will discover how
    to manage three big virtualization programs, namely KVM, XenServer, and Docker.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the second section, we will take a look at the Cloud capabilities provided
    by the Ubuntu Server.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Virtualization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a number of different virtualization technologies available under
    the Ubuntu Server. In this section, we will discover the virtualization concept
    in general with its different technologies and approach. Then, we will study some
    of the most popular virtualization programs, such as **Kernel-based Virtual Machine**
    (**KVM**), XenServer and Docker, with one program from each technology.
  prefs: []
  type: TYPE_NORMAL
- en: An introduction to virtualization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Virtualization is used to run one or more operating systems / applications as
    a simple software on one or more computers/servers instead of not being able to
    install more than one operating system per machine. These **virtual machines**
    are called **VMs**, **environments**, and even **VEs**. The virtualization of
    **operating systems** (**OS**) is a technique that allows you to run multiple
    OSes simultaneously on a single computer as if they were working on separate computers.
  prefs: []
  type: TYPE_NORMAL
- en: The benefits of virtualization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Virtualization has several advantages. The following are some of its benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: You can use a different OS without restarting your computer to use programs
    that do not natively work on Ubuntu
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can also use devices that don't work with Ubuntu but that can work with
    other OSs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can perform testing under the operating systems without jeopardizing a stable
    environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can also perform software testing in controlled, isolated and secure environments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can transport OS from one computer to another using a virtual machine running
    on a computer with a compatible hypervisor
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Individuals and **Small and Medium Enterprise** (**SMEs**) / **Small and Medium
    Industries** (**SMIs**) will generally be more interested in running two different
    OSes at the same time to run software that are compatible with one hypervisor
    but not the other. Large companies are increasingly using virtualization to save
    space in server rooms, simplify installations, facilitate restarts after incidents,
    and of course, develop secure and reliable business networks.
  prefs: []
  type: TYPE_NORMAL
- en: Different techniques of virtualization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The main aspect of the virtualization concept is an entity called **hypervisor**.
    A hypervisor is a software, firmware, or hardware that creates and runs virtual
    machines. The machine that runs a hypervisor is called the host machine, and every
    virtual machine that runs on a hypervisor is called a guest machine. There are
    two types of hypervisors that we will see in this section. Besides a hypervisor,
    there is another main piece of virtualization concept that takes more than one
    name. Some call it an **isolator**, while others call it a **container**, **virtualization
    engine**, or even an **operating-system-level virtualization**. In our case, we
    will call it an isolator. We will discover this, as well as the two hypervisor
    types, in this section.
  prefs: []
  type: TYPE_NORMAL
- en: Type 1 hypervisor
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This type of hypervisor is also called a **native** or **bare-metal hypervisor**.
    It runs directly on a host's hardware, and it handles the hardware directly and
    manages the guest OS. An example of this hypervisor type is the **XenServer**.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can model it by using the following schema:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Type 1 hypervisor](img/B04800_05_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Type 2 hypervisor
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This type of hypervisor is also called a **hosted hypervisor**. It runs on the
    host OS just like any other software. It provides an emulation of the hardware
    level to guest systems. An example of this hypervisor type is **Oracle VirtualBox**.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Some virtualization programs, such as KVM, can't be easily classified into either
    of the two types. **KVM** is a kernel module that converts the host OS to a type
    1 hypervisor, but at the same time, the host OS always works as a general-purpose
    OS that runs other applications that compete for VM resources. Therefore, KVM
    can also be categorized as a type 2 hypervisor.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can model type 2 hypervisor by using the following schema:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Type 2 hypervisor](img/B04800_05_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: An isolator
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'An isolator is a piece of software that is used to isolate applications'' executions
    in what are called contexts or execution areas. An isolator allows you to run
    the same application in a multi-instance mode several times (multiple execution
    instances) even if it was not designed for it. This solution is very efficient
    because of the little overhead (the time spent by a system to do more than just
    manage itself). Note that virtualized environments are not completely isolated.
    The performance is always a key factor. However, we cannot really talk about OS
    virtualization. We can model it by using the following schema:'
  prefs: []
  type: TYPE_NORMAL
- en: '![An isolator](img/B04800_05_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The different approaches towards virtualization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before starting a virtualization project, it is mandatory to understand the
    two main approaches in this field—**full virtualization** and **paravirtualization**.
    Both XenServer and KVM offer these two approaches. Therefore, you need to know
    the differences between them very well, and this is what we will explain in the
    following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Paravirtualization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The paravirtualization approach requires a modified version of the guest OS,
    that generates special instructions that can be easily handled by the hypervisor,
    which simply interprets and passes them to the physical hardware.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, the guest OS knows that it is virtualized. As a result, it will
    generate instructions that are best optimized for use in a VE and don't need to
    be translated first.
  prefs: []
  type: TYPE_NORMAL
- en: Full virtualization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The other approach is full virtualization, which allows you to use an unmodified
    OS as a guest. One of its disadvantages is that it requires special hardware support,
    which is something that is nowadays provided as a special feature in modern CPUs
    (both AMD and Intel processors). Thanks to this built-in support within the server's
    CPU, fully virtualized machines can work as efficiently as possible in spite of
    the fact that the instructions coming from the virtualized OS first need to be
    translated by the hypervisor.
  prefs: []
  type: TYPE_NORMAL
- en: KVM (Kernel-based Virtual Machine)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will discover the default virtualization technology that
    is actually supported by Ubuntu. Named **KVM** (**Kernel-based Virtual Machine**),
    this virtualization technology is a free software with support built into the
    Linux kernel. This software takes advantage of the virtualization support that
    is built into the Intel and AMD processors and allows you to run a number of different
    distributions and OSes as **VMs** (**virtual machines**) on a single host.
  prefs: []
  type: TYPE_NORMAL
- en: Prerequisites
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Before starting the installation process, you should verify that your computer
    supports virtualization. To check this, you need to run the `kvm-ok` command,
    which is a part of the `cpu-checker` package. Therefore, you first of all need
    to install this package and then invoke the command by using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, check the result and verify that you got the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This means that you should look for another computer. However, you may get
    something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, you may get something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This means that you can move on to the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Sometimes your CPU supports virtualization, but you may get a message saying
    that it can't. In such cases, most of the time, virtualization is disabled in
    the BIOS. Therefore, you will have to enable it from there. All that you need
    to do is restart your computer and access the BIOS by using the appropriate function
    key (it appears on the screen for a few seconds just after the boot; most of the
    time, you need to use *F12*). From the BIOS screen that appears, look for something
    such as a CPU or performance heading and select it. Then, look for a virtualization
    selection, such as **Intel Virtualization Technology**, and enable it. Save your
    changes and reboot.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring the KVM networking
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are two main ways that can be used to set up the network for your VMs.
    The default networking setup provides a private network under *192.168.122.0/24*.
    A DHCP server will hand out the rest of the IPs. Alternatively, you can set up
    static IPs for your VM. The IP of the KVM host is *192.168.122.1*. VMs communicate
    with the outside world via this gateway by using **NAT** (**Network Address Translation**).
    This works fine, especially for VMs on a desktop, but since we are talking about
    servers here, my assumption is that you want machines outside the KVM host to
    be able to communicate with your VMs. While you can certainly set up some iptables
    DNAT rules and forward traffic back in, this solution doesn't scale very well.
    The real solution is to set up a bridged network so that your VMs appear to be
    on the same network as that of your host.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is relatively simple to set up the `br0` bridge interface on Ubuntu. Essentially,
    you need to identify the interface over which you want to bridge traffic (probably
    `eth0` or possibly `bond0` if you set up bonding), transfer all of its configuration
    to `br0` along with a few extra bridge options, and change the original interface
    to the manual mode. It will make more sense when you see the examples. Consider
    an instance where I had a DHCP set up for `eth0,` and my old configuration in
    `/etc/network/interfaces` looked like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, my new configuration will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For more information about network bridging on an Ubuntu Server, you can visit
    [https://help.ubuntu.com/community/NetworkConnectionBridge](https://help.ubuntu.com/community/NetworkConnectionBridge).
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that I changed the `inet` mode for `eth0` from `dhcp` to `manual`. If
    `eth0` has a static IP configured, I can just transfer the configuration to `br0`
    instead. Let''s take a look at the following configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This will go to the following configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Once I have set up `/etc/network/interfaces` to have the bridge, I then restart
    the network by using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To know more about advanced network configurations for KVM on the Ubuntu Server,
    you can take a look at the community page at [https://help.ubuntu.com/community/KVM/Networking](https://help.ubuntu.com/community/KVM/Networking)
    and the official Ubuntu documentation at [https://wiki.ubuntu.com/KvmWithBridge](https://wiki.ubuntu.com/KvmWithBridge).
  prefs: []
  type: TYPE_NORMAL
- en: The KVM installation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To perform the KVM virtualization, you need to install some additional software
    besides KVM. The following software components need to be added:'
  prefs: []
  type: TYPE_NORMAL
- en: '`libvirt`: This provides an interface to the virtualization hardware'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`qemu`: This emulates the PC hardware to virtual machines'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bridge-utils`: This offers a way to bridge networking from virtual machines
    through the host'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To install the basic software needed for the KVM virtualization, run the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that to manage this set of programs, you will mainly use the **command
    language interpreter** (**CLI**) commands. In case you would like to use a GUI
    to manage your VMs, there is the famous `virt-manager` graphical software that
    does the job. Note that you need to either have a graphical environment installed,
    or connect to your server by using SSH with the `-X` option. There is another
    solution—install `virt-manager` on another desktop/laptop that has a graphical
    environment and then use it to remotely manage your VMs by using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'To install `virt-manager`, execute the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: With `virt-manager` installed, you now have a choice of managing virtual machines
    from a graphical interface or from the command line. Next, you want to make sure
    that the user account from which you want to manage virtualization is configured
    to do so.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'After finishing the installation process, you should add the user whom you
    wish to manage the virtualization of the `libvirtd` group by using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Finally, reboot your server, log in as the user, and check whether the virtualization
    services are running. At this point, you can start managing your VE.
  prefs: []
  type: TYPE_NORMAL
- en: Managing virtual machines
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If you want to manage a VE by using the `virt-manager` graphic tool, simply
    run the `virt-manager` command, and you will get an intuitive, easy-to-use GUI.
    You can customize it by editing the **preferences** sub-menu of the **edit** menu.
    You also need to check the connection details via the **edit** menu to customize
    advanced settings, such as networks and storage, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Managing virtual machines](img/B04800_05_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Then, you can start creating and managing your VMs; it is very easy and intuitive.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, if you choose to work using CLI, you should master the options
    that can be used with the main virtualization commands. To get started, you can
    use the `virt-install` command to install a virtual machine. With `virt-clone`,
    you can clone an existing virtual image. To manage VMs, you can use the `virsh`
    command to list information about VMs as well as start, stop, and reboot them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that before creating a VM by using `virt-install`, you need to create
    the storage image beforehand. One way to do that is by using the `qemu-img` command.
    For example, the following command will create a 20 GB storage image named `ubuntuserver`
    of the `qcow2` type under the `/media/Data` directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'After performing this step, you can create a VM. Here''s an example of a `virt-install`
    command line that creates an Ubuntu virtual machine. This command incorporates
    many of the options that you would need to click on or fill in on the `virt-manager`
    window. Note that this command incorporates the image that we created earlier
    in this section by using the `qemu-img` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: To see the signification of each of these options (and much more) that can be
    used with the `virt-install` command, you need to check the `virt-install man`
    page (type man `virt-install`).
  prefs: []
  type: TYPE_NORMAL
- en: Once the `virt-install` command starts, you can open an application from the
    desktop to see the progress of the installation. The `virt-manager` and `virt-viewer`
    commands are among those commands that you can use to view your VM's console.
    After the VM is installed, you can manage your VMs by using the `virsh` command.
  prefs: []
  type: TYPE_NORMAL
- en: The `virsh` command provides a good way to manage your VMs after they are created.
    You can use `virsh` to see which VMs are running. Then, you can start, stop, pause,
    and otherwise manage them. There are many alternatives to the `virsh` command
    that you can use to manage VMs. Refer to the `virsh man` page (type `man virsh`)
    for details.
  prefs: []
  type: TYPE_NORMAL
- en: XenServer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The second virtualization platform that we will discuss is the famous **XenServer**.
    Since version 7.10, XenServer was supported by the Ubuntu Server, but starting
    from version 8.04, Canonical made the decision to go with KVM as the default solution
    for virtualization in the Ubuntu Server.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will discuss how to set up the Ubuntu Server as a host for
    the Xen virtualization. We will also learn how to install guests in a Xen environment.
    Just before starting the hands-on part of this section, let's discover a bit of
    the Xen terminology. In Xen, there's no difference between a host and a guest
    OS. This is because the words "host" and "guest" suggest a hierarchical relation
    that doesn't exist (take a look at the type 1 hypervisor model described in the
    first section of this chapter). So, Xen talks about domains. There is the **domain
    0** OS (which can be compared to the host OS in other virtualization technologies)
    and the other OSes (which can be compared to guest OSs).
  prefs: []
  type: TYPE_NORMAL
- en: These other OSes are referred to as **domain U** machines. The **domain 0**
    OS (or just **dom0**) is the first OS that loads on a physical machine, and it
    has specific responsibilities in the Xen environment, including driver management.
    The **domain U** (or just **domU**) machines are virtualized machines that do
    not have a special responsibility with regard to virtualization.
  prefs: []
  type: TYPE_NORMAL
- en: Prerequisites
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The hardware supported by Linux is available for Xen (it should just be compatible
    with the kernel). By default, Xen supports all the operating systems that are
    modified to operate within it, which is called paravirtualization. Xen supports
    unmodified operating systems as well through hardware virtualization, which is
    called full virtualization. However, here we must use a CPU that has hardware
    virtualization support (Intel VT and AMD-V). There is more than one way of verifying
    this point. For example, we can check the flags set for the CPU in `/proc/cpuinfo`.
    By using the `egrep` command, we can search that file for Intel-VT support (vmx)
    or AMD-V support (svm) by using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of this command is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Prerequisites](img/B04800_05_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Another way of checking this point is by using the `xm dmesg` command to see
    an overview of all the features that are relevant to the Xen virtualization, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: If you don't get a result, your CPU doesn't support virtualization, which means
    that you can't virtualize unmodified OSes.
  prefs: []
  type: TYPE_NORMAL
- en: Installing XenServer
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Installing XenServer is quite easy for Ubuntu. All that you have to do is run
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Then, restart your system and from **GRand Unified Bootloader** (**GRUB**),
    choose the entry containing XenServer.
  prefs: []
  type: TYPE_NORMAL
- en: After rebooting, check whether or not you are using the good kernel. Run the
    `sudo uname -a` command and verify that `xen` is present in the result. Also,
    verify that `dom0` is launched by using the `sudo xm list` command.
  prefs: []
  type: TYPE_NORMAL
- en: 'Verify that the network is properly configured. The `ifconfig` command must
    return at least three interfaces, namely `lo` (the loopback system), `eth0` (the
    bridge that is no longer your network interface but is the image for `domU`),
    and `peth0` (the network interface). If this is not the case, edit the `/etc/xen/xend-config.sxp`
    file and ensure that you have the following lines uncommented:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Don''t forget to restart the Xen daemon after modifying this script by using
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The `Xen` daemon is responsible for virtual network infrastructure management.
  prefs: []
  type: TYPE_NORMAL
- en: The networking concept in a XenServer environment
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Xen has a specific network environment that is different from other VEs. Every
    domain (starting from `dom0`) has its own virtual drivers that serve as a network
    card; they are simply named `eth0`, `eth1` and so on. Inside the `dom0` OS, you
    will find a logical representation (logical interfaces) for these virtual drivers,
    with the name having the `vifx.y` pattern, where `x` represents the ID of the
    virtualized OS (the **U** in **domU**) and `y` represents the number of the virtualized
    network board (starting from 0).
  prefs: []
  type: TYPE_NORMAL
- en: For example, the first network card (`eth0`) in `dom0` is represented by `vif0.0`,
    the second network card (`eth1`) in `dom3` is represented by `vif3.1`, and so
    on.
  prefs: []
  type: TYPE_NORMAL
- en: 'Continuing with the exploring of this concept, in the `dom0` system, all the
    `vif` interfaces are attached to the virtual bridge (called `xenbr0`), that behaves
    like a real switch. Next, this bridge communicates with `peth0`, which is the
    representation of the physical network card, that finally talks directly to the
    network board in your server. The following figure is a graphical representation
    of how all of this is organized:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The networking concept in a XenServer environment](img/B04800_05_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: After creating the virtual network, you have to add the `max_loop=64` line loop
    in the `/etc/modules` file. This is mandatory as you need to ensure that you can
    create enough virtual disks for your virtual machines. A reboot is needed to confirm
    that this new setting works before you start creating virtual machines.
  prefs: []
  type: TYPE_NORMAL
- en: Managing virtual machines
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Like KVM, XenServer can also be managed by using either GUI or CLI. For GUI,
    there is a multitude of tools. The following are some of these tools:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Virt-manager**: We had a look at this in the KVM section. This works very
    well if you wish to create and manage XenServer VMs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**OpenXenManager**: This is a dedicated GUI that can be used to manage Xen.
    You can install it by using the following command:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**XCP Project Kronos**: **XCP** stands for **Xen Cloud Platform**. To install
    this, you have to add the `ppa:ubuntu-xen-org/xcp1` PPA to your source list (see
    [Chapter 2](ch02.html "Chapter 2. Configuring and Administering Ubuntu Server"),
    *Configuring and Administering Ubuntu Server*, to learn how to do this), update
    the package list, and finally run `sudo apt-get install xcp-storage-managers`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**xen-tools**: You can install this by using the following command:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the following part of this section, we will concentrate on CLI tools. The
    native way of doing this is by creating a storage image by using a tool, such
    as `dd`, as discussed in the backup/restore section in [Chapter 4](ch04.html "Chapter 4. Security
    with Ubuntu"), *Security with Ubuntu*. Next, you need to create a configuration
    file for the guest system, which will contain all the settings used by the guest
    system (RAM, hard disk, and so on), and create a VM based on that `config` file
    by using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The `xm create` command can also be used without a `config` file, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The `xm` manual contains a lot of helpful information if you wish to use `xm`.
    Take a look at it before you start using `xm`.
  prefs: []
  type: TYPE_NORMAL
- en: An introduction to Docker
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Docker is a famous program that automates and simplifies the deployment of
    applications and services inside software containers. It is one of the best tools
    that is classified under the isolator category (see the first section of this
    chapter). Docker is based on an additional layer of abstraction and automation
    of an operating-system-level virtualization (also known as the isolator). It was
    supported by the Ubuntu Server from its 14.04 release. According to an industry
    analyst firm named 451 Research:'
  prefs: []
  type: TYPE_NORMAL
- en: '*"Docker is a tool that can package an application and its dependencies in
    a virtual container that can run on any Linux server. This helps enable flexibility
    and portability on where the application can run, whether on premises, public
    cloud, private cloud, bare metal, etc."*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How Docker works
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As discussed earlier, an isolator provides an environment (containers) to run
    processes in isolation. This is exactly what's done by Docker in a lightweight
    manner by implementing a high-level API that uses resource isolation features
    provided by the Linux kernel (such as kernel namespaces, cgroups, and so on) to
    allow separate containers to run inside a single Linux instance.
  prefs: []
  type: TYPE_NORMAL
- en: Unlike a virtual machine, a Docker container does not require a separate OS.
    Instead, it uses resource isolation (CPU, memory, block I/O, network, and so on)
    to isolate an application's view of the operating system. There are two ways that
    can be used by Docker to access the Linux kernel's virtualization features. The
    first way involves directly using the `libcontainer` library, which has been available
    since Docker 0.9\. The second way requires you to indirectly use a multitude of
    tools, such as `libvirt`, `systemd-nspawn`, and **LXC** (**Linux Containers**).
  prefs: []
  type: TYPE_NORMAL
- en: The resource isolation and service restrictions that result from the use of
    containers provide an almost completely private view of the operating system.
    Therefore, every container has its own process ID space, file system structure,
    and network interfaces. By adding a few additional constraints for each container
    to use only a defined amount of resources, such as CPU, memory, and I/O, we can
    limit the disadvantages of sharing the same kernel between multiple containers.
  prefs: []
  type: TYPE_NORMAL
- en: The use of Docker for container management will simplify the setup of distributed
    systems as well as the deployment of new nodes, which can open a new era for the
    **platform as a service** (**PaaS**) mode.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Docker
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For Ubuntu Server 14.04 and later, Docker is part of the main Ubuntu repositories.
    Therefore, to install Docker, you just have to run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'For older releases, you have to update your source list before executing the
    installation command. This is done by performing the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a file named `/etc/apt/sources.list.d/docker.list` and put the following
    line in it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, download the GPG key and install the `lxc-docker` package by using the
    following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If you want to avoid using `sudo` with every Docker command, add the user to
    the Docker group by using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'When the installation is finished, you have to start Docker just like any other
    ordinary service by using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Using Docker
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As an example, we will have a look at how to use Docker with a LAMP container.
    But first, let''s explore some terminology that we will need later to understand
    different actions:'
  prefs: []
  type: TYPE_NORMAL
- en: '**DockerFile**: This is a source file that contains instructions for a configuration
    file'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Image**: This is a compilation of `DockerFile` that is used to build a portable
    image that is ready for deployment'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Container**: This is the execution of an image, simply a process that is
    used to run an image'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let's move on to practical stuff.
  prefs: []
  type: TYPE_NORMAL
- en: 'First of all, for an image, you can either prepare yours or simply download
    one of the prepared images built by the community. You can search for them either
    via the Web by visiting [https://hub.docker.com/explore/](https://hub.docker.com/explore/),
    or via CLI by using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'You will get a long list of images. You have to choose your own image. For
    this example, we have chosen the `reinblau/lamp` image. To install this image,
    all that you need to do is run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'This command will download and install this image. After finishing this step,
    you need to run it in a container. This is done by using the `docker run` command,
    which can take some arguments such as the port NATing that was used in the LAMP
    case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Here, this means that port `80` of the host machine will be mapped to port `80`
    of the `docker` container. The same goes for port `3306`. We can get this information
    from the repository page of Docker.
  prefs: []
  type: TYPE_NORMAL
- en: At this step, we can start using the LAMP server that is working in this `docker`
    container.
  prefs: []
  type: TYPE_NORMAL
- en: 'When working on a `docker` container, you will have a prompt that looks like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'After you finish working, you need to save the changes on your image. To do
    this, you need to run the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'To list the images installed on your machine, you need to run the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'To list containers (the running images), you need to execute the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'To get the job ID of your container, execute the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'This job ID is useful when you need to stop a container by using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'When you would like to remove the job ID, use the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: One of the best advantages of Docker is the possibility of easily importing/exporting
    images.
  prefs: []
  type: TYPE_NORMAL
- en: 'To export a container in `tar.gz`, execute the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'To import a `tar.gz` file, execute the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Cloud computing for the Ubuntu Server
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Cloud computing is one of the latest trends and hottest subjects in the IT world,
    and the Ubuntu Server is one of the leading OSes in this field, especially with
    its infrastructure based on OpenStack deployed by big names such as NASA, NSA,
    HP, AT&T, Alcatel-Lucen, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: In the following section, we will explore two of the best open source Clouds
    that we can easily deploy on the Ubuntu Server—one for file sharing and the other
    for PaaS—as well as the best part concerning OpenStack deployment on Ubuntu.
  prefs: []
  type: TYPE_NORMAL
- en: The ownCloud software
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The **ownCloud** software allows you to create and use a storage server and
    share files online. In the next section, we will see the technologies used in
    ownCloud software.
  prefs: []
  type: TYPE_NORMAL
- en: The technology used in ownCloud
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The ownCloud software uses the WebDAV protocol to seamlessly access a server
    through a network drive on Linux, Windows, or Mac. There is also sync software
    for many platforms (Linux, Mac, Windows, Android, and so on) so that you can keep
    a local copy of your files and work offline. The ownCloud software not only provides
    a file sharing service, but also can be used to manage your calendar, contacts,
    bookmarks, and even music.
  prefs: []
  type: TYPE_NORMAL
- en: The project is developed in PHP. It is thus installed on many web servers. It
    doesn't require specific functionalities such as Java, or particular web server
    extensions.
  prefs: []
  type: TYPE_NORMAL
- en: In the following section, we will cover only the installation process of the
    ownCloud server. The installation and configuration of a client is beyond the
    scope of this book.
  prefs: []
  type: TYPE_NORMAL
- en: The ownCloud server installation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Since the release of version 5.0 of ownCloud, its installation is very simple.
    Packages for ownCloud are available for the supported versions of Ubuntu at [http://download.owncloud.org/download/repositories/stable/](http://download.owncloud.org/download/repositories/stable/).
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, to install ownCloud for Ubuntu 15.04, run the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'You can add the repository key to `apt`. Keep in mind that the owner of the
    key may distribute updates, packages, and repositories that your system will trust.
    To add the key, run the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Your server is now available at `http://<server_ip>/owncloud/`. You must create
    an account in the first connection. In case the server complains about unmet dependencies,
    restart the web server by using the `sudo service apache2 reload` command.
  prefs: []
  type: TYPE_NORMAL
- en: 'To enable secure connections to the Apache server (HTTPS), run the following
    commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Now, log in to the server via `https://<server_ip>/owncloud/`. From the **Administration**
    menu, which is available at `https://<server_ip>/owncloud/index.php/settings/admin`,
    check off the **Force HTTPS** checkbox.
  prefs: []
  type: TYPE_NORMAL
- en: CozyCloud
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: CozyCloud is a free personal Cloud server. It focuses on applications and collaboration
    applications related to personal data. CozyCloud is a personal **PaaS** (**Platform
    as a Service**) solution that allows you to deploy personal web applications in
    a click. You can select the existing Cozy applications (Notes, Todos, Calendar,
    Contacts, Photos, and so on), adapt an existing Node.js application, or start
    your own web application `from-scratch` (documentation and tutorials related to
    this are available on the Internet).
  prefs: []
  type: TYPE_NORMAL
- en: Installing CozyCloud on Ubuntu Server
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'First of all, start by installing Python and the `pip` tools on your machine
    by using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Once you have the `pip` tools installed on your machine, you have to install
    `fabric` and `fabtools` by using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, download the `fabric` file (a script that will run commands on your remote
    server), as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Once your system is prepared, use the `fabric` script from your local machine
    to launch the Cozy installation (run it in the same directory as that of `fabfile`
    that you downloaded before). This is done by using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Once you run the preceding command, you need to be patient for a few moments.
    As you may know, deployments of some commands or applications can take some time
    depending on your network and hardware capabilities. When prompted by the installer,
    you have to enter your settings.
  prefs: []
  type: TYPE_NORMAL
- en: After the installation is complete, you can access `https://<IP_address>:443`
    to create the principal Cozy account. The use of HTTPS is mandatory. In case you
    simply use HTTP, you will just see the `nginx` welcome page.
  prefs: []
  type: TYPE_NORMAL
- en: Using CozyCloud
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Once the installation is complete, you can access your platform using HTTPS,
    as explained before. Since this is your first login, you need to register your
    account (provide an e-mail and a password).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The password that you choose will also become the key that enables Cozy applications
    to encrypt certain information in the database.
  prefs: []
  type: TYPE_NORMAL
- en: You will then arrive at the Cozy home page that displays the installed applications.
    The operation is similar to that of a smartphone—you go to the marketplace (**tab
    +Apps**) and install the existing applications or the application that you built
    (if they are already on a GitHub repository).
  prefs: []
  type: TYPE_NORMAL
- en: An integral aspect of application development for CozyCloud that deserves a
    mention is that Cozy is a PaaS, which means that the development of an application
    does not depend on an SDK (as is the case with an Android or iPhone app). You
    can create a web application as you're used to and deploy it within Cozy or anywhere
    else!
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A good starting point in case you wish to document about Cozy is [https://github.com/cozy/cozy-setup/wiki](https://github.com/cozy/cozy-setup/wiki).
    This page contains resources related to development.
  prefs: []
  type: TYPE_NORMAL
- en: OpenStack
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: OpenStack is a free software that allows the construction of private and public
    Clouds. OpenStack is a community and a project in addition to the software that
    is designed to help organizations implement their own Clouds. OpenStack consists
    of a series of software and open source projects that are maintained by the community,
    which includes OpenStack Compute (named Nova), OpenStack Object Storage (named
    Swift), OpenStack Image Service (named Glance), and many more components that
    are increasing in number with every new release.
  prefs: []
  type: TYPE_NORMAL
- en: Users are mainly deploying it as an **IaaS** (**Infrastructure as a Service**).
    This technology consists of a set of interconnected projects that control pools
    of processing, storage, and networking resources over a datacenter, which is managed
    by users through multiple utilities such as a web-based dashboard, command-line
    tools, or even a RESTful API.
  prefs: []
  type: TYPE_NORMAL
- en: 'Canonical provide a fully integrated and optimized combination of the latest
    release of the Ubuntu Server and the latest release of OpenStack, allowing users
    to get the best user experience with Ubuntu OpenStack. According to the OpenStack
    User Survey that was conducted in November 2014:'
  prefs: []
  type: TYPE_NORMAL
- en: '*64% of production OpenStack clouds are run on Ubuntu.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Canonical provides a set of useful tools. When associated with OpenStack, they
    give it more dimensions. In this section, we will start by discovering these tools.
    Then, we will move on to see how to install OpenStack in an Ubuntu Server.
  prefs: []
  type: TYPE_NORMAL
- en: OpenStack tools
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As mentioned previously, Ubuntu is the most popular operating system for OpenStack
    in the world. Ubuntu offers a set of innovative tools and programs that help users
    build their enterprise-scale Cloud in the easiest and fastest way.
  prefs: []
  type: TYPE_NORMAL
- en: Juju
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Juju, which also means magic, is the service orchestration management tool that
    was mainly developed by Canonical for Cloud computing. Juju concentrates on services.
    It provides a new concept of software deployment in an easy and quick manner with
    possibilities of integration and scalability on a large number of Cloud infrastructures.
    One of the primary components of Juju is called Charms, which can be written in
    any programming language that can be executed from the command line.
  prefs: []
  type: TYPE_NORMAL
- en: MAAS
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The concept of **Metal as a Service** (**MAAS**) was created by Canonical to
    provide a system that can simplify the task of setting up a physical hardware
    on which you can deploy complex scalable services in the same manner as that of
    Ubuntu's OpenStack Cloud infrastructure does.
  prefs: []
  type: TYPE_NORMAL
- en: MAAS takes care of preparing the new node, installing the Ubuntu image, configuring
    it, and making it functional. Besides, it checks hardware-specific tasks, such
    as burn-in tests, firmware, and the RAID upgrade.
  prefs: []
  type: TYPE_NORMAL
- en: The MAAS and Juju combination will breathe new life into old hardware by recycling
    it for use in other parts of your infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: Landscape
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The official management tool for Cloud computing under the Ubuntu Server is
    Landscape. It is one of the most powerful tools of the Ubuntu OpenStack combination.
    It is a rich web-based GUI that allows users to easily build its Cloud in minutes,
    monitor it in real time, and manage it in the most efficient way.
  prefs: []
  type: TYPE_NORMAL
- en: LXD
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Also known as the Linux container hypervisor, LXD is the next-generation hypervisor
    provided by Canonical. It combines the density of containers with the manageability
    of virtual machines. LXD simplifies deployment and the running of VMs in a connected
    and secure environment with high-scalability possibilities and the ability of
    interoperability.
  prefs: []
  type: TYPE_NORMAL
- en: Snappy
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Snappy is a Cloud-based operating system provided by Canonical and based on
    the Ubuntu Server. It was developed to be used with **Internet of Things** (**IoT**)
    devices. The difference between the Snappy Ubuntu core and the standard Ubuntu
    system is that applications are provided through a simpler, faster mechanism and
    most importantly, it provides a stronger security guarantee for apps, making it
    ideal for Docker and other Cloud deployment frameworks.
  prefs: []
  type: TYPE_NORMAL
- en: The OpenStack setup
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Mastering OpenStack, from its setup, configuration, and administration, to troubleshooting
    and maintenance, are subjects that need to be explained in books with hundreds
    of pages. In this section, we don't have much space to elaborate on all of this.
    So, I will try to make you get a taste of it. We will discover the main lines
    steps of setting up an OpenStack Cloud on an Ubuntu Server in two ways—the manual
    installation and the DevStack-based installation.
  prefs: []
  type: TYPE_NORMAL
- en: Installing OpenStack using DevStack
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: DevStack is a script that can be used to quickly create an OpenStack development
    environment or demonstrate OpenStack services and provide examples of using them
    from a CLI. It changed from a simple demonstration tool to a useful, quick sanity
    check for the OpenStack installation.
  prefs: []
  type: TYPE_NORMAL
- en: The mission of DevStack is to provide and maintain tools used for the installation
    of the central OpenStack services from the source (the `git` repository master
    or specific branches) suitable for development and operational testing. It also
    demonstrates and documents examples of configuring and running services as well
    as using command-line clients.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the steps needed to install OpenStack using DevStack:'
  prefs: []
  type: TYPE_NORMAL
- en: Install the selected OS. In our case, it is Ubuntu Server 15.04.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Download DevStack by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `devstack` repository contains a script that installs OpenStack and templates
    for configuration files.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Configure your environment. You can refer to [http://docs.openstack.org/developer/devstack/configuration.html](http://docs.openstack.org/developer/devstack/configuration.html)
    for more details.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Start the installation by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: It takes a few minutes to run the preceding command. We recommend that you read
    the preceding script while it is being installed.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can find a lot of guides at [http://docs.openstack.org/developer/devstack/](http://docs.openstack.org/developer/devstack/).
  prefs: []
  type: TYPE_NORMAL
- en: The manual installation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The manual installation is actually the most suitable for you if you want to
    deploy a real Cloud and not just to test the power of OpenStack. We can install
    the Cloud on only one machine, but it is recommended by Canonical that you should
    use at least seven machines, each with two hard disks, and two of them must have
    two **network interfaces** (**NICs**).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you want to just set up OpenStack on a single Ubuntu Server based on the
    14.04 LTS or 15.04 releases, a good tutorial is available at [https://fosskb.wordpress.com/2015/04/18/installing-openstack-kilo-on-ubuntu-15-04-single-machine-setup/](https://fosskb.wordpress.com/2015/04/18/installing-openstack-kilo-on-ubuntu-15-04-single-machine-setup/).
  prefs: []
  type: TYPE_NORMAL
- en: 'However, in case you want to get a real Cloud according to the Canonical recommendations,
    the following is a summary of the steps that are required if you wish to get your
    own Cloud OpenStack running based on the Ubuntu servers:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First of all, you have to install the Ubuntu Server on one of the machines
    that have two network interfaces. Then, you need to set up a private network with
    all the machines plugged in, with the network divided into the following three
    logical ranges:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The dynamic range maps an IP address to every NIC connected to the network
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The static range maps an IP address to every machine connected to the network
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The floating IP range maps an IP address to every instance that you'll have
    in your Cloud
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Secondly, you need to add the needed repositories to your source list and update
    your package list by using the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, if you want to set up MAAS, you need to run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, perform the following step-by-step instructions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Access the MAAS UI at `http://<maas_ip_address>/MAAS/` and follow the instructions
    provided there to create a profile of an administrator. Then, log in with those
    credentials.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Import disk images for Ubuntu.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Add the SSH key to your user profile by visiting `http://<maas_ip_address>/MAAS/account/prefs/`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Copy the MAAS key (you will need this later).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Fill in the other details, such as the gateway and DNS, in the networks that
    were automatically created for each NIC.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Next, you need to configure the MAAS cluster, as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click on the **Clusters** tab and select **Cluster master**.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: You will see a list of network interfaces on the machine. Click on the edit
    symbol for the interface that is connected to the private network where all the
    nodes are visible.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Set this interface to manage DHCP and DNS.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Set the router IP to the default gateway for this private network.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Fill in the details for the dynamic and static ranges; remember that you should
    leave gaps for the floating IPs.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Save the changes.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, you need to enlist and commission the machines, as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Ensure that all the machines are set to the **Preboot Execution Environment**
    (**PXE**) boot. If possible, disable all the other boot options, including local
    disk in the BIOS.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Enlist the machines by powering them on. This can usually be done by some sort
    of a virtual console. They will all appear in the node list in MAAS, and they
    can be powered down again.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Edit each machine in the node's list and fill in the power type and power parameters
    (that is, the username and password) so that MAAS can turn them on and off as
    needed.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Select all the machines and, by using the **Bulk action** dropdown, commission
    them.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Wait until all the machines are commissioned (that is, in the `Ready` state).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'At this point, you need to set up `Landscape` and launch the OpenStack `Autopilot`
    by using the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Choose the **Landscape OpenStack Autopilot** option.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Fill in the MAAS credentials using the MAAS key that you saved when you set
    up MAAS.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the link to access the Landscape UI.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Resolve the remaining issues on the checklist. Finally, click on the **Configure**
    button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Go to the given URL to get to the landing page of the Landscape UI.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The landing page contains a checklist at the bottom that shows the status of
    all your resources. Verify that all of them are green to confirm the sanity status
    of your infrastructure.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on **Configure** and enter an optional name for your region and Cloud.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Select the following components (this is an initial list; more options will
    be added in the later versions as they pass the tests in the OpenStack Interoperability
    Lab):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The hypervisor component (KVM)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The networking component (Open vSwitch)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The storage components:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Object (Ceph, Swift)
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: Block (Ceph, iSCSI)
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: Select the hardware on which you need to deploy the Cloud and click on **Save
    selection**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on **Install** to build your Cloud.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, start using your Cloud!
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we focused on one of the most interesting features of the Ubuntu
    Server, namely virtualization and Cloud computing. At this point, you can define
    and easily use a good set of programs related to this subject on the Ubuntu server.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will discover some useful tips that an Ubuntu system
    administrator needs to make their life easier.
  prefs: []
  type: TYPE_NORMAL
