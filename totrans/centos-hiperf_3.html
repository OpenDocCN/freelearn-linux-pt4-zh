<html><head></head><body>
<div id="page" style="height:0pt"/><div class="book" title="Chapter&#xA0;3.&#xA0;A Closer Look at High Availability"><div class="book" id="LTSU2-1d2c6d19b9d242db82da724021b51ea0"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch03" class="calibre1"/>Chapter 3. A Closer Look at High Availability</h1></div></div></div><p class="calibre8">In this chapter, we will look at the components of a high-availability cluster in greater detail than we were able to do initially during <a class="calibre1" title="Chapter 1. Cluster Basics and Installation on CentOS 7" href="part0014_split_000.html#DB7S1-1d2c6d19b9d242db82da724021b51ea0">Chapter 1</a>, <span class="strong"><em class="calibre9">Cluster Basics and Installation on CentOS 7</em></span>; you may want to review that chapter in order to refresh your memory before proceeding further.</p><p class="calibre8">In this chapter, we will cover the following topics:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Failover—a premier on high availability and performance</li><li class="listitem">Fencing — isolating the malfunctioning nodes</li><li class="listitem">Split brain — preparing to avoid inconsistencies</li><li class="listitem">Quorum — scoring inside your cluster</li><li class="listitem">Configuring our cluster via PCS GUI</li></ul></div><p class="calibre8">We will set out on this chapter by asking ourselves a few questions about how to achieve high availability, and we will attempt to get our answers as we go along. In the next chapter, we will set up actual real-life examples:</p><div class="book"><ul class="itemizedlist"><li class="listitem">How can we ensure an automatic failover without the need for human intervention?</li><li class="listitem">How many nodes are needed in a cluster in order to ensure high availability in several failure scenarios?</li><li class="listitem">How do we consistently ensure data integrity and high availability when an offline node comes online again?</li></ul></div><p class="calibre8">Overall, clusters can be classified into two main categories. For simplicity, we will use a cluster consisting of two nodes for the following definitions, but the concept can be easily extended to a cluster with a higher number of members:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong class="calibre2">Active/Active (A/A)</strong></span>: In this type of cluster, all nodes are active at the same time. Thus, they<a id="id113" class="calibre1"/> are able to serve requests simultaneously and equally, each with independent workloads. When a failover is necessary, the remaining node is assigned an additional processing load, thus impacting the overall performance of the cluster negatively.</li><li class="listitem"><span class="strong"><strong class="calibre2">Active/Passive (A/P)</strong></span>: In this type of cluster, there is an active node and a passive <a id="id114" class="calibre1"/>node. The former handles all traffic under normal circumstances, while the latter just sits idle waiting to enter the scene during a failover, when it actually takes over the situation by servicing requests using its own resources until the other node comes back online.</li></ul></div><p class="calibre8">As you can infer from the last two paragraphs, an A/P cluster presents a clearly desired advantage over A/A, wherein, in the event of a failover, the same percentage of hardware and software resources is made available to end users. This results in a constant performance level in a transparent way, which is specially desired in database servers, where performance is a critical requirement. On the other hand, A/A clusters usually provide higher availability since at least two servers actively run applications and provide services to end users. In the next chapter, you will notice that we will initially set up an A/P cluster in detail and also provide the overall instructions to convert it into an A/A cluster if you wish to do so at a later stage.</p></div>

<div class="book" title="Chapter&#xA0;3.&#xA0;A Closer Look at High Availability">
<div class="book" title="Failover – an introduction to high availability and performance"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_1"><a id="ch03lvl1sec17" class="calibre1"/>Failover – an introduction to high availability and performance</h1></div></div></div><p class="calibre8">The failover<a id="id115" class="calibre1"/> process can be roughly described as the action of switching, in the event of power or network failure, to an available resource to resume operations with the least downtime as possible, with no downtime being the primary goal of high availability clusters.</p><p class="calibre8">In <a class="calibre1" title="Chapter 2. Installing Cluster Services and Configuring Network Components" href="part0018_split_000.html#H5A42-1d2c6d19b9d242db82da724021b51ea0">Chapter 2</a>, <span class="strong"><em class="calibre9">Installing Cluster Services and Configuring Network Components</em></span>, we configured a simple but essential resource for our purposes: a virtual IP address. You will also recall that in order to start becoming acquainted with PCS—the tool that is used as a frontend to PCS (the configuration manager)—we presented a brief introduction to its basic syntax and usage.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="tip03" class="calibre1"/>Tip</h3><p class="calibre8">As in other cases in the Linux ecosystem, the program/protocol/package name is written in caps, while the tool and utility is written in lowercase. Thus, PCS is used to indicate the package name, and it is the command-line utility that is used to manage PCS.</p></div><p class="calibre8">With the <code class="email">pcs status</code> command, we will be able to view the current status of the cluster and several important<a id="id116" class="calibre1"/> pieces of information, as shown in the following screenshot:</p><div class="mediaobject"><img src="../images/00024.jpeg" alt="Failover – an introduction to high availability and performance" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">The following lines present the cluster resources that are currently available for <code class="email">MyCluster</code>:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">Full list of resources:</strong></span>
<span class="strong"><strong class="calibre2">virtual_ip    (ocf::heartbeat:IPaddr2):    Started node01</strong></span></pre></div><p class="calibre8">As indicated, the virtual IP address (conveniently named <code class="email">virtual_ip</code> in <a class="calibre1" title="Chapter 2. Installing Cluster Services and Configuring Network Components" href="part0018_split_000.html#H5A42-1d2c6d19b9d242db82da724021b51ea0">Chapter 2</a>, <span class="strong"><em class="calibre9">Installing Cluster Services and Configuring Network Components</em></span>) is started on <code class="email">node01</code>. Since the virtual IP is a cluster resource, it is to be expected that in case the node fails, an automatic failover of this resource is triggered to <code class="email">node02</code>. We will simulate a node going<a id="id117" class="calibre1"/> offline due to a real issue by stopping both <code class="email">corosync</code> and <code class="email">pacemaker</code> on that cluster member.</p><p class="calibre8">For our current purposes, this simulation will not entitle shutting down (power off) the node because we want to show something interesting in the output of <code class="email">pcs status</code> after stopping <code class="email">corosync</code> and <code class="email">pacemaker</code> in that node.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="tip04" class="calibre1"/>Tip</h3><p class="calibre8">You can also simulate a failover by pausing one of the virtual machines in VirtualBox (select the <span class="strong"><strong class="calibre2">VM</strong></span> option in <span class="strong"><strong class="calibre2">Oracle VM VirtualBox Manager</strong></span> and press <span class="strong"><em class="calibre9">Ctrl</em></span> + <span class="strong"><em class="calibre9">P</em></span> or choose <span class="strong"><strong class="calibre2">Pause</strong></span> from the <span class="strong"><strong class="calibre2">Machine Menu</strong></span>), and you can also do it by disabling the networking using the <code class="email">systemctl disable network</code> command in that node.</p></div><p class="calibre8">Let's stop <code class="email">pacemaker</code> and <code class="email">corosync</code> in <code class="email">node01</code>:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">pcs cluster stop node01</strong></span></pre></div><p class="calibre8">And run again, but on the other node, that is <code class="email">node02</code>, using the following command:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">pcs status</strong></span></pre></div><p class="calibre8">To view the current status of the cluster, its nodes, and resources, which is shown in the following screenshot, you will need to run <code class="email">pcs status</code> on the node where the cluster is currently running:</p><div class="mediaobject"><img src="../images/00025.jpeg" alt="Failover – an introduction to high availability and performance" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">There are a few lines from the preceding screenshot that are worth discussing.</p><p class="calibre8">The <span class="strong"><strong class="calibre2">OFFLINE: [ node01 ]</strong></span> line indicates that <code class="email">node01</code> is offline—as far as the cluster as a whole is <a id="id118" class="calibre1"/>concerned—which is what we were expecting after stopping the cluster resource manager and the messaging services in that member. However, the following code indicates that the <code class="email">pcsd</code> daemon, the remote configuration interface, is still running on <code class="email">node01</code>, which makes it possible to still control <code class="email">pacemaker</code> and <code class="email">corosync</code> in that node, either locally or remotely from another node:</p><div class="informalexample"><pre class="programlisting">PCSD Status:
 node01: Online</pre></div><p class="calibre8">Finally, the <code class="email">virtual_ip    (ocf::heartbeat:IPaddr2):    Started node02</code> command allows us to see that the failover of the virtual IP from <code class="email">node01</code> to <code class="email">node02</code> was performed automatically and without errors. If, for some reason, you run into errors while performing the virtual IP address failover, you will want to check the related logs for information as to what could have gone wrong.</p><p class="calibre8">For example, let's examine a case where the cluster resource does not have another node to failover to. Picture a scenario where <code class="email">node02</code> is offline (either because you paused the <span class="strong"><strong class="calibre2">VM</strong></span> or actually shut it down), and all of a sudden, <code class="email">node01</code> goes down as well (remember that we are talking about the clustering services not being available instead of an actual power or network outage). Of course, all of this happens behind the scenes—the only thing that you know right now is that you have users complaining that they cannot access whatever application, resource, or service is being offered from your cluster.</p><p class="calibre8">The first <a id="id119" class="calibre1"/>thing you may feel inclined to try is to see whether the virtual IP address is pingable from within your network (change the IP address as per your choice while configuring the resource at the end of <a class="calibre1" title="Chapter 2. Installing Cluster Services and Configuring Network Components" href="part0018_split_000.html#H5A42-1d2c6d19b9d242db82da724021b51ea0">Chapter 2</a>, <span class="strong"><em class="calibre9">Installing Cluster Services and Configuring Network Components</em></span>):</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">ping -c 4 192.168.0.4</strong></span></pre></div><p class="calibre8">You will notice that none of the four packets was able to reach its intended destination:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">PING 192.168.0.4 (192.168.0.4) 56(84) bytes of data.</strong></span>
<span class="strong"><strong class="calibre2">From 192.168.0.2 icmp_seq=1 Destination Host Unreachable</strong></span>
<span class="strong"><strong class="calibre2">From 192.168.0.2 icmp_seq=2 Destination Host Unreachable</strong></span>
<span class="strong"><strong class="calibre2">From 192.168.0.2 icmp_seq=3 Destination Host Unreachable</strong></span>
<span class="strong"><strong class="calibre2">From 192.168.0.2 icmp_seq=4 Destination Host Unreachable</strong></span>
<span class="strong"><strong class="calibre2">--- 192.168.0.4 ping statistics ---</strong></span>
<span class="strong"><strong class="calibre2">4 packets transmitted, 0 received, +4 errors, 100% packet loss, time 3000ms</strong></span></pre></div><p class="calibre8">For that reason, go to <code class="email">node01</code>, where you first started the resource to check on the node's status:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">Error: cluster is not currently running on this node</strong></span></pre></div><p class="calibre8">Then you see that the cluster is down on <code class="email">node01</code>. But wasn't the failover supposed to happen automatically? At this point, you have two options:</p><div class="book"><ul class="itemizedlist"><li class="listitem">Go to <code class="email">node02</code> to check whether the cluster is running there.</li><li class="listitem">Check the logs on <code class="email">node01</code>. Note that this assumes that you shut down <code class="email">node02</code> and then <code class="email">node01</code>. In any event, you want to check the log in the node that you shut down last.</li></ul></div><p class="calibre8">A brief search for the keyword <code class="email">virtual_ip</code> in <code class="email">/var/log/pacemaker.log</code> (or whatever name you set for the resource during the last stages of <a class="calibre1" title="Chapter 2. Installing Cluster Services and Configuring Network Components" href="part0018_split_000.html#H5A42-1d2c6d19b9d242db82da724021b51ea0">Chapter 2</a>, <span class="strong"><em class="calibre9">Installing Cluster Services and Configuring Network Components</em></span>) in <code class="email">node01</code> tells you what the problem is. Here is a brief excerpt of the <code class="email">grep virtual_ip /var/log/pacemaker.log</code> file:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">Mar 21 07:52:45 [3839] node01    pengine:     info: native_print:     virtual_ip    (ocf::heartbeat:IPaddr2):    Stopped</strong></span>
<span class="strong"><strong class="calibre2">Mar 21 07:52:45 [3839] node01    pengine:     info: native_color:     Resource virtual_ip cannot run anywhere</strong></span>
<span class="strong"><strong class="calibre2">Mar 21 07:52:45 [3839] node01    pengine:     info: LogActions:     Leave   virtual_ip    (Stopped)</strong></span></pre></div><p class="calibre8">The first message indicates that <code class="email">virtual_ip</code> was stopped on <code class="email">node01</code>, and the second message states that it could not be failed over anywhere. The result is that the resource is left as <code class="email">Stopped</code> (as outlined in the third message) until it is manually re-enabled from either node in the cluster. However, remember that you need to start the cluster on such a node beforehand:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">pcs cluster start node01</strong></span></pre></div><p class="calibre8">Then, run <a id="id120" class="calibre1"/>the following command on <code class="email">node01</code>:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">pcs resource enable virtual_ip</strong></span></pre></div><p class="calibre8">A further check on <code class="email">pcs status</code> may or may not indicate that the resource is still stopped (it is a good idea to ping the virtual IP address here as well). If <code class="email">virtual_ip</code> refuses to start, we can use the following command to obtain verbose information about why this particular resource is not being started properly, and then perform a reset of the cluster resource to make it reload its proper configuration:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">pcs resource debug-start virtual_ip --full</strong></span></pre></div><p class="calibre8">Remember that <code class="email">pcs</code> takes an option (not required) and a command as arguments, which may in turn be followed by specific options. In this regard, <code class="email">pcs cluster stop</code>, where <code class="email">cluster</code> is the command and <code class="email">stop</code> represents a specific action of such a command, can be used to shut down <code class="email">corosync</code> and <code class="email">pacemaker</code> on either the local node, all nodes, or a specific node. In the following extract of <code class="email">man pcs</code> you can review the syntax of pcs cluster stop:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">stop [--all] [node] [...]</strong></span>
<span class="strong"><strong class="calibre2">Stop  corosync  and  pacemaker  on  specified node(s), if a node is not specified then corosync and pacemaker are stopped on the local node. If --all is specified then corosync and pacemaker are stopped on all nodes.</strong></span></pre></div><div class="informalexample" title="Note"><h3 class="title2"><a id="note13" class="calibre1"/>Note</h3><p class="calibre8">Remember that when <code class="email">corosync</code> and <code class="email">pacemaker</code> are running on both nodes, you can run any PCS command to configure the cluster from any of the nodes. In the event of a severe failure, where <code class="email">pcsd</code> becomes unavailable on both nodes, you will have to resort to using SSH authentication from one node to the other to troubleshoot and fix issues.</p><p class="calibre8">As it happens in other cases, log files are the best friends of system administrators, and they can play a key role in helping you to find out what the root causes of issues are when they happen. There are three logs that you may want to check once in a while and even as you are performing a failover:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><code class="email">/var/log/pacemaker.log</code></li><li class="listitem"><code class="email">/var/log/cluster/corosync.log</code></li><li class="listitem"><code class="email">/var/log/pcsd/pcsd.log</code></li></ul></div></div><div class="informalexample" title="Note"><h3 class="title2"><a id="note14" class="calibre1"/>Note</h3><p class="calibre8">In addition, you can also search in the systemd log with <code class="email">journalctl -xn</code> and use <code class="email">grep</code> to filter a specific word or phrase.</p></div><div class="informalexample" title="Note"><h3 class="title2"><a id="tip05" class="calibre1"/>Tip</h3><p class="calibre8">You <a id="id121" class="calibre1"/>can reset the status of a cluster resource with the <code class="email">pcs resource disable &lt;resource_name&gt;</code> and <code class="email">pcs resource enable &lt;resource_name&gt;</code> commands.</p></div></div></div>
<div class="book" title="Fencing &#x2013; isolating the malfunctioning nodes" id="MSDG1-1d2c6d19b9d242db82da724021b51ea0"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch03lvl1sec18" class="calibre1"/>Fencing – isolating the malfunctioning nodes</h1></div></div></div><p class="calibre8">As the number of nodes in a cluster increases, its availability increases, but so does the chance of one of them failing at some point. This failure event, whether serious or not, suggests that <a id="id122" class="calibre1"/>we must secure a way to isolate the malfunctioning node from the cluster in order for it to fully release its processing tasks to the rest of the cluster. Think of what an erratic node can cause in a shared storage cluster—data corruption would inevitably occur. The word malfunctioning, in this context, means not only what it suggests in the typical usage of the English language (something that is not working properly), but also a node, which also includes the resources started on it, whose state cannot be determined by the cluster for whatever reason.</p><p class="calibre8">This is where the term fencing comes into play. By definition, cluster fencing is the process of isolating, or separating, a node from using its resources or starting services, which it should not have access to, and from the rest of the nodes as well. One of the ABC rules of computer clustering can thus be formulated as, do not let a malfunctioning node run any cluster resources - fence it in all cases. In line with the last statement, an unresponsive node must be taken offline before another node will take over.</p><p class="calibre8">Fencing is <a id="id123" class="calibre1"/>performed using a mechanism known as STONITH, which we briefly introduced during the last chapter (in few words, STONITH is a fencing method that is used to isolate a failed node in order to prevent it from causing problems in a cluster). You will recall that we disabled this feature at that point and mentioned that we would revisit the topic here. A quick inspection of the cluster's configuration, as shown in the following screenshot, will confirm that that STONITH is currently disabled:</p><div class="mediaobject"><img src="../images/00026.jpeg" alt="Fencing – isolating the malfunctioning nodes" class="calibre10"/></div><p class="calibre11"> </p><div class="informalexample" title="Note"><h3 class="title2"><a id="tip06" class="calibre1"/>Tip</h3><p class="calibre8">If you run the <code class="email">pcs config</code> code, you will be able to view the current configuration for the cluster in detail, which is illustrated in the preceding screenshot.</p><p class="calibre8">At the very end, the <code class="email">stonith-enabled: false</code> line clearly reminds us that STONITH is disabled in our cluster.</p><p class="calibre8">You will want to add <code class="email">pcs config</code> to the list of essential commands that you must keep in mind as we move forward with the cluster configuration. It will allow you to inspect, at a quick glance, the settings and resources made available through the cluster.</p></div><p class="calibre8">So, let's<a id="id124" class="calibre1"/> begin by re-enabling STONITH:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">pcs property set stonith-enabled=true</strong></span></pre></div><p class="calibre8">Next, check on the configuration again, either with the <code class="email">pcs config</code> or <code class="email">pcs property list</code> command. For brevity, in the case illustrated in the following screenshot, we use the <code class="email">pcs property list</code> command in order to introduce you to yet another useful PCS command. Note how we check on this property before and after re-enabling STONITH:</p><div class="mediaobject"><img src="../images/00027.jpeg" alt="Fencing – isolating the malfunctioning nodes" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">Once we have <a id="id125" class="calibre1"/>enabled STONITH in our cluster, it is time to finally set up fencing in our cluster by configuring a STONITH resource (also known as a STONITH device).</p></div>
<div class="book" title="Installing and configuring a STONITH device"><div class="book" id="NQU22-1d2c6d19b9d242db82da724021b51ea0"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch03lvl1sec19" class="calibre1"/>Installing and configuring a STONITH device</h1></div></div></div><p class="calibre8">It is worth <a id="id126" class="calibre1"/>noting that a STONITH device is a cluster resource<a id="id127" class="calibre1"/> that will be used to bring down a malfunctioning or unresponsive node. Installing the following packages on both nodes will make several STONITH devices available in our cluster. If you are setting up your 2-node cluster with two virtual machines, as suggested early in <a class="calibre1" title="Chapter 1. Cluster Basics and Installation on CentOS 7" href="part0014_split_000.html#DB7S1-1d2c6d19b9d242db82da724021b51ea0">Chapter 1</a>, <span class="strong"><em class="calibre9">Cluster Basics and Installation on CentOS 7</em></span>, install the following packages on both nodes:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">yum update &amp;&amp; yum install fence-agents-all fence-virt</strong></span></pre></div><p class="calibre8">Once the installation is complete, you can list all the available agents with the <code class="email">pcs stonith list</code> command, as shown in the next screenshot.</p><p class="calibre8">Each of the listed devices in the following screenshot are described by several available parameters, which can be shown with <code class="email">pcs stonith describe agent</code>, where you must replace <code class="email">agent</code> with the corresponding name of the resource. Note that we will use these parameters when we actually configure the STONITH device in a later step. The required parameters<a id="id128" class="calibre1"/> are indicated by the word (<code class="email">required</code>) at the beginning <a id="id129" class="calibre1"/>of the description, use the <code class="email">pcs stonith describe fence_ilo</code> command, which returns the following output:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">Stonith options for: fence_ilo</strong></span>
<span class="strong"><strong class="calibre2"> ipaddr (required): IP Address or Hostname</strong></span>
<span class="strong"><strong class="calibre2"> login (required): Login Name</strong></span>
<span class="strong"><strong class="calibre2"> passwd: Login password or passphrase</strong></span>
<span class="strong"><strong class="calibre2"> ssl: SSL connection</strong></span>
<span class="strong"><strong class="calibre2"> notls: Disable TLS negotiation</strong></span>
<span class="strong"><strong class="calibre2"> ribcl: Force ribcl version to use</strong></span>
<span class="strong"><strong class="calibre2"> ipport: TCP/UDP port to use for connection with device</strong></span>
<span class="strong"><strong class="calibre2"> inet4_only: Forces agent to use IPv4 addresses only</strong></span>
<span class="strong"><strong class="calibre2"> inet6_only: Forces agent to use IPv6 addresses only</strong></span>
<span class="strong"><strong class="calibre2"> passwd_script: Script to retrieve password</strong></span>
<span class="strong"><strong class="calibre2"> ssl_secure: SSL connection with verifying fence device's' certificate</strong></span>
<span class="strong"><strong class="calibre2"> ssl_insecure: SSL connection without verifying fence device's' certificate</strong></span>
<span class="strong"><strong class="calibre2"> action (required): Fencing Action</strong></span>
<span class="strong"><strong class="calibre2"> verbose: Verbose mode</strong></span>
<span class="strong"><strong class="calibre2"> debug: Write debug information to given file</strong></span>
<span class="strong"><strong class="calibre2"> version: Display version information and exit</strong></span>
<span class="strong"><strong class="calibre2"> help: Display help and exit</strong></span>
<span class="strong"><strong class="calibre2"> power_timeout: Test X seconds for status change after ON/OFF</strong></span>
<span class="strong"><strong class="calibre2"> shell_timeout: Wait X seconds for cmd prompt after issuing command</strong></span>
<span class="strong"><strong class="calibre2"> login_timeout: Wait X seconds for cmd prompt after login</strong></span>
<span class="strong"><strong class="calibre2"> power_wait: Wait X seconds after issuing ON/OFF</strong></span>
<span class="strong"><strong class="calibre2"> delay: Wait X seconds before fencing is started</strong></span>
<span class="strong"><strong class="calibre2"> retry_on: Count of attempts to retry power on</strong></span>
<span class="strong"><strong class="calibre2"> stonith-timeout: How long to wait for the STONITH action to complete per a stonith device.</strong></span>
<span class="strong"><strong class="calibre2"> priority: The priority of the stonith resource. Devices are tried in order of highest priority to lowest.</strong></span>
<span class="strong"><strong class="calibre2"> pcmk_host_map: A mapping of host names to ports numbers for devices that do not support host names.</strong></span>
<span class="strong"><strong class="calibre2"> pcmk_host_list: A list of machines controlled by this device (Optional unless pcmk_host_check=static-list).</strong></span>
<span class="strong"><strong class="calibre2"> pcmk_host_check: How to determine which machines are controlled by the device.</strong></span></pre></div><div class="mediaobject"><img src="../images/00028.jpeg" alt="Installing and configuring a STONITH device" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">Among these<a id="id130" class="calibre1"/> parameters, you can see that there is an action (<code class="email">action</code>) that<a id="id131" class="calibre1"/> should take place when a fencing event is going to happen, a host list that will be controlled by this device (<code class="email">pcmk_host_list</code>), and a waiting time (<code class="email">timeout</code> or <code class="email">stonith-timeout</code>), that is, the time taken to wait for a fencing action to complete. These are essential pieces of information that you will need to take into account while specifying the STONITH options during the creation of the device and setting up your infrastructure.</p><p class="calibre8">The next step, which consists of creating the device itself, will largely depend on the hardware <a id="id132" class="calibre1"/>device that you have available. For example, if you<a id="id133" class="calibre1"/> want to fence a Hewlett-Packard node (such as a Proliant server) with a built-in iLO interface, you would use the <code class="email">fence_ilo</code> agent, or if your nodes are sitting on top of VMWare virtualization, you may need to<a id="id134" class="calibre1"/> choose <code class="email">fence_vmware_soap</code>. Another popular option is Dell with <span class="strong"><strong class="calibre2">Dell Remote Access Controller</strong></span> (<span class="strong"><strong class="calibre2">DRAC</strong></span>), for which you would use <code class="email">fence_drac5</code>. Unfortunately, as of today, there is no out-of-the-box fencing device available for VirtualBox.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="tip07" class="calibre1"/>Tip</h3><p class="calibre8">An <span class="strong"><strong class="calibre2">iLO</strong></span> (<span class="strong"><strong class="calibre2">Integrated Lights Out</strong></span>) card is a separate interface with a separate network<a id="id135" class="calibre1"/> connection and IP address that allows a system administrator to perform certain operations on HP servers remotely via HTTPS. Similar functionality is available in Dell servers with built-in DRACs.</p></div><p class="calibre8">Let's now create a STONITH <code class="email">fence_ilo</code> device named <code class="email">Stonith_1</code>, which can fence <code class="email">node01</code> (although we are showing this example using <code class="email">node01</code>, note that this has to be done on a per-node basis):</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">pcs stonith create Stonith_1 fence_ilo pcmk_host_list="""node01" action=reboot --force</strong></span></pre></div><p class="calibre8">The basic syntax to create a fencing device is as follows:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">pcs stonith create stonith_device_name stonith_device_type stonith_device_options</strong></span></pre></div><p class="calibre8">You can view an explained list of <code class="email">stonith_device_options</code> with man <code class="email">stonithd</code>.</p><p class="calibre8">To update the device, use the following command:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">pcs stonith update stonith_device_name stonith_device_options</strong></span></pre></div><p class="calibre8">To delete the device, use the following command:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">pcs stonith delete stonith_device_name</strong></span></pre></div><p class="calibre8">Finally, The <code class="email">pcs stonith show [stonith_device_name] --full</code> command will display all the options used for <code class="email">[stonith_device_name]</code> or all fencing devices if <code class="email">[stonith_device_name]</code> is not specified.</p><p class="calibre8">You can then simulate a fencing situation (note that this is done automatically behind the scenes under a real-life event) by killing the <code class="email">pacemaker</code> and <code class="email">corosync</code> processes with the following commands:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">pcs cluster stop node01 # Clean stop of the cluster on node_name</strong></span>
<span class="strong"><strong class="calibre2">pcs stonith fence node01 --off</strong></span></pre></div><p class="calibre8">Also, confirm<a id="id136" class="calibre1"/> that <code class="email">node_name</code> is actually offline using<a id="id137" class="calibre1"/> the <code class="email">pcs stonith confirm node01</code> command.</p></div>
<div class="book" title="Split-brain &#x2013; preparing to avoid inconsistencies" id="OPEK1-1d2c6d19b9d242db82da724021b51ea0"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch03lvl1sec20" class="calibre1"/>Split-brain – preparing to avoid inconsistencies</h1></div></div></div><p class="calibre8">Up to this point, we have considered a few essential concepts in clustering, leading to the following <a id="id138" class="calibre1"/>not completely fictitious scenario—what happens if a cluster is formed by nodes that are located in separate networks and the communication link between them goes down? The same applies when the nodes are in the same network and the link goes down as well. That is, none of the nodes have actually gone offline, but each appears to the other as unavailable. The default behavior would be that each node assumes that the other is down and continues serving whatever resources or applications the cluster was previously running.</p><p class="calibre8">So far, so good! Now, let's say the network link comes back online but both nodes still think they are the main cluster member. That is where data corruption—at the worst—or inconsistency—at the best—occur. This is caused by possible changes made to data on either side without having been replicated to the other end.</p><p class="calibre8">This is why configuring fencing is so important, as is ensuring redundant communication links between <a id="id139" class="calibre1"/>cluster members so that such a <span class="strong"><strong class="calibre2">Single Point Of Failure</strong></span> (<span class="strong"><strong class="calibre2">SPOF</strong></span>) does not end up causing the split-brain situation in our cluster.</p><p class="calibre8">As far as the fencing is concerned, only the node that is marked as <span class="strong"><strong class="calibre2">Designated Controller</strong></span> (<span class="strong"><strong class="calibre2">DC</strong></span>) and <a id="id140" class="calibre1"/>also has quorum can fence the other nodes and run the applications and resources as master, or active, in our A/P cluster. By doing so, we ensure that the other node will not be allowed to take over resources that may lead to the data inconsistencies described earlier.</p></div>
<div class="book" title="Quorum &#x2013; scoring inside your cluster" id="PNV61-1d2c6d19b9d242db82da724021b51ea0"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch03lvl1sec21" class="calibre1"/>Quorum – scoring inside your cluster</h1></div></div></div><p class="calibre8">In simple terms, the concept of quorum indicates the minimum number of members that are required to be <a id="id141" class="calibre1"/>active in order for the cluster, as a whole, to be available. Specifically, a cluster is said to have quorum when the number of active nodes is greater than the total number of nodes divided by two. Another way to express this is that quorum is achieved by at least a simple majority (50% of the total number of nodes + 1).</p><p class="calibre8">Although the concept of quorum doesn't prevent a split-brain scenario, it will decide which node (or group of nodes) is dominant and allowed to run the cluster so that when a split-brain situation occurs, only one node (or group of nodes) will be able to run the cluster services.</p><p class="calibre8">By default, when the cluster does not have quorum, <code class="email">pacemaker</code> will stop all resources altogether so that they will not be started on more nodes than desired. However, a cluster member will still listen for other nodes to reappear on the network, but they will not work as a cluster until the quorum exists again.</p><p class="calibre8">You can easily<a id="id142" class="calibre1"/> confirm this behavior by stopping the cluster on <code class="email">node01</code> and <code class="email">node02</code> and then restarting it again. You will notice that <code class="email">virtual_ip</code> remains stopped:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">Full list of resources:</strong></span>
<span class="strong"><strong class="calibre2">virtual_ip    (ocf::heartbeat:IPaddr2):    Stopped</strong></span></pre></div><p class="calibre8">Until you enable it manually using the following command:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">pcs resource enable virtual_ip</strong></span></pre></div><p class="calibre8">For a 2-node cluster, as it is in our case, when we used the <code class="email">pcs cluster</code> setup in <a class="calibre1" title="Chapter 2. Installing Cluster Services and Configuring Network Components" href="part0018_split_000.html#H5A42-1d2c6d19b9d242db82da724021b51ea0">Chapter 2</a>, <span class="strong"><em class="calibre9">Installing Cluster Services and Configuring Network Components</em></span>, the following section was added in <code class="email">/etc/corosync/corosync.conf</code> for us:</p><div class="informalexample"><pre class="programlisting">quorum {
provider: corosync_votequorum
two_node: 1
}</pre></div><p class="calibre8">The <code class="email">two_node: 1</code> line tells <code class="email">corosync</code> that in a 2-node cluster, one member is enough to hold up the quorum. Thus, even when some people would argue that a 2-node cluster is pointless, our cluster will continue working when at least one of the nodes is online. Perhaps you already noticed while stopping and starting the cluster in one node previously, but it is worth pointing out that when trying to stop one of the members in our 2-node clusters, you will be asked to use the <code class="email">--force</code> option:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">pcs cluster stop node01 --force</strong></span></pre></div><p class="calibre8">To display the current list of nodes in the cluster and its individual contributions toward cluster quorum (which is shown in the following figure under <span class="strong"><strong class="calibre2">Votes</strong></span> column), run the <code class="email">corosync-quorumtool -l</code> command:</p><div class="mediaobject"><img src="../images/00029.jpeg" alt="Quorum – scoring inside your cluster" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">In a prospective split-brain situation, as described earlier, and supposing that the cluster is divided into<a id="id143" class="calibre1"/> two partitions, the partition with a majority of votes remains available, while the other is fenced automatically by the DC if STONITH has been put in place and properly configured. For example, in a 4-node cluster, quorum is established when at least three cluster nodes are functioning. Otherwise, the cluster no longer has quorum and <code class="email">pacemaker</code> will stop the services run by the cluster.</p></div>
<div class="book" title="Configuring our cluster with PCS GUI" id="QMFO1-1d2c6d19b9d242db82da724021b51ea0"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch03lvl1sec22" class="calibre1"/>Configuring our cluster with PCS GUI</h1></div></div></div><p class="calibre8">If you followed<a id="id144" class="calibre1"/> the steps outlined in <a class="calibre1" title="Chapter 2. Installing Cluster Services and Configuring Network Components" href="part0018_split_000.html#H5A42-1d2c6d19b9d242db82da724021b51ea0">Chapter 2</a>, <span class="strong"><em class="calibre9">Installing Cluster Services and Configuring Network Components</em></span>, to enable the Hacluster<a id="id145" class="calibre1"/> account for cluster administration, we can also use the PCS GUI, a cluster management web interface, to manage clusters. This includes the ability to add, remove, and edit existing clusters.</p><p class="calibre8">To navigate to the PCS web interface, go to <code class="email">https://&lt;ip_of_one_node&gt;:2224</code> (note that it's <code class="email">https</code> and not <code class="email">http</code>), accept the security exceptions, and then log in using the credentials that were previously set for Hacluster, as shown in the following screenshot:</p><div class="mediaobject"><img src="../images/00030.jpeg" alt="Configuring our cluster with PCS GUI" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">The next screen that you will see (which is as shown in the following screenshot) will present the <a id="id146" class="calibre1"/>menus to remove an existing cluster, add<a id="id147" class="calibre1"/> an existing cluster, or create a new one. When you click on the <span class="strong"><strong class="calibre2">Add Existing</strong></span> button, you will be prompted to enter the hostname or IP address of a node that currently belongs to an existing cluster that you want to manage using the web UI:</p><div class="mediaobject"><img src="../images/00031.jpeg" alt="Configuring our cluster with PCS GUI" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">Then, click on the cluster name and feel free to browse through the menu at the top of the following figure, which also serves the purpose of letting us add, remove, or edit the resources that we have been hitherto talking about:</p><div class="mediaobject"><img src="../images/00032.jpeg" alt="Configuring our cluster with PCS GUI" class="calibre10"/></div><p class="calibre11"> </p></div>
<div class="book" title="Summary" id="RL0A1-1d2c6d19b9d242db82da724021b51ea0"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch03lvl1sec23" class="calibre1"/>Summary</h1></div></div></div><p class="calibre8">In this chapter, we explored situations of node failures and essential techniques for malfunctioning cluster members, along with some essential cluster concepts in greater depth. In addition to this, we saw how to add cluster resources in order to further configure our newly created cluster into a real-world usage case, which we will deal with during the next chapter.</p><p class="calibre8">It is also worth reiterating that there are certain hardware components that we have not been able to discuss in detail, such as fencing devices, and you should take note of the fencing agents and devices (as per <code class="email">pcs stonith list</code>) and see if any of them applies to the available hardware in your case.</p><p class="calibre8">Last but not least, you need to remember that in order to avoid split-brain situations, besides applying thoroughly the concepts outlined in the present chapter, you also need to ensure redundant communication links between the networks where the nodes are located. This will help you prevent a <span class="strong"><strong class="calibre2">Single Point Of Failure</strong></span> (<span class="strong"><strong class="calibre2">SPOF</strong></span>) to potentially cause such an unwanted event.</p></div></body></html>