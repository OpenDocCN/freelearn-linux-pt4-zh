- en: Chapter 7. NSX Cross vCenter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will have a detailed discussion of the NSX cross vCenter
    feature. Starting from NSX 6.2, we can manage multiple vCenter Servers from a
    single pane of glass by leveraging NSX features across vCenter environments. We
    will primarily cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding NSX cross vCenter Server
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Components of NSX cross vCenter Server
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cross vCenter universal logical switches
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cross vCenter universal logical router
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Network choke points in NSX cross vCenter Server
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding NSX cross vCenter Server
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Earlier versions of NSX had a **1:1** relationship with vCenter Server and
    that means NSX features and functionalities were limited to that specific vCenter
    Server. So whenever we are scaling vCenter Servers, it demands separate installation
    and configuration of NSX Manager and each of these environments has to be managed
    separately. When VMware released NSX 6.2 in August 2015, security and cross vCenter
    Server networking were exciting features that were announced. With cross vCenter
    networking and security features, we can extend logical switches across vCenter
    boundaries and, adding to that, we can extend distributed routing and distributed
    firewalling seamlessly across VCs to provide a true network hybridity between
    both the sites. There are numerous use cases customers can benefit from with this
    cross VC NSX integration. The following are a few of them:'
  prefs: []
  type: TYPE_NORMAL
- en: By leveraging cross vCenter Server, we can have a primary and secondary vSphere
    environment and can easily configure disaster recovery sites.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Seamless migration of workloads from one vSphere environment to another.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simplified data center routing across vCenter Server sites; centralized security
    policy management; firewall rules can be managed from one centralized location.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NSX features and functionalities can be locally deployed (single vCenter Server);
    also we can deploy it across vCenter Server (cross vCenter Server). That way,
    local objects can be managed locally and global objects can be managed globally.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following figure depicts a cross vCenter Server NSX environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Understanding NSX cross vCenter Server](img/B03244_07_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'I know we are all excited to know how NSX cross VC works. But let''s be very
    clear with prerequirements and a few points before discussing this feature:'
  prefs: []
  type: TYPE_NORMAL
- en: The VSphere environment should be version 6.0.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each vCenter Server should be registered with a unique NSX Manager. Okay! That
    is an interesting point, isn't it? When I first heard about cross VC NSX architecture,
    I thought all we needed would be one NSX Manager moving forward. But further reading
    and lab sessions proved my understanding was wrong.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We have to promote one NSX Manager as **primary** and the others will be **secondary**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can certainly demote NSX roles based on business requirements. For example,
    a secondary NSX Manager can be demoted to a standalone NSX Manager and that way,
    we are going back to where NSX was initially when it started (pre 6.2 NSX version).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Even though cross VC NSX is a great architecture, I would still call it a new
    kid in town and it lacks all the features that were possible in a standalone NSX
    Manager instance. Keeping that negativity aside, I strongly believe newer versions
    of NSX will start supporting all the features across vCenter Servers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Carefully plan and integrate cross VC NSX environments; to be precise, watch
    out for what features we need in the primary and secondary sites and how we need
    to manage those features. For example, if we need just a Distributed Firewall
    feature in the secondary site, I wouldn't recommend cross VC NSX integration unless
    we want to manage these firewall policies from a single pane of glass.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Components of NSX cross vCenter Server
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Cross vCenter NSX includes the following components:'
  prefs: []
  type: TYPE_NORMAL
- en: Universal controller cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Universal transport zone
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Universal logical switch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Universal distributed logical router
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Universal IP set
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Universal MAC set
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Universal security group
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following table depicts NSX cross vCenter Server deployment options; based
    on these points, we will have a detailed explanation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Components of NSX cross vCenter Server](img/image_07_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding table, I have updated key NSX features that customers would
    be ideally configuring in a cross vCenter NSX environment. Any other features,
    such as load balancing and L2 bridging, do not have any global level fitting between
    the NSX sites so they always remain local to the vCenter Server environment. Before
    exploring universal NSX features, we need to know what roles are available for
    NSX Manager.
  prefs: []
  type: TYPE_NORMAL
- en: 'The NSX Manager instance has the following roles and a synchronization module
    will be running on the primary NSX Manager to ensure universal objects are synchronized
    to the secondary NSX Manager. The NSX Manager instance has the following roles:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Standalone**:Before configuring NSX roles, all the NSX Managers are standalone
    NSX Managers. A fresh installation of NSX Manager or an upgraded version of NSX
    Manager from VCNS are perfect examples of standalone NSX Managers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Primary**:There will be only **one Primary NSX Manager** in a cross vCenter
    NSX environment and we will be creating all universal objects in the primary NSX
    Manager. To be more specific, any deployment, modification, or deletion tasks
    will be done on the primary NSX Manager.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Secondary**: Whenever a standalone NSX Manager is added to the primary NSX
    Manager instance, it is called a secondary NSX Manager. All the universal objects
    are read-only on the secondary NSX Manager instance. A secondary NSX Manager instance
    cannot have its own controllers. We can have a total of seven secondary NSX Managers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Transit**:There will be instances wherein we need to remove/change primary
    and secondary roles for the NSX Manager and this is where the transit role is
    important. However, if the NSX Manager instance has universal objects, it cannot
    be assigned the standalone role by definition. In such cases, the NSX Manager
    instance is assigned the transit role. In the transit role, a universal object
    can only be deleted. An NSX Manager instance can be assigned the secondary role
    after all the universal objects are deleted.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following diagram explains the various NSX roles that we have explained
    so far and the process to promote and demote NSX roles based on universal objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Components of NSX cross vCenter Server](img/image_07_003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Before moving ahead with further discussion of cross vCenter, we need to know
    the importance of the **Universal Synchronization Service**. The Universal Synchronization
    Service is the heart of cross vCenter NSX communication.
  prefs: []
  type: TYPE_NORMAL
- en: Universal Synchronisation Service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The **Universal Synchronization Service** is responsible for synchronizing configuration
    changes from the primary NSX Manager instance to all the secondary NSX Manager
    instances. These are inbuilt services that are running in primary NSX Manager
    and they do REST API calls to secondary NSX Managers for synchronization. Okay,
    let's do a few quick tests to see what the state of the service is before we start
    assigning roles to NSX Managers.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure shows a GUI connection to NSX 6.2 and in the highlighted
    column we can see the NSX Universal Synchronization Service status:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Universal Synchronisation Service](img/image_07_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'In our setup, we have two NSX Managers and vCenter Servers are registered with
    a common **Platform Service Controller** (**PSC**). The PSC was introduced in
    vSphere 6 and handles functions such as vCenter Single Sign-On, licensing, certificate
    management, and server reservation. Controllers are already deployed in the NSX
    Manager 192.168.110.15, which will be our primary NSX Manager in a short while.
    We all know how to register NSX Manager with an individual vCenter Server since
    we have already discussed that in [Chapter 3](ch03.html "Chapter 3. NSX Manager
    Installation and Configuration") , *NSX Manager Installation and Configuration*.
    Assuming that we have already done that registration successfully, it''s time
    to promote the **192.168.110.15** NSX Manager as primary and **192.168.210.15**
    as secondary:'
  prefs: []
  type: TYPE_NORMAL
- en: Select the **Management** tab and highlight **NSX Manager**s.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the **Actions** icon.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Select **Assign Primary Role**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Universal Synchronisation Service](img/image_07_005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Any guess what will happen when we promote NSX Manager to primary? If your thoughts
    match the output, I'm going to show that result right away. Congratulations if
    your answers are correct.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure depicts NSX Manager primary role registration; the **Replicator
    Service** is automatically starting:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Universal Synchronisation Service](img/image_07_006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The preceding screenshot is the NSX Manager logs from the primary NSX Manager.
    As we can see in the GUI as well, **Replicator Service** is automatically started
    since the registration is successful. The following figure shows the Universal
    Synchronization Service in a running state:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Universal Synchronisation Service](img/image_07_007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: So watch out for this output and verify in the GUI whether the output matches
    the output in the logs. It is extremely important and useful for troubleshooting.
  prefs: []
  type: TYPE_NORMAL
- en: Universal segment ID
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The universal segment ID pool is used to assign VNIs to universal logical switches,
    to ensure that we don't use the same segment ID pool for local and global logical
    switches; there would be overlapping segment IDs in that eventually.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure shows **Universal Segment ID pool** creation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Universal segment ID](img/B03244_07_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The whole purpose of creating universal logical switches is to span the logical
    network across vCenter sites without doing traditional complex routing and switching.
    That way, universal logical switches will be available on all the vCenter Servers
    in the cross domain NSX site and we can simply connect virtual machines to those
    logical switches. The virtual machine logical switches will always remain as port
    groups and NSX will take care of cross vCenter switching. Haven't we configured
    a more simplified Layer 2 switching than this? First of all, was it possible do
    a Layer 2 switching like this in the past? I strongly believe we have all already
    moved away from legacy network design thinking with the amount of awareness that
    we have added so far in this book.
  prefs: []
  type: TYPE_NORMAL
- en: Let's go ahead and add a secondary role to our second NSX Manager so that we
    can start creating universal transport zones and universal logical switches.
  prefs: []
  type: TYPE_NORMAL
- en: 'The procedure for adding a secondary NSX Manager is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Log in to the vCenter linked to the primary NSX Manager.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Navigate to **Home** | **Networking & Security** | **Installation** and select
    the **Management** tab.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the primary NSX Manager. Then select **Actions** | **Add Secondary NSX
    Manager**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter the IP address, username, and password of the secondary NSX Manager.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **OK**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following figure depicts the **Add Secondary NSX Manager** option:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Universal segment ID](img/image_07_009.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'A successful addition of a secondary NSX Manager will show the role as secondary
    as depicted in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Universal segment ID](img/image_07_010.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Universal transport zone
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since we have a primary and secondary NSX Manager, let's go ahead and create
    a universal transport zone. First and foremost, there can only be **one universal
    transport zone in a cross vCenter NSX environment**. During the NSX Manager roles
    in this chapter, we have gone through the difference between primary, secondary
    and transit roles and there is no exception while creating a universal transport
    zone. Universal objects are always created from the primary NSX Manager.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure shows universal logical switch creation and we have added
    a primary NSX-VC pairing vSphere cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Universal transport zone](img/image_07_011.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'To add clusters from the secondary NSX-VC pairing vSphere site, we need to
    change the manager settings to secondary and click on **Connect Cluster Option**,
    which will display all clusters in the secondary NSX-VC site. Whenever we add
    new clusters, all we need to do is connect those newly added clusters to the universal
    transport zone and in my view this is the simplest way we can scale a software-defined
    data center:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Universal transport zone](img/image_07_012.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s do a quick test: we will go ahead and create a universal logical switch
    and will check if logical switches are getting populated in the primary and secondary
    NSX sites. Sounds great? Let''s get started then.'
  prefs: []
  type: TYPE_NORMAL
- en: Cross vCenter universal logical switch creation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Okay! We need to check a few prerequirements for logical switch creation to
    ensure that we are able to create the logical switch at the same time and it is
    functioning as expected. The following are the key points that should be followed
    while creating a universal logical switch:'
  prefs: []
  type: TYPE_NORMAL
- en: A VSphere distributed switch should be configured
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Controllers must be deployed in the primary NSX Manager
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: VSphere Host clusters must be prepared for NSX
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: VXLAN must be configured
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A universal segment ID pool must be configured (should not overlap with local
    segment ID)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A universal transport zone must be created
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s go ahead and create a **universal logical switch**:'
  prefs: []
  type: TYPE_NORMAL
- en: In vSphere web client, navigate to **Home** | **Networking & Security** | **Logical
    Switches**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the NSX Manager on which you want to create a logical switch (this should
    be the primary NSX Manager; if we select the secondary NSX Manager, it won't be
    universal object selection).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the **New Logical Switch** icon.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'This being a universal logical switch, we certainly need to have a universal
    transport zone and segment ID created; however, we have created that already.
    Assuming that we have met all the pre requirements, let''s move on:'
  prefs: []
  type: TYPE_NORMAL
- en: Type the universal logical switch name; in our example, we are naming it ****Universal****
     switch.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the **Transport Zone**; this should be the **Universal Transport Zone** created
    earlier in this chapter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following figure represents universal logical switch creation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Cross vCenter universal logical switch creation](img/image_07_013.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Adding virtual machines to universal logical switches
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Since we have already created universal logical switches, we will go ahead
    and attach two virtual machines from two vCenter sites and perform a basic ping
    test. Considering the amount of knowledge that we have added so far, this lab
    task will be a cakewalk for all of us. Let''s get started:'
  prefs: []
  type: TYPE_NORMAL
- en: In logical switches, we need to select the logical switch to which you want
    to add virtual machines.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the **Add Virtual Machine** icon.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the virtual machines you want to add to the logical switch. In our case,
    we are selecting the **Web-Site A** machine, which is preconfigured with IP 1**72.17.10.11**
    as shown in the following figure:![Adding virtual machines to universal logical
    switches](img/image_07_014.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the vNICs that you want to connect as shown in the following figure:![Adding
    virtual machines to universal logical switches](img/image_07_015.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click **Next** and **Finish** the connection configuration task for **Web-Site
    A.**
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following screenshot portrays the Web-Site A machine and its IP details:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Adding virtual machines to universal logical switches](img/image_07_016.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: If we don't see the correct virtual machine in the available objects section,
    there's a strong chance we are in the wrong NSX Manager. We have to be in the
    correct NSX Manager (primary/secondary) to see the VC-virtual machine inventory
    list.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Since we have done with the Site-A, virtual machines have been added to the
    universal logical switch, we need to switch our NSX Manager role to secondary
    so that we can add machines from the secondary NSX Manager VC inventory to the
    same universal logical switch. How do we do that? It's a simple switch and is
    demonstrated in the following screenshot:![Adding virtual machines to universal
    logical switches](img/image_07_017.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We need to repeat Steps 1,2, and 3 and add virtual machine **Web-Site B** from
    the second vCenter Server, which is preconfigured with IP **172.17.10.12**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the **Add Virtual Machine** icon.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the virtual machines you want to add to the logical switch. In our case,
    we are selecting the **Web-Site B** machine.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following screenshot shows the **Web-Site B** machine and its IP details:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Adding virtual machines to universal logical switches](img/image_07_018.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Now we have created a universal logical switch and connected the **Web-Site
    A** and **Web-Site B** machines residing in two vCenter Servers. Traditionally,
    we need a Layer 2 switch for such circumstances since virtual machines are on
    two vCenter Servers and the same subnet. However, the cross vCenter NSX universal
    logical switch is a game-changer for data center Layer 2 switching. This is certainly
    a great use case not only for cross vCenter virtual machine connectivity we can
    easily design an active-active,active-passive vSphere data center for disaster
    recovery configuration with VMware SRM.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s do a simple ping test to confirm if these web servers are communicating
    as expected. The following screenshot shows **Web-Site B** virtual machine connectivity
    from **Web-Site A**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Adding virtual machines to universal logical switches](img/image_07_019.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Okay! So we have Layer 2 connectivity between two vCenter sites by leveraging
    universal logical switches. If this entire network flow sounds complex or confusing,
    let''s focus on the following figure, which portrays the entire configuration
    that we did so far for establishing universal logical switching:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Adding virtual machines to universal logical switches](img/image_07_020.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Cross vCenter Server Universal Logical Routers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Universal Logical Routers provides a optimized routing between vCenter Server
    sites for East-West data center traffic. For now, we can call this router a **Global
    NSX Router**, which will ease management tasks such as configuring and creating
    routes (static/dynamic) and firewall rules from a single pane of glass. Once again,
    I will re-emphasize: creation/deletion and all management activity relative to
    universal logical routers can be only done from the primary NSX Manager. We will
    go ahead and configure a cross vCenter Server universal logical router and establish
    a routing between two vCenter Server sites. We are taking the same virtual machines
    that we used in universal logical switching for this configuration; however, I
    have changed the IP/subnet of **Web-Site B**, which demands a routing between
    **Web-Site A** and **Web-Site B**. Let''s get started then:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Cross vCenter Server Universal Logical Routers](img/image_07_021.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The procedure for deploying a universal logical router is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Log in to vSphere web client.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on **Networking & Security** and then click **NSX Edges**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Universal Logical (Distributed) Router** (we will discuss local egress
    in the *Network choke points* section of this chapter):![Cross vCenter Server
    Universal Logical Routers](img/image_07_022.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter the **User Name** and P**assword** for the **Universal Distributed Logical
    Router** (**UDLR**) as shown in the following figure:![Cross vCenter Server Universal
    Logical Routers](img/image_07_023.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Select the **Datacenter** and** NSX  EdgeAppliance** details as shown in the
    following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: Please note that **NSX Edge Appliance** is not mandatory if we are leveraging
    only static routes. However, **Appliance deployment** is a must for dynamic routing
    and firewall.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Cross vCenter Server Universal Logical Routers](img/image_07_024.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: For High Availability interface configuration, we connect the interface to the
    vSphere distributed port group and they will communicate over the APIPA range
    (169.250.0.0/26) IP address as shown in the following screenshot:![Cross vCenter
    Server Universal Logical Routers](img/image_07_025.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, we will add logical interfaces to the UDLR.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following screenshot shows the universal switch connection from Site-A
    to connect the Web-Site-A VM to the UDLR:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Cross vCenter Server Universal Logical Routers](img/image_07_026.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'We need to repeat Step 7 to add the Web-Site-B (VM residing in the second vCenter)
    to the UDLR as shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Cross vCenter Server Universal Logical Routers](img/image_07_027.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now that we have connected both the universal switches to the UDLR, let''s
    go ahead and verify the routing table. No rocket science here, if we have followed
    all the steps so far diligently. Our UDLR should show those two logical networks
    as directly connected networks. The following screenshot depicts the output for
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '![Cross vCenter Server Universal Logical Routers](img/image_07_028.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Since the UDLR is showing **172.16.20.0** and **172.17.10.0** networks connected,
    we should be able to perform a simple **ICMP** ping between these machines, considering
    we have appropriate firewall rules added in the router. In our example, the default
    rule is to allow all the traffic so there should not be any choke points here.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot portrays a successful ICMP ping from **Web-Site-B**
    (172.16.10.11) to **Web-Site-A** (172.17.10.11):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Cross vCenter Server Universal Logical Routers](img/image_07_029.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s take an example, to be clear with the overall learning process, showing
    how routes are getting pushed to the underlying ESXi host; we have a multi-tenant
    topology as an example which I have shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: Dynamic routing protocol (OSPF) is running between Site-A and B Edges to their
    respective data center routers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Site-A and Site-B NSX Edges are connected with Universal Distributed Logical
    Routers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Static routes are created on NSX Edges to reach the 172.16.10.0 series network
    (we can certainly leverage dynamic routing protocols as well, based on business
    requirements).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: UDLR control VMs will send the learnt route to the NSX Controller cluster for
    distribution. Just to reiterate, controllers are running only in the primary NSX
    Manager since there is a cross VC NSX solution and all NSX Managers are well aware
    of universal NSX objects through the universal synchronization service.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The primary NSX Controllers will send those routes to the underlying ESXi hosts.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The ESXi host kernel routing module will update its routing table and will take
    care of data path traffic for those networks which it has learnt from the controllers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The preceding mentioned six steps are basic routing learning processes in an
    NSX environment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Cross vCenter Server Universal Logical Routers](img/image_07_030.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Network choke points
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let me get started by saying: *Never offer or implement any design unless you
    are well aware that it addresses all the customer''s needs*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'That rule is not specific to marketing or sales folk. It''s general advice
    for anyone who deals with technology. If not, we will hear the feedback: *I''m
    having a nightmare; all the problems started happening after that design change.
    Can you please get rid of that?* We have designed or seen various types of vSphere
    networks. Every network topology will have a loophole. Nothing is perfect in this
    world and all we can do is ensure that we are better prepared for failures, this
    seems more like an advantage than a failure? I want all of you to pause for a
    minute and have a look at the preceding topology; make a note of all failure scenarios
    that might interrupt data traffic. Adding to that, if we have carefully observed
    the topology, we will see that universal control VMs and Edges are running on
    two different sites. So how will the UDLR control VM ensure that whatever routes
    it is learning from that specific NSX Edge are the only routes learnt by the underlying
    ESXi host that are specific to that site? I know that is a slightly confusing
    statement. Never mind, all we need is that routes learned by Site-A appliances
    (Edges/Control VM) are sent to the Site-A ESXi host and vice versa for Site-B.
    Okay! Let''s get started then and keep reading the following useful points to
    ensure that our design satisfies our customer requirement without inviting any
    further problems:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Both the data centers have two NSX appliances running and we need to ensure
    they are running in HA mode with vSphere HA also configured. That way, single
    appliance/host failure will have less impact:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: NSX Edge
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: UDLR Control VM
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensure that we are using **LOCALE-ID (by default, this value is set to the NSX
    Managers-UUID)**. With the Locale-ID configuration, NSX Controllers will send
    routes to ESXi hosts matching Locale-ID. Going via our topology, each site ESXi
    host will maintain a site-specific local routing table. We can set Locale-ID per
    cluster, host level and UDLR level. This would perfectly fit in a multi-tenant
    network/cloud environment wherein each tenant wants to maintain routes which are
    specific to that tenant.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: All **South-North** traffic is handled by **Site A NSX Edge** and **SITE B NSX
    Edge** in their respective sites. Starting from NSX 6.1, **Equal Cost Multi Path** (**ECMP**)
    is supported. Hence, we can deploy multiple NSX Edges and the ECMP algorithm will
    HASH the traffic based on source and destination IP. ECMP can be enabled on Edges
    and DLR. That way, if there is a failure, it will recalculate the HASH and will
    route the traffic to the active edge/DLR. In addition to that, there will be designs
    that might demand back-to-back ECMP configuration, Distributed Logical Router
    to NSX Edge and NSX Edge to physical routers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We should never design something that breaks a working topology. While we deal
    with ECMP, we need to be aware that NSX Edge has a stateful firewall. There is
    a good chance we might have asymmetric routing issues; basically, a packet that
    travels from source to destination uses one path and while replying, takes another
    path, because at any time only one Edge will be aware of the traffic flow. No
    worries: while we enable ECMP in NSX 6.1, we will get a message that says enabling
    this feature will **disable Edge firewall**. **Don''t worry**, we are not compromising
    on firewall rules in such designs. Either we can deploy any third-party physical
    firewall (as shown in the figure) between NSX Edges and Upstream router or we
    need to leverage Distributed Firewall, which will filter the traffic at the VNIC
    level. However, starting from NSX 6.1.3, ECMP and logical firewall can work together
    and for the same reason it won''t get disabled by default when we enable ECMP.
    However, starting from NSX 6.1.3, ECMP and logical firewall can work together
    and for the same reason it won''t get disabled by default when we enable ECMP
    (Active/Standby NSX Edges). The following diagram depicts an **ECMP**-added configuration
    for the same topology:![Network choke points](img/image_07_031.jpg)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Since we have NSX Edges running on each site, **overlapping** IP addresses are
    supported by configuring a NAT on the site-specific Edge. Again, a highly demanding
    use case, especially for cloud providers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We can have eight NSX Edges participating in ECMP configuration at a time; in
    our case, eight ECMP edges per site with a total of 16 Edges we can run in that
    way.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How about a worst case scenario of complete Site A or Site B failure one at
    a time? There is certainly a solution for any problem, but in this case, the solution
    will be slightly tedious and based on the physical network design. Reconfiguring
    all NSX components in another site may not work.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Site-B is where we have the primary NSX Manager and Site-B had a complete failure.
    Starting from NSX Manager role changing, we need to deploy Edges and appliances
    and can bring the environment back to normal only if the physical network design
    is equally matching for both the sites. I know this is a tedious process,so if
    we want to automate such tasks,we need to leverage NSX API and VRO workflow's
    so that that would ease lot of manual tasks. In a rare case, we may have to reconfigure
    the physical network so that Site-B machines can communicate with the physical
    network while they are residing in Site-A during the outage.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There is a lot to be discussed about types of failures, such as NSX components
    in network sites failing at the same time or virtual environment and physical
    network partial/full failure scenarios. There are also routing protocol (OSPF/BGP)
    specific failure scenarios that also bring up some good points for discussion.
    It is extremely hard to cover all such failure scenarios and carry out precautionary
    steps based on the type of design in just one book. Luckily, the NSX product documentation
    from VMware is not limited to installation, configuration, and general designs.
    There are a few design guides they have released specific to vendor integration,
    such as NSX+UCS design, NSX+CISCO ACI, and so on. It's worth reading such documents
    once we have mastered the basics and, hopefully, what we have learnt so far in
    all seven chapters is a foundation step for climbing the network virtualization
    ladder. It's been a remarkable discussion so far on VMware NSX topologies and,
    optimistically, by this time, we all are clear on how VMware NSX is reinventing
    data center networking.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We started this chapter with an introduction to NSX cross vCenter Server followed
    by cross vCenter Server components, and universal object creation, and we ended
    by discussing a few design decisions that we should be well aware of during cross
    vCenter Server NSX deployment. Way back, network troubleshooting was single-handedly
    done by network architects and support engineers, which made life easy for vSphere
    folk. NSX being a network software layer running on top of vSphere, people often
    believe that it might make their life somewhat threatening since they have a clear
    visibility on both for both hypervisor and network virtualization layers.
  prefs: []
  type: TYPE_NORMAL
- en: For me, troubleshooting is an art; if we follow a systematic procedure for checking
    a problem, resolving the problem is a cakewalk. There is no secret or straightforward
    automation that will help us analyze and fix a problem in network virtualization.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will have a detailed discussion on NSX troubleshooting.
    So let's ensure that we recall whatever we learnt and get our hands dirty by applying
    those points based on the situation.
  prefs: []
  type: TYPE_NORMAL
