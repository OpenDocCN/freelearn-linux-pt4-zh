- en: Chapter 2. Setting up the CoreOS Lab
  prefs: []
  type: TYPE_NORMAL
- en: CoreOS can be deployed in Bare Metal, VMs, or a cloud provider such as Amazon
    AWS or Google GCE. In this chapter, we will cover how to set up the CoreOS development
    environment in Vagrant, Amazon AWS, Google GCE, and Bare Metal. This development
    environment will be used in all the chapters going forward.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Cloud-config for CoreOS
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CoreOS with Vagrant
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CoreOS with Amazon AWS
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CoreOS with Google GCE
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The CoreOS installation on Bare Metal.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The basic debugging of the CoreOS cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Different CoreOS deployment options are covered here because of the following
    reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: Vagrant with Virtualbox is useful for users who don't have a cloud account.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For some users, using a local machine might not be possible as VMs occupy a
    lot of resources, and using a cloud-based VM is the best choice in this case.
    As AWS and GCE are the most popular cloud providers, I chose these two.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bare metal installation would be preferable for traditional in-house data centers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this book's examples, I have used one of the three approaches (Vagrant, AWS,
    and GCE) based on the simplicity of one of the approaches, better integration
    with one of the three approaches, or because of issues with a particular approach.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cloud-config
  prefs: []
  type: TYPE_NORMAL
- en: Cloud-config is a declarative configuration file format that is used by many
    Linux distributions to describe the initial server configuration. The cloud-init
    program takes care of parsing `cloud-config` during server initialization and
    configures the server appropriately. The `cloud-config` file provides you with
    a default configuration for the CoreOS node.
  prefs: []
  type: TYPE_NORMAL
- en: The CoreOS cloud-config file format
  prefs: []
  type: TYPE_NORMAL
- en: The `coreos-cloudinit` program takes care of the default configuration of the
    CoreOS node during bootup using the `cloud-config` file. The `cloud-config` file
    describes the configuration in the YAML format ([http://www.yaml.org/](http://www.yaml.org/)).
    CoreOS cloud-config follows the `cloud-config` specification with some CoreOS-specific
    options. The link, [https://coreos.com/os/docs/latest/cloud-config.html](https://coreos.com/os/docs/latest/cloud-config.html)
    covers the details of CoreOS `cloud-config`.
  prefs: []
  type: TYPE_NORMAL
- en: The main sections of cloud-config
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the main sections in the CoreOS `cloud-config` YAML file:'
  prefs: []
  type: TYPE_NORMAL
- en: 'CoreOS:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Etcd2: config parameters for etcd2'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fleet: config parameters for Fleet'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Flannel: config parameters for Flannel'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Locksmith: config parameters for Locksmith'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Update: config parameters for automatic updates'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Units: Systemd units that need to be started'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ssh_authorized_keys`: Public keys for the core user'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hostname`: Hostname for the CoreOS system'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`users`: Additional user account and group details'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`write_files`: Creates files with specified user data'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`manage_etc_hosts`: Specifies the contents of `/etc/hosts`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A sample CoreOS cloud-config
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a sample `cloud-config` file for a single node CoreOS cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '`#cloud-config coreos:   etcd2:     # Static cluster     name: etcdserver     initial-cluster-token: etcd-cluster-1
        initial-cluster: etcdserver=http://$private_ipv4:2380     initial-cluster-state: new
        advertise-client-urls: http://$public_ipv4:2379     initial-advertise-peer-urls: http://$private_ipv4:2380
        # listen on both the official ports and the legacy ports     # legacy ports can be omitted if your application doesn''t depend on them
        listen-client-urls: http://0.0.0.0:2379,http://0.0.0.0:4001     listen-peer-urls: http://$private_ipv4:2380,http://$private_ipv4:7001
      fleet:     public-ip: $public_ipv4     metadata: "role=services"   flannel:
        interface: $public_ipv4   update:       reboot-strategy: "etcd-lock"   units:
        # To use etcd2, comment out the above service and uncomment these     # Note: this requires a release that contains etcd2
        - name: etcd2.service       command: start     - name: fleet.service       command: start
        - name: flanneld.service       drop-ins:         - name: 50-network-config.conf
              content: |             [Service]             ExecStartPre=/usr/bin/etcdctl set /coreos.com/network/config ''{ "Network": "10.1.0.0/16" }''
          command: start     - name: docker-tcp.socket       command: start       enable: true
          content: |         [Unit]         Description=Docker Socket for the API
            [Socket]         ListenStream=2375         Service=docker.service         BindIPv6Only=both
            [Install]         WantedBy=sockets.target  write_files:   - path: "/etc/motd"
        permissions: "0644"     owner: "root"     content: |       --- My CoreOS Cluster ---`'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are some notes on the preceding `cloud-config`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `etcd2` section specifies the configuration parameters for the `etcd2`
    service. In this case, we specify parameters needed to start `etcd` on the CoreOS
    node. The `public_ipv4` and `private_ipv4` environment variables are substituted
    with the CoreOS node''s IP address. As there is only one node, we use the static
    cluster definition approach rather than using a discovery token. Based on the
    specified parameters, the `20-cloudinit.conf` Drop-In Unit gets created in `/run/systemd/system/etcd2.service.d`
    with the following environment variables:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`[Service] Environment="ETCD_ADVERTISE_CLIENT_URLS=http://172.17.8.101:2379"
    Environment="ETCD_INITIAL_ADVERTISE_PEER_URLS=http://172.17.8.101:2380" Environment="ETCD_INITIAL_CLUSTER=etcdserver=http://172.17.8.101:2380"
    Environment="ETCD_INITIAL_CLUSTER_STATE=new" Environment="ETCD_INITIAL_CLUSTER_TOKEN=etcd-cluster-1"
    Environment="ETCD_LISTEN_CLIENT_URLS=http://0.0.0.0:2379,http://0.0.0.0:4001"
    Environment="ETCD_LISTEN_PEER_URLS=http://172.17.8.101:2380,http://172.17.8.101:7001"
    Environment="ETCD_NAME=etcdserver"`'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The `fleet` section specifies the configuration parameters for the `fleet`
    service, including any metadata for the node. The `20-cloudinit.conf` Drop-In
    Unit gets created in `/run/systemd/system/fleet.service.d` with the following
    environment variables:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`[Service] Environment="FLEET_METADATA=role=services" Environment="FLEET_PUBLIC_IP=172.17.8.101"`'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The update section specifies the update strategy for the CoreOS node. This
    gets updated in the node as `/etc/coreos/update.conf`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`GROUP=alpha REBOOT_STRATEGY=etcd-lock`'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The `units` section starts `etcd2`, `fleet`, and `flannel`. For `flannel`,
    we have a drop-in unit to update the subnet to be used for containers created
    with the Flannel network service. The `50-network-config.conf` Drop-in unit gets
    created in `/etc/systemd/system/flanneld.service.d`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`[Service] ExecStartPre=/usr/bin/etcdctl set /coreos.com/network/config ''{ "Network": "10.1.0.0/16" }''`'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The `docker-tcp.socket` unit in the units section is a new `systemd` unit, and
    we specified the service content that allows for the docker daemon to be exposed
    through port `2375`. The unit will be created in `/etc/systemd/system`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `write_files` section can be used to create any static files. An example
    could be a hello text when a user logs in, which we can do with `/etc/motd`. The
    hello message would look as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Last login: Tue Sep 15 14:15:04 2015 from 10.0.2.2 --- My CoreOS Cluster ---
    core@core01 ~ $`'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The cloud-config validator
  prefs: []
  type: TYPE_NORMAL
- en: Cloud-config uses the YAML syntax. YAML is a human-readable data serialization
    format and uses indents and spaces for alignment. It is better to validate the
    `cloud-config` YAML configuration files before using them. There are two options
    to validate the CoreOS `cloud-config`.
  prefs: []
  type: TYPE_NORMAL
- en: A hosted validator
  prefs: []
  type: TYPE_NORMAL
- en: Use this CoreOS-provided link ([https://coreos.com/validate/](https://coreos.com/validate/))
    to validate `cloud-config`.
  prefs: []
  type: TYPE_NORMAL
- en: Here is an example of a valid and invalid `cloud-config` and the results using
    the validator.
  prefs: []
  type: TYPE_NORMAL
- en: Valid cloud-config
  prefs: []
  type: TYPE_NORMAL
- en: 'As we can see in the following screenshot, the validator says that the following
    `cloud-config` is valid:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00100.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Invalid cloud-config
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we can see that the validator has specified that `-` is missing in line
    14\. YAML uses spaces for the delimiting, so we need to make sure that the number
    of spaces is exact:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00167.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The cloudinit validator
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use the `coreos-cloudinit --validate` option available in CoreOS to
    validate the cloud-config. Let''s look at the following sample `cloud-config`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00109.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'When we validate this, we get no errors, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00112.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, let''s try the same `cloud-config` with errors. Here, we have `|` missing
    in the content line:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00017.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We see the following errors when we validate:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00120.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Executing cloud-config
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two `cloud-config` files that are run as part of the CoreOS bootup:'
  prefs: []
  type: TYPE_NORMAL
- en: System cloud-config
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: User cloud-config
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: System `cloud-config` is given by the provider (such as Vagrant or AWS) and
    is embedded as part of the CoreOS provider image. Different providers such as
    Vagrant, AWS, and GCE have their `cloud-config` present in `/usr/share/oem/cloud-config.yaml`.
    This `cloud-config` is responsible for setting up the provider-specific configurations,
    such as networking, SSH keys, mount options, and so on. The `coreos-cloudinit`
    program first executes system `cloud-config` and then user `cloud-config`.
  prefs: []
  type: TYPE_NORMAL
- en: Depending on the provider, user `cloud-config` can be supplied using either
    config-drive or an internal user data service. Config-drive is a universal way
    to provide `cloud-config` by mounting a read-only partition that contains `cloud-config`
    to the host machine. Rackspace uses config-drive to get user `cloud-config`, and
    AWS uses its internal user data service to fetch the user data and doesn't rely
    on config-drive. In the Vagrant scenario, Vagrantfile takes care of copying the
    `cloud-config` to the CoreOS VM.
  prefs: []
  type: TYPE_NORMAL
- en: The CoreOS cluster with Vagrant
  prefs: []
  type: TYPE_NORMAL
- en: 'Vagrant can be installed in Windows or Linux. The following is my development
    environment for the Vagrant CoreOS:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Windows 7: I use mysysgit ([https://git-for-windows.github.io/](https://git-for-windows.github.io/))
    to get a Linux-like shell for Windows'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Vagrant 1.7.2: [https://www.vagrantup.com/downloads.html](https://www.vagrantup.com/downloads.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Virtualbox 4.3.28: [https://www.virtualbox.org/wiki/Downloads](https://www.virtualbox.org/wiki/Downloads)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For a few of the examples in the book, I have used Vagrant to run CoreOS inside
    a Linux VM running on top of Windows laptop with Virtualbox.
  prefs: []
  type: TYPE_NORMAL
- en: Steps to start the Vagrant environment
  prefs: []
  type: TYPE_NORMAL
- en: 'Check out the coreos-vagrant code base:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`git clone https://github.com/coreos/coreos-vagrant.git`'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Copy the sample `user-data` and `config.rb` files in the coreos-vagrant directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`cd coreos-vagrant``mv user-data.sample user-data``mv config.rb.sample config.rb`'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Edit `Vagrantfile`, `user-data`, and `config.rb` based on your need.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Start the CoreOS cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Vagrant up`'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'SSH to the individual node:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Vagrant ssh core-<id>`'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Important files to be modified
  prefs: []
  type: TYPE_NORMAL
- en: The following are important files to be modified along with commonly needed
    modifications.
  prefs: []
  type: TYPE_NORMAL
- en: Vagrantfile
  prefs: []
  type: TYPE_NORMAL
- en: 'Vagrant sets up the VM environment based on the configuration defined in `Vagrantfile`.
    The following are certain relevant functionalities in the CoreOS context:'
  prefs: []
  type: TYPE_NORMAL
- en: The version of CoreOS software to be used is specified using `update_channel`.
    The version can be specified as `stable`, `beta`, and `alpha`. More details on
    CoreOS software versions are covered in [Chapter 3](index_split_075.html#filepos216260),
    CoreOS Autoupdate.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CPU and memory for the VM and ports to be exposed from the VM.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SSH key management.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: User-data
  prefs: []
  type: TYPE_NORMAL
- en: The `user-data` file is essentially the `cloud-config` file that specifies the
    discovery token, environment variables, and list of units to be started by default.
    Vagrant copies the `cloud-config` file to `/var/lib/coreos-vagrant/vagrantfile-user-data`
    inside the VM. The `coreos-cloudinit` reads `vagrantfile-user-data` on every boot
    and uses it to create the machine's user data file.
  prefs: []
  type: TYPE_NORMAL
- en: Config.rb
  prefs: []
  type: TYPE_NORMAL
- en: The `config.rb` file specifies the count of CoreOS nodes. This file also provides
    you with an option to automatically generate a discovery token. Some options here
    overlap with the `Vagrantfile` like image version.
  prefs: []
  type: TYPE_NORMAL
- en: Vagrant – a three-node cluster with dynamic discovery
  prefs: []
  type: TYPE_NORMAL
- en: Here, we will create a three-node CoreOS cluster with `etcd2` and `fleet` running
    on each node and nodes discovering each other dynamically.
  prefs: []
  type: TYPE_NORMAL
- en: Generating a discovery token
  prefs: []
  type: TYPE_NORMAL
- en: When we start a multinode CoreOS cluster, there needs to be a bootstrapping
    mechanism to discover the cluster members. For this, we generate a token specifying
    the number of initial nodes in the cluster as an argument. Each node needs to
    be started with this discovery token. Etcd will use the discovery token to put
    all the nodes with the same discovery token as part of the initial cluster. CoreOS
    runs the service to provide the discovery token from its central servers.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two approaches to generate a discovery token:'
  prefs: []
  type: TYPE_NORMAL
- en: 'From the browser: `https://discovery.etcd.io/new?size=3`'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using curl: `curl https://discovery.etcd.io/new?size=3`'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a curl example with a generated discovery token. This token
    needs to be copied to `user-data`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00358.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Steps for cluster creation
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a `cloud-config` user data with the updated discovery token
    that we generated in the preceding section along with the necessary environment
    variables and service units. All three nodes will use this `cloud-config`:'
  prefs: []
  type: TYPE_NORMAL
- en: '`#cloud-config coreos:   etcd2:     #generate a new token for each unique cluster from https://discovery.etcd.io/new
        discovery: https://discovery.etcd.io/9a6b7af06c8a677b4e5f76ae9ce0da9c     # multi-region and multi-cloud deployments need to use $public_ipv4
        advertise-client-urls: http://$public_ipv4:2379     initial-advertise-peer-urls: http://$private_ipv4:2380
        # listen on both the official ports and the legacy ports     # legacy ports can be omitted if your application doesn''t depend on them
        listen-client-urls: http://0.0.0.0:2379,http://0.0.0.0:4001     listen-peer-urls: http://$private_ipv4:2380,http://$private_ipv4:7001
      fleet:     public-ip: $public_ipv4   flannel:     interface: $public_ipv4   units:
        # Note: this requires a release that contains etcd2     - name: etcd2.service
          command: start     - name: fleet.service       command: start`'
  prefs: []
  type: TYPE_NORMAL
- en: We need to update `num_instances` to `3` in `config.rb` and then perform `vagrant
    up`.
  prefs: []
  type: TYPE_NORMAL
- en: To verify the basic cluster operation, we can check the following output, where
    we should see the cluster members.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following `etcdctl` member output shows the three cluster members:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00362.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The following fleet member output shows the three cluster members:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00364.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Vagrant – a three-node cluster with static discovery
  prefs: []
  type: TYPE_NORMAL
- en: Here, we will create a three-node CoreOS cluster and use a static approach to
    mention its cluster neighbors. In the dynamic discovery approach, we need to use
    a discovery token to discover the cluster members. Static discovery can be used
    for scenarios where access to the token server is not available to cluster members,
    and the cluster member IP addresses are known in advance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we need to create three separate instances of the CoreOS Vagrant environment
    by performing `git clone` separately for each node.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The `config.rb` file must be updated for each node with `num_instances` set
    to one.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Vagrantfile should be updated for each node so that IP addresses are statically
    assigned as `172.17.8.101` for `core-01`, `172.17.8.102` for `core-02`, and `172.17.8.103`
    for `core-03`. IP addresses should be updated based on your environment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The `cloud-config` user data for the first node is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`#cloud-config coreos:   etcd2:     name: core-01     initial-advertise-peer-urls: http://172.17.8.101:2380
        listen-peer-urls: http://172.17.8.101:2380     listen-client-urls: http://172.17.8.101:2379,http://127.0.0.1:2379
        advertise-client-urls: http://172.17.8.101:2379     initial-cluster-token: etcd-cluster-1
        initial-cluster: core-01=http://172.17.8.101:2380,core-02=http://172.17.8.102:2380,core-03=http://172.17.8.103:2380
        initial-cluster-state: new   fleet:     public-ip: $public_ipv4   flannel:
        interface: $public_ipv4   units:     - name: etcd2.service       command: start
        - name: fleet.service       command: start`'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `cloud-config` user data for the second node is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`#cloud-config coreos:   etcd2:     name: core-02     initial-advertise-peer-urls: http://172.17.8.102:2380
        listen-peer-urls: http://172.17.8.102:2380     listen-client-urls: http://172.17.8.102:2379,http://127.0.0.1:2379
        advertise-client-urls: http://172.17.8.102:2379     initial-cluster-token: etcd-cluster-1
        initial-cluster: core-01=http://172.17.8.101:2380,core-02=http://172.17.8.102:2380,core-03=http://172.17.8.103:2380
        initial-cluster-state: new   fleet:     public-ip: $public_ipv4   flannel:
        interface: $public_ipv4   units:     - name: etcd2.service       command: start
        - name: fleet.service       command: start`'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `cloud-config` user data for the third node is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`#cloud-config coreos:   etcd2:     name: core-03     initial-advertise-peer-urls: http://172.17.8.103:2380
        listen-peer-urls: http://172.17.8.103:2380     listen-client-urls: http://172.17.8.103:2379,http://127.0.0.1:2379
        advertise-client-urls: http://172.17.8.103:2379     initial-cluster-token: etcd-cluster-1
        initial-cluster: core-01=http://172.17.8.101:2380,core-02=http://172.17.8.102:2380,core-03=http://172.17.8.103:2380
        initial-cluster-state: new   fleet:     public-ip: $public_ipv4   flannel:
        interface: $public_ipv4   units:     - name: etcd2.service       command: start
        - name: fleet.service       command: start`'
  prefs: []
  type: TYPE_NORMAL
- en: We need to perform `vagrant up` separately for each of the nodes. We should
    see the cluster member list updated in both the `etcdctl member list` and `fleetctl
    list-machines` outputs.
  prefs: []
  type: TYPE_NORMAL
- en: Vagrant – a production cluster with three master nodes and three worker nodes
  prefs: []
  type: TYPE_NORMAL
- en: 'In [Chapter 1](index_split_023.html#filepos77735), CoreOS Overview, we covered
    the CoreOS cluster architecture. A production cluster has one set of nodes (called
    master) to run critical services, and another set of nodes (called worker) to
    run application services. In this example, we create three master nodes running
    `etcd` and other critical services and another three worker nodes. Etcd in the
    worker nodes will proxy to the master nodes. Worker nodes will be used for user-created
    services while master nodes will be used for system services. This avoids resource
    contention. The following are the steps needed for this creation:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a Vagrant three-node cluster for the master and a three-node cluster
    for the worker.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Update Vagrantfile to use non-conflicting IP address ranges between the master
    and worker nodes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the dynamic discovery token approach to create a token for the three-node
    clusters and update the `cloud-config` user data for both the master and worker
    nodes to the same token. We have specified the token size as `3` as worker nodes
    don't run `etcd`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following is the user data for the master cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '`#cloud-config coreos:   etcd2:     discovery: https://discovery.etcd.io/d49bac8527395e2a7346e694124c8222
        advertise-client-urls: http://$public_ipv4:2379     initial-advertise-peer-urls: http://$private_ipv4:2380
        # listen on both the official ports and the legacy ports     listen-client-urls: http://0.0.0.0:2379,http://0.0.0.0:4001
        listen-peer-urls: http://$private_ipv4:2380,http://$private_ipv4:7001   fleet:
         metadata: "role=master"      public-ip: $public_ipv4   units:     - name: etcd2.service
          command: start     - name: fleet.service       command: start`'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the user data for the worker cluster. The discovery token
    needs to be the same for the master and worker clusters:'
  prefs: []
  type: TYPE_NORMAL
- en: '`#cloud-config coreos:   etcd2:     discovery: https://discovery.etcd.io/d49bac8527395e2a7346e694124c8222
        advertise-client-urls: http://$public_ipv4:2379     initial-advertise-peer-urls: http://$private_ipv4:2380
        # listen on both the official ports and the legacy ports     listen-client-urls: http://0.0.0.0:2379,http://0.0.0.0:4001
        listen-peer-urls: http://$private_ipv4:2380,http://$private_ipv4:7001   fleet:
         metadata: "role=worker"      public-ip: $public_ipv4   units:     - name: etcd2.service
          command: start     - name: fleet.service       command: start`'
  prefs: []
  type: TYPE_NORMAL
- en: The only difference between the master and worker user data is in the metadata
    used for fleet. In this example, we used `role` as `master` for the master cluster
    and `role` as `worker` for the worker cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Let's look at the `etcdctl` member list and fleet machine list. The following
    output will be the same across all the nodes in the master and worker cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `etcdctl` member output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00306.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The fleet member output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00370.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The following is the `journalctl –u etcd2.service` output on worker nodes that
    show worker nodes proxying to master nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00372.jpg)'
  prefs: []
  type: TYPE_IMG
- en: A CoreOS cluster with AWS
  prefs: []
  type: TYPE_NORMAL
- en: 'Amazon AWS provides you with a public cloud service. CoreOS can be run on the
    VMs provided by AWS. The following are some prerequisites for this setup:'
  prefs: []
  type: TYPE_NORMAL
- en: You need an account in AWS. AWS provides you with a one-year trial account for
    free.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create and download a key pair. The key pair is needed to SSH to the nodes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The AWS interface can be accessed through the AWS console, which is a GUI interface,
    or by AWS CLI. AWS CLI ([http://aws.amazon.com/cli/](http://aws.amazon.com/cli/))
    can be installed in either Windows or Linux.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The following are two approaches of creating a CoreOS cluster with AWS.
  prefs: []
  type: TYPE_NORMAL
- en: AWS – a three-node cluster using Cloudformation
  prefs: []
  type: TYPE_NORMAL
- en: 'Cloudformation is an AWS orchestration tool to manage a collection of AWS resources
    that include compute, storage, and networking. The link, [https://s3.amazonaws.com/coreos.com/dist/aws/coreos-stable-hvm.template](https://s3.amazonaws.com/coreos.com/dist/aws/coreos-stable-hvm.template),
    has the template file for the CoreOS cluster. The following are some of the key
    sections in the template:'
  prefs: []
  type: TYPE_NORMAL
- en: The AMI image ID to be used based on the region
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The EC2 Instance type
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The security group configuration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The CoreOS cluster size including the minimum and maximum size to autoscale
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The initial cloud-config to be used
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For the following example, I modified the template to use `t2.micro` instead
    of `m3.medium` for the instance size. The following CLI can be used to create
    a three-node CoreOS cluster using `Cloudformation`. The discovery token in the
    below command needs to be updated with the generated token for your case:'
  prefs: []
  type: TYPE_NORMAL
- en: '`aws cloudformation create-stack \     --stack-name coreos-test \     --template-body file://mycoreos-stable-hvm.template \
        --capabilities CAPABILITY_IAM \     --tags Key=Name,Value=CoreOS \     --parameters \      ParameterKey=DiscoveryURL,ParameterValue="https://discovery.etcd.io/925755234ab82c1ef7bcfbbacdd8c088" \
            ParameterKey=KeyPair,ParameterValue="keyname"`'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the output of the successful stack using `aws cloudformation
    list-stacks`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00347.jpg)'
  prefs: []
  type: TYPE_IMG
- en: After the preceding step, we can see that members are getting discovered successfully
    by both `etcd` and `fleet`.
  prefs: []
  type: TYPE_NORMAL
- en: AWS – a three-node cluster using AWS CLI
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are some prerequisites to create a CoreOS cluster in AWS using
    AWS CLI:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a token for a three-node cluster from the discovery token service.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set up a security group exposing the ports `ssh`, `icmp`, `2379`, and `2380`.
    `2379` and `2380` are needed for the `etcd2` client-to-server and server-to-server
    communication.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Determine the AMI image ID using this link ([https://coreos.com/os/docs/latest/booting-on-ec2.html](https://coreos.com/os/docs/latest/booting-on-ec2.html))
    based on your AWS Zone and update channel. The latest image IDs for different
    AWS Zones get automatically updated in this link.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following CLI will create the three-node cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '`aws ec2 run-instances --image-id ami-85ada4b5 --count 3 --instance-type t2.micro --key-name "yourkey" --security-groups "coreos-test" --user-data file://cloud-config.yaml`'
  prefs: []
  type: TYPE_NORMAL
- en: Here, the `ami-85ada4b5` image ID is from the stable update channel. The `coreos-test`
    security group has the necessary ports that need to be exposed outside.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the `cloud-config` that I used:'
  prefs: []
  type: TYPE_NORMAL
- en: '`#cloud-config coreos:   etcd2:     # specify the initial size of your cluster with ?size=X
        discovery: https://discovery.etcd.io/47460367c9b15edffeb49de30cab9354     advertise-client-urls: http://$private_ipv4:2379,http://$private_ipv4:4001
        initial-advertise-peer-urls: http://$private_ipv4:2380     listen-client-urls: http://0.0.0.0:2379,http://0.0.0.0:4001
        listen-peer-urls: http://$private_ipv4:2380,http://$private_ipv4:7001   units:
        - name: etcd2.service       command: start     - name: fleet.service       command: start`'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following output shows the `etcd` member list and fleet member list with
    three nodes in the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00379.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The same example can be tried from the AWS Console, where we can specify the
    options from the GUI.
  prefs: []
  type: TYPE_NORMAL
- en: A CoreOS cluster with GCE
  prefs: []
  type: TYPE_NORMAL
- en: 'Google''s GCE is another public cloud provider like Amazon AWS. CoreOS can
    be run on the VMs provided by GCE. The following are some prerequisites for this
    setup:'
  prefs: []
  type: TYPE_NORMAL
- en: You need a GCE account. GCE provides you with a free trial account for 60 days.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GCE resources can be accessed using gcloud SDK or GCE GUI Console. SDK can be
    downloaded from [https://cloud.google.com/sdk/](https://cloud.google.com/sdk/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A base project in GCE needs to be created under which all the resources reside.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A security token needs to be created, which is used for SSH access.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GCE – a three-node cluster using GCE CLI
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are some prerequisites to create a CoreOS cluster in GCE:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a token for a three-node cluster from a discovery token service.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set up a security group exposing the ports `ssh`, `icmp`, `2379`, and `2380`.
    `2379` and `2380` are needed for the `etcd2` client-to-server and server-to-server
    communication.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The link, [https://coreos.com/os/docs/latest/booting-on-google-compute-engine.html](https://coreos.com/os/docs/latest/booting-on-google-compute-engine.html),
    gets automatically updated with the latest GCE CoreOS releases from the stable,
    beta, and alpha channels. We need to pick the appropriate image that is needed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following CLI can be used to create a three-node CoreOS GCE cluster from
    the stable release:'
  prefs: []
  type: TYPE_NORMAL
- en: '`gcloud compute instances create core1 core2 core3 --image https://www.googleapis.com/compute/v1/projects/coreos-cloud/global/images/coreos-stable-717-3-0-v20150710 --zone us-central1-a --machine-type n1-standard-1 --metadata-from-file user-data=cloud-config.yaml`'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the `cloud-config.yaml` file that''s used:'
  prefs: []
  type: TYPE_NORMAL
- en: '`#cloud-config coreos:   etcd2:     # specify the initial size of your cluster with ?size=X
        discovery: https://discovery.etcd.io/46ad006905f767331a36bb2a4dbde3f5     advertise-client-urls: http://$private_ipv4:2379,http://$private_ipv4:4001
        initial-advertise-peer-urls: http://$private_ipv4:2380     listen-client-urls: http://0.0.0.0:2379,http://0.0.0.0:4001
        listen-peer-urls: http://$private_ipv4:2380,http://$private_ipv4:7001   units:
        - name: etcd2.service       command: start     - name: fleet.service       command: start`'
  prefs: []
  type: TYPE_NORMAL
- en: We can SSH to any of the nodes using `gcloud compute ssh <nodeid>`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following output shows you that the cluster is created successfully and
    members are seen from both `etcd` and `fleet`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00382.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The CoreOS cluster can also be created using the GCE Console GUI interface.
  prefs: []
  type: TYPE_NORMAL
- en: CoreOS installation on Bare Metal
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two approaches to install CoreOS on Bare Metal:'
  prefs: []
  type: TYPE_NORMAL
- en: CoreOS ISO image
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PXE or IPXE boot
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The steps below covers the approach to install CoreOS on Bare Metal using an
    ISO image.
  prefs: []
  type: TYPE_NORMAL
- en: I installed using a CoreOS ISO image on the Virtualbox CD drive. The procedure
    should be the same if we burn the ISO image on CD and then install on Bare Metal.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is summary of the steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Download the required ISO image based on stable, beta, and alpha versions from
    [https://coreos.com/os/docs/latest/booting-with-iso.html](https://coreos.com/os/docs/latest/booting-with-iso.html).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Start a new Linux machine in Virtualbox with the required CPU, memory, and network
    settings, and mount the ISO image on the IDE drive.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create an SSH key to log in to the CoreOS node using `ssh-keygen`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Start the Linux machine and then use the CoreOS script to install CoreOS on
    the hard disk with the necessary `cloud-config`. The cloud-config used here is
    similar to cloud-config is used in previous sections, SSH key needs to be manually
    updated.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Remove the CD drive from Virtualbox and reboot. This will load the CoreOS image
    from the hard disk.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: I have used the stable ISO image version 766.4.0.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows you the initial storage mounting on Virtualbox
    with the ISO image on the IDE drive:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00386.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The easiest way to get `cloud-config` is by `wget`. When we boot from the CD,
    we cannot cut and paste as there is no Windows manager. The easiest way to get
    `cloud-config` to the node is by having cloud-config in a hosting location and
    fetch it using `wget`. The SSH key needs to be updated appropriately.
  prefs: []
  type: TYPE_NORMAL
- en: '`wget https://github.com/smakam/coreos/raw/master/single-node-cloudconfig.yml`'
  prefs: []
  type: TYPE_NORMAL
- en: 'The installation of CoreOS to the hard disk can be done using the CoreOS-provided
    script:'
  prefs: []
  type: TYPE_NORMAL
- en: '`sudo coreos-install -d /dev/sda -C stable -c ~/cloud-config.yaml`'
  prefs: []
  type: TYPE_NORMAL
- en: 'After successful installation, we can shut down the node and remove the IDE
    drive so that the bootup can happen from the hard disk. The following screenshot
    shows you the storage selection in Virtualbox to boot using the hard disk:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00420.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'After the node is booted up, we can SSH to the node as we have already set
    up the SSH key. The following output shows you the CoreOS version on Bare Metal:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00393.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Basic debugging
  prefs: []
  type: TYPE_NORMAL
- en: The following are some basic debugging tools and approaches to debug issues
    in the CoreOS cluster.
  prefs: []
  type: TYPE_NORMAL
- en: journalctl
  prefs: []
  type: TYPE_NORMAL
- en: Systemd-Journal takes care of logging all the kernel and systemd services. Journal
    log files from all the services are stored in a centralized location in `/var/log/journal`.
    The logs are stored in the binary format, and this keeps it easy to manipulate
    to different formats.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some common examples that shows how to use Journalctl:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Journalctl`: This lists the combined journal log from all the sources.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Journalctl –u etcd2.service`: This lists the logs from `etcd2.service`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Journalctl –u etcd2.service –f`: This lists the logs from `etcd2`. service
    like `tail –f` format.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Journalctl –u etcd2.service –n 100`: This lists the logs of the last 100 lines.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Journalctl –u etcd2.service –no-pager`: This lists the logs with no pagination,
    which is useful for search.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Journalctl –p err –n 100`: This lists all 100 errors by filtering the logs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`journalctl -u etcd2.service --since today`: This lists today''s logs of `etcd2.service`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`journalctl -u etcd2.service -o json-pretty`: This lists the logs of `etcd2.service`
    in JSON-formatted output.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: systemctl
  prefs: []
  type: TYPE_NORMAL
- en: The `systemctl` utility can be used for basic monitoring and troubleshooting
    of the systemd units.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example shows you the status of the `systemdunit docker.service`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00395.jpg)'
  prefs: []
  type: TYPE_IMG
- en: We can stop and restart services in case there are issues with a particular
    service.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following command will restart docker.service:'
  prefs: []
  type: TYPE_NORMAL
- en: '`sudo systemctl restart docker.service`'
  prefs: []
  type: TYPE_NORMAL
- en: 'When a service file is changed or environment variables are changed, we need
    to execute the following command to reload configuration before restarting the
    service for the changes to take effect:'
  prefs: []
  type: TYPE_NORMAL
- en: '`sudo systemctl daemon-reload`'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following command is useful to see the units that have failed:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Systemctl --failed`'
  prefs: []
  type: TYPE_NORMAL
- en: Cloud-config
  prefs: []
  type: TYPE_NORMAL
- en: Earlier, we looked at how the `cloud-config` YAML file can be prevalidated.
    In case there are runtime errors, we can check it with `journalctl -b _EXE=/usr/bin/coreos-cloudinit`.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we make changes to the `cloud-config` user data after the initial node setup,
    we can perform the following steps to activate the new configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: Perform `vagrant reload --provision` to get the new configuration.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The new `cloud-config` user data will be in `/var/lib/coreos-vagrant` as `vagrantfile-user-data`.
    Perform `sudo coreos-cloudinit --from-file vagrantfile-user-data` to update the
    new configuration.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logging from one CoreOS node to another
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, it is useful to SSH to other nodes from one of the CoreOS nodes in
    the cluster. The following set of commands can be used to forward the SSH agent
    that we can use to SSH from other nodes. More information on SSH agent forwarding
    can be found at [http://rabexc.org/posts/using-ssh-agent](http://rabexc.org/posts/using-ssh-agent).
  prefs: []
  type: TYPE_NORMAL
- en: '`` eval `ssh-agent` ```ssh-add <key> (Key is the private key)``ssh -i <key> core@<ip> -A (key is the private key)`'
  prefs: []
  type: TYPE_NORMAL
- en: 'After this, we can either SSH to the machine ID or a specific Fleet unit, as
    shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00485.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: SSH agent forwarding is not secure and should be used only to debug.'
  prefs: []
  type: TYPE_NORMAL
- en: Important files and directories
  prefs: []
  type: TYPE_NORMAL
- en: 'Knowing these files and directories helps with debugging the issues:'
  prefs: []
  type: TYPE_NORMAL
- en: Systemd unit file location - `/usr/lib64/systemd/system`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Network unit files `- /usr/lib64/systemd/network`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: User-written unit files and drop-ins to change the default parameters `- /etc/systemd/system`.
    Drop-ins for specific configuration changes can be done using the configuration
    file under the specific service directory. For example, to modify the fleet configuration,
    create the `fleet.service.d` directory and put the configuration file in this
    directory.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: User-written network unit files `- /etc/systemd/network`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Runtime environment variables and drop-in configuration of individual components
    such as `etcd` and `fleet` `- /run/systemd/system/`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The vagrantfile user data containing the `cloud-config` user data used with
    Vagrant `- /var/lib/coreos-vagrant`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `systemd-journald` logs `- /var/log/journal`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cloud-config.yaml` associated with providers such as Vagrant, AWS, and `GCE-
    /usr/share/oem`. (CoreOS first executes this `cloud-config` and then executes
    the user-provided `cloud-config`.)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Release channel and update strategy `- /etc/coreos/update.conf`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The public and private IP address (`COREOS_PUBLIC_IPV4` and `COREOS_PRIVATE_IPV4`)
    `- /etc/environment`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The machine ID for the particular CoreOS node `- /etc/machine-id`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The flannel network configuration `- /run/flannel/`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Common mistakes and possible solutions
  prefs: []
  type: TYPE_NORMAL
- en: For CoreOS on the cloud provider, there is a need to open up ports 2379 and
    2380 on the VM. 2379 is used for etcd client-to-server communication, and 2380
    is used for etcd server-to-server communication.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A discovery token needs to be generated every time for each cluster and cannot
    be shared. When a stale discovery token is shared, members will not be able to
    join the etcd cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running multiple CoreOS clusters with Vagrant simultaneously can cause issues
    because of overlapping IP ranges. Care should be taken so that common parameters
    such as the IP address are not shared across clusters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cloud-config YAML files need to be properly indented. It is better to use the
    cloud-config validator to check for issues.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When using discovery token, CoreOS node needs to have Internet access to access
    the token service.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When creating a discovery token, you need to use the size based on the count
    of members and all members need to be part of the bootstrap. If all members are
    not present, the cluster will not be formed. Members can be added or removed later.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we covered the basics of CoreOS cloud-config and how to set
    up the CoreOS development environment with Vagrant, Amazon AWS, Google GCE, and
    Bare Metal. We also covered some basic debugging steps for commonly encountered
    issues. As described in this chapter, it is easy to install CoreOS in the local
    data center or Cloud environments. It is better to try out deployment in a development
    cluster before moving to production environments. In the next chapter, we will
    cover how the CoreOS automatic update works.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs: []
  type: TYPE_NORMAL
- en: 'Vagrant installation: [https://coreos.com/os/docs/latest/booting-on-vagrant.html](https://coreos.com/os/docs/latest/booting-on-vagrant.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'AWS installation: [https://coreos.com/os/docs/latest/booting-on-ec2.html](https://coreos.com/os/docs/latest/booting-on-ec2.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'GCE installation: [https://coreos.com/os/docs/latest/booting-on-google-compute-engine.html](https://coreos.com/os/docs/latest/booting-on-google-compute-engine.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bare Metal installation: [https://coreos.com/os/docs/latest/installing-to-disk.html](https://coreos.com/os/docs/latest/installing-to-disk.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'CoreOS CloudInit: [https://github.com/coreos/coreos-cloudinit](https://github.com/coreos/coreos-cloudinit)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Further reading and tutorials
  prefs: []
  type: TYPE_NORMAL
- en: 'Introduction to the cloud-config format: [https://www.digitalocean.com/community/tutorials/an-introduction-to-cloud-config-scripting](https://www.digitalocean.com/community/tutorials/an-introduction-to-cloud-config-scripting)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'CoreOS with AWS Cloudformation: [http://blog.michaelhamrah.com/2015/03/managing-coreos-clusters-on-aws-with-cloudformation/](http://blog.michaelhamrah.com/2015/03/managing-coreos-clusters-on-aws-with-cloudformation/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The CoreOS bare-metal installation: [http://stevieholdway.tumblr.com/post/90167512059/coreos-bare-metal-iso-install-tutorial](http://stevieholdway.tumblr.com/post/90167512059/coreos-bare-metal-iso-install-tutorial)
    and [http://linuxconfig.org/how-to-perform-a-bare-metal-installation-of-coreos-linux](http://linuxconfig.org/how-to-perform-a-bare-metal-installation-of-coreos-linux)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Using journalctl to view systemd logs: [https://www.digitalocean.com/community/tutorials/how-to-use-journalctl-to-view-and-manipulate-systemd-logs](https://www.digitalocean.com/community/tutorials/how-to-use-journalctl-to-view-and-manipulate-systemd-logs)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
