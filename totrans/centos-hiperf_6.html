<html><head></head><body>
<div id="page" style="height:0pt"/><div class="book" title="Chapter&#xA0;6.&#xA0;Measuring and Increasing Performance"><div class="book" id="1AT9A2-1d2c6d19b9d242db82da724021b51ea0"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch06" class="calibre1"/>Chapter 6. Measuring and Increasing Performance</h1></div></div></div><p class="calibre8">Up to this point, we have created an active/passive cluster, added several resources to it, and tested its failover capabilities. We also discussed how to troubleshoot common issues. The final step in our journey consists of measuring and increasing the performance of our cluster as it has been installed so far—as far as the services running on it are concerned.</p><p class="calibre8">In addition, we will provide the overall instructions to convert your A/P cluster into an A/A one.</p></div>

<div class="book" title="Chapter&#xA0;6.&#xA0;Measuring and Increasing Performance">
<div class="book" title="Setting up a sample database"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_1"><a id="ch06lvl1sec39" class="calibre1"/>Setting up a sample database</h1></div></div></div><p class="calibre8">In order to properly test our MariaDB database server, we need a database populated with sample<a id="id250" class="calibre1"/> data. For this reason, we will use the Employees database, developed by Patrick Crews and Giuseppe Maxia and provided by Oracle Corporation under a Creative Commons Attribution-Share Alike 3.0 Unported License. It provides a very large dataset (~160 MB and ~4 million records) spread over six tables, which will be ideal for our performance tests.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="note27" class="calibre1"/>Note</h3><p class="calibre8">The Creative Commons Attribution-Share Alike 3.0 Unported License, available at <a class="calibre1" href="http://creativecommons.org/licenses/by-sa/3.0/">http://creativecommons.org/licenses/by-sa/3.0/</a>, grants us the following freedoms regarding the Employees database:</p><p class="calibre8"><span class="strong"><em class="calibre9">Share: This lets us copy and redistribute the material in any medium or format</em></span></p><p class="calibre8"><span class="strong"><em class="calibre9">Adapt: This lets us remix, transform, and build upon the material</em></span></p><p class="calibre8"><span class="strong"><em class="calibre9">for any purpose, even commercially.</em></span></p><p class="calibre8"><span class="strong"><em class="calibre9">The licensor cannot revoke these freedoms as long as you follow the license terms.</em></span></p></div></div></div>

<div class="book" title="Chapter&#xA0;6.&#xA0;Measuring and Increasing Performance">
<div class="book" title="Setting up a sample database">
<div class="book" title="Downloading and installing the Employees database"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch06lvl2sec21" class="calibre1"/>Downloading and installing the Employees database</h2></div></div></div><p class="calibre8">Let's proceed with <a id="id251" class="calibre1"/>downloading and installing the database <a id="id252" class="calibre1"/>using the following steps:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">To download <a id="id253" class="calibre1"/>the Employees table, go to <a class="calibre1" href="https://launchpad.net/test-db/">https://launchpad.net/test-db/</a> and grab the link for the tarball of the latest stable release (at the time of writing this book, it is v1.0.6), as shown in the following screenshot:<div class="mediaobject"><img src="../images/00067.jpeg" alt="Downloading and installing the Employees database" class="calibre10"/></div><p class="calibre13"> </p></li><li class="listitem" value="2">Then, download it to the node on which the database server is running (in our case, it is <code class="email">node01</code>). To do so, you will need to install two packages named <code class="email">wget</code> and <code class="email">bzip2</code> first, using the following command:<div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">yum –y install wget bzip2 &amp;&amp; wget https://launchpad.net/test-db/employees-db-1/1.0.6/+download/employees_db-full-1.0.6.tar.bz2</strong></span></pre></div><p class="calibre15">Then, extract/unarchive its contents in your current working directory:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">tar xjf employees_db-full-1.0.6.tar.bz2</strong></span></pre></div></li><li class="listitem" value="3">This will create a subdirectory named <code class="email">employees_db</code>, where the main installation script (<code class="email">employees.sql</code>) resides, as can be seen in the output of the following two commands:<div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">cd employees_db</strong></span>
<span class="strong"><strong class="calibre2">ls</strong></span></pre></div></li><li class="listitem" value="4">Next, use the following command to connect to the cluster database server we set up and configured in <a class="calibre1" title="Chapter 4. Real-world Implementations of Clustering" href="part0030_split_000.html#SJGS1-1d2c6d19b9d242db82da724021b51ea0">Chapter 4</a>, <span class="strong"><em class="calibre9">Real-world Implementations of Clustering</em></span> (note that you will be prompted to enter the password for the root MariaDB user):<div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">mysql -h 192.168.0.4 -u root -p -t &lt; employees.sql</strong></span></pre></div></li><li class="listitem" value="5">This will<a id="id254" class="calibre1"/> also install the employees database<a id="id255" class="calibre1"/> and load the corresponding information into its tables:<div class="book"><ul class="itemizedlist1"><li class="listitem"><code class="email">departments</code></li><li class="listitem"><code class="email">employees</code></li><li class="listitem"><code class="email">dept_emp</code></li><li class="listitem"><code class="email">dept_manager</code></li><li class="listitem"><code class="email">titles</code></li><li class="listitem"><code class="email">salaries</code></li></ul></div><div class="note" title="Note"><h3 class="title2"><a id="note28" class="calibre1"/>Note</h3><p class="calibre8">After you are done setting up the sample database, feel free to perform a forced failover to verify that the resources and the database, along with their tables and records, become available in the current passive node. Review chapter 4 to recall instructions if you need.</p></div><p class="calibre15">Due to the high volume of data being loaded into the database, it is to be expected that the installation may take around a minute or two to complete. While we are at it, we will see the progress of the import process: the database structure and the storage engine are instantiated, then the tables are created, and finally, they are populated with data, as shown here:</p><div class="mediaobject"><img src="../images/00068.jpeg" alt="Downloading and installing the Employees database" class="calibre10"/></div><p class="calibre13"> </p></li><li class="listitem" value="6">We can <a id="id256" class="calibre1"/>verify by logging into the database <a id="id257" class="calibre1"/>server and issuing these commands to first list all databases. Then, switch to the recently installed Employees database, and use it for the subsequent queries:<div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">SHOW DATABASES;</strong></span>
<span class="strong"><strong class="calibre2">USE employees;</strong></span>
<span class="strong"><strong class="calibre2">SHOW TABLES;</strong></span></pre></div></li><li class="listitem" value="7">The output should be similar to the one shown in the preceding screenshot.<div class="mediaobject"><img src="../images/00069.jpeg" alt="Downloading and installing the Employees database" class="calibre10"/></div><p class="calibre13"> </p></li><li class="listitem" value="8">Before we<a id="id258" class="calibre1"/> proceed with the actual performance<a id="id259" class="calibre1"/> tests (measuring general performance before and after a failover event), feel free to investigate those tables (and the fields they contain) using the <code class="email">DESCRIBE</code> statement. Then browse the records with the <code class="email">SELECT</code> statement, as shown here:<div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">DESCRIBE salaries;</strong></span>
<span class="strong"><strong class="calibre2">SELECT * FROM salaries LIMIT 5;</strong></span></pre></div></li><li class="listitem" value="9">The result can be seen in the following screenshot:<div class="mediaobject"><img src="../images/00070.jpeg" alt="Downloading and installing the Employees database" class="calibre10"/></div><p class="calibre13"> </p></li></ol><div class="calibre14"/></div><p class="calibre8">Once you<a id="id260" class="calibre1"/> have taken some time to become acquainted <a id="id261" class="calibre1"/>with the structure of the database, we are ready to proceed with the tests.</p></div></div></div>

<div id="page" style="height:0pt"/><div class="book" title="Introducing initial cluster tests"><div class="book" id="1BRPS2-1d2c6d19b9d242db82da724021b51ea0"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch06lvl1sec40" class="calibre1"/>Introducing initial cluster tests</h1></div></div></div><p class="calibre8">In addition, for the actual performance tests, you should note that MariaDB comes with several database-related utilities that can come in handy for a variety of administration tasks. One <a id="id262" class="calibre1"/>of them is <code class="email">mysqlshow</code>, which returns complete information about databases and tables in one quick command.</p><p class="calibre8">Its generic syntax is as follows:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">mysqlshow [options] [db_name [tbl_name [col_name]]]</strong></span></pre></div><p class="calibre8">So, we could use the following command to display the description for the titles table in the <code class="email">employees</code> database:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">mysqlshow employees titles -h 192.168.0.4 -u root -p</strong></span></pre></div><div class="informalexample" title="Note"><h3 class="title2"><a id="note29" class="calibre1"/>Note</h3><p class="calibre8">You can list the complete set of utilities that are included in your MariaDB installation using the <code class="email">ls /bin | grep mysql</code> command. Each of those tools has a corresponding manual page, which can be invoked from the command line as usual.</p></div><p class="calibre8">We will use another of the tools that are included by MariaDB to see how our database server performs when placed under significant load. The tool is <code class="email">mysqlslap</code>, a diagnostic program designed to emulate client load for a <a id="id263" class="calibre1"/>MariaDB/MySQL server and to report the timing of each stage. It works as if multiple clients are accessing the server simultaneously.</p><p class="calibre8">Before <a id="id264" class="calibre1"/>executing the actual commands that we will use in the following tests, we will introduce a few of the flags available for <code class="email">mysqlslap</code>:</p><div class="book"><ul class="itemizedlist"><li class="listitem"><code class="email">--create-schema</code>: This command specifies the database in which we will run <a id="id265" class="calibre1"/>the tests</li><li class="listitem"><code class="email">--query</code>: This<a id="id266" class="calibre1"/> is a string (or alternatively, a file) containing the <code class="email">SELECT</code> statements used to retrieve data</li><li class="listitem"><code class="email">--delimiter</code>: This <a id="id267" class="calibre1"/>command allows you to specify a delimiter to separate multiple queries in the same string in <code class="email">--query</code></li><li class="listitem"><code class="email">--concurrency</code>: This <a id="id268" class="calibre1"/>command is the number of simultaneous connections to simulate</li><li class="listitem"><code class="email">--iterations</code>: This<a id="id269" class="calibre1"/> is the number of times to run the tests</li><li class="listitem"><code class="email">--number-of-queries</code>: This command limits each client (refer to <code class="email">--concurrency</code>) to<a id="id270" class="calibre1"/> that amount of queries</li></ul></div><p class="calibre8">In addition, there are other switches listed in the manual page for <code class="email">mysqlslap</code> that you can use if you want.</p><p class="calibre8">That said, we will run the following tests against the database server in our cluster.</p></div>

<div class="book" title="Introducing initial cluster tests">
<div class="book" title="Test 1 – retrieving all fields from all records"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch06lvl2sec22" class="calibre1"/>Test 1 – retrieving all fields from all records</h2></div></div></div><p class="calibre8">In this<a id="id271" class="calibre1"/> first test, we will perform a rather simple query that consists of retrieving all fields from all records in the employees table. We will simulate <code class="email">10</code> concurrent connections and make <code class="email">50</code> queries overall. This will result in clients running <code class="email">5</code> queries each (50/10 = 5):</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">mysqlslap --create-schema=employees --query="SELECT * FROM employees" --concurrency=10 --iterations=2 --number-of-queries=50 -h 192.168.0.4 -u root -p</strong></span></pre></div><p class="calibre8">After a couple of minutes, you will be able to see output similar to the one shown in the following screenshot. Although here we list the result of an isolated test, you may want to perform this operation several times on your own and write down the results for a later comparison. However, if you choose to do so, make sure that the query results are not cached by<a id="id272" class="calibre1"/> running the following command in your MariaDB server session after each run:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">RESET QUERY CACHE;</strong></span></pre></div><div class="mediaobject"><img src="../images/00071.jpeg" alt="Test 1 – retrieving all fields from all records" class="calibre10"/></div><p class="calibre11"> </p></div></div>

<div class="book" title="Introducing initial cluster tests">
<div class="book" title="Test 2 – performing JOIN operations"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch06lvl2sec23" class="calibre1"/>Test 2 – performing JOIN operations</h2></div></div></div><p class="calibre8">In this <a id="id273" class="calibre1"/>second test, we will do a <code class="email">JOIN</code> operation between the employees and salaries tables (a more realistic example) and modify the number of connections, queries, and iterations a bit:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">mysqlslap --create-schema=employees --query="SELECT A.first_name, A.last_name, B.salary FROM employees A JOIN salaries B on A.emp_no = B.emp_no" --concurrency=3 --number-of-queries=12 --iterations=2 -h 192.168.0.4 -u root -p</strong></span></pre></div><p class="calibre8">In the following screenshot, we can see an expected increase in the time it took to run the queries this time:</p><div class="mediaobject"><img src="../images/00072.jpeg" alt="Test 2 – performing JOIN operations" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">Before proceeding further, feel free to play around with the number of connections, iterations, and queries, or with the query itself. Based on these values, you may knock the database server down. That is to be expected at some point, since we have been building our infrastructure and examples on a virtual machine-based cluster. For this reason, you may want to increase the processing resources on each node's Virtualbox configuration to the extent of the<a id="id274" class="calibre1"/> available capacity, or consider acquiring real hardware to set up your cluster.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="note30" class="calibre1"/>Note</h3><p class="calibre8">Database administration and optimization are topics out of the scope of this book. It is strongly recommended that you also take these subjects into account before moving the cluster to a production environment. Since the performance of the database and web servers can be optimized separately through their corresponding settings, in this book, we will focus our efforts on analyzing and improving the availability of these resources (which we have named <code class="email">dbserver</code> and <code class="email">webserver</code> respectively) using their respective configuration files and internal settings.</p></div></div></div>

<div class="book" title="Introducing initial cluster tests">
<div class="book" title="Performing a failover"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_3"><a id="ch06lvl2sec24" class="calibre1"/>Performing a failover</h2></div></div></div><p class="calibre8">We will now<a id="id275" class="calibre1"/> force a failover by stopping the cluster functionality on the node where all the resources are currently running (<code class="email">node01</code>) so that they will move to <code class="email">node02</code>. Here, we will perform tests 1 and 2, and we expect to see a similar behavior to what we saw earlier. It is important to keep in mind that during a failover, data is not encrypted automatically. If you have concerns about sensitive data being failed over an unsecured connection, you should take the necessary precaution to use encryption either at the filesystem or at the Logical Volume level. Before we do this, however, we must keep in mind that moving a sensitive resource, such as a database server, around a cluster constantly may negatively impact the availability of such resource. For this reason, we will want it to remain in the node where it is active unless in the case that there is an actual node shutdown. The concept of resource stickiness does exactly this: it allows us to instruct all cluster resources to either fall back to their original node when it becomes available again after an outage, or to remain where they are currently active. The following syntax is used to specify the default value for all resources:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">pcs resource defaults resource-stickiness=value</strong></span></pre></div><p class="calibre8">The higher the value, the more the resource will prefer to stay where it is. By default, Pacemaker uses <code class="email">0</code> as value, which tells the cluster that it is desired (and optimal) to move the resource around in the case of failover. To specify the stickiness of a specific resource, use the following syntax to set the stickiness for a specific resource:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">pcs resource meta &lt;resource_id&gt; stickiness=value</strong></span></pre></div><p class="calibre8">Let's assume that you use <code class="email">INFINITY</code> as the value in the preceding command:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">pcs resource defaults resource-stickiness=INFINITY</strong></span>
<span class="strong"><strong class="calibre2">pcs resource meta &lt;resource_id&gt; stickiness=INFINITY</strong></span></pre></div><p class="calibre8">(Where you need to replace <code class="email">resource_id</code> with the actual resource identification)</p><p class="calibre8">Then, both the default stickiness for all resources and for the resource identified by <code class="email">resource_id</code> will be set to <code class="email">INFINITY</code>. That being said, let's now perform the failover. Take note of the current node and resource status by using the following command:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">pcs status</strong></span></pre></div><p class="calibre8">Then, stop<a id="id276" class="calibre1"/> the cluster by using the following command:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">pcs cluster stop</strong></span></pre></div><p class="calibre8">Then, verify that all resources have been properly started on the other node. If not, troubleshoot using the tools explained in <a class="calibre1" title="Chapter 5. Monitoring the Cluster Health" href="part0041_split_000.html#173721-1d2c6d19b9d242db82da724021b51ea0">Chapter 5</a>, <span class="strong"><em class="calibre9">Monitoring the Cluster Health</em></span>. Finally, proceed to run tests 1 and 2 on <code class="email">node02</code>.</p><p class="calibre8">The results in our present case are explained here.</p><p class="calibre8">For test 1, refer to the following screenshot:</p><div class="mediaobject"><img src="../images/00073.jpeg" alt="Performing a failover" class="calibre10"/><div class="caption"><p class="calibre17">Summarizing results of test 1 on both nodes</p></div></div><p class="calibre11"> </p><p class="calibre8">For our convenience, let's put both results in the following for a quick comparison:</p><div class="informalexample"><table border="1" class="calibre18"><colgroup class="calibre19"><col class="calibre20"/><col class="calibre20"/><col class="calibre20"/></colgroup><thead class="calibre21"><tr class="calibre22"><th valign="bottom" class="calibre23"><p class="calibre24">TEST 1 [seconds]</p></th><th valign="bottom" class="calibre23"><p class="calibre24">Node01</p></th><th valign="bottom" class="calibre23"><p class="calibre24">Node02</p></th></tr></thead><tbody class="calibre25"><tr class="calibre22"><td valign="top" class="calibre26"><p class="calibre24">Average, all queries</p></td><td valign="top" class="calibre26"><p class="calibre24">20.770</p></td><td valign="top" class="calibre26"><p class="calibre24">20.179</p></td></tr><tr class="calibre22"><td valign="top" class="calibre26"><p class="calibre24">Minimum, all queries</p></td><td valign="top" class="calibre26"><p class="calibre24">20.242</p></td><td valign="top" class="calibre26"><p class="calibre24">19.930</p></td></tr><tr class="calibre22"><td valign="top" class="calibre26"><p class="calibre24">Maximum, all queries</p></td><td valign="top" class="calibre26"><p class="calibre24">21.298</p></td><td valign="top" class="calibre26"><p class="calibre24">20.428</p></td></tr></tbody></table></div><p class="calibre8">On the other hand, for test 2, the following screenshot and the next table show the details:</p><div class="mediaobject"><img src="../images/00074.jpeg" alt="Performing a failover" class="calibre10"/><div class="caption"><p class="calibre17">Summarizing results of test 2 on both nodes</p></div></div><p class="calibre11"> </p><div class="informalexample"><table border="1" class="calibre18"><colgroup class="calibre19"><col class="calibre20"/><col class="calibre20"/><col class="calibre20"/></colgroup><thead class="calibre21"><tr class="calibre22"><th valign="bottom" class="calibre23"><p class="calibre24">TEST 2 [seconds]</p></th><th valign="bottom" class="calibre23"><p class="calibre24">Node01</p></th><th valign="bottom" class="calibre23"><p class="calibre24">Node02</p></th></tr></thead><tbody class="calibre25"><tr class="calibre22"><td valign="top" class="calibre26"><p class="calibre24">Average, all queries</p></td><td valign="top" class="calibre26"><p class="calibre24">40.008</p></td><td valign="top" class="calibre26"><p class="calibre24">39.084</p></td></tr><tr class="calibre22"><td valign="top" class="calibre26"><p class="calibre24">Minimum, all queries</p></td><td valign="top" class="calibre26"><p class="calibre24">38.713</p></td><td valign="top" class="calibre26"><p class="calibre24">38.779</p></td></tr><tr class="calibre22"><td valign="top" class="calibre26"><p class="calibre24">Maximum, all queries</p></td><td valign="top" class="calibre26"><p class="calibre24">41.304</p></td><td valign="top" class="calibre26"><p class="calibre24">39.389</p></td></tr></tbody></table></div><p class="calibre8">As you<a id="id277" class="calibre1"/> can see, the results are very similar in both cases, which confirms that the failover did not affect the performance of the database server running on top of our cluster. While it is true that the failover did not improve performance either, we can see that the availability of the resource during a failover has been confirmed with a negative impact on the functionality of the cluster.</p></div></div>

<div id="page" style="height:0pt"/><div class="book" title="Measuring and improving performance"><div class="book" id="1CQAE2-1d2c6d19b9d242db82da724021b51ea0"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch06lvl1sec41" class="calibre1"/>Measuring and improving performance</h1></div></div></div><p class="calibre8">You will recall from earlier chapters that by definition, a resource is a service that is made highly available by the cluster. Every resource is assigned what is called a <span class="strong"><strong class="calibre2">resource agent</strong></span>, an<a id="id278" class="calibre1"/> external shell script that manages the actual resource for the cluster, independently of how those services would be managed by systemd if they were left to its care. Thus, the actual operation of the resource is transparent <a id="id279" class="calibre1"/>to the cluster, since it is being managed by the resource agent.</p><p class="calibre8">Resource agents are found inside <code class="email">/usr/lib/ocf/resource.d</code>, so feel free to take a look at them to become better acquainted with their structure. In most circumstances, you will not need to modify them, but work on the specific resources' configuration files, as we shall see. You will recall from earlier chapters that adding a cluster resource involved using an argument of the <code class="email">standard:provider:resource_agent</code> form (<code class="email">ocf:heartbeat:mysql</code>, for example).You can also view the complete list of resource standards and providers with <code class="email">pcs resource standards</code> and <code class="email">pcs resource providers</code> respectively. Additionally, you can view the available agents for each <code class="email">standard:provider</code> pair with <code class="email">pcs resource agents standard:provider</code>.</p></div>

<div class="book" title="Measuring and improving performance">
<div class="book" title="Apache's configuration and settings"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_1"><a id="ch06lvl2sec25" class="calibre1"/>Apache's configuration and settings</h2></div></div></div><p class="calibre8">When the<a id="id280" class="calibre1"/> Apache web server is<a id="id281" class="calibre1"/> first installed, by default, it comes with<a id="id282" class="calibre1"/> several modules in the form of <span class="strong"><strong class="calibre2">Dynamic Shared Objects</strong></span> (<span class="strong"><strong class="calibre2">DSOs</strong></span>) that extend its functionality. The downside is that some of them may consume resources unnecessarily if they remain loaded and your applications don't' use them. As you can probably guess, this may lead to performance loss over time.</p><p class="calibre8">In CentOS 7, you can view the list of currently loaded and shared modules with <code class="email">httpd -M</code>. The following output is truncated for the sake of brevity, but should be very similar in your case:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">Loaded Modules:</strong></span>
<span class="strong"><strong class="calibre2"> core_module (static)</strong></span>
<span class="strong"><strong class="calibre2"> so_module (static)</strong></span>
<span class="strong"><strong class="calibre2"> http_module (static)</strong></span>
<span class="strong"><strong class="calibre2"> access_compat_module (shared)</strong></span>
<span class="strong"><strong class="calibre2"> actions_module (shared)</strong></span>
<span class="strong"><strong class="calibre2"> alias_module (shared)</strong></span>
<span class="strong"><strong class="calibre2"> allowmethods_module (shared)</strong></span>
<span class="strong"><strong class="calibre2"> auth_basic_module (shared)</strong></span>
<span class="strong"><strong class="calibre2"> auth_digest_module (shared)</strong></span>
<span class="strong"><strong class="calibre2"> authn_anon_module (shared)</strong></span>
<span class="strong"><strong class="calibre2"> authn_core_module (shared)</strong></span></pre></div><p class="calibre8">A careful<a id="id283" class="calibre1"/> inspection of the module<a id="id284" class="calibre1"/> list and solid knowledge of what your applications actually needs will help you define which modules are not needed, and thus, they can be unloaded for the time being.</p><p class="calibre8">Look at the following line in <code class="email">/etc/httpd/conf/httpd.conf</code>:</p><div class="informalexample"><pre class="programlisting">IncludeOptional conf.modules.d/*.conf</pre></div><p class="calibre8">This line indicates that Apache will look in the <code class="email">conf.modules.d</code> directory for instructions to load module inside <code class="email">.conf</code> files. For example, in the standard installation, <code class="email">00-base.conf</code> contains ~70 <code class="email">LoadModule</code> directives that point to DSOs inside /<code class="email">etc/httpd/modules</code>. It is in these <code class="email">.conf</code> files that you can enable or disable (by prepending each <code class="email">LoadModule</code> directive with a <code class="email">#</code> symbol, thus commenting that line) Apache modules. Note that this must be performed on both nodes.</p></div></div>

<div class="book" title="Measuring and improving performance">
<div class="book" title="Loading and disabling modules"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_2"><a id="ch06lvl2sec26" class="calibre1"/>Loading and disabling modules</h2></div></div></div><p class="calibre8">In<a id="id285" class="calibre1"/> the <a id="id286" class="calibre1"/>following screenshot, <code class="email">userdir_module</code> modules, <code class="email">version_module</code>, and <code class="email">vhost_alias_module</code> are loaded, whereas <code class="email">buffer_module</code>, <code class="email">watchdog_module</code>, and <code class="email">heartbeat_module</code> are disabled through <code class="email">00-base.conf</code>:</p><div class="mediaobject"><img src="../images/00075.jpeg" alt="Loading and disabling modules" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">For<a id="id287" class="calibre1"/> example, in order to disable<a id="id288" class="calibre1"/> the <code class="email">userdir</code> module, comment the corresponding <code class="email">LoadModule</code> directive in <code class="email">/etc/httpd/conf.modules.d/00-base.conf</code> on both nodes:</p><div class="informalexample"><pre class="programlisting">#LoadModule userdir_module modules/mod_userdir.so</pre></div><p class="calibre8">Restart the cluster resource on the node where it is currently active:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">pcs resource restart webserver</strong></span></pre></div></div></div>

<div class="book" title="Measuring and improving performance">
<div class="book" title="Placing limits on the number of Apache processes and children"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_3"><a id="ch06lvl2sec27" class="calibre1"/>Placing limits on the number of Apache processes and children</h2></div></div></div><p class="calibre8">In order for <a id="id289" class="calibre1"/>Apache<a id="id290" class="calibre1"/> to be able to handle as many simultaneous requests as needed, but preventing it from consuming more RAM than you can afford for your application(s), you need to set the <code class="email">MaxRequestWorkers</code> (called <code class="email">MaxClients</code> before version 2.3.13) directive to an appropriate value based mostly on the available physical memory that can be allotted in your specific environment. Note that if this value is set too high, you may bring the web server (and the resource altogether) to its knees.</p><p class="calibre8">On the other hand, setting it to an appropriate value, which is calculated based on the memory usage of each Apache process compared to the allotted RAM, will allow the web server to respond to that many requests at once. If the number of requests surpasses the capacity of the server, the extra requests will be served once the first ones have already been served, thus avoiding the resource from hanging for all connections.</p><p class="calibre8">For further<a id="id291" class="calibre1"/> details, refer to the Apache MPM Common directives documentation at <a class="calibre1" href="http://httpd.apache.org/docs/2.4/mod/mpm_common.html">http://httpd.apache.org/docs/2.4/mod/mpm_common.html</a>. Keep in mind that Apache fine-tuning is out of the scope of this book, and the actions mentioned here are generally not enough for production use.</p></div></div>

<div class="book" title="Measuring and improving performance">
<div class="book" title="Database resource"><div class="book"><div class="book"><div class="book"><h2 class="title1" id="calibre_pb_4"><a id="ch06lvl2sec28" class="calibre1"/>Database resource</h2></div></div></div><p class="calibre8">Since you <a id="id292" class="calibre1"/>will seldom use a web server<a id="id293" class="calibre1"/> without an accompanying database server, you also need to look on that side of things to improve performance. Here are some basic things you will want to look at.</p><div class="book" title="Creating indexes"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch06lvl3sec01" class="calibre1"/>Creating indexes</h3></div></div></div><p class="calibre8">A database <a id="id294" class="calibre1"/>containing tables of hundreds of thousands or<a id="id295" class="calibre1"/> million of records can quickly become a performance bottleneck when a typical <code class="email">SELECT-FROM-WHERE</code> statement is made to retrieve a specific record. Going through every row in a table to accomplish this is considered highly inefficient as it is performed at the hard disk level.</p><p class="calibre8">With indexes, the operation is performed in memory instead of disk, and records can be automatically sorted so that it's faster to find the one we want because an index only contains the actual sorted data and a link to the original data record. In addition, we can create an index for each column we need to sort by, so using indexes becomes a handy tool to improve performance.</p><p class="calibre8">To begin, exit your MariaDB session and run test 3 to measure performance without indexes:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">mysqlslap --create-schema=employees --query="SELECT * FROM employees WHERE emp_no=1007" --concurrency=15 --number-of-queries=150 --iterations=10 -h 192.168.0.4 -u root -p</strong></span></pre></div><p class="calibre8">Now, let's create indexes on the <code class="email">emp_no</code> field in the employees and salaries tables since we will use them in our <code class="email">WHERE</code> clause, and then perform test 3 again. Perform these steps:</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">First, log in to the database server using the following command:<div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">mysql -h 192.168.0.4 -u root -p</strong></span></pre></div></li><li class="listitem" value="2">Then, issue the following commands from the MariaDB shell:<div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">USE employees;</strong></span>
<span class="strong"><strong class="calibre2">RESET QUERY CACHE;</strong></span>
<span class="strong"><strong class="calibre2">CREATE INDEX employees_emp_no ON employees(emp_no);</strong></span>
<span class="strong"><strong class="calibre2">CREATE INDEX salaries_emp_no ON salaries(emp_no);</strong></span></pre></div></li><li class="listitem" value="3">After that, exit the MariaDB shell and run the test again to compare performance. The results are shown in the following screenshots and summarized against the previous example (without indexes) in the next table:<div class="mediaobject"><img src="../images/00076.jpeg" alt="Creating indexes" class="calibre10"/></div><p class="calibre13"> </p></li></ol><div class="calibre14"/></div><p class="calibre8">Now, let's<a id="id296" class="calibre1"/> look at the results of the same test, but this time <a id="id297" class="calibre1"/>using indexes:</p><div class="mediaobject"><img src="../images/00077.jpeg" alt="Creating indexes" class="calibre10"/><div class="caption"><p class="calibre17">Summarizing results of test 2 with and without indexes on node01</p></div></div><p class="calibre11"> </p><div class="informalexample"><table border="1" class="calibre18"><colgroup class="calibre19"><col class="calibre20"/><col class="calibre20"/><col class="calibre20"/></colgroup><thead class="calibre21"><tr class="calibre22"><th valign="bottom" class="calibre23"><p class="calibre24">TEST 3 (in seconds)</p></th><th valign="bottom" class="calibre23"><p class="calibre24">Node01 (without indexes)</p></th><th valign="bottom" class="calibre23"><p class="calibre24">Node01 (with indexes)</p></th></tr></thead><tbody class="calibre25"><tr class="calibre22"><td valign="top" class="calibre26"><p class="calibre24">Average, all queries</p></td><td valign="top" class="calibre26"><p class="calibre24">0.043</p></td><td valign="top" class="calibre26"><p class="calibre24">0.038</p></td></tr><tr class="calibre22"><td valign="top" class="calibre26"><p class="calibre24">Minimum, all queries</p></td><td valign="top" class="calibre26"><p class="calibre24">0.035</p></td><td valign="top" class="calibre26"><p class="calibre24">0.037</p></td></tr><tr class="calibre22"><td valign="top" class="calibre26"><p class="calibre24">Maximum, all queries</p></td><td valign="top" class="calibre26"><p class="calibre24">0.055</p></td><td valign="top" class="calibre26"><p class="calibre24">0.046</p></td></tr></tbody></table></div><p class="calibre8">The preceding screenshots demonstrate that creating indexes on searchable fields will improve performance as it will prevent the server from having to go through all rows before returning the results.</p></div><div class="book" title="Using query cache"><div class="book"><div class="book"><div class="book"><h3 class="title2"><a id="ch06lvl3sec02" class="calibre1"/>Using query cache</h3></div></div></div><p class="calibre8">In a MariaDB database server, the results of <code class="email">SELECT</code> queries are stored in a query cache so that <a id="id298" class="calibre1"/>when the exact same operation is performed<a id="id299" class="calibre1"/> again, the results can be returned faster. This is precisely the case in most modern websites where similar queries are made over and over again (high-read and low-write environments).</p><p class="calibre8">So, how does this happen at the server level? If an incoming query is not found in the cache, it will be processed normally and then stored, along with its result set, in the query cache. Otherwise, the results are pulled from the cache, which makes it possible to complete<a id="id300" class="calibre1"/> the operation much faster than if it was processed normally.</p><p class="calibre8">In MariaDB, the<a id="id301" class="calibre1"/> query cache is enabled by default (<code class="email">SHOW VARIABLES LIKE 'query'query'_cache_type';</code>), but its size is set to zero (<code class="email">SHOW VARIABLES LIKE 'query'query'_cache_size';</code>), as indicated in the following screenshot: </p><div class="mediaobject"><img src="../images/00078.jpeg" alt="Using query cache" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">For this reason, we need to set the query cache size variable to an appropriate value according to the use of our application. In the following screenshot, this variable is set to 100 KB (<code class="email">SET GLOBAL query_cache_size = 102400;</code>), and we can see that the query cache size has been updated accordingly:</p><div class="mediaobject"><img src="../images/00079.jpeg" alt="Using query cache" class="calibre10"/></div><p class="calibre11"> </p><p class="calibre8">Note that the right value for the query cache size will depend largely, if not entirely, on the needs of your specific case. Setting it too high will result in performance degradation as the system will have to allocate extra resources to manage a large cache. On the other hand, setting it to a very low value will cause at least some repeated queries to be processed<a id="id302" class="calibre1"/> normally and not be cached. In the preceding <a id="id303" class="calibre1"/>example, we allocated 100 KB of data as cache to store queries and their corresponding results.</p><p class="calibre8">For further details, refer to the <a id="id304" class="calibre1"/>MariaDB documentation (<a class="calibre1" href="https://mariadb.com">https://mariadb.com</a>), specifically to the <span class="strong"><em class="calibre9">Managing MariaDB/Optimization and tuning</em></span> section.</p><div class="informalexample" title="Note"><h3 class="title2"><a id="note31" class="calibre1"/>Note</h3><p class="calibre8">The MariaDB documentation contains very helpful information to tune a database server starting from the ground up (all the way from the operating system level through query optimization). Other tools to increase performance and stability are <a id="id305" class="calibre1"/>MySQL tuner (<a class="calibre1" href="http://mysqltuner.com/">http://mysqltuner.com/</a>), MySQL<a id="id306" class="calibre1"/> Tuning Primer (<a class="calibre1" href="https://launchpad.net/mysql-tuning-primer">https://launchpad.net/mysql-tuning-primer</a>), and phpMyAdmin<a id="id307" class="calibre1"/> Advisor (<a class="calibre1" href="https://www.phpmyadmin.net/">https://www.phpmyadmin.net/</a>). The last tool is available in the <span class="strong"><strong class="calibre2">Status</strong></span> tab of a standard phpMyAdmin installation.</p></div></div></div></div>
<div class="book" title="Moving to an A/A cluster"><div class="book" id="1DOR02-1d2c6d19b9d242db82da724021b51ea0"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch06lvl1sec42" class="calibre1"/>Moving to an A/A cluster</h1></div></div></div><p class="calibre8">As you will recall from the introduction of <a class="calibre1" title="Chapter 3. A Closer Look at High Availability" href="part0023_split_000.html#LTSU2-1d2c6d19b9d242db82da724021b51ea0">Chapter 3</a>, <span class="strong"><em class="calibre9">A Closer Look at High Availability</em></span>, A/A clusters tend to provide higher availability as several nodes are actively running applications at the same time (which, by the way, requires that the necessary data for those<a id="id308" class="calibre1"/> applications be available simultaneously on all cluster members). The downside is that if one or more nodes go offline, the remaining ones are assigned extra processing load, thus negatively impacting the overall performance of the cluster.</p><p class="calibre8">That being said, let's examine briefly the required steps to convert our current A/P cluster to an A/A one. Make sure a STONITH resource has been defined (refer to chapter 3 for further details).</p><div class="book"><ol class="orderedlist"><li class="listitem" value="1">Enable STONITH resource by using the following command:<div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">pcs property set stonith-enabled=trueInstall</strong></span></pre></div></li><li class="listitem" value="2">Install the additional software that will be needed for this:<div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">yum update &amp;&amp; yum install gfs2-utils dlm</strong></span></pre></div><p class="calibre15">As opposed to a traditional journaling filesystem such as <code class="email">ext4</code> (which we have used for our filesystems up until this point in the book), you will need a way to ensure that all nodes are granted simultaneous access to the same block storage. <span class="strong"><strong class="calibre2">Global File System 2</strong></span> (also known as <span class="strong"><strong class="calibre2">GFS2</strong></span>) provides<a id="id309" class="calibre1"/> such a feature through its command-line tools, which are included in the <code class="email">gfs2-utils</code> package.</p></li><li class="listitem" value="3">In addition, the <code class="email">dlm</code> package will install the <span class="strong"><strong class="calibre2">Distributed Lock Manager</strong></span> (also known as <span class="strong"><strong class="calibre2">DLM</strong></span>), a requirement in cluster filesystems to synchronize access to<a id="id310" class="calibre1"/> shared resources. Add (and clone) the Distributed Lock Manager as a cluster resource of the <code class="email">ocf</code> class, pacemaker provider, and <code class="email">controld</code> class:<div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">pcs cluster cib dlm_cfg</strong></span>
<span class="strong"><strong class="calibre2">pcs -f dlm_cfg resource create dlm ocf:pacemaker:controld op monitor interval=60s</strong></span>
<span class="strong"><strong class="calibre2">pcs -f dlm_cfg resource clone dlm clone-max=2 clone-node-max=1</strong></span></pre></div></li><li class="listitem" value="4">Now, push<a id="id311" class="calibre1"/> the newly created resource to the CIB:<div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">pcs cluster cib-push dlm_cfg</strong></span></pre></div></li><li class="listitem" value="5">Choose a replicated storage resource and create a <code class="email">gfs2</code> filesystem on top of its associated device node.<p class="calibre15">For example, let's use the <code class="email">/dev/drbd0</code> device we created in <a class="calibre1" title="Chapter 4. Real-world Implementations of Clustering" href="part0030_split_000.html#SJGS1-1d2c6d19b9d242db82da724021b51ea0">Chapter 4</a>, <span class="strong"><em class="calibre9">Real-world Implementations of Clustering</em></span>. We will need to unmount it from the node with the DRBD primary role (most likely, <code class="email">node01</code>) before we can create a <code class="email">gfs2</code> filesystem on it:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">umount /dev/drbd0</strong></span>
<span class="strong"><strong class="calibre2">mkfs.gfs2 -p lock_dlm -j 2 -t MyCluster:Web /dev/drbd0</strong></span></pre></div><p class="calibre15">Here, as you can see in the following screenshot, <code class="email">MyCluster</code> is the original name of our cluster, <code class="email">Web</code> is a random name, and the <code class="email">-j</code> flag is used to indicate that the filesystem will use two journals (in this case one for each node - you will want to change this number if your cluster consists in more nodes). Finally, the <code class="email">-p</code> option tells us that we are going to use the DLM provided by the kernel:</p><div class="mediaobject"><img src="../images/00080.jpeg" alt="Moving to an A/A cluster" class="calibre10"/></div><p class="calibre13"> </p><p class="calibre15">You will <a id="id312" class="calibre1"/>also need to change the <code class="email">fstype</code> option of the <code class="email">web_fs</code> resource from <code class="email">ext4</code> (the original filesystem used when we first created it in <a class="calibre1" title="Chapter 4. Real-world Implementations of Clustering" href="part0030_split_000.html#SJGS1-1d2c6d19b9d242db82da724021b51ea0">Chapter 4</a>, <span class="strong"><em class="calibre9">Real-world Implementations of Clustering</em></span>) to <code class="email">gfs2</code> in the PCS resource configuration:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">pcs resource update web_fs fstype=gfs2</strong></span></pre></div><p class="calibre15">It is important to note that if the cluster attempts to start <code class="email">web_fs</code> before <code class="email">dlm-clone</code>, we will run into an issue (we cannot mount a <code class="email">gfs2</code> filesystem if the <code class="email">dlm</code> functionality is not present). Thus, we need to add colocation and ordering constraints so that <code class="email">web_fs</code> will always start on the node where <code class="email">dlm-clone</code> starts:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">pcs constraint colocation add web_fs with dlm-clone INFINITY</strong></span></pre></div><p class="calibre15"><code class="email">anddlm-clone</code> will be started before <code class="email">web_fs</code>.</p></li><li class="listitem" value="6">The <code class="email">pcs constraint</code> order <code class="email">dlm-clone</code> then <code class="email">web_fsClone</code> the virtual IP address resource.<p class="calibre15">Cloning the IP address will allow us to effectively use resources on both nodes, but at the same time, any given packet will be sent to only one node (thus, implementing a basic load-balancing method in our cluster):</p><p class="calibre15">To do this, we will save the cluster configuration to a file named <code class="email">load_balancing_cfg</code> and update such file with the :</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">pcs cluster cib load_balancing_cfg</strong></span></pre></div><p class="calibre15">You will notice from the pcs resource help that the clone operation allows you to specify certain options. In the following lines, <code class="email">clone-max</code> specifies the number of nodes that host the <code class="email">virtual_ip</code> resource (2 in this case), whereas clone-node-max indicates the number of resource instances each node is allowed to run. Next, <code class="email">globally-unique</code> instructs the resource agent that each node is distinct from the rest and thus, handles distinct traffic as well. Finally, <code class="email">clusterip_hash=sourceip</code> tells us that the packet's source IP address will be used to decide which node gets to process which request:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">pcs -f load_balancing_cfg resource clone virtual_ip clone-max=2 clone-node-max=2 globally-unique=true</strong></span>
<span class="strong"><strong class="calibre2">pcs -f load_balancing_cfg resource update virtual_ip clusterip_hash=sourceip</strong></span></pre></div><p class="calibre15">The next steps consists of  cloning the filesystem and Apache and/or MariaDB resources. Note that in order to allow two primaries in a DRBD device so that you can serve content from both at the same time, you will need to set the allow-two-primaries directive to yes (<code class="email">allow-two-primaries yes;</code>) in the net section of the resource configuration file (<code class="email">/etc/drbd.d/drbd0.res</code>, for example):</p><div class="informalexample"><pre class="programlisting">resource drbd0
  net {
    protocol C;
    allow-two-primaries yes;
  }
  ...
}</pre></div></li><li class="listitem" value="7">Once again, save the current CIB to a local file and add the clone resource information. In the next example, we will use <code class="email">web_fs</code>, <code class="email">web_drbd_clone</code> and <code class="email">webserver</code>:<div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">pcs cluster cib current_cfg</strong></span>
<span class="strong"><strong class="calibre2">pcs -f current_cfg resource clone web_fs</strong></span>
<span class="strong"><strong class="calibre2">pcs -f current_cfg resource clone webserver</strong></span></pre></div></li><li class="listitem" value="8">Now, <code class="email">web_drbd</code> should be allowed to serve both instances as primary or master:<div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">pcs -f current_cfg resource update web_drbd_clone master-max=2</strong></span></pre></div></li><li class="listitem" value="9">Then, activate the new configuration:<div class="informalexample"><pre class="programlisting"><span class="strong"><strong class="calibre2">pcs cluster cib-push current_cfg</strong></span></pre></div></li><li class="listitem" value="10">Last but not least, you need to keep in mind that you will need to set the value of the resource stickiness to <code class="email">0</code> in order for it to return an instance to its original node after a failover. To do so, refer to the <span class="strong"><em class="calibre9">Performing a failover</em></span> section this same chapter.</li></ol><div class="calibre14"/></div><p class="calibre8">You can<a id="id313" class="calibre1"/> now proceed to force a failover as usual, and test the resource availability. Unfortunately, this is not possible in a Virtualbox environment as I have explained previously. However, it's entirely possible if you are able to build your cluster with real hardware and an actual STONITH device.</p></div>
<div class="book" title="Summary" id="1ENBI1-1d2c6d19b9d242db82da724021b51ea0"><div class="book"><div class="book"><div class="book"><h1 class="title" id="calibre_pb_0"><a id="ch06lvl1sec43" class="calibre1"/>Summary</h1></div></div></div><p class="calibre8">In this last chapter, we set up a couple of performance testing tools for the example services that you need to make highly available in your cluster, and provided a few suggestions to optimize their performance separately as well. Note that those suggestions are not intended to represent an exhaustive list of tuning methods, but a starting point instead. We have also provided the overall instructions so that you can convert an A/P cluster into an A/A one.</p><p class="calibre8">Finally, keep in mind that this book was written using virtual machines instead of specialized hardware. Thus, we have run into some associated limitations, such as the lack for real STONITH devices that would otherwise have allowed us to actually demonstrate the functionalities of an A/A cluster. However, the principles outlined in this book will undoubtedly be a guide to set up your own clusters, whether you are experimenting with virtual machines as well or using real hardware.</p><p class="calibre8">Best of success in your endeavors!</p></div></body></html>