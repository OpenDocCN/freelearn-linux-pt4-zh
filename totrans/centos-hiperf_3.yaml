- en: Chapter 3. A Closer Look at High Availability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will look at the components of a high-availability cluster
    in greater detail than we were able to do initially during [Chapter 1](part0014_split_000.html#DB7S1-1d2c6d19b9d242db82da724021b51ea0
    "Chapter 1. Cluster Basics and Installation on CentOS 7"), *Cluster Basics and
    Installation on CentOS 7*; you may want to review that chapter in order to refresh
    your memory before proceeding further.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Failover—a premier on high availability and performance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fencing — isolating the malfunctioning nodes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Split brain — preparing to avoid inconsistencies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quorum — scoring inside your cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring our cluster via PCS GUI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will set out on this chapter by asking ourselves a few questions about how
    to achieve high availability, and we will attempt to get our answers as we go
    along. In the next chapter, we will set up actual real-life examples:'
  prefs: []
  type: TYPE_NORMAL
- en: How can we ensure an automatic failover without the need for human intervention?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How many nodes are needed in a cluster in order to ensure high availability
    in several failure scenarios?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do we consistently ensure data integrity and high availability when an offline
    node comes online again?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Overall, clusters can be classified into two main categories. For simplicity,
    we will use a cluster consisting of two nodes for the following definitions, but
    the concept can be easily extended to a cluster with a higher number of members:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Active/Active (A/A)**: In this type of cluster, all nodes are active at the
    same time. Thus, they are able to serve requests simultaneously and equally, each
    with independent workloads. When a failover is necessary, the remaining node is
    assigned an additional processing load, thus impacting the overall performance
    of the cluster negatively.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Active/Passive (A/P)**: In this type of cluster, there is an active node
    and a passive node. The former handles all traffic under normal circumstances,
    while the latter just sits idle waiting to enter the scene during a failover,
    when it actually takes over the situation by servicing requests using its own
    resources until the other node comes back online.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you can infer from the last two paragraphs, an A/P cluster presents a clearly
    desired advantage over A/A, wherein, in the event of a failover, the same percentage
    of hardware and software resources is made available to end users. This results
    in a constant performance level in a transparent way, which is specially desired
    in database servers, where performance is a critical requirement. On the other
    hand, A/A clusters usually provide higher availability since at least two servers
    actively run applications and provide services to end users. In the next chapter,
    you will notice that we will initially set up an A/P cluster in detail and also
    provide the overall instructions to convert it into an A/A cluster if you wish
    to do so at a later stage.
  prefs: []
  type: TYPE_NORMAL
- en: Failover – an introduction to high availability and performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The failover process can be roughly described as the action of switching, in
    the event of power or network failure, to an available resource to resume operations
    with the least downtime as possible, with no downtime being the primary goal of
    high availability clusters.
  prefs: []
  type: TYPE_NORMAL
- en: 'In [Chapter 2](part0018_split_000.html#H5A42-1d2c6d19b9d242db82da724021b51ea0
    "Chapter 2. Installing Cluster Services and Configuring Network Components"),
    *Installing Cluster Services and Configuring Network Components*, we configured
    a simple but essential resource for our purposes: a virtual IP address. You will
    also recall that in order to start becoming acquainted with PCS—the tool that
    is used as a frontend to PCS (the configuration manager)—we presented a brief
    introduction to its basic syntax and usage.'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As in other cases in the Linux ecosystem, the program/protocol/package name
    is written in caps, while the tool and utility is written in lowercase. Thus,
    PCS is used to indicate the package name, and it is the command-line utility that
    is used to manage PCS.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the `pcs status` command, we will be able to view the current status of
    the cluster and several important pieces of information, as shown in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Failover – an introduction to high availability and performance](img/00024.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The following lines present the cluster resources that are currently available
    for `MyCluster`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: As indicated, the virtual IP address (conveniently named `virtual_ip` in [Chapter
    2](part0018_split_000.html#H5A42-1d2c6d19b9d242db82da724021b51ea0 "Chapter 2. Installing
    Cluster Services and Configuring Network Components"), *Installing Cluster Services
    and Configuring Network Components*) is started on `node01`. Since the virtual
    IP is a cluster resource, it is to be expected that in case the node fails, an
    automatic failover of this resource is triggered to `node02`. We will simulate
    a node going offline due to a real issue by stopping both `corosync` and `pacemaker`
    on that cluster member.
  prefs: []
  type: TYPE_NORMAL
- en: For our current purposes, this simulation will not entitle shutting down (power
    off) the node because we want to show something interesting in the output of `pcs
    status` after stopping `corosync` and `pacemaker` in that node.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can also simulate a failover by pausing one of the virtual machines in VirtualBox
    (select the **VM** option in **Oracle VM VirtualBox Manager** and press *Ctrl*
    + *P* or choose **Pause** from the **Machine Menu**), and you can also do it by
    disabling the networking using the `systemctl disable network` command in that
    node.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s stop `pacemaker` and `corosync` in `node01`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'And run again, but on the other node, that is `node02`, using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'To view the current status of the cluster, its nodes, and resources, which
    is shown in the following screenshot, you will need to run `pcs status` on the
    node where the cluster is currently running:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Failover – an introduction to high availability and performance](img/00025.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: There are a few lines from the preceding screenshot that are worth discussing.
  prefs: []
  type: TYPE_NORMAL
- en: 'The **OFFLINE: [ node01 ]** line indicates that `node01` is offline—as far
    as the cluster as a whole is concerned—which is what we were expecting after stopping
    the cluster resource manager and the messaging services in that member. However,
    the following code indicates that the `pcsd` daemon, the remote configuration
    interface, is still running on `node01`, which makes it possible to still control
    `pacemaker` and `corosync` in that node, either locally or remotely from another
    node:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, the `virtual_ip (ocf::heartbeat:IPaddr2): Started node02` command
    allows us to see that the failover of the virtual IP from `node01` to `node02`
    was performed automatically and without errors. If, for some reason, you run into
    errors while performing the virtual IP address failover, you will want to check
    the related logs for information as to what could have gone wrong.'
  prefs: []
  type: TYPE_NORMAL
- en: For example, let's examine a case where the cluster resource does not have another
    node to failover to. Picture a scenario where `node02` is offline (either because
    you paused the **VM** or actually shut it down), and all of a sudden, `node01`
    goes down as well (remember that we are talking about the clustering services
    not being available instead of an actual power or network outage). Of course,
    all of this happens behind the scenes—the only thing that you know right now is
    that you have users complaining that they cannot access whatever application,
    resource, or service is being offered from your cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing you may feel inclined to try is to see whether the virtual
    IP address is pingable from within your network (change the IP address as per
    your choice while configuring the resource at the end of [Chapter 2](part0018_split_000.html#H5A42-1d2c6d19b9d242db82da724021b51ea0
    "Chapter 2. Installing Cluster Services and Configuring Network Components"),
    *Installing Cluster Services and Configuring Network Components*):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'You will notice that none of the four packets was able to reach its intended
    destination:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'For that reason, go to `node01`, where you first started the resource to check
    on the node''s status:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Then you see that the cluster is down on `node01`. But wasn''t the failover
    supposed to happen automatically? At this point, you have two options:'
  prefs: []
  type: TYPE_NORMAL
- en: Go to `node02` to check whether the cluster is running there.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check the logs on `node01`. Note that this assumes that you shut down `node02`
    and then `node01`. In any event, you want to check the log in the node that you
    shut down last.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A brief search for the keyword `virtual_ip` in `/var/log/pacemaker.log` (or
    whatever name you set for the resource during the last stages of [Chapter 2](part0018_split_000.html#H5A42-1d2c6d19b9d242db82da724021b51ea0
    "Chapter 2. Installing Cluster Services and Configuring Network Components"),
    *Installing Cluster Services and Configuring Network Components*) in `node01`
    tells you what the problem is. Here is a brief excerpt of the `grep virtual_ip
    /var/log/pacemaker.log` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The first message indicates that `virtual_ip` was stopped on `node01`, and
    the second message states that it could not be failed over anywhere. The result
    is that the resource is left as `Stopped` (as outlined in the third message) until
    it is manually re-enabled from either node in the cluster. However, remember that
    you need to start the cluster on such a node beforehand:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, run the following command on `node01`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'A further check on `pcs status` may or may not indicate that the resource is
    still stopped (it is a good idea to ping the virtual IP address here as well).
    If `virtual_ip` refuses to start, we can use the following command to obtain verbose
    information about why this particular resource is not being started properly,
    and then perform a reset of the cluster resource to make it reload its proper
    configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Remember that `pcs` takes an option (not required) and a command as arguments,
    which may in turn be followed by specific options. In this regard, `pcs cluster
    stop`, where `cluster` is the command and `stop` represents a specific action
    of such a command, can be used to shut down `corosync` and `pacemaker` on either
    the local node, all nodes, or a specific node. In the following extract of `man
    pcs` you can review the syntax of pcs cluster stop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Remember that when `corosync` and `pacemaker` are running on both nodes, you
    can run any PCS command to configure the cluster from any of the nodes. In the
    event of a severe failure, where `pcsd` becomes unavailable on both nodes, you
    will have to resort to using SSH authentication from one node to the other to
    troubleshoot and fix issues.
  prefs: []
  type: TYPE_NORMAL
- en: 'As it happens in other cases, log files are the best friends of system administrators,
    and they can play a key role in helping you to find out what the root causes of
    issues are when they happen. There are three logs that you may want to check once
    in a while and even as you are performing a failover:'
  prefs: []
  type: TYPE_NORMAL
- en: '`/var/log/pacemaker.log`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`/var/log/cluster/corosync.log`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`/var/log/pcsd/pcsd.log`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In addition, you can also search in the systemd log with `journalctl -xn` and
    use `grep` to filter a specific word or phrase.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can reset the status of a cluster resource with the `pcs resource disable
    <resource_name>` and `pcs resource enable <resource_name>` commands.
  prefs: []
  type: TYPE_NORMAL
- en: Fencing – isolating the malfunctioning nodes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As the number of nodes in a cluster increases, its availability increases, but
    so does the chance of one of them failing at some point. This failure event, whether
    serious or not, suggests that we must secure a way to isolate the malfunctioning
    node from the cluster in order for it to fully release its processing tasks to
    the rest of the cluster. Think of what an erratic node can cause in a shared storage
    cluster—data corruption would inevitably occur. The word malfunctioning, in this
    context, means not only what it suggests in the typical usage of the English language
    (something that is not working properly), but also a node, which also includes
    the resources started on it, whose state cannot be determined by the cluster for
    whatever reason.
  prefs: []
  type: TYPE_NORMAL
- en: This is where the term fencing comes into play. By definition, cluster fencing
    is the process of isolating, or separating, a node from using its resources or
    starting services, which it should not have access to, and from the rest of the
    nodes as well. One of the ABC rules of computer clustering can thus be formulated
    as, do not let a malfunctioning node run any cluster resources - fence it in all
    cases. In line with the last statement, an unresponsive node must be taken offline
    before another node will take over.
  prefs: []
  type: TYPE_NORMAL
- en: 'Fencing is performed using a mechanism known as STONITH, which we briefly introduced
    during the last chapter (in few words, STONITH is a fencing method that is used
    to isolate a failed node in order to prevent it from causing problems in a cluster).
    You will recall that we disabled this feature at that point and mentioned that
    we would revisit the topic here. A quick inspection of the cluster''s configuration,
    as shown in the following screenshot, will confirm that that STONITH is currently
    disabled:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Fencing – isolating the malfunctioning nodes](img/00026.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you run the `pcs config` code, you will be able to view the current configuration
    for the cluster in detail, which is illustrated in the preceding screenshot.
  prefs: []
  type: TYPE_NORMAL
- en: 'At the very end, the `stonith-enabled: false` line clearly reminds us that
    STONITH is disabled in our cluster.'
  prefs: []
  type: TYPE_NORMAL
- en: You will want to add `pcs config` to the list of essential commands that you
    must keep in mind as we move forward with the cluster configuration. It will allow
    you to inspect, at a quick glance, the settings and resources made available through
    the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, let''s begin by re-enabling STONITH:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, check on the configuration again, either with the `pcs config` or `pcs
    property list` command. For brevity, in the case illustrated in the following
    screenshot, we use the `pcs property list` command in order to introduce you to
    yet another useful PCS command. Note how we check on this property before and
    after re-enabling STONITH:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Fencing – isolating the malfunctioning nodes](img/00027.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Once we have enabled STONITH in our cluster, it is time to finally set up fencing
    in our cluster by configuring a STONITH resource (also known as a STONITH device).
  prefs: []
  type: TYPE_NORMAL
- en: Installing and configuring a STONITH device
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It is worth noting that a STONITH device is a cluster resource that will be
    used to bring down a malfunctioning or unresponsive node. Installing the following
    packages on both nodes will make several STONITH devices available in our cluster.
    If you are setting up your 2-node cluster with two virtual machines, as suggested
    early in [Chapter 1](part0014_split_000.html#DB7S1-1d2c6d19b9d242db82da724021b51ea0
    "Chapter 1. Cluster Basics and Installation on CentOS 7"), *Cluster Basics and
    Installation on CentOS 7*, install the following packages on both nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Once the installation is complete, you can list all the available agents with
    the `pcs stonith list` command, as shown in the next screenshot.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each of the listed devices in the following screenshot are described by several
    available parameters, which can be shown with `pcs stonith describe agent`, where
    you must replace `agent` with the corresponding name of the resource. Note that
    we will use these parameters when we actually configure the STONITH device in
    a later step. The required parameters are indicated by the word (`required`) at
    the beginning of the description, use the `pcs stonith describe fence_ilo` command,
    which returns the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '![Installing and configuring a STONITH device](img/00028.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Among these parameters, you can see that there is an action (`action`) that
    should take place when a fencing event is going to happen, a host list that will
    be controlled by this device (`pcmk_host_list`), and a waiting time (`timeout`
    or `stonith-timeout`), that is, the time taken to wait for a fencing action to
    complete. These are essential pieces of information that you will need to take
    into account while specifying the STONITH options during the creation of the device
    and setting up your infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: The next step, which consists of creating the device itself, will largely depend
    on the hardware device that you have available. For example, if you want to fence
    a Hewlett-Packard node (such as a Proliant server) with a built-in iLO interface,
    you would use the `fence_ilo` agent, or if your nodes are sitting on top of VMWare
    virtualization, you may need to choose `fence_vmware_soap`. Another popular option
    is Dell with **Dell Remote Access Controller** (**DRAC**), for which you would
    use `fence_drac5`. Unfortunately, as of today, there is no out-of-the-box fencing
    device available for VirtualBox.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An **iLO** (**Integrated Lights Out**) card is a separate interface with a separate
    network connection and IP address that allows a system administrator to perform
    certain operations on HP servers remotely via HTTPS. Similar functionality is
    available in Dell servers with built-in DRACs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now create a STONITH `fence_ilo` device named `Stonith_1`, which can
    fence `node01` (although we are showing this example using `node01`, note that
    this has to be done on a per-node basis):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The basic syntax to create a fencing device is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: You can view an explained list of `stonith_device_options` with man `stonithd`.
  prefs: []
  type: TYPE_NORMAL
- en: 'To update the device, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'To delete the device, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Finally, The `pcs stonith show [stonith_device_name] --full` command will display
    all the options used for `[stonith_device_name]` or all fencing devices if `[stonith_device_name]`
    is not specified.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can then simulate a fencing situation (note that this is done automatically
    behind the scenes under a real-life event) by killing the `pacemaker` and `corosync`
    processes with the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Also, confirm that `node_name` is actually offline using the `pcs stonith confirm
    node01` command.
  prefs: []
  type: TYPE_NORMAL
- en: Split-brain – preparing to avoid inconsistencies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Up to this point, we have considered a few essential concepts in clustering,
    leading to the following not completely fictitious scenario—what happens if a
    cluster is formed by nodes that are located in separate networks and the communication
    link between them goes down? The same applies when the nodes are in the same network
    and the link goes down as well. That is, none of the nodes have actually gone
    offline, but each appears to the other as unavailable. The default behavior would
    be that each node assumes that the other is down and continues serving whatever
    resources or applications the cluster was previously running.
  prefs: []
  type: TYPE_NORMAL
- en: So far, so good! Now, let's say the network link comes back online but both
    nodes still think they are the main cluster member. That is where data corruption—at
    the worst—or inconsistency—at the best—occur. This is caused by possible changes
    made to data on either side without having been replicated to the other end.
  prefs: []
  type: TYPE_NORMAL
- en: This is why configuring fencing is so important, as is ensuring redundant communication
    links between cluster members so that such a **Single Point Of Failure** (**SPOF**)
    does not end up causing the split-brain situation in our cluster.
  prefs: []
  type: TYPE_NORMAL
- en: As far as the fencing is concerned, only the node that is marked as **Designated
    Controller** (**DC**) and also has quorum can fence the other nodes and run the
    applications and resources as master, or active, in our A/P cluster. By doing
    so, we ensure that the other node will not be allowed to take over resources that
    may lead to the data inconsistencies described earlier.
  prefs: []
  type: TYPE_NORMAL
- en: Quorum – scoring inside your cluster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In simple terms, the concept of quorum indicates the minimum number of members
    that are required to be active in order for the cluster, as a whole, to be available.
    Specifically, a cluster is said to have quorum when the number of active nodes
    is greater than the total number of nodes divided by two. Another way to express
    this is that quorum is achieved by at least a simple majority (50% of the total
    number of nodes + 1).
  prefs: []
  type: TYPE_NORMAL
- en: Although the concept of quorum doesn't prevent a split-brain scenario, it will
    decide which node (or group of nodes) is dominant and allowed to run the cluster
    so that when a split-brain situation occurs, only one node (or group of nodes)
    will be able to run the cluster services.
  prefs: []
  type: TYPE_NORMAL
- en: By default, when the cluster does not have quorum, `pacemaker` will stop all
    resources altogether so that they will not be started on more nodes than desired.
    However, a cluster member will still listen for other nodes to reappear on the
    network, but they will not work as a cluster until the quorum exists again.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can easily confirm this behavior by stopping the cluster on `node01` and
    `node02` and then restarting it again. You will notice that `virtual_ip` remains
    stopped:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Until you enable it manually using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'For a 2-node cluster, as it is in our case, when we used the `pcs cluster`
    setup in [Chapter 2](part0018_split_000.html#H5A42-1d2c6d19b9d242db82da724021b51ea0
    "Chapter 2. Installing Cluster Services and Configuring Network Components"),
    *Installing Cluster Services and Configuring Network Components*, the following
    section was added in `/etc/corosync/corosync.conf` for us:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The `two_node: 1` line tells `corosync` that in a 2-node cluster, one member
    is enough to hold up the quorum. Thus, even when some people would argue that
    a 2-node cluster is pointless, our cluster will continue working when at least
    one of the nodes is online. Perhaps you already noticed while stopping and starting
    the cluster in one node previously, but it is worth pointing out that when trying
    to stop one of the members in our 2-node clusters, you will be asked to use the
    `--force` option:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'To display the current list of nodes in the cluster and its individual contributions
    toward cluster quorum (which is shown in the following figure under **Votes**
    column), run the `corosync-quorumtool -l` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Quorum – scoring inside your cluster](img/00029.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: In a prospective split-brain situation, as described earlier, and supposing
    that the cluster is divided into two partitions, the partition with a majority
    of votes remains available, while the other is fenced automatically by the DC
    if STONITH has been put in place and properly configured. For example, in a 4-node
    cluster, quorum is established when at least three cluster nodes are functioning.
    Otherwise, the cluster no longer has quorum and `pacemaker` will stop the services
    run by the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring our cluster with PCS GUI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you followed the steps outlined in [Chapter 2](part0018_split_000.html#H5A42-1d2c6d19b9d242db82da724021b51ea0
    "Chapter 2. Installing Cluster Services and Configuring Network Components"),
    *Installing Cluster Services and Configuring Network Components*, to enable the
    Hacluster account for cluster administration, we can also use the PCS GUI, a cluster
    management web interface, to manage clusters. This includes the ability to add,
    remove, and edit existing clusters.
  prefs: []
  type: TYPE_NORMAL
- en: 'To navigate to the PCS web interface, go to `https://<ip_of_one_node>:2224`
    (note that it''s `https` and not `http`), accept the security exceptions, and
    then log in using the credentials that were previously set for Hacluster, as shown
    in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Configuring our cluster with PCS GUI](img/00030.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The next screen that you will see (which is as shown in the following screenshot)
    will present the menus to remove an existing cluster, add an existing cluster,
    or create a new one. When you click on the **Add Existing** button, you will be
    prompted to enter the hostname or IP address of a node that currently belongs
    to an existing cluster that you want to manage using the web UI:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Configuring our cluster with PCS GUI](img/00031.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Then, click on the cluster name and feel free to browse through the menu at
    the top of the following figure, which also serves the purpose of letting us add,
    remove, or edit the resources that we have been hitherto talking about:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Configuring our cluster with PCS GUI](img/00032.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explored situations of node failures and essential techniques
    for malfunctioning cluster members, along with some essential cluster concepts
    in greater depth. In addition to this, we saw how to add cluster resources in
    order to further configure our newly created cluster into a real-world usage case,
    which we will deal with during the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: It is also worth reiterating that there are certain hardware components that
    we have not been able to discuss in detail, such as fencing devices, and you should
    take note of the fencing agents and devices (as per `pcs stonith list`) and see
    if any of them applies to the available hardware in your case.
  prefs: []
  type: TYPE_NORMAL
- en: Last but not least, you need to remember that in order to avoid split-brain
    situations, besides applying thoroughly the concepts outlined in the present chapter,
    you also need to ensure redundant communication links between the networks where
    the nodes are located. This will help you prevent a **Single Point Of Failure**
    (**SPOF**) to potentially cause such an unwanted event.
  prefs: []
  type: TYPE_NORMAL
