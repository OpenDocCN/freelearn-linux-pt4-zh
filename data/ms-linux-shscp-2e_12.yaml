- en: Summarizing Logs with AWK
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 AWK 汇总日志
- en: In the previous chapter, we talked about regular expressions and we saw how
    to use them to empower `sed` and AWK. In this chapter, we will discuss some practical
    examples of using AWK.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们讨论了正则表达式，并且看到了如何利用它们来增强 `sed` 和 AWK。本章中，我们将讨论一些使用 AWK 的实际示例。
- en: 'One of the tasks that AWK is really good at is filtering data from log files.
    These log files may be many lines in length, perhaps 250,000 or more. I have worked
    with data with over a million lines. AWK can process these lines quickly and effectively.
    As an example, we will work with a web server access log with 30,000 lines to
    show how effective and well-written AWK code can be. As we work our way through
    the chapter, we will also see different log files and review some of the techniques
    that we can employ with the `awk` command and the AWK programming language to
    help with the reporting and administration of our services. In this chapter, we
    will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: AWK 的一个强项是从日志文件中过滤数据。这些日志文件可能有很多行，可能达到 250,000 行或更多。我曾处理过超过一百万行的数据。AWK 可以快速高效地处理这些行。作为例子，我们将处理一个包含
    30,000 行的 Web 服务器访问日志，以展示高效且写得很好的 AWK 代码的效果。在本章中，我们将看到不同的日志文件，并回顾一些我们可以使用 `awk`
    命令和 AWK 编程语言来帮助报告和管理服务的技术。在本章中，我们将涵盖以下主题：
- en: HTTPD log file format
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HTTPD 日志文件格式
- en: Displaying data from web logs
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 显示来自 Web 日志的数据
- en: Displaying the highest ranking client IP addresses
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 显示排名最高的客户端 IP 地址
- en: Displaying the browser data
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 显示浏览器数据
- en: Working with email logs
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理电子邮件日志
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'The source code for this chapter can be downloaded from here:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的源代码可以从这里下载：
- en: '[https://github.com/PacktPublishing/Mastering-Linux-Shell-Scripting-Second-Edition/tree/master/Chapter12](https://github.com/PacktPublishing/Mastering-Linux-Shell-Scripting-Second-Edition/tree/master/Chapter12)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Mastering-Linux-Shell-Scripting-Second-Edition/tree/master/Chapter12](https://github.com/PacktPublishing/Mastering-Linux-Shell-Scripting-Second-Edition/tree/master/Chapter12)'
- en: The HTTPD log file format
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: HTTPD 日志文件格式
- en: When working with any file, the first task is to become familiar with the file
    schema. In simple terms, we need to know what is represented by each field and
    what is used to delimit the fields. We will be working with the access log file
    from an Apache HTTPD web server. The location of the log file can be controlled
    from the `httpd.conf` file. The default log file location on a Debian-based system
    is `/var/log/apache2/access.log`; other systems may use the `httpd` directory
    in place of `apache2`.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理任何文件时，首要任务是熟悉文件的模式。简单来说，我们需要了解每个字段所表示的内容以及用什么来分隔字段。我们将处理 Apache HTTPD Web
    服务器的访问日志文件。日志文件的位置可以通过 `httpd.conf` 文件进行控制。在基于 Debian 的系统中，默认的日志文件位置是 `/var/log/apache2/access.log`；其他系统可能会使用
    `httpd` 目录来替代 `apache2`。
- en: The `log` file is already in the code bundle, so you can download it and use
    it directly.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '`log` 文件已经包含在代码包中，所以你可以直接下载并使用它。'
- en: 'Using the `tail` command, we can display the end of the `log` file. Although,
    to be fair, the use of `cat` will do just as well with this file, as it will have
    just a few lines:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `tail` 命令，我们可以显示 `log` 文件的结尾。虽然说实话，使用 `cat` 命令也能很好地完成这项任务，因为这个文件只有几行：
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The output of the command and the contents of the file are shown in the following
    screenshot:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 命令的输出和文件内容如下所示：
- en: '![](img/9b3f97e4-b874-4381-89a5-3f60d78dd4e8.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9b3f97e4-b874-4381-89a5-3f60d78dd4e8.png)'
- en: 'The output does wrap a little onto the new lines, but we do get a feel of the
    layout of the log. We can also see that even though we feel that we access just
    one web page, we are in fact accessing two items: the `index.html` and the `ubuntu-logo.png`.
    We also failed to access the `favicon.ico` file. We can see that the file is space
    separated. The meaning of each of the fields is laid out in the following table:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 输出内容确实会稍微换行，但我们仍然能感受到日志的布局。我们还可以看到，尽管我们感觉只访问了一个网页，但实际上我们访问了两个项目：`index.html`
    和 `ubuntu-logo.png`。我们也未能成功访问 `favicon.ico` 文件。可以看到，文件是以空格分隔的。每个字段的含义如下表所示：
- en: '| **Field** | **Purpose** |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| **字段** | **用途** |'
- en: '| 1 | Client IP address. |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 客户端 IP 地址。 |'
- en: '| 2 | Client identity as defined by RFC 1413 and the `identd` client. This
    is not read unless `IdentityCheck` is enabled. If it is not read, the value will
    be with a hyphen. |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 按 RFC 1413 和 `identd` 客户端定义的客户端身份。如果未启用 `IdentityCheck`，则不会读取此字段。如果未读取，则该值将是一个连字符。
    |'
- en: '| 3 | The user ID of the user authentication if enabled. If authentication
    is not enabled, the value will be a hyphen. |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 用户认证的用户ID（如果启用）。如果未启用认证，值将为连字符。 |'
- en: '| 4 | The date and time of the request in the format of `day/month/year:hour:minute:second
    offset`. |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 请求的日期和时间，格式为`日/月/年:时:分:秒 偏移量`。 |'
- en: '| 5 | The actual request and method. |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 实际请求和方法。 |'
- en: '| 6 | The return status code, such as `200` or `404`. |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 返回状态代码，如`200`或`404`。 |'
- en: '| 7 | File size in bytes. |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 文件大小（以字节为单位）。 |'
- en: 'Even though these fields are defined by Apache, we have to be careful. The
    time, date, and time zone is a single field and is defined within square braces;
    however, there are additional spaces inside the field between that data and the
    time zone. To ensure that we print the complete time field if required, we need
    to print both `$4` and `$5`. This is shown in the following command example:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这些字段由Apache定义，但我们仍然需要小心。时间、日期和时区是一个字段，并在方括号内定义；但是，在该数据和时区之间还有额外的空格。为了确保在需要时打印完整的时间字段，我们需要打印`$4`和`$5`。以下命令示范了这一点：
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We can view the command and the output it produces in the following screenshot:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在以下截图中查看命令及其产生的输出：
- en: '![](img/71c919e5-13bb-4764-9402-d54f64c1d840.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](img/71c919e5-13bb-4764-9402-d54f64c1d840.png)'
- en: Displaying data from web logs
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 显示来自Web日志的数据
- en: We have already had a preview of how we can use AWK to view the log files from
    the Apache web server; however, we will now move onto our demonstration file that
    has greater and more varied content.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经预览了如何使用AWK查看Apache web服务器的日志文件；然而，接下来我们将转到我们的演示文件，该文件包含更多和更为多样的内容。
- en: Selecting entries by date
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 按日期选择条目
- en: 'Having seen how we can display the date, we should perhaps look at how we print
    entries from just one day. To do this, we can use the match operator in `awk`.
    This is denoted by the tilde or squiggly line, if you prefer. As we only need
    the date element, there is no need for us to use both the date and time zone field.
    The following command shows how to print entries from September 10, 2014:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经了解了如何显示日期，或许我们应该看看如何仅打印一天的条目。为此，我们可以在`awk`中使用匹配操作符。这由波浪线（~）表示，或者你也可以叫它波浪线。如果我们只需要日期元素，就没有必要同时使用日期和时区字段。以下命令展示了如何打印2014年9月10日的条目：
- en: '[PRE2]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'For completeness, this command and partial output is shown in the following
    screenshot:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完整性，以下截图展示了该命令和部分输出：
- en: '![](img/1cd97c0b-241d-484c-9072-4fb73de7885e.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1cd97c0b-241d-484c-9072-4fb73de7885e.png)'
- en: 'The round brackets or parentheses embrace the range of lines that we are looking
    for and we have omitted the main block, which ensures that we print the complete
    matching lines from the range. There is nothing stopping us from further filtering
    on the fields to print from the matching lines. For example, if we want to print
    out just the client IP address that is being used to access the web server, we
    can print field `1`. This is shown in the following command example:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 圆括号包围了我们正在查找的行范围，我们省略了主块，这样可以确保我们打印范围内完全匹配的行。没有任何限制阻止我们进一步筛选并从匹配的行中打印字段。例如，如果我们只想打印出用于访问Web服务器的客户端IP地址，我们可以打印字段`1`。以下命令示范了这一点：
- en: '[PRE3]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'If we want to be able to print the total number of accesses on a given date,
    we could pipe the entries through to the `wc` command. This is demonstrated in
    the following:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想能够打印特定日期的总访问次数，可以将条目通过管道传输到`wc`命令。这在下面进行了演示：
- en: '[PRE4]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'However, if we want to use `awk` to do this for us, this will be more efficient
    than starting a new process and we can count the entries. If we use the built-in
    variable `NR`, we can print entire lines in the files, not just those within the
    range. It is best to increment our own variable in the main block instead of matching
    the range for each line. The `END` block can be implemented to print the `count`
    variable we use. The following command line acts as an example:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果我们希望使用`awk`来执行此任务，这将比启动一个新进程更高效，并且我们可以统计条目。如果我们使用内置变量`NR`，我们可以打印文件中的整行，而不仅仅是范围内的行。最好在主块中增加我们自己的变量，而不是为每一行匹配范围。可以在`END`块中实现打印我们使用的`count`变量。以下命令行作为示例：
- en: '[PRE5]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The output of the count from both `wc` and the internal counter will give us
    `16205` as a result from the demonstration file. We should use the variable increment
    within the main block if we want to count and nothing else:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '`wc`和内部计数器的计数输出将给我们演示文件的结果`16205`。如果我们只想计数而不做其他任何操作，我们应该在主块中使用变量递增：'
- en: '[PRE6]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We can see this in the following output:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在以下输出中看到这一点：
- en: '![](img/5a3b0cfe-80b4-4adf-b946-15e89e22cd86.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5a3b0cfe-80b4-4adf-b946-15e89e22cd86.png)'
- en: Summarizing 404 errors
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 汇总`404`错误
- en: The status code of the request page is shown in field `9` of the log. The `404`
    status will represent the page not found error on the server. I am sure we have
    all seen that in our browsers at some stage. This may be indicative of a misconfigured
    link on your site or just produced by a browser searching for the icon image to
    display in tabbed browsers for the page. You can also identify potential threats
    to your site by requests looking for standard pages that may give access to additional
    information on PHP driven sites, such as WordPress.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 请求页面的状态码显示在日志的字段`9`中。`404`状态码表示服务器上的页面未找到错误。我相信我们在某个阶段都在浏览器中见过这种情况。这可能表示你的网站中某个链接配置错误，或者浏览器正在寻找一个图标图片以便在标签浏览器中显示该页面。你还可以通过查找请求标准页面来识别可能对你的网站构成威胁的行为，这些页面可能会提供有关PHP驱动网站（如WordPress）的额外信息。
- en: 'Firstly, we can solely print the status of the request:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们可以仅仅打印出请求的状态：
- en: '[PRE7]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We can now extend the code a little as well as ourselves and just print the
    `404` errors:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以稍微扩展一下代码以及我们自己，只打印出`404`错误：
- en: '[PRE8]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We can extend this a little further by printing both the status code and the
    page that was being accessed. This will need us to print field `9` and field `7`.
    Simply put, this will be as shown in the following code:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以进一步扩展，通过打印出状态码和正在访问的页面。这需要我们打印字段`9`和字段`7`。简而言之，这将如下所示：
- en: '[PRE9]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Many of these failed accessed pages will be duplicated. To summarize these
    records, we can use the command pipeline to achieve this with the `sort` and `uniq`
    commands:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这些失败访问的页面会有重复的情况。为了汇总这些记录，我们可以使用命令管道结合`sort`和`uniq`命令来实现：
- en: '[PRE10]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: To use the `uniq` command, the data must be pre-sorted; hence, we use the `sort`
    command to prepare the data.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`uniq`命令时，数据必须先进行排序；因此，我们使用`sort`命令准备数据。
- en: Summarizing HTTP access codes
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 汇总HTTP访问码
- en: 'It is time for us to leave the pure command line and start working with the
    AWK control files. As always, when the complexity of the required result set increases,
    we see an increase in the complexity of the `awk` code. We will create a `status.awk`
    file in our current directory. The file should look similar to the following file:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候离开纯命令行，开始处理AWK控制文件了。正如我们所知，当所需结果集的复杂性增加时，`awk`代码的复杂性也随之增加。我们将在当前目录下创建一个`status.awk`文件。该文件应与以下文件相似：
- en: '[PRE11]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'First, we will strip down the main code block and this is very simple and sparse.
    This is a simple way to count each unique occurrence of a status code. Instead
    of using a simple variable, we feed this into an array. The array in this case
    is called a record. An array is a multi-values variable and the slots in the array
    are known as keys. So we will have a collection of variables stored in the array.
    For example, we expect to see entries for `record[200]` and `record[404]`. We
    populate each key with their occurrence count. Each time we find a `404` code,
    we increment the count that is stored in the associated key:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将简化主代码块，这非常简单且简洁。这是一种简单的方法，用来计算每个状态码的唯一出现次数。我们不使用简单的变量，而是将其传入一个数组。在这种情况下，数组叫做记录。数组是一个多值变量，数组中的槽位称为键。因此，我们将会有一组存储在数组中的变量。例如，我们期望看到`record[200]`和`record[404]`的条目。我们将每个键填充上它们的出现次数。每当我们找到一个`404`代码时，我们就增加存储在关联键中的计数：
- en: '[PRE12]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'In the `END` block, we create the summary information using a `for` loop to
    print out each key and value from the array:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在`END`块中，我们使用`for`循环创建汇总信息，打印出数组中的每个键值对：
- en: '[PRE13]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'To run this, the associated command line will be similar to the following:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行此命令，相关的命令行将类似于以下内容：
- en: '[PRE14]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'To view the command and output, we have included the following screenshot:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 为了查看命令和输出，我们包含了以下截图：
- en: '![](img/979b1d94-c4a5-47df-a82e-101b6c030214.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](img/979b1d94-c4a5-47df-a82e-101b6c030214.png)'
- en: 'We can take this further and focus on the `404` errors. You could, of course,
    choose any of the status codes. We can see from the results that we have `4382
    404` status codes. To summarize these `404` codes, we will copy the `status.awk`
    to a new file named `404.awk`. We can edit the `404.awk` adding an `if` statement
    to work only on the `404` codes. The file should be similar to the following code:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以进一步关注 `404` 错误。当然，你可以选择任何状态码。从结果中我们看到 `4382 404` 状态码。为了总结这些 `404` 代码，我们将把
    `status.awk` 复制到一个名为 `404.awk` 的新文件中。我们可以编辑 `404.awk`，添加一个 `if` 语句，使其只处理 `404`
    代码。该文件应该类似于以下代码：
- en: '[PRE15]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'If we execute the code with the following command:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用以下命令执行代码：
- en: '[PRE16]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The output will be similar to the following screenshot:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将类似于以下截图：
- en: '![](img/a26e123c-4f6c-49d1-a770-3e239e236898.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a26e123c-4f6c-49d1-a770-3e239e236898.png)'
- en: Resources hits
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 资源请求
- en: 'You can check how many times a specific page or a resource was requested using
    AWK:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用 AWK 检查特定页面或资源的请求次数：
- en: '[PRE17]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The preceding command will sort the requested resources from the highest requested
    resource to the lowest:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的命令将按请求资源的次数从高到低排序：
- en: '![](img/407e25dc-56a9-4b51-bffb-34a501f600ae.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](img/407e25dc-56a9-4b51-bffb-34a501f600ae.png)'
- en: The resources could be images, text files, or CSS files.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这些资源可能是图片、文本文件或 CSS 文件。
- en: 'If you want to look at the requested PHP files, you can use `grep` to get PHP
    files only:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想查看请求的 PHP 文件，可以使用 `grep` 只获取 PHP 文件：
- en: '[PRE18]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '![](img/029c03ca-516f-449d-a193-880605109e0e.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](img/029c03ca-516f-449d-a193-880605109e0e.png)'
- en: Alongside each page, there is the number of hits.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 每个页面旁边都有访问次数。
- en: You can grab any statistics from the `log` file and get unique values and sort
    them the same way.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从 `log` 文件中获取任何统计数据，提取唯一值并以相同的方式排序。
- en: Identify image hotlinking
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 识别图片热链接
- en: As we talk about resources, there is a problem that you may face, which is image
    hotlinking. It's about using your images from other servers by linking to them.
    This behavior of image hotlinking can leak your bandwidth.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 说到资源时，你可能会遇到一个问题，那就是图片热链接。它指的是通过链接到其他服务器上的图片来使用你的图片。这种图片热链接的行为可能会泄露你的带宽。
- en: 'And since we are talking about AWK, we will see how to use AWK to find out
    how it is using our images:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们在谈论 AWK，接下来我们将看到如何使用 AWK 查找它是如何使用我们的图片的：
- en: '[PRE19]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Note that you can prevent image hotlinking by a small `.htaccess` file if you
    are using Apache, by checking if the referrer is not your domain:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，如果你使用的是 Apache，可以通过一个小的 `.htaccess` 文件防止图片热链接，方法是检查引荐来源是否不是你的域名：
- en: '[PRE20]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Displaying the highest ranking IP address
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 显示最高排名的 IP 地址
- en: 'You should now be aware of some the powers of `awk` and how immense the language
    structure is in itself. The data we have been able to produce from the 30,000
    line file is truly powerful and easily extracted. We just need to replace the
    field we have used before with `$1`. This field represents the client IP address.
    If we make use of the following code, we will be able to print each IP Address
    and also the number of times it has been used to access the web server:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在应该了解一些 `awk` 的强大功能，以及它本身庞大的语言结构。我们从 30,000 行的文件中提取的数据确实很强大，且容易提取。我们只需将之前使用的字段替换为
    `$1`。这个字段表示客户端 IP 地址。如果我们使用以下代码，我们将能够打印出每个 IP 地址以及它访问 web 服务器的次数：
- en: '[PRE21]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We want to be able to extend this to show only the highest ranking IP address,
    the address that has been used the most to access the site. The work, again, will
    mainly be in the `END` block and will make use of a comparison against the current
    highest ranking address. The following file can be created and saved as `ip.awk`:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望能够扩展这个，显示出最高排名的 IP 地址，也就是访问站点最多的地址。工作主要还是在 `END` 块中，并将与当前最高排名地址进行比较。以下文件可以创建并保存为
    `ip.awk`：
- en: '[PRE22]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'We can see the output of the command in the following screenshot. Part of the
    client IP address has been obscured as it is from my public web server:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在以下截图中看到命令的输出。部分客户端 IP 地址被遮挡，因为它来自我的公共 web 服务器：
- en: '![](img/b821d655-ea19-4f24-8550-2dd28c60b366.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b821d655-ea19-4f24-8550-2dd28c60b366.jpg)'
- en: The functionality of the code comes from within the `END` block. On entering
    the `END` block, we run into a `for` loop. We iterate through each entry in the
    `ip` array. We use the conditional `if` statement to see whether the current value
    that we are iterating through is higher than the current maximum. If it is, this
    becomes the new highest entry. When the `loop` has finished, we print the IP address
    that has the highest entry.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的功能来自 `END` 块。在进入 `END` 块时，我们运行一个 `for` 循环。我们遍历 `ip` 数组中的每个条目。我们使用条件语句 `if`
    来查看当前迭代的值是否大于当前最大值。如果是，那么它就成为新的最大条目。当 `loop` 循环结束时，我们打印出具有最高值的 IP 地址。
- en: Displaying the browser data
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 显示浏览器数据
- en: 'The browser that is used to access the website is contained within the log
    file in field `12`. It may be interesting to display the list of browsers used
    to access your site. The following code will assist you in displaying the list
    of accesses by the reported browser:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 用于访问网站的浏览器信息包含在日志文件的字段 `12` 中。展示用于访问网站的浏览器列表可能会很有意思。以下代码将帮助你展示按浏览器报告的访问列表：
- en: '[PRE23]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'You can see how we can create little plugins to `awk` with these files and
    adjust the field and array names to suit. The output is shown in the following
    screenshot:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到我们如何创建小插件来与这些文件配合使用 `awk`，并调整字段和数组名称以适应需求。输出如下截图所示：
- en: '![](img/8c801f02-d3dc-4623-8779-435026722d5a.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8c801f02-d3dc-4623-8779-435026722d5a.png)'
- en: Interestingly, we see that Mozilla 4 and 5 make up the majority of the requesting
    client. We see that Mozilla 4 is listed here `1713` times. The Mozilla/5.0 entry
    here is malformed with an extra double quote. It appears later with 27,000 accesses.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，我们看到 Mozilla 4 和 5 占据了大多数请求客户端。我们看到 Mozilla 4 在这里出现了 `1713` 次。这里的 Mozilla/5.0
    条目由于额外的双引号而格式错误。它稍后以 27,000 次访问出现。
- en: Working with email logs
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理邮件日志
- en: We have worked with logs from the Apache HTTP web server. The reality is that
    we can apply the same ideals and methodology to any log file. We will take a look
    at Postfix mail logs. The mail log holds all activity from the SMTP server and
    we can then see who has been sending emails to whom. The log file is usually located
    at `/var/log/mail.log`. I will access this on my Ubuntu 15.10 server that has
    a local email delivery. All this means is that the STMP server is listening only
    to the localhost interface of `127.0.0.1`.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们曾处理过来自 Apache HTTP 网络服务器的日志。事实上，我们可以将相同的理念和方法应用于任何日志文件。我们将查看 Postfix 邮件日志。邮件日志包含了来自
    SMTP 服务器的所有活动，然后我们就能看到谁向谁发送了邮件。该日志文件通常位于 `/var/log/mail.log`。我将在我的 Ubuntu 15.10
    服务器上访问这个日志文件，该服务器配置了本地邮件传送。这意味着 SMTP 服务器只监听 `127.0.0.1` 的本地接口。
- en: The log format will change a little depending on the type of message. For example,
    `$7` will contain `from` logs on outbound messages, whereas inbound messages will
    contain `to`.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 日志格式会根据消息类型略有变化。例如，`$7` 会包含外发消息的 `from` 日志，而接收消息则会包含 `to`。
- en: 'If we want to list all the inbound messages to the SMTP server, we can use
    the following command:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想列出所有发送到 SMTP 服务器的消息，可以使用以下命令：
- en: '[PRE24]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'As the string `to` is very short, we can add identification to it by ensuring
    that the field begins with `to` using the `^`. The command and output is shown
    in the following screenshot:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 由于字符串 `to` 非常简短，我们可以通过确保字段以 `to` 开头来为其添加标识，使用 `^` 来实现。命令和输出如下截图所示：
- en: '![](img/2b73c3f8-6754-47d5-8092-c7885c69ab43.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2b73c3f8-6754-47d5-8092-c7885c69ab43.png)'
- en: It will be easy to extend the `to` or `from` searches to also include usernames.
    We can see the format of the delivered or received mail. Working with the same
    template we used with the Apache logs, we can easily display the highest recipient
    or sender.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展对 `to` 或 `from` 的搜索以包含用户名将变得非常简单。我们可以看到邮件的发送或接收格式。使用与 Apache 日志相同的模板，我们可以轻松显示出最高的接收者或发送者。
- en: Summary
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: We now have some heavy ammunition behind our text processing and we can begin
    to understand just how powerful AWK can be. Working with real data is particularly
    useful in gauging the performance and accuracy of our searches. Having begun working
    with simple Apache entries on the newly installed Ubuntu 15.10 Apache web server,
    we soon migrated to the larger sample data from a live web server. With 30,000
    lines, this file gives us some real meat to work with and in no time, we were
    able to produce credible reports. We closed up the return to the Ubuntu 15.10
    server to analyze the Postfix SMTP logs. We can see that we can very much drag
    and drop the technology that we have previously used into the new log files.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经为文本处理提供了一些强大的工具，可以开始理解 AWK 的强大功能。使用真实数据对于评估我们搜索的性能和准确性特别有用。我们从新安装的 Ubuntu
    15.10 Apache 网络服务器上开始使用简单的 Apache 条目，很快就迁移到了来自实际 Web 服务器的更大样本数据。这个包含 30,000 行的数据文件为我们提供了真正的内容，短短时间内，我们就能够生成可信的报告。然后我们返回到
    Ubuntu 15.10 服务器，分析 Postfix SMTP 日志。我们可以看到，我们可以非常轻松地将之前使用的技术应用到新的日志文件中。
- en: Next up, we stick with AWK and look at how we can report on the `lastlog` data
    and on flat XML files.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们继续使用 AWK，并了解如何报告 `lastlog` 数据和扁平 XML 文件。
- en: Questions
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: Which field in the `access_log` file contains the IP address?
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`access_log` 文件中的哪个字段包含 IP 地址？'
- en: What is the command used to count the lines processed by AWK?
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用于统计 AWK 处理的行数的命令是什么？
- en: How do you get IP addresses of unique visitors from the Apache access log file?
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何从 Apache 访问日志文件中获取独立访客的 IP 地址？
- en: How do you get the most visited PHP page from the Apache access log file?
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何从 Apache 访问日志文件中获取访问量最多的 PHP 页面？
- en: Further reading
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Please see the following for further reading relating to this chapter:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅以下内容，进一步阅读本章相关的内容：
- en: '[https://httpd.apache.org/docs/1.3/logs.html](https://httpd.apache.org/docs/1.3/logs.html)'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://httpd.apache.org/docs/1.3/logs.html](https://httpd.apache.org/docs/1.3/logs.html)'
