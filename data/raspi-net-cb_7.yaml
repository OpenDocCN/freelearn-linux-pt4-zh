- en: Chapter 7. Clustering
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章 集群
- en: 'In this chapter, we will cover:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖：
- en: Installing a high-availability load balancer
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装高可用负载均衡器
- en: Installing a distributed filesystem
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装分布式文件系统
- en: Creating a super computer
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建超级计算机
- en: Introduction
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引言
- en: The recipes in this chapter are for network clusters of Raspberry Pis.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的食谱是针对树莓派的网络集群的。
- en: A network cluster is more than one computer networked together as a single system.
    Computers are clustered for scaling and high availability. Clusters are used to
    scale performance by distributing the workload of the system across all of the
    computers in the cluster. In a highly available system, the network cluster continues
    to function even if one of the computers in the cluster goes down.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 网络集群是指多个计算机通过网络连接，作为一个单一的系统。计算机集群用于扩展和高可用性。集群通过将系统的工作负载分配到集群中的所有计算机上来扩展性能。在高可用性系统中，即使集群中的一台计算机发生故障，网络集群仍然可以继续工作。
- en: Clusters of Raspberry Pis can be used to keep a website up and running, even
    if one of the Raspberry Pis used to host the website fails. Raspberry Pi clusters
    can also be used to distribute processing and data storage across a number of
    Raspberry Pis to create a Raspberry Pi supercomputer.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 树莓派集群可以用于保持网站的持续运行，即使用来托管网站的树莓派之一发生故障。树莓派集群还可以用于将处理和数据存储分布到多个树莓派上，从而创建一个树莓派超级计算机。
- en: The recipes in this chapter are not specific to the Raspberry Pi. They can be
    repeated on most (Debian-based) Linux operating systems. The recipes are included
    in the book to demonstrate the possibilities of clustering Raspberry Pi computers.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的食谱并不专门针对树莓派。它们可以在大多数（基于Debian的）Linux操作系统上重复使用。编写这些食谱是为了展示树莓派计算机集群的可能性。
- en: After completing the recipes in this chapter, you will have used load balancers
    to keep a website highly available, distributed files and data over the combined
    storage in a cluster of Raspberry Pis, and created a Raspberry Pi supercomputer.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 完成本章中的食谱后，你将使用负载均衡器保持网站的高可用性，分发文件和数据到树莓派集群中的联合存储，并创建一个树莓派超级计算机。
- en: Installing a high-availability load balancer
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装高可用负载均衡器
- en: This recipe turns four Raspberry Pis into a highly available website cluster.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本食谱将四台树莓派转变为一个高可用性的网站集群。
- en: Two Raspberry Pis are used as web servers sharing the load of hosting the website.
    The other two Raspberry Pis are load balancers and they distribute the load of
    the incoming web requests across the two web servers.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 两台树莓派用作Web服务器，共享托管网站的负载。其他两台树莓派作为负载均衡器，负责将进入的Web请求负载均衡到两台Web服务器之间。
- en: Only one load balancer is required to balance the load. The second is configured
    to replace the first, if the first load balancer should fail.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 只需要一个负载均衡器来平衡负载。第二个负载均衡器配置为在第一个负载均衡器发生故障时替代它。
- en: The web servers in this recipe use the Apache HTTP server to serve simple stateless
    websites that demonstrate load balancing in action.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本食谱中的Web服务器使用Apache HTTP服务器提供简单的无状态网站，以演示负载均衡的实际操作。
- en: The load balancers in this recipe use HA Proxy to balance web requests between
    the two web servers and **Keepalived** to create a virtual IP address for the
    website that will be automatically redirected to the backup load balancer, if
    the current load balancer fails.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本食谱中的负载均衡器使用HA Proxy在两台Web服务器之间平衡Web请求，并使用**Keepalived**创建一个虚拟IP地址。如果当前负载均衡器发生故障，该IP地址将自动重定向到备份负载均衡器。
- en: After completing this recipe, you will have created a highly available website.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 完成本食谱后，你将创建一个高可用性的网站。
- en: Getting ready
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'These are the ingredients for this recipe:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 本食谱的配料如下：
- en: Four basic networking setups for the Raspberry Pi all connected to the same
    network switch
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 树莓派的四种基本网络设置，所有设备都连接到同一个网络交换机
- en: Five available IP addresses on the local network
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本地网络上的五个可用IP地址
- en: This recipe does not require the desktop GUI and could either be run from the
    text-based console or from within an LXTerminal.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 本食谱不需要桌面GUI，可以通过基于文本的控制台或LXTerminal运行。
- en: With the Secure Shell server running on each Raspberry Pi, this recipe can be
    completed remotely using a Secure Shell client. Websites are typically managed
    remotely.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在每台树莓派上运行Secure Shell服务器时，可以使用Secure Shell客户端远程完成本食谱。网站通常是通过远程方式管理的。
- en: How to do it...
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点……
- en: 'The steps to building a highly available Raspberry Pi website cluster are:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 构建高可用树莓派网站集群的步骤如下：
- en: Log in to each Raspberry Pi. Set its hostname and IP address. Name the two load
    balancers `lb1` and `lb2`. Name the two web servers `web1` and `web2`. Use IP
    addresses from your network.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录到每个 Raspberry Pi。设置其主机名和 IP 地址。将两个负载均衡器命名为 `lb1` 和 `lb2`。将两个 Web 服务器命名为 `web1`
    和 `web2`。使用您网络中的 IP 地址。
- en: 'The following hostnames and IP addresses are used in this recipe: `lb1` – 192.168.2.101;
    `lb2` – 192.168.2.102; `web1` – 192.168.2.111, and `web2` – 192.168.2.112.'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本配方中使用了以下主机名和 IP 地址：`lb1` – 192.168.2.101；`lb2` – 192.168.2.102；`web1` – 192.168.2.111；`web2`
    – 192.168.2.112。
- en: Note
  id: totrans-28
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The `raspi-config` command can be used to change the hostname of your Raspberry
    Pi. [Chapter 2](ch02.html "Chapter 2. Administration"), *Administration*, has
    recipes for configuring the Raspberry Pi that use the `raspi-config` command.
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以使用 `raspi-config` 命令更改 Raspberry Pi 的主机名。[第二章](ch02.html "第二章 管理")，*管理*，提供了使用
    `raspi-config` 命令配置 Raspberry Pi 的方法。
- en: '[Chapter 5](ch05.html "Chapter 5. Advanced Networking"), *Advanced Networking*,
    has a recipe for changing the static IP address.'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[第五章](ch05.html "第五章 高级网络")，*高级网络*，提供了更改静态 IP 地址的配置方法。'
- en: 'Next, we''ll set up the web servers. Log in to each of the web servers: `web1`
    and `web2`.'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将设置 Web 服务器。登录到每个 Web 服务器：`web1` 和 `web2`。
- en: Note
  id: totrans-32
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Repeat the following steps on both of the web servers: `web1` and `web2`.'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在 `web1` 和 `web2` 两个 Web 服务器上重复以下步骤。
- en: Now, we'll install Apache2 on each web server. Use the `apt-get install` command
    to install the Apache web server daemon (Apache2).
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将在每个 Web 服务器上安装 Apache2。使用 `apt-get install` 命令安装 Apache Web 服务器守护进程（Apache2）。
- en: '[PRE0]'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Create unique test pages for each web server.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为每个 Web 服务器创建独特的测试页面。
- en: Change the directories (`cd`) to the web server root `(/var/www/html`).
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将目录（`cd`）更改为 Web 服务器根目录 `(/var/www/html)`。
- en: '[PRE1]'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Use the `chown` command to give the user `pi` ownership to the directory (`.`)
    and all of the files in it (`*`).
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `chown` 命令将用户 `pi` 的所有权赋给该目录（`.`）及其所有文件（`*`）。
- en: '[PRE2]'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Create a web page for the web server using the `echo` command.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `echo` 命令为 Web 服务器创建一个网页。
- en: '[PRE3]'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Note
  id: totrans-43
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: During normal operation, both web servers will be serving identical content.
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在正常操作期间，两个 Web 服务器将提供相同的内容。
- en: For testing, the page contents, `<body>web1</body>`, should be unique for each
    web server. Use `<body>web2</body>` for web server `web2`.
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在测试过程中，页面内容 `<body>web1</body>` 应该对每个 Web 服务器是唯一的。对于 Web 服务器 `web2`，使用 `<body>web2</body>`。
- en: Use the `touch` command to create a file (`lb-check.txt`) that can be used by
    the load balancers to validate that the web server is running.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `touch` 命令创建一个文件（`lb-check.txt`），该文件可以被负载均衡器用来验证 Web 服务器是否正在运行。
- en: '[PRE4]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now, test the web servers. Use a web browser to test the web servers. Test
    both their hostnames: `http://web1.local/` and `http://web2.local/`, as well as
    their IP addresses: `http://192.168.2.111/` and `http://192.168.2.112/`.![How
    to do it...](img/B04745_07_01.jpg)'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，测试 Web 服务器。使用 Web 浏览器测试 Web 服务器。测试它们的主机名：`http://web1.local/` 和 `http://web2.local/`，以及它们的
    IP 地址：`http://192.168.2.111/` 和 `http://192.168.2.112/`。![如何操作...](img/B04745_07_01.jpg)
- en: Set up the load balancers. Log in to each of the load balancers, `lb1` and `lb2`.
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置负载均衡器。登录到每个负载均衡器 `lb1` 和 `lb2`。
- en: Note
  id: totrans-50
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Repeat the following steps on both `lb1` and `lb2`.
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在 `lb1` 和 `lb2` 上重复以下步骤。
- en: Install HAProxy and Keepalived on each load balancer. Use the `apt-get install`
    command to download and install the `haproxy` and `keepalived` packages.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在每个负载均衡器上安装 HAProxy 和 Keepalived。使用 `apt-get install` 命令下载并安装 `haproxy` 和 `keepalived`
    包。
- en: '[PRE5]'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Configure HAProxy for each load balancer. Use the `cat` command to add the `listen
    stats` and `listen webfarm` sections to the bottom of the `/etc/haproxy/haproxy.cfg`
    configuration file.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为每个负载均衡器配置 HAProxy。使用 `cat` 命令将 `listen stats` 和 `listen webfarm` 部分添加到 `/etc/haproxy/haproxy.cfg`
    配置文件的底部。
- en: '[PRE6]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Use the `systemctl restart` command to restart `haproxy.service`.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `systemctl restart` 命令重新启动 `haproxy.service`。
- en: '[PRE7]'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Enable listening on virtual IP addresses for both load balancers. Add the configuration
    parameter `net.ipv4.ip_nonlocal_bind=1` to the bottom of the `sysctl.conf` configuration
    file.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为两个负载均衡器启用虚拟 IP 地址监听。将配置参数 `net.ipv4.ip_nonlocal_bind=1` 添加到 `sysctl.conf` 配置文件的底部。
- en: '[PRE8]'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Use the `sysctl –p` command to load the updated configuration.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `sysctl –p` 命令加载更新的配置。
- en: '[PRE9]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Configure Keepalived for both load balancers.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为两个负载均衡器配置 Keepalived。
- en: 'Use the `cat` command to create the `keepalived.conf` configuration file that
    defines the following: a function to check the status of the HAProxy daemon (`chk_haproxy`);
    the network interface `eth0` to listen on; the load balancer''s priority (the
    highest is the master load balancer); and the virtual IP address (192.168.2.100)
    that the load balancers share.'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`cat`命令创建`keepalived.conf`配置文件，定义以下内容：检查HAProxy守护进程状态的函数（`chk_haproxy`）；监听的网络接口`eth0`；负载均衡器的优先级（最高的是主负载均衡器）；以及负载均衡器共享的虚拟IP地址（192.168.2.100）。
- en: Note
  id: totrans-64
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: It is important that the load balancers have different priorities.
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要的是，负载均衡器应具有不同的优先级。
- en: On load balancer `lb1`, use `priority 101` (as shown next).
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在负载均衡器`lb1`上，使用`priority 101`（如下所示）。
- en: On load balancer `lb2`, use `priority 100`.
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在负载均衡器`lb2`上，使用`priority 100`。
- en: '[PRE10]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Use the `systemctl restart` command to restart `keepalived.service`.
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`systemctl restart`命令重启`keepalived.service`。
- en: '[PRE11]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Test the cluster. Use a web browser to test the cluster. Browse to the cluster's
    virtual IP address (`http://192.168.2.100`).
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试集群。使用网页浏览器测试集群。浏览到集群的虚拟IP地址（`http://192.168.2.100`）。
- en: Notice that with each refresh of the browser, the web page displayed alternates
    between the web page from web server `web1` and the web page from `web2`. The
    cluster is working!
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意到每次刷新浏览器时，显示的网页在web服务器`web1`和`web2`的网页之间交替。集群工作正常！
- en: Note
  id: totrans-73
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: For an actual website, the web servers `web1` and `web2` should be serving the
    same content, stateless copies of the same website, or the same web service.
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于实际的网站，web服务器`web1`和`web2`应提供相同的内容、无状态的相同网站副本，或相同的Web服务。
- en: Test web server failure. Log in to `web1` and use the `poweroff` command to
    shut it down.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试web服务器故障。登录到`web1`并使用`poweroff`命令关闭它。
- en: '[PRE12]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Use a web browser to validate that the virtual IP address of the cluster (192.1682.1.00)
    is still working.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用网页浏览器验证集群的虚拟IP地址（192.168.2.100）是否仍然有效。
- en: Notice that with every refresh of the browser, the web page displayed is from
    the only running web server, `web2`.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意，每次刷新浏览器时，显示的网页都来自唯一正在运行的web服务器`web2`。
- en: Use a web browser to check the status of the HA Proxy on `lb1` (`http://lb1.local:8880`).![How
    to do it...](img/B04745_07_02.jpg)
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用网页浏览器检查`lb1`上HA Proxy的状态（`http://lb1.local:8880`）。![如何操作...](img/B04745_07_02.jpg)
- en: Notice that the status of web server `web1` is displayed in red indicating that
    it is down. The status of `web2` is green because it is still running.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意到web服务器`web1`的状态显示为红色，表示其已关闭。`web2`的状态是绿色，表示其仍在运行。
- en: Restart the web server, `web1`.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重启web服务器`web1`。
- en: Refresh the HAProxy status page (`http://lb1.local:8880`) and notice that the
    status of web server `web1` is once again green.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 刷新HAProxy状态页面（`http://lb1.local:8880`），并注意到web服务器`web1`的状态再次变为绿色。
- en: Continually refresh the virtual IP address of the cluster (`http://192.168.2.100`)
    and notice that the web page displayed once again alternates between the web page
    from web server `web1` and the web page from web server `web2`.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不断刷新集群的虚拟IP地址（`http://192.168.2.100`），并注意到显示的网页一次又一次地在web服务器`web1`和web服务器`web2`的网页之间交替。
- en: The cluster runs even if one web server fails!
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 即使一个web服务器出现故障，集群仍然能够运行！
- en: Test load balancer failure. Log in to the master load balancer, `lb1`.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试负载均衡器故障。登录到主负载均衡器`lb1`。
- en: Use the `ip addr` command to show the IP addresses that share the network interface
    `eth0`.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`ip addr`命令显示共享网络接口`eth0`的IP地址。
- en: '[PRE13]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Notice that there are two IPv4 (`inet`) addresses including the cluster's virtual
    IP address (`http://192.168.2.100`) assigned to network interface `eth0`.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请注意，网络接口`eth0`上有两个IPv4（`inet`）地址，包括集群的虚拟IP地址（`http://192.168.2.100`）。
- en: Now, log in to the failover load balancer `lb2`.
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，登录到故障转移负载均衡器`lb2`。
- en: Use the `ip addr` command to show the IP addresses that share the network interface
    `eth0` on load balancer `lb2`.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`ip addr`命令显示负载均衡器`lb2`上共享网络接口`eth0`的IP地址。
- en: '[PRE14]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Notice that there is only one IPv4 (`inet`) address assigned to the network
    interface `eth0` on load balancer `lb2` and it is not the cluster's virtual IP
    address.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请注意，负载均衡器`lb2`上的网络接口`eth0`只分配了一个IPv4（`inet`）地址，而该地址不是集群的虚拟IP地址。
- en: Remove the master load balancer `lb1` from the cluster by disconnecting its
    network cable.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过断开网络电缆，将主负载均衡器`lb1`从集群中移除。
- en: Use the `ip addr` command once again to show the IP addresses that are sharing
    the network interface `eth0` on load balancer `lb2`.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次使用`ip addr`命令显示负载均衡器`lb2`上共享网络接口`eth0`的IP地址。
- en: '[PRE15]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Notice that there are now two IPv4 (`inet`) addresses including the cluster's
    virtual IP address (`http://192.168.2.100`) assigned to network interface `eth0`
    on `lb2`.
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意，现在在 `lb2` 的网络接口 `eth0` 上有两个 IPv4（`inet`）地址，包括集群的虚拟 IP 地址（`http://192.168.2.100`）。
- en: Notice by continuously refreshing the cluster's virtual IP address (`http://192.168.2.100`)
    that load balancing still works—that the web page still alternates between `web1`
    and `web2`.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过不断刷新集群的虚拟 IP 地址（`http://192.168.2.100`），可以看到负载均衡依然有效——网页仍然在 `web1` 和 `web2`
    之间交替显示。
- en: The cluster runs even if one load balancer fails!
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 即使一个负载均衡器发生故障，集群仍能运行！
- en: Now, let's restore normal operation. Add `lb1` back to the cluster by connecting
    its network cable.
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们恢复正常操作。通过连接网络电缆将 `lb1` 重新加入集群。
- en: Use the `ip addr` command on load balancer `lb2` to show that the cluster's
    virtual IP address (192.168.2.100) is no longer assigned to network interface
    `eth0` on load balancer `lb2` (see step *32*).
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在负载均衡器 `lb2` 上使用 `ip addr` 命令，可以显示集群的虚拟 IP 地址（192.168.2.100）不再分配给负载均衡器 `lb2`
    上的网络接口 `eth0`（参见步骤 *32*）。
- en: Use the `ip addr` command on load balancer `lb1` to show that load balancer
    `lb1` once again has the cluster's virtual IP address assigned to its network
    interface `eth0` (see step *29*).
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在负载均衡器 `lb1` 上使用 `ip addr` 命令，可以显示负载均衡器 `lb1` 再次将集群的虚拟 IP 地址分配给其网络接口 `eth0`（参见步骤
    *29*）。
- en: The highly available website cluster is up and running!
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 高可用性网站集群已成功运行！
- en: How it works...
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: The recipe begins by setting up four Raspberry Pis with new hostnames and IP
    addresses so that they can be used more effectively in a cluster.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 该配方开始时通过设置四台树莓派的新主机名和 IP 地址，以便它们能更有效地用于集群。
- en: The load balancers are named `lb1` and `lb2`; and their IP addresses are respectively
    set to 192.168.2.101 and 192.168.2.102\.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 负载均衡器被命名为 `lb1` 和 `lb2`，它们的 IP 地址分别设置为 192.168.2.101 和 192.168.2.102。
- en: The web servers are named `web1` and `web2` with their respective IP addresses
    set to 192.168.2.111 and 192.168.112.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: Web 服务器命名为 `web1` 和 `web2`，它们的 IP 地址分别设置为 192.168.2.111 和 192.168.112。
- en: The `raspi-config` command can be used to change the Raspberry Pi hostname (examples
    of using the `raspi-config` command can be found in [Chapter 2](ch02.html "Chapter 2. Administration"),
    *Administration*).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用 `raspi-config` 命令更改树莓派的主机名（使用 `raspi-config` 命令的示例可以在 [第 2 章](ch02.html
    "第 2 章。管理")，*管理* 中找到）。
- en: A recipe for *Configuring a static IP address* can be found in [Chapter 5](ch05.html
    "Chapter 5. Advanced Networking"), *Advanced Networking*.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 *配置静态 IP 地址* 的配方可以在 [第 5 章](ch05.html "第 5 章。高级网络")，*高级网络* 中找到。
- en: Setting up the web servers
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 配置 Web 服务器
- en: After each Raspberry Pi is properly named and addressed, the Apache HTTP daemon
    is set up on each of the two web servers, `web1` and `web2`.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个树莓派正确命名并分配地址后，`web1` 和 `web2` 两台 Web 服务器上都已配置好 Apache HTTP 守护进程。
- en: Installing Apache2 on each web server
  id: totrans-111
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在每台 Web 服务器上安装 Apache2
- en: The `apt-get install` command is used to install the `apache2` package on each
    web server.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `apt-get install` 命令在每台 Web 服务器上安装 `apache2` 包。
- en: Installation includes starting the Apache HTTP server and restarting it with
    each boot.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 安装过程包括启动 Apache HTTP 服务器并在每次启动时重启它。
- en: Note
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '[Chapter 5](ch05.html "Chapter 5. Advanced Networking"), *Advanced Networking*,
    has a recipe for installing a web server with more detailed instructions on setting
    up a web server.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '[第 5 章](ch05.html "第 5 章。高级网络")，*高级网络*，中有安装 Web 服务器的配方，提供了更详细的 Web 服务器设置说明。'
- en: Creating unique test web pages for each web server
  id: totrans-116
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 为每台 Web 服务器创建独特的测试网页
- en: 'The `cd` command is used to change the web server''s root directory, `/var/www/html`,
    where two files will be created: the default web page, `index.html`, and a file
    for the load balancers to check periodically to ensure that the web server is
    still running, `lb-check.txt`.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '`cd` 命令用于更改 Web 服务器的根目录 `/var/www/html`，在该目录下将创建两个文件：默认网页 `index.html` 和一个供负载均衡器定期检查以确保
    Web 服务器仍在运行的文件 `lb-check.txt`。'
- en: The `chown` command is used to change the ownership of the root directory (`.`)
    and all the files in it (`*`) to the user `pi`. After changing ownership, the
    user `pi` can create and delete files in the web server's root directory.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `chown` 命令将根目录（`./`）及其中的所有文件（`*`）的所有权更改为用户 `pi`。更改所有权后，用户 `pi` 可以在 Web 服务器的根目录中创建和删除文件。
- en: 'Two files are created on each web server: `index.html` and `lb-check.txt`.
    The `lb-check.txt` file can be empty. It just needs to exist.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 每台 Web 服务器上都会创建两个文件：`index.html` 和 `lb-check.txt`。`lb-check.txt` 文件可以为空，它只需要存在。
- en: The `echo` command is used to write the very simple `index.html` file, and the
    `touch` command is used to create an empty `lb-check.txt` file.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `echo` 命令写入非常简单的 `index.html` 文件，使用 `touch` 命令创建一个空的 `lb-check.txt` 文件。
- en: This recipe intentionally uses unique `index.html` files on each web server
    to demonstrate load balancing in action. On web server `web1`, the body of the
    web page is `web1` and on web server `web2` the `body` is `web2`.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 本文故意在每个 web 服务器上使用唯一的 `index.html` 文件来演示负载均衡的实际效果。在 web 服务器 `web1` 上，网页内容是 `web1`，而在
    web 服务器 `web2` 上，网页内容是 `web2`。
- en: During the normal operation of a website cluster, clients of the website should
    see the same web page regardless of which web server the load balancer has selected.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在网站集群的正常运行过程中，网站的客户端应该看到相同的网页，无论负载均衡器选择了哪个 web 服务器。
- en: During the normal operation of a website cluster, each of the cluster's web
    servers will be identical. They will either have identical `index.html` files
    or they will be configured to serve the same web application.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在网站集群的正常运行过程中，集群中的每个 web 服务器应该是相同的。它们要么拥有相同的 `index.html` 文件，要么配置为提供相同的 web
    应用程序。
- en: This recipe uses two different `index.html` files to demonstrate load balancing.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 本文使用两个不同的 `index.html` 文件来演示负载均衡。
- en: Testing the web servers
  id: totrans-125
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 测试 web 服务器
- en: 'A web browser is used to test that each web server is up and running.     The hostname and IP address of both web servers are tested:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 web 浏览器测试每个 web 服务器是否正常运行。测试两个 web 服务器的主机名和 IP 地址：
- en: '[PRE16]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Setting up the load balancers
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设置负载均衡器
- en: After the web servers have been installed and tested, HA Proxy and Keepalived
    are set up on the two load balancers, **lb1** and **lb2**. HA Proxy is the load
    balancer service, and Keepalived is the failover service. HA Proxy distributes
    web requests between the two web servers and Keepalived replaces the master load
    balancer with another, if it fails.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在 web 服务器安装并测试完成后，HAProxy 和 Keepalived 在两个负载均衡器 **lb1** 和 **lb2** 上进行设置。HAProxy
    是负载均衡服务，Keepalived 是故障切换服务。HAProxy 在两个 web 服务器之间分配 web 请求，Keepalived 在主负载均衡器出现故障时会用另一个负载均衡器替代。
- en: Install haproxy and keepalived on each load balancer
  id: totrans-130
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在每个负载均衡器上安装 haproxy 和 keepalived
- en: The `apt-get install` command is used to install the HAProxy and Keepalived
    software distribution packages on each load balancer.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `apt-get install` 命令在每个负载均衡器上安装 HAProxy 和 Keepalived 软件包。
- en: Installation includes starting and restarting both HAProxy and Keepalived with
    each boot. However, HAProxy and Keepalived still need to be configured.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 安装过程包括在每次启动时启动和重新启动 HAProxy 和 Keepalived。然而，HAProxy 和 Keepalived 仍然需要进行配置。
- en: Configuring HAProxy for each load balancer
  id: totrans-133
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 为每个负载均衡器配置 HAProxy
- en: 'The default HAProxy configuration file `(/etc/haproxy/haproxy.cfg`) needs two
    new sections: `listen stats` and `listen webfarm`.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 默认的 HAProxy 配置文件 `(/etc/haproxy/haproxy.cfg)` 需要两个新部分：`listen stats` 和 `listen
    webfarm`。
- en: The `listen stats` section creates a protected single-page web server on port
    `8880` for all network interfaces of the load balancer (0.0.0.0) including the
    virtual network interface for the cluster (192.168.2.100). The statistics web
    server is protected (`stats auth`) by a username (`pi`) and a password (`raspberry`).
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '`listen stats` 部分在负载均衡器的所有网络接口（0.0.0.0）上创建一个受保护的单页 web 服务器，端口为 `8880`，包括集群的虚拟网络接口（192.168.2.100）。统计信息
    web 服务器通过用户名（`pi`）和密码（`raspberry`）进行保护（`stats auth`）。'
- en: The `listen webfarm` section defines the collection of web servers (server `web1`,
    server `web2`) that the HAProxy will load balance using the roundrobin load-balancing
    algorithm, as well as the method (`httpchk HEAD`) and URL (`/lb-check.txt`) that
    are used to test if the web servers are still running.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '`listen webfarm` 部分定义了由 HAProxy 使用轮询负载均衡算法进行负载均衡的 web 服务器集合（服务器 `web1`，服务器
    `web2`），以及用于测试 web 服务器是否仍在运行的方法（`httpchk HEAD`）和 URL（`/lb-check.txt`）。'
- en: A secure shell (`sudo bash`) is used to update the HAProxy's configuration file
    (`/etc/haproxy/haproxy.cfg`).
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 使用安全外壳（`sudo bash`）更新 HAProxy 的配置文件（`/etc/haproxy/haproxy.cfg`）。
- en: Within the Secure Shell, the `cat` command is used to append the lines following
    the `cat` command up to the end of data mark (`<<EOD`) to the bottom of the file
    (`>>haproxy.cfg`).
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在安全外壳中，`cat` 命令用于将 `cat` 命令之后的行追加到数据标记结束（`<<EOD`）并写入文件底部（`>>haproxy.cfg`）。
- en: The Secure Shell is released (`exit`) after the file is updated.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 文件更新完成后，退出安全外壳（`exit`）。
- en: The `systemctl` command is used to restart the HAProxy service (`happroxy.service`)
    on each load balancer, so that the service on each load balancer can update its
    configuration.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `systemctl` 命令在每个负载均衡器上重新启动 HAProxy 服务 (`happroxy.service`)，以便服务在每个负载均衡器上更新其配置。
- en: Enable listening on virtual IP addresses for both load balancers
  id: totrans-141
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 启用两个负载均衡器上的虚拟 IP 地址监听。
- en: The Raspberry Pi's Linux kernel is not by default configured to listen on the
    virtual IP addresses used by Keepalived. The system kernel configuration file
    (`/etc/sysctl.conf`) needs to be updated to permit non-local network binding.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 树莓派的 Linux 内核默认未配置为监听 Keepalived 使用的虚拟 IP 地址。系统内核配置文件 (`/etc/sysctl.conf`) 需要更新以允许非本地网络绑定。
- en: A secure shell (`sudo bash`) is used to update the system kernel configuration
    file (`sysctl.conf`).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 使用安全外壳 (`sudo bash`) 更新系统内核配置文件 (`sysctl.conf`)。
- en: Within the Secure Shell, the `echo` command is used to enable virtual IP addresses
    by appending the statement `net.ipv4.ip_nonlocal_bind=1` to the bottom of the
    system kernel configuration file (`systctl.conf`) (`>>`).
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在安全外壳内部，使用 `echo` 命令通过将语句 `net.ipv4.ip_nonlocal_bind=1` 追加到系统内核配置文件 (`systctl.conf`)
    的底部来启用虚拟 IP 地址 (`>>`)。
- en: The Secure Shell is released (`exit`) after the file is updated.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在更新文件后，安全外壳（Secure Shell）会释放 (`exit`)。
- en: The `sysctl –p` command is used to load the updated kernel configuration.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `sysctl –p` 命令加载更新的内核配置。
- en: Configuring Keepalived for both load balancers
  id: totrans-147
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 配置两个负载均衡器的 Keepalived。
- en: Although Keepalived is installed and ready, it has not been configured.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 Keepalived 已安装并准备就绪，但尚未配置。
- en: A secure shell (`sudo bash`) is used to create a Keepalived configuration file
    (`/etc/keepalived/keepalived.conf`).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 使用安全外壳 (`sudo bash`) 创建 Keepalived 配置文件 (`/etc/keepalived/keepalived.conf`)。
- en: Within the secure shell, the `cat` command is used to create the configuration
    file by copying the lines following the `cat` command up to the end of data mark
    (`<<EOD`) to the configuration file (`>keepalived.conf`).
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在安全外壳内部，使用 `cat` 命令通过复制从 `cat` 命令后面的行到结束数据标记 (`<<EOD`) 到配置文件 (`>keepalived.conf`)
    来创建配置文件。
- en: The Secure Shell is released (`exit`) after the file is updated.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在更新文件后，安全外壳（Secure Shell）会释放 (`exit`)。
- en: 'Keepalived configuration has two sections: `vrrp_script chk_haproxy` and `vrrp_instance
    VI_1`.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: Keepalived 配置有两个部分：`vrrp_script chk_haproxy` 和 `vrrp_instance VI_1`。
- en: The `vrrp_script chk_haproxy` section defines a script (`killall -0 haproxy`)
    that will complete with an OK status so long as a process named `haproxy` is running.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '`vrrp_script chk_haproxy` 部分定义了一个脚本 (`killall -0 haproxy`)，只要名为 `haproxy` 的进程正在运行，就会完成
    OK 状态。'
- en: The command name `killall` is misleading; the `-0` parameter tells the command
    to do nothing more than exit with an OK status. The `killall` command can also
    be used to `kill` processes; however, that is not its purpose here.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '`killall` 命令的命令名称有误导性；`-0` 参数告诉命令仅退出并显示 OK 状态。`killall` 命令也可以用来终止进程；但在这里不是其目的。'
- en: The `vrrp_instance VI_1` section defines the `virtual_ipaddress` that is shared
    by the two load balancers (192.168.2.100). This section also defines the network
    interface (`eth0`) that is used to bind the virtual IP address, the `track_script`
    (`chk_haproxy`) that is used to keep track of the `haproxy` process, and a priority
    that is used to determine which of the load balancers is the `MASTER`.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '`vrrp_instance VI_1` 部分定义了两个负载均衡器（192.168.2.100）共享的 `virtual_ipaddress`。该部分还定义了用于绑定虚拟
    IP 地址的网络接口 (`eth0`)，用于跟踪 `haproxy` 进程的 `track_script` (`chk_haproxy`)，以及用于确定哪个负载均衡器为
    `MASTER` 的优先级。'
- en: Note
  id: totrans-156
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The `priority` parameter should be different on the two load balancers.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '`priority` 参数在两个负载均衡器上应不同。'
- en: The master load balancer, `lb1`, should have a higher priority (priority `101`)
    than the failover load balancer, `lb2` (priority `100`).
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 主负载均衡器 `lb1` 的优先级应比备用负载均衡器 `lb2` 更高（优先级 `101`）。
- en: The priority should be different on each of the load balancers. In this recipe,
    load balancer `lb1` has the priority `101` and load balancer `lb2` has the priority
    `100`. The load balancer with the highest priority (`lb1`) is used as the master
    and the other load balancer (`lb2`) is used as a failover slave.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 每个负载均衡器的优先级应不同。在本示例中，负载均衡器 `lb1` 的优先级为 `101`，负载均衡器 `lb2` 的优先级为 `100`。具有最高优先级
    (`lb1`) 的负载均衡器用作主节点，另一个负载均衡器 (`lb2`) 用作备份从节点。
- en: Only the master load balancer (`lb1`) listens on the defined virtual network
    address (192.168.2.100). The failover load balancer (`lb2`) does not.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 只有主负载均衡器（`lb1`）监听定义的虚拟网络地址（192.168.2.100）。故障切换负载均衡器（`lb2`）不监听。
- en: The HAProxy running on the master load balancer (`lb1`) is the service used
    by the cluster to balance web requests between the web servers. The HAProxy on
    the failover load balancer (`lb2`) is still running, but it is not used by the
    cluster because the failover load balancer (`lb2`) is not listening on the cluster's
    virtual IP address (192.168.2.100).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 运行在主负载均衡器（`lb1`）上的HAProxy是集群用来在Web服务器之间平衡Web请求的服务。故障切换负载均衡器（`lb2`）上的HAProxy仍在运行，但它不被集群使用，因为故障切换负载均衡器（`lb2`）没有监听集群的虚拟IP地址（192.168.2.100）。
- en: If the master load balancer (`lb1`) does fail, the load balancer with the next
    highest priority (`lb2`) becomes the master.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 如果主负载均衡器（`lb1`）发生故障，具有下一个最高优先级（`lb2`）的负载均衡器将成为主负载均衡器。
- en: If the master `track_script` reports of load balancer (`lb1`) indicates that
    the master's `haproxy` process is no longer running, the master transfers control
    of the virtual IP address (192.168.2.100) to the failover load balancer (`lb2`).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 如果主负载均衡器（`lb1`）的 `track_script` 报告显示主负载均衡器的 `haproxy` 进程不再运行，主负载均衡器将把虚拟IP地址（192.168.2.100）的控制权转交给故障切换负载均衡器（`lb2`）。
- en: If the failover load balancer (`lb2`) can no longer connect to the master load
    balancer (`lb1`), the failover load balancer (`lb2`) will attempt to take over
    the virtual IP address.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 如果故障切换负载均衡器（`lb2`）无法再连接到主负载均衡器（`lb1`），故障切换负载均衡器（`lb2`）将尝试接管虚拟IP地址。
- en: The `virtual_router_id` parameter defines a unique ID (`51`) that is used by
    the load balancers keeping the same virtual IP address up and running.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '`virtual_router_id` 参数定义了一个唯一的ID（`51`），该ID由负载均衡器用于保持相同的虚拟IP地址持续运行。'
- en: The Secure Shell is released (`exit`) after the file is created.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 文件创建完成后，退出安全外壳（`exit`）。
- en: The `systemctl` command is used to restart the Keepalived service (`keepalived.service`)
    on both load balancers, so that the service on each load balancer can update its
    configuration.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '`systemctl` 命令用于在两个负载均衡器上重启Keepalived服务（`keepalived.service`），以便每个负载均衡器上的服务可以更新其配置。'
- en: Testing the cluster
  id: totrans-168
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 测试集群
- en: A web browser is used to validate that the website cluster is up and running
    on the defined virtual IP address (192.168.2.100).
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Web浏览器验证网站集群是否仍在定义的虚拟IP地址（192.168.2.100）上运行。
- en: When the website URL (`http://192.168.2.100/`) is refreshed in the browser,
    the page displayed in the browser alternates between the default web page (`index.html`)
    from web server `web1` and the default page from web server `web2`. The master
    load balancer (`lb1`) is alternating web requests (round robin) between the two
    web servers.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 当在浏览器中刷新网站URL（`http://192.168.2.100/`）时，浏览器中显示的页面在Web服务器 `web1` 的默认网页（`index.html`）和Web服务器
    `web2` 的默认页面之间交替显示。主负载均衡器（`lb1`）在两个Web服务器之间交替（轮询）处理Web请求。
- en: The cluster is working!
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 集群正在运行！
- en: Testing web server failure
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试Web服务器故障
- en: In order to test that the website cluster's virtual IP address still responds
    to web requests after the failure of a single web server, web server `web1` is
    shut down using the `poweroff` command.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试在单个Web服务器故障后，网站集群的虚拟IP地址是否仍然能响应Web请求，使用 `poweroff` 命令关闭Web服务器 `web1`。
- en: After web server `web1` has been shut down, a web browser is used to validate
    that the website cluster is still up and running on the defined virtual IP address
    (`192.168.2.100`).
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在Web服务器 `web1` 被关闭后，使用Web浏览器验证网站集群是否仍在定义的虚拟IP地址（`192.168.2.100`）上正常运行。
- en: When the website URL (`http://192.168.2.100/`) is refreshed in the browser,
    the web page displayed in the browser no longer alternates between the two web
    servers. Now, only the default page (`index.html`) from web server `web2` is displayed.
    The master load balancer (`lb1`) is still running but can only serve web requests
    from web server web2.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 当在浏览器中刷新网站URL（`http://192.168.2.100/`）时，浏览器中显示的网页不再在两个Web服务器之间交替。现在，只有Web服务器
    `web2` 的默认页面（`index.html`）被显示。主负载均衡器（`lb1`）仍在运行，但只能为来自Web服务器 `web2` 的Web请求提供服务。
- en: Then, the web browser is used to browse the URL of the HAProxy statistics page
    (`http://lb1.local:8880/`) of the master load balancer (`lb1`). The statistics
    page shows that web server `web1` is no longer available by displaying the statistics
    for the web server with a red background color. Web server `web2` is still running,
    so its statistics are displayed with a green background color.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，使用网页浏览器访问主负载均衡器（`lb1`）的HAProxy统计页面URL（`http://lb1.local:8880/`）。统计页面显示Web服务器`web1`不可用，并以红色背景色显示该Web服务器的统计信息。Web服务器`web2`仍在运行，因此其统计信息以绿色背景色显示。
- en: The website continues to work properly, even if one web server is down.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 即使一个Web服务器发生故障，网站也会继续正常运行。
- en: Next, web server `web1` is restarted.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，重新启动Web服务器`web1`。
- en: After web server `web1` has restarted, the master load balancer (`lb1`) detects
    the availability of the web server's tracking file (`http://lb1.local/chk_haproxy.txt`)
    and web server `web1` is added back to the load balancer's `webfarm`.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在Web服务器`web1`重新启动后，主负载均衡器（`lb1`）检测到Web服务器跟踪文件（`http://lb1.local/chk_haproxy.txt`）的可用性，并将Web服务器`web1`重新加入到负载均衡器的`webfarm`中。
- en: A refresh of the HAProxy statistics page shows that the statistics from web
    server `web1` are once again green, and continually refreshing the website's virtual
    URL (`http://192.168.2.100/`) once again alternates between `web1` and `web2`.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 刷新HAProxy统计页面显示，来自Web服务器`web1`的统计数据再次变为绿色，并且不断刷新网站的虚拟URL（`http://192.168.2.100/`）时，页面在`web1`和`web2`之间交替切换。
- en: The website is protected from web server failure and web servers can be added
    on demand to handle more requests!
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 网站受到Web服务器故障的保护，可以按需添加Web服务器来处理更多的请求！
- en: Testing load balancer failure
  id: totrans-182
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 测试负载均衡器故障
- en: Removing the master load balancer (`lb1`) from the network by disconnecting
    its network cable tests the failover of the master load balancer.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 通过断开主负载均衡器（`lb1`）的网络连接来将其移出网络，从而测试主负载均衡器的故障切换。
- en: Before the master load balancer (`lb1`) is disconnected from the network, the
    `ip addr` command is used to show that the website cluster's virtual IP address
    (`192.168.2.100`) is bound to the master load balancer's network interface (`eth0`).
    The `ip addr` command is also used on the failover load balancer (`lb2`) to show
    that it does not have the cluster's virtual IP address bound to its network interface
    (`eth0`).
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在主负载均衡器（`lb1`）断开与网络的连接之前，使用`ip addr`命令显示网站集群的虚拟IP地址（`192.168.2.100`）绑定到主负载均衡器的网络接口（`eth0`）。`ip
    addr`命令也用于故障切换负载均衡器（`lb2`）以显示它的网络接口（`eth0`）上未绑定集群的虚拟IP地址。
- en: After the master load balancer (`lb1`) has been disconnected from the network,
    the `ip addr` command is run again on the failover load balancer (`lb2`). Now
    that the master load balancer (`lb1`) is disconnected from the network, the failover
    load balancer (`lb2`) has taken over the cluster's virtual IP address (`192.168.2.100`).
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在主负载均衡器（`lb1`）断开与网络的连接后，再次在故障切换负载均衡器（`lb2`）上运行`ip addr`命令。由于主负载均衡器（`lb1`）已从网络中断开，故障切换负载均衡器（`lb2`）已接管了集群的虚拟IP地址（`192.168.2.100`）。
- en: While the master load balancer (`lb1`) is disconnected from the network, a web
    browser is used to validate that the website cluster is still up and running on
    the defined virtual IP address (`192.168.2.100`).
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 当主负载均衡器（`lb1`）断开与网络的连接时，使用网页浏览器验证网站集群是否仍在定义的虚拟IP地址（`192.168.2.100`）上正常运行。
- en: When the website URL (`http://192.168.2.100/`) is refreshed in the browser,
    the web page displayed in the browser continues to alternate between the two web
    servers. Load balancing still works even though the master load balancer (`lb1`)
    is offline. The failover load balancer (`lb2`) has taken over load balancing successfully!
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 当在浏览器中刷新网站URL（`http://192.168.2.100/`）时，浏览器中显示的网页继续在两个Web服务器之间交替。即使主负载均衡器（`lb1`）脱机，负载均衡仍然有效。故障切换负载均衡器（`lb2`）已成功接管负载均衡！
- en: The website cluster continues to work properly, even if one load balancer is
    down!
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 即使一个负载均衡器发生故障，网站集群仍然能够继续正常运行！
- en: Restoring normal operation
  id: totrans-189
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 恢复正常运行
- en: Normal operation is restored to the website cluster by reconnecting the master
    load balancer (`lb1`) to the network.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将主负载均衡器（`lb1`）重新连接到网络，恢复网站集群的正常运行。
- en: After the master load balancer (`lb1`) has been reconnected, the `ip addr` command
    is again run on each load balancer. The master load balancer (`lb1`) once again
    has the cluster's virtual IP address (`192.168.2.100`) bound to its network interface
    (`eth0`) and the failover load balancer (`lb2`) no longer has the virtual IP address
    bound to its network interface.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在主负载均衡器（`lb1`）重新连接后，`ip addr`命令再次在每个负载均衡器上运行。主负载均衡器（`lb1`）再次将集群的虚拟IP地址（`192.168.2.100`）绑定到其网络接口（`eth0`），而故障切换负载均衡器（`lb2`）不再将虚拟IP地址绑定到其网络接口。
- en: The highly available website cluster is up and running!
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 高可用性网站集群已启动并运行！
- en: There's more…
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容……
- en: This recipe is a very simple example of a highly available website cluster that
    can be used to serve any stateless website such as a collection of static web
    pages or a website created with a website generator like **Jekyll** ([http://jekyllrb.com/](http://jekyllrb.com/)).
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子是一个非常简单的高可用性网站集群示例，可以用于服务任何无状态的网站，例如静态网页集合或使用像**Jekyll** ([http://jekyllrb.com/](http://jekyllrb.com/))
    这样的站点生成器创建的网站。
- en: Scaling horizontally by adding more web servers
  id: totrans-195
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过添加更多Web服务器进行水平扩展
- en: A cluster is scaled horizontally by adding more servers.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 通过添加更多服务器来水平扩展集群。
- en: The website cluster in this recipe can be scaled horizontally by adding more
    Raspberry Pi web servers. Each additional web server added to the cluster should
    be configured exactly the same as the existing web servers (see steps *2* through
    *8*).
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 本示例中的网站集群可以通过添加更多树莓派Web服务器来进行水平扩展。每添加一个新的Web服务器到集群中，都应将其配置与现有的Web服务器完全相同（参见步骤*2*到*8*）。
- en: Scaling a Raspberry Pi cluster vertically is limited by the amount of memory
    available in a Raspberry Pi. The memory allocated by the GPU can be reduced freeing
    more memory for use by services; however, the physical memory of a Raspberry Pi
    cannot be increased.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 树莓派集群的垂直扩展受限于树莓派可用的内存量。可以减少GPU分配的内存，从而为服务腾出更多内存；然而，树莓派的物理内存无法增加。
- en: The fixed memory size of the Raspberry Pi puts limits on scaling Raspberry Pi
    clusters. They can be easily scaled horizontally, but not vertically.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 树莓派的固定内存大小限制了树莓派集群的扩展性。它们可以很容易地进行水平扩展，但无法垂直扩展。
- en: Session cookies
  id: totrans-200
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 会话cookie
- en: Many websites are stateful, not stateless. Stateful websites use session cookies
    to create unique sessions that require a login. The HAProxy configuration in this
    recipe is for stateless websites and does not recognize session cookies.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 许多网站是有状态的，而不是无状态的。有状态的网站使用会话cookie来创建需要登录的唯一会话。本示例中的HAProxy配置适用于无状态网站，并不识别会话cookie。
- en: A user session is stored in a web application server and the session cookie
    is a unique key that is used to identify each unique user session in the web server.
    In most situations, sessions cannot be shared across web servers. The load balancer
    needs to ensure that once a user starts a session with one web server, all requests
    to the website cluster are directed to that web server and not to any other.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 用户会话存储在Web应用服务器中，会话cookie是用于识别每个唯一用户会话的唯一键。在大多数情况下，会话不能跨Web服务器共享。负载均衡器需要确保一旦用户在某个Web服务器上开始会话，所有对网站集群的请求都被定向到该Web服务器，而不是其他服务器。
- en: Web application servers and frameworks like Apache Tomcat and PHP depend on
    session cookies. Apache Tomcat uses the session cookie `JSESSIONID`, and PHP uses
    the `PHPSESSID` session cookie.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: Web应用服务器和框架如Apache Tomcat和PHP依赖于会话cookie。Apache Tomcat使用会话cookie `JSESSIONID`，而PHP使用`PHPSESSID`会话cookie。
- en: For websites that depend on session cookies, the load balancer for the website
    cluster needs to ensure that web requests from the same unique user (as identified
    by the session cookie) are always sent to the same web server because only that
    web server has the user's session.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 对于依赖于会话cookie的网站，网站集群的负载均衡器需要确保来自同一唯一用户（由会话cookie识别）的Web请求始终发送到同一Web服务器，因为只有该Web服务器拥有该用户的会话。
- en: 'To enable the HAProxy servers in this recipe to recognize session cookies for
    Apache Tomcat (or other Java application servers), replace the two server configuration
    parameters in the HAProxy configuration file (`/etc/haproxy/haproxy.cfg`) with
    the following three lines:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使本示例中的HAProxy服务器能够识别Apache Tomcat（或其他Java应用服务器）的会话cookie，请将HAProxy配置文件（`/etc/haproxy/haproxy.cfg`）中的两个服务器配置参数替换为以下三行：
- en: '[PRE17]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The first line turns on the cookie tracking option using the `JSESSIONID` cookie
    plus a unique prefix for each web server. The two server configuration parameters
    have been updated to set a unique `cookie` prefix for each server (`web1` and
    `web2`).
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 第一行使用 `JSESSIONID` Cookie 和每个 Web 服务器的唯一前缀来启用 Cookie 跟踪选项。两个服务器的配置参数已更新，为每个服务器（`web1`
    和 `web2`）设置唯一的 `cookie` 前缀。
- en: After restarting the HAProxy service (`systemctl restart haproxy.service`),
    the cluster will recognize session cookies.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在重启 HAProxy 服务（`systemctl restart haproxy.service`）后，集群将识别会话 Cookie。
- en: See also
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: '**Computer cluster** ([https://en.wikipedia.org/wiki/Computer_cluster](https://en.wikipedia.org/wiki/Computer_cluster)):
    This Wikipedia article describes the concepts and history of computer clusters.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算机集群** ([https://en.wikipedia.org/wiki/Computer_cluster](https://en.wikipedia.org/wiki/Computer_cluster)):
    这篇维基百科文章描述了计算机集群的概念和历史。'
- en: '**Keepalived** ([http://www.keepalived.org/](http://www.keepalived.org/)):
    The main goal of this project is to provide simple and robust facilities for load
    balancing and high availability to a Linux system and Linux-based infrastructures.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Keepalived** ([http://www.keepalived.org/](http://www.keepalived.org/)):
    该项目的主要目标是为 Linux 系统及基于 Linux 的基础设施提供简单且稳健的负载均衡和高可用性功能。'
- en: '**HAProxy** ([http://www.haproxy.org/](http://www.haproxy.org/)): HAProxy is
    a free, very fast, and reliable solution offering high availability, load balancing,
    and proxying for TCP and HTTP-based applications.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**HAProxy** ([http://www.haproxy.org/](http://www.haproxy.org/)): HAProxy 是一个免费的、非常快速且可靠的解决方案，提供高可用性、负载均衡和
    TCP 与 HTTP 应用程序的代理功能。'
- en: '**systemctl – control the systemd system and service manager** ([http://manpages.debian.org/cgi-bin/man.cgi?query=systemctl](http://manpages.debian.org/cgi-bin/man.cgi?query=systemctl)):
    The Debian manual page for `systemctl` describes the command and its options.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**systemctl – 控制 systemd 系统和服务管理器** ([http://manpages.debian.org/cgi-bin/man.cgi?query=systemctl](http://manpages.debian.org/cgi-bin/man.cgi?query=systemctl)):
    Debian 手册页面中描述了 `systemctl` 命令及其选项。'
- en: '**sysctl – read/write system parameters** ([http://manpages.debian.org/cgi-bin/man.cgi?query=sysctl&sektion=8](http://manpages.debian.org/cgi-bin/man.cgi?query=sysctl&sektion=8)):
    The Debian manual page for `sysctl` describes the command and its options.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**sysctl – 读取/写入系统参数** ([http://manpages.debian.org/cgi-bin/man.cgi?query=sysctl&sektion=8](http://manpages.debian.org/cgi-bin/man.cgi?query=sysctl&sektion=8)):
    Debian 手册页面中描述了 `sysctl` 命令及其选项。'
- en: '**killall – kill processes by name** ([http://manpages.debian.org/cgi-bin/man.cgi?query=killall](http://manpages.debian.org/cgi-bin/man.cgi?query=killall)):
    The Debian manual page for `killall` describes the command and its options.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**killall – 按名称杀死进程** ([http://manpages.debian.org/cgi-bin/man.cgi?query=killall](http://manpages.debian.org/cgi-bin/man.cgi?query=killall)):
    Debian 手册页面中描述了 `killall` 命令及其选项。'
- en: '**Jekyll** ([http://jekyllrb.com/](http://jekyllrb.com/)): Transform your plain
    text into static websites and blogs.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Jekyll** ([http://jekyllrb.com/](http://jekyllrb.com/)): 将纯文本转换为静态网站和博客。'
- en: '**Scalability** ([https://en.wikipedia.org/wiki/Scalability](https://en.wikipedia.org/wiki/Scalability)):
    This Wikipedia article defines scalability, both horizontal and vertical.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可扩展性** ([https://en.wikipedia.org/wiki/Scalability](https://en.wikipedia.org/wiki/Scalability)):
    这篇维基百科文章定义了水平和垂直的可扩展性。'
- en: '**Session cookie** ([https://en.wikipedia.org/wiki/HTTP_cookie#Session_cookie](https://en.wikipedia.org/wiki/HTTP_cookie#Session_cookie)):
    This Wikipedia article about HTTP cookies also defines session cookies.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**会话 Cookie** ([https://en.wikipedia.org/wiki/HTTP_cookie#Session_cookie](https://en.wikipedia.org/wiki/HTTP_cookie#Session_cookie)):
    这篇关于 HTTP Cookie 的维基百科文章也定义了会话 Cookie。'
- en: Installing a distributed filesystem
  id: totrans-219
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装分布式文件系统
- en: This recipe turns four Raspberry Pis into a highly available distributed filesystem
    using GlusterFS.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 这个配方将四台树莓派变成一个高可用的分布式文件系统，使用的是 GlusterFS。
- en: GlusterFS is a scalable network filesystem suitable for data-intensive tasks
    such as cloud storage and media streaming. GlusterFS is free and open source software
    and can utilize common off-the-shelf hardware like the Raspberry Pi.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: GlusterFS 是一个可扩展的网络文件系统，适用于数据密集型任务，如云存储和媒体流。GlusterFS 是免费且开源的软件，可以利用常见的现成硬件，如树莓派。
- en: After completing this recipe, you will have clustered four Raspberry Pis to
    create a highly available distributed filesystem.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这个配方后，你将把四台树莓派集群起来，创建一个高可用的分布式文件系统。
- en: Getting ready
  id: totrans-223
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Here are the ingredients for this recipe:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 这是这个配方所需的材料：
- en: Four basic networking setups for the Raspberry Pi
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 树莓派的四种基本网络配置
- en: Four available IP addresses on the local network
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本地网络上的四个可用 IP 地址
- en: This recipe does not require the desktop GUI and could either be run from the
    text-based console or from within an LXTerminal.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程不需要桌面GUI，可以从基于文本的控制台或LXTerminal中运行。
- en: With the Secure Shell server running on each Raspberry Pi, this recipe can be
    completed remotely using a Secure Shell client. A distributed filesystem is typically
    managed remotely.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个树莓派上运行Secure Shell服务时，本教程可以通过Secure Shell客户端远程完成。分布式文件系统通常是通过远程管理的。
- en: How to do it...
  id: totrans-229
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'The steps to building a highly available Raspberry Pi distributed filesystem
    are:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 构建高可用的树莓派分布式文件系统的步骤如下：
- en: Log in to each of the four Raspberry Pis and set their hostnames. Name the Raspberry
    Pis `gluster1`, `gluster2`, `gluster3`, and `gluster4`.
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录到四个树莓派，设置它们的主机名。将树莓派命名为`gluster1`、`gluster2`、`gluster3`和`gluster4`。
- en: Note
  id: totrans-232
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The `raspi-config` command can be used to change the hostname of your Raspberry
    Pi. [Chapter 2](ch02.html "Chapter 2. Administration"), *Administration*, has
    recipes for configuring the Raspberry Pi that use the `raspi-config` command.
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`raspi-config`命令可用于更改树莓派的主机名。[第2章](ch02.html "第2章. 管理")，*管理*，包含使用`raspi-config`命令配置树莓派的教程。'
- en: Installing the GlusterFS server on each Raspberry Pi
  id: totrans-234
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在每个树莓派上安装GlusterFS服务器
- en: 'Log in to each of the four Raspberry Pis: `gluster1`, `gluster2`, `gluster3`,
    and `gluster4`.'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录到四个树莓派：`gluster1`、`gluster2`、`gluster3`和`gluster4`。
- en: Use the `apt-get install` command to install the GlusterFS server (`glusterfs-server`).
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`apt-get install`命令安装GlusterFS服务器（`glusterfs-server`）。
- en: '[PRE18]'
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Note
  id: totrans-238
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Repeat the installation of `glusterfs-server` on each of the four Raspberry
    Pis: `gluster1`, `gluster2`, `gluster3`, and `glsuter4`.'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在四个树莓派上重复安装`glusterfs-server`：`gluster1`、`gluster2`、`gluster3`和`gluster4`。
- en: Now, let's create a trusted storage pool. After each of the Raspberry Pis has
    had GlusterFS installed, log in to `gluster1` and use the `gluster peer probe`
    command to link the other three Raspberry Pis into a single trusted storage pool.
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们创建一个受信存储池。在每个树莓派上安装了GlusterFS后，登录到`gluster1`，使用`gluster peer probe`命令将其他三个树莓派连接到一个受信存储池中。
- en: '[PRE19]'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Use the `gluster` `peer status` command to check that the storage pool has been
    created successfully.
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`gluster` `peer status`命令检查存储池是否已成功创建。
- en: '[PRE20]'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Also use the `gluster peer status` from another peer in the storage pool (`gluster2`)
    to validate the storage pool.
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 还可以从存储池中的另一个节点（`gluster2`）使用`gluster peer status`验证存储池。
- en: '[PRE21]'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Notice that the `Hostname` displayed for `gluster1` is an IP address (`192.168.2.12`).
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意，`gluster1`显示的`Hostname`是一个IP地址（`192.168.2.12`）。
- en: Use the `gluster peer probe` command on any other peer (`gluster2`) to add the
    hostname of `gluster1` to the storage pool.
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`gluster peer probe`命令在任何其他节点（`gluster2`）上将`gluster1`的主机名添加到存储池中。
- en: Note
  id: totrans-248
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Do not use the `gluster peer probe` command to add itself to the trusted server
    pool! *A storage peer cannot add itself to the pool!*
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 不要使用`gluster peer probe`命令将自身添加到受信服务器池！*一个存储节点不能将自己添加到池中！*
- en: Any attempt for a peer to add itself could damage the entire storage pool.
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 任何节点尝试将自己添加到池中，可能会破坏整个存储池。
- en: '[PRE22]'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: It's time to create a striped replicated volume from the trusted storage pool.
    From any peer in the trusted storage pool (`gluster1`), use the `gluster volume
    create` command to create a distributed striped replicated volume (`stripe 2 replica
    2`) using the four peers of the trusted storage pool (`gluster1`, `gluster2`,
    `gluster3`, and `gluster4`). On each peer, the `/srv/vol0` directory is used to
    store the GlusterFS configuration and data for the new volume (`vol0`).
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，是时候从受信存储池创建一个条带化复制卷了。从受信存储池中的任何节点（`gluster1`），使用`gluster volume create`命令创建一个分布式条带化复制卷（`stripe
    2 replica 2`），并使用受信存储池的四个节点（`gluster1`、`gluster2`、`gluster3`和`gluster4`）。在每个节点上，`/srv/vol0`目录用于存储新卷（`vol0`）的GlusterFS配置和数据。
- en: '[PRE23]'
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Use the `gluster volume start` command to start the newly created volume (`vol0`).
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`gluster volume start`命令启动新创建的卷（`vol0`）。
- en: '[PRE24]'
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Now, let's mount the distributed striped replicated volume. Use the `mount`
    command to mount the `glusterfs` volume `vol0` from the peer, `gluster1.local`,
    on the local mount point, `/mnt`.
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们挂载分布式条带化复制卷。使用`mount`命令将来自节点`gluster1.local`的`glusterfs`卷`vol0`挂载到本地挂载点`/mnt`。
- en: '[PRE25]'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Test the striped replicated volume. Use the `cp` command to copy a large file
    (`/boot/kernel.img`) to the local mount point (`/mnt`) of the newly created distributed
    striped replicated volume (`vol0`).
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试条带化复制卷。使用`cp`命令将一个大文件（`/boot/kernel.img`）复制到新创建的分布式条带化复制卷（`vol0`）的本地挂载点（`/mnt`）。
- en: '[PRE26]'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Notice that the copied file (`/mnt/kernel.img`) has the same size (`4056224`)
    and checksum (`d5e64…35ec`) as the original file.
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意，复制的文件（`/mnt/kernel.img`）的大小（`4056224`）和校验和（`d5e64…35ec`）与原始文件相同。
- en: Use the `ls -la` command to display the entire contents of the GlusterFS storage
    directory for the distributed volume (`/srv/vol0`).
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `ls -la` 命令显示分布式卷（`/srv/vol0`）的 GlusterFS 存储目录的完整内容。
- en: '[PRE27]'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Notice that only part of the data from the large file (`kernel.img`) is stored
    on this peer (`gluster1`). The size of the file (`2090144`) in the storage directory
    (`/srv/vol0`) is significantly smaller than the size (`4056224`) of the original
    file (`/boot/kernel.img`).
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意，只有部分来自大文件（`kernel.img`）的数据存储在此对等节点（`gluster1`）上。存储目录（`/srv/vol0`）中的文件大小（`2090144`）显著小于原始文件（`/boot/kernel.img`）的大小（`4056224`）。
- en: Log in to each of the other three peers (`gluster2`, `gluster3`, and `gluster4`)
    and use the `ls –l` command to check the size of the files in each of the other
    storage directories for the volume (`/srv/vol0`).
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录到其余三个对等节点（`gluster2`、`gluster3` 和 `gluster4`），并使用 `ls –l` 命令检查每个存储目录（`/srv/vol0`）中的文件大小。
- en: '[log in to peer `gluster2`]'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[登录到对等节点 `gluster2`]'
- en: '[PRE28]'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Notice that there are two different file sizes (`2090144` and `1966080`) for
    the data storage file (`/srv/vol0/kernel.img`) on each of the peers.
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意，每个对等节点上的数据存储文件（`/srv/vol0/kernel.img`）有两个不同的文件大小（`2090144` 和 `1966080`）。
- en: Notice that the data storage files (`/srv/vol0/kernel.img`) on peers `gluster1`
    and `gluster2` have the same size; and that the data storage files on peers `gluster3`
    and `gluster4` also have the same size. This is an example of how a replicated
    volume duplicates storage across replicated peers in case one of the replicated
    peers goes down.
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意，`gluster1` 和 `gluster2` 上的数据存储文件（`/srv/vol0/kernel.img`）大小相同；`gluster3` 和
    `gluster4` 上的数据存储文件大小也相同。这是复制卷如何在复制对等节点之间复制存储的一个例子，以防其中一个复制对等节点宕机。
- en: Notice that the sum of the two file sizes is equal to the size of the original
    file (`4056224`). This is an example of how a striped volume divides the data
    of large files across striped peers.
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意，两个文件的大小之和等于原始文件的大小（`4056224`）。这是条带化卷如何在条带化对等节点之间划分大文件数据的一个例子。
- en: Test the high availability of the cluster. Remove one of the Raspberry Pis (`gluster4`)
    from the network by disconnecting its network cable.
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试集群的高可用性。通过断开网络电缆将一台树莓派（`gluster4`）从网络中移除。
- en: Use the `gluster` peer status command on one of the remaining peers (`gluster1`)
    to check the status of the distributed filesystem's secure storage pool.
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在剩余的一个对等节点（`gluster1`）上使用 `gluster` 对等节点状态命令检查分布式文件系统的安全存储池状态。
- en: '[PRE29]'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Notice that `Hostname: gluster4.local` is shown as `Disconnected`.'
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '注意，`Hostname: gluster4.local` 显示为 `Disconnected`。'
- en: Use the `sha1sum` command on `gluster1` to validate the large file stored in
    the filesystem (`/mnt/kernel.img`) has not changed.
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `gluster1` 上使用 `sha1sum` 命令验证存储在文件系统中的大文件（`/mnt/kernel.img`）没有发生变化。
- en: '[PRE30]'
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Notice that the checksum (`d5e64…35ec`) is still the same.
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意，校验和（`d5e64…35ec`）仍然相同。
- en: The distributed filesystem functions, even if one peer is down!
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 即使一个对等节点宕机，分布式文件系统仍然可以正常工作！
- en: Test the healing of replicated peers. While `gluster4` is still disconnected
    from the cluster, use the `cp` command to copy another large file (`/boot/kernel7.img`)
    to the self-healing distributed striped replicated filesystem.
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试复制对等节点的修复功能。当 `gluster4` 仍然与集群断开连接时，使用 `cp` 命令将另一个大文件（`/boot/kernel7.img`）复制到自愈的分布式条带化复制文件系统中。
- en: '[PRE31]'
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Use the `ls` and `sha1sum` commands to check that the copied file (`/mnt/kernel7.img`)
    is identical to the original file (`/boot/kernel7.img`).
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `ls` 和 `sha1sum` 命令检查复制的文件（`/mnt/kernel7.img`）是否与原始文件（`/boot/kernel7.img`）完全相同。
- en: '[PRE32]'
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Use the `ls –l` command to check the file sizes in the storage directory (`/srv/vol0`)
    of each peer to validate that the newly copied file (`kernel7.img`) is also striped
    and replicated.
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `ls –l` 命令检查每个对等节点的存储目录（`/srv/vol0`）中的文件大小，以验证新复制的文件（`kernel7.img`）是否也被条带化和复制。
- en: '[log in to peer `gluster1`]'
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[登录到对等节点 `gluster1`]'
- en: '[PRE33]'
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[log in to peer `gluster2`]'
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[登录到对等节点 `gluster2`]'
- en: '[PRE34]'
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[log in to peer `gluster3`]'
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[登录到对等节点 `gluster3`]'
- en: '[PRE35]'
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Notice that the data storage file (`/srv/vol0/kernel7.img`) on peers `gluster1`
    and `gluster2` has the same size and that the total size of the striped files
    (`2066464 + 1966080`) is equal to the size of the original file (`4032544`). The
    distributed filesystem continues to stripe and replicate files even if one peer
    is down!
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意，`gluster1`和`gluster2`上的数据存储文件（`/srv/vol0/kernel7.img`）大小相同，且条带化文件的总大小（`2066464
    + 1966080`）等于原始文件的大小（`4032544`）。即使某个节点宕机，分布式文件系统仍然会继续进行条带化和复制文件！
- en: Reconnect peer `gluster4` to the network.
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新连接`gluster4`节点到网络。
- en: Immediately use the `ls –l` command to check the files in the data storage directory
    (`/srv/vol0`) on reconnected peer `gluster4`.
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新连接的节点`gluster4`上，立即使用`ls –l`命令检查数据存储目录（`/srv/vol0`）中的文件。
- en: '[PRE36]'
  id: totrans-292
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Notice that the newly copied file (`kernel7.img`) has been created in the data
    storage directory (`/srv/vol0`), but the file size is empty (`0`).
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意，新复制的文件（`kernel7.img`）已在数据存储目录（`/srv/vol0`）中创建，但文件大小为空（`0`）。
- en: After waiting five minutes, use the `ls –l` command to once again check the
    data storage directory on `gluster4`.
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 等待五分钟后，再次使用`ls –l`命令检查`gluster4`上的数据存储目录。
- en: '[PRE37]'
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Notice that the storage file `kernel7.img` is no longer empty. The data storage
    file (`kernel7.img`) on `gluster4` is now the same size (`1966080`) as the storage
    file on peer `gluster3`.
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意，存储文件`kernel7.img`不再为空。`gluster4`上的数据存储文件（`kernel7.img`）现在与`gluster3`上的存储文件大小相同（`1966080`）。
- en: The distributed filesystem has healed itself!
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分布式文件系统已经恢复正常！
- en: This cluster of four Raspberry Pis is now a highly available distributed filesystem!
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，这四个树莓派组成的集群已经成为一个高可用的分布式文件系统！
- en: How it works...
  id: totrans-299
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The recipe begins by changing the hostnames of four Raspberry Pis that are linked
    together on the same network. The new hostnames of the Raspberry Pis are `gluster1`,
    `gluster2`, `gluster3`, and `gluster4`.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 该步骤从更改四个树莓派的主机名开始，这些树莓派都连接在同一个网络中。树莓派的新主机名为`gluster1`、`gluster2`、`gluster3`和`gluster4`。
- en: Installing the GlusterFS server on each Raspberry Pi
  id: totrans-301
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在每个树莓派上安装GlusterFS服务器
- en: After the Raspberry Pis are renamed, the `apt-get install` command is used on
    each of the Raspberry Pis to install the GlusterFS server software distribution
    package (`glusterfs-server`).
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 在重命名树莓派后，使用`apt-get install`命令在每个树莓派上安装GlusterFS服务器软件包（`glusterfs-server`）。
- en: 'The installation of the `glusterfs-server` package includes starting the GlusterFS
    server on each of the Raspberry Pis: `gluster1`, `gluster2`, `gluster3`, and `gluster4`.'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 安装`glusterfs-server`软件包时，还会在每个树莓派上启动GlusterFS服务器：`gluster1`、`gluster2`、`gluster3`和`gluster4`。
- en: The `gluster peer probe` command is used from the `gluster1` Raspberry Pi to
    link the other Raspberry Pis (`gluster2`, `gluster3`, and `gluster4`) into a trusted
    peer relationship.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 从`gluster1`树莓派使用`gluster peer probe`命令将其他树莓派（`gluster2`、`gluster3`和`gluster4`）链接到可信节点关系中。
- en: The first peer in the storage pool (`gluster1`) establishes the trusted peer
    relationship with the other storage pool peers (`gluster2`, `gluster3`, `gluster4`).
    However, once the trusted relationship is established, any peer can be used as
    the storage pool master—to manage storage volumes, to manage the trusted peer
    relationships, or to be mounted as the distributed filesystem's network attachable
    endpoint.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 存储池中的第一个节点（`gluster1`）与其他存储池节点（`gluster2`，`gluster3`，`gluster4`）建立了可信节点关系。然而，一旦建立了可信关系，任何节点都可以作为存储池的主节点——管理存储卷、管理可信节点关系，或者作为分布式文件系统的网络可挂载端点。
- en: The `gluster peer status` command is used on both `gluster1` and `gluster2`
    to validate the trusted storage pool is up and running. On both peers, the other
    three storage pool peers are displayed as being part of the storage pool.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 在`gluster1`和`gluster2`上使用`gluster peer status`命令验证可信存储池是否正在运行。在这两个节点上，其他三个存储池节点都显示为存储池的一部分。
- en: The `gluster peer status` command on `gluster2`, however, displays an IP address
    for the `Hostname` field of the first peer, `gluster1`. So, the `gluster peer`
    command is used on `gluster2` to add the hostname of `gluster1` to the metadata
    of the storage pool.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，`gluster2`上的`gluster peer status`命令显示了第一个节点`gluster1`的IP地址作为`Hostname`字段。因此，使用`gluster
    peer`命令在`gluster2`上将`gluster1`的主机名添加到存储池的元数据中。
- en: Note
  id: totrans-308
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Do not have a peer add itself to the trusted storage pool!
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 不要让节点将自己添加到可信存储池！
- en: A peer using the command `gluster peer probe` with its own hostname could damage
    the trusted storage pool!
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 使用命令`gluster peer probe`并带上自己的主机名的节点可能会破坏可信存储池！
- en: Creating a striped replicated volume in the trusted storage pool
  id: totrans-311
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在受信任存储池中创建条带化复制卷
- en: The `cluster volume create` command is used from `gluster1` to create a new
    striped replicated volume that is distributed across the four storage pool peers
    (`gluster1.local`, `gluster2.local`, `gluster3.local`, `gluster4.local`).
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`cluster volume create`命令从`gluster1`节点创建一个新的条带化复制卷，该卷分布在四个存储池节点上（`gluster1.local`，`gluster2.local`，`gluster3.local`，`gluster4.local`）。
- en: The new volume is named `vol0`. It has two stripes (`stripe 2`) and two replicas
    (replica 2). It uses the same storage directory (`/srv/vol0`) on each of the storage
    pool peers (`gluster1.local`, `gluster2.local`, `gluster3.local`, and `gluster4.local`).
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 新的卷命名为`vol0`，它有两个条带（`stripe 2`）和两个副本（`replica 2`）。它在每个存储池节点（`gluster1.local`，`gluster2.local`，`gluster3.local`，`gluster4.local`）上使用相同的存储目录（`/srv/vol0`）。
- en: Using a storage directory on a peer's root filesystem (`/`) is not recommended,
    nor is it allowed by default. The `force` keyword is used to override the default
    behavior.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 不建议使用节点根文件系统（`/`）上的存储目录，默认情况下也不允许这样做。可以使用`force`关键字来覆盖默认行为。
- en: This recipe uses the root filesystem to keep the recipe simple. For a more robust,
    reliable distributed filesystem with higher performance, attach a high-speed external
    USB disk to each Raspberry Pi and configure the storage directory for the volume
    to be on the external disk instead of on the root filesystem. [Chapter 4](ch04.html
    "Chapter 4. File Sharing"), *File Sharing*, has more than one recipe for mounting
    an external USB disk on a Raspberry Pi.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 本食谱使用根文件系统以简化操作。对于更健壮、可靠的分布式文件系统并具有更高性能的需求，可以将高速外部USB磁盘连接到每个Raspberry Pi，并配置卷的存储目录位于外部磁盘上，而不是根文件系统上。[第4章](ch04.html
    "第4章 文件共享")，*文件共享*，提供了多种将外部USB磁盘挂载到Raspberry Pi上的食谱。
- en: After the volume (`vol0`) is created, the `gluster volume start` command is
    used to start sharing the newly created volume with GlusterFS clients. The `gluster
    volume start` command could be run from any peer in the cluster. In this case,
    it is run from `gluster1`.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建卷（`vol0`）之后，使用`gluster volume start`命令将新创建的卷与GlusterFS客户端共享。`gluster volume
    start`命令可以从集群中的任何节点运行。在此案例中，从`gluster1`节点运行。
- en: Mount the distributed striped replicated volume
  id: totrans-317
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 挂载分布式条带化复制卷
- en: Now that the distributed striped replicated volume (`vol0`) has been created
    and started, it is time for a GlusterFS client to mount the newly created volume.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，分布式条带化复制卷（`vol0`）已经创建并启动，可以让GlusterFS客户端挂载新创建的卷。
- en: To keep this recipe simple, `gluster1` is used as the client. However, any computer
    on the local network with the GlusterFS client software installed should now be
    able to mount the distributed volume (`vol0`) from any trusted peer in the GlusterFS
    storage pool.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化操作，本食谱使用`gluster1`作为客户端。然而，任何安装了GlusterFS客户端软件的本地网络计算机，现在应该都可以从任何受信任的节点挂载分布式卷（`vol0`）。
- en: The `mount –t glusterfs` command is used from `gluster1` to mount the distributed
    volume (`vol0`) from the trusted storage peer `gluster1.local` on its local directory,
    `/mnt`. The Raspberry Pi named `gluster1` is both the client and the server of
    the distributed volume (`vol0`).
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`mount –t glusterfs`命令从`gluster1`节点挂载受信任的存储节点`gluster1.local`上的分布式卷（`vol0`）到其本地目录`/mnt`。名为`gluster1`的Raspberry
    Pi既是分布式卷（`vol0`）的客户端，也是服务器。
- en: Testing the striped replicated volume
  id: totrans-321
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试条带化复制卷
- en: The `cp` command is used to copy a large file from the local filesystem (`/boot/kernel.img`)
    to the distributed striped replicated volume mounted at `/mnt`.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`cp`命令将大文件从本地文件系统（`/boot/kernel.img`）复制到挂载在`/mnt`的分布式条带化复制卷。
- en: The `ls –l` command and the `sha1sum` command are used to validate that the
    copied file (`/mnt/kernel.img`) has been copied successfully by checking that
    its size (`4056224`) and checksum (`d5e64…35ec`) are the same as the original
    file (`/boot/kernel.img`).
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`ls –l`命令和`sha1sum`命令验证复制的文件（`/mnt/kernel.img`）是否成功复制，通过检查文件的大小（`4056224`）和校验和（`d5e64…35ec`）是否与原文件（`/boot/kernel.img`）相同。
- en: The `ls –la` command is used on each peer of the storage pool (`gluster1`, `gluster2`,
    `gluster3`, and `gluster4`) to display the contents of the peer's storage directory
    (`/srv/vol0`).
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`ls –la`命令在存储池的每个节点（`gluster1`，`gluster2`，`gluster3`和`gluster4`）上显示该节点存储目录（`/srv/vol0`）的内容。
- en: None of the peer's storage directories has a file (`/srv/kernel.img`) as large
    as the original file (`/boot/kernel.img`).
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 没有任何节点的存储目录中存在与原文件（`/boot/kernel.img`）大小相同的文件（`/srv/kernel.img`）。
- en: Replication
  id: totrans-326
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 复制
- en: There are two sets of storage files (`/srv/kernel.img`) with the same size.
    The first set of storage files with the same size (`2090144`) can be found on
    peers `gluster1` and `gluster2`. The second set of peers, `gluster3` and `gluster4`,
    also have storage files that are the same size (`1966080`). The peers `gluster1`
    and `gluster2` are replicas of each other; `gluster3` and `gluster4` are also
    replicas.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 有两组大小相同的存储文件（`/srv/kernel.img`）。第一组存储文件大小相同（`2090144`），可以在 `gluster1` 和 `gluster2`
    上找到。第二组存储文件，`gluster3` 和 `gluster4`，也具有相同的大小（`1966080`）。`gluster1` 和 `gluster2`
    是彼此的副本；`gluster3` 和 `gluster4` 也是副本。
- en: Data replication is used to keep the distributed volume highly available. If
    one of the trusted storage peers goes down or is disconnected from the network,
    a replica of the unavailable peer's stored data is still available. If `gluster1`
    were to go down, `gluster2` would still have a replica of the stored data. If
    `gluster4` were disconnected from the network, `gluster3` would still have a replica
    of its data.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 数据复制用于保持分发卷的高可用性。如果一个受信存储节点出现故障或与网络断开连接，无法访问的节点的存储数据副本仍然可用。如果 `gluster1` 出现故障，`gluster2`
    仍然会有该数据的副本。如果 `gluster4` 与网络断开，`gluster3` 仍然会有它的数据副本。
- en: Striping
  id: totrans-329
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 条带化
- en: The sum of the two different file sizes (`2090144` and `1966080`) equals the
    size of the original file (`4056224`). The original file has been distributed
    (striped) across the trusted storage peers. The trusted storage peers `gluster1`
    and `gluster2` are replicating one part (`2090144`) of the large file (`kernel.img`),
    and the trusted peers `gluster3` and `gluster4` are storing replicas of the other
    part (`1966080`).
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 两个不同的文件大小（`2090144` 和 `1966080`）之和等于原始文件的大小（`4056224`）。原始文件已经分布（条带化）到受信存储节点上。受信存储节点
    `gluster1` 和 `gluster2` 正在复制大文件（`kernel.img`）的一部分（`2090144`），而受信节点 `gluster3`
    和 `gluster4` 正在存储另一部分的副本（`1966080`）。
- en: Data striping is a technique for distributing large files across multiple storage
    peers. Parts of the file (stripes) are distributed evenly across the striped storage
    peers so that sequentially reading (or writing) a large amount of data from a
    single large file does not continuously put a load on only one of the trusted
    storage peers. Striping a file distributes the load to access the file across
    the striped storage peers by distributing the data across the peers. Striping
    increases the data transfer rate of the distributed volume.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 数据条带化是一种将大文件分布到多个存储节点的技术。文件的部分内容（条带）被均匀地分布到条带化的存储节点上，这样顺序读取（或写入）一个大文件时，不会持续对单一存储节点造成负担。通过将文件的数据分布到各个存储节点，条带化将访问文件的负载分配到多个存储节点上。条带化提高了分发卷的数据传输速率。
- en: Testing the high availability of the cluster
  id: totrans-332
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试集群的高可用性
- en: In order to test the cluster's ability to remain available when one of the trusted
    data storage peers goes down, the trusted data storage peer `gluster4.local` is
    removed from the cluster by disconnecting its network cable.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试当一个受信数据存储节点出现故障时集群能否保持可用，受信数据存储节点 `gluster4.local` 被通过断开其网络电缆从集群中移除。
- en: After the network cable has been removed from `gluster4`, the `gluster peer
    status` command is used (on any remaining peer) to show that trusted storage peer
    `gluster4.local` has been `Disconnected` from the cluster.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 在从 `gluster4` 拔掉网线后，可以使用 `gluster peer status` 命令（在任何剩余的节点上执行）查看，受信存储节点 `gluster4.local`
    已被标记为与集群 `断开连接`。
- en: The `sha1sum` command is used to validate that the checksum (`d5e64…35ec`) of
    the distributed file (`/mnt/kernel.img`) still matches the checksum of the original
    file (`/boot/kernel.img`).
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: '`sha1sum` 命令用于验证分发文件（`/mnt/kernel.img`）的校验和（`d5e64…35ec`）是否与原始文件（`/boot/kernel.img`）的校验和匹配。'
- en: The GlusterFS distributed filesystem still functions properly when one peer
    is removed from the storage pool! The cluster is highly available!
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 即使一个节点从存储池中移除，GlusterFS 分发文件系统仍能正常工作！集群具有高可用性！
- en: Testing the healing of replicated peers
  id: totrans-337
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试复制节点的修复
- en: While the trusted storage peer `gluster4` is still disconnected from the cluster,
    the `cp` command is used to copy another large file (`/boot/kernel7.img`) to the
    distributed storage volume (`vol0`) mounted locally on `gluster1` at `/mnt`.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 在受信存储节点 `gluster4` 仍与集群断开连接的情况下，使用 `cp` 命令将另一个大文件（`/boot/kernel7.img`）复制到分发存储卷（`vol0`），并将其挂载到本地
    `gluster1` 的 `/mnt` 目录。
- en: The checksum of the copied file (`/mnt/kernel7.img`) is compared to the checksum
    of the original file (`/boot/kernel7.img`) using the `sha1sum` command. The files
    are identical.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `sha1sum` 命令将复制文件（`/mnt/kernel7.img`）的校验和与原始文件（`/boot/kernel7.img`）的校验和进行比较。文件完全相同。
- en: The `ls –la` command is used on each of the remaining trusted storage peers
    (`gluster1`, `gluster2`, and `gluster3`) to validate that the new large file (`kermel7.img`)
    has also been striped and replicated across the storage directories (`/srv/vol0`)
    of the distributed volume. The trusted storage peers `gluster1` and `gluster2`
    have replicas of one portion of the file while peer `gluster3` has the other portion
    of the file.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个剩余的受信存储对等节点（`gluster1`、`gluster2` 和 `gluster3`）上使用 `ls –la` 命令，验证新大文件（`kernel7.img`）是否也已在分布式卷的存储目录（`/srv/vol0`）中进行条带和复制。受信存储对等节点
    `gluster1` 和 `gluster2` 各自拥有文件的一部分副本，而对等节点 `gluster3` 拥有文件的另一部分副本。
- en: After the new large file has been striped and replicated across the distributed
    volume, the trusted peer `gluster4` is once again connected to the cluster.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 在新大文件已经在分布式卷上进行条带和复制之后，受信对等节点 `gluster4` 再次连接到集群。
- en: Immediately after the peer `gluster4` has been reconnected to the cluster, the
    `ls –la` command is used to display the contents of the data storage directory
    (`/srv/vol0`) on `gluster4`. The file copied to the distributed volume (`vol0`)
    while `gluster4` was disconnected from the cluster (`kernel7.img`) has been created
    in the data storage directory; however, the file is empty (`0`).
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 在对等节点 `gluster4` 重新连接到集群后，立即使用 `ls –la` 命令显示 `gluster4` 上数据存储目录（`/srv/vol0`）的内容。复制到分布式卷（`vol0`）的文件（`kernel7.img`）在
    `gluster4` 从集群断开期间已经创建在数据存储目录中；然而，文件是空的（`0`）。
- en: After waiting a few minutes for the GlusterFS healing service to finish replicating
    the striped portion of the new large file (`kernel7.img`) from peer `gluster3`
    to peer `gluster4`, the `ls –la` command is used once again to validate that peer
    `gluster4` has replicated its portion of the striped file and that the distributed
    volume (`vol0`) has been healed.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 在等待几分钟，直到 GlusterFS 修复服务完成将新大文件（`kernel7.img`）的条带部分从对等节点 `gluster3` 复制到对等节点
    `gluster4` 后，再次使用 `ls –la` 命令验证对等节点 `gluster4` 是否已复制其条带文件部分，并确认分布式卷（`vol0`）已完成修复。
- en: The four Raspberry Pis are now a self-healing highly available distributed filesystem.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 这四个 Raspberry Pi 现在构成了一个自修复的高可用分布式文件系统。
- en: There's more …
  id: totrans-345
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多…
- en: GlusterFS is a peer-based distributed filesystem. There is no master server
    in a GlusterFS trusted storage pool. In this recipe, `gluster1` was the first
    peer in the trusted storage pool and invited the other trusted peers to join the
    pool. Even though it was the first peer in the storage pool, `gluster1` is still
    an equal peer and not the master.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: GlusterFS 是一个基于对等节点的分布式文件系统。在 GlusterFS 的受信存储池中没有主服务器。在这个方案中，`gluster1` 是受信存储池中的第一个对等节点，并邀请其他受信对等节点加入池中。即使它是存储池中的第一个对等节点，`gluster1`
    仍然是一个平等的对等节点，而不是主节点。
- en: On the other hand, the current recipe only allows a GlusterFS client to mount
    a filesystem endpoint from one of the trusted storage pool peers (`gluster1`,
    `gluster2`, `gluster3`, or `gluster4`). In this recipe, `gluster1` was the peer
    providing the distributed filesystem endpoint.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，当前的方案只允许 GlusterFS 客户端从一个受信存储池对等节点（`gluster1`、`gluster2`、`gluster3` 或 `gluster4`）挂载文件系统端点。在此方案中，`gluster1`
    是提供分布式文件系统端点的对等节点。
- en: Should the mounted peer (`gluster1`) go down, the client would not be able to
    access the distributed filesystem even if the other peers in the cluster have
    kept the filesystem available. In the recipe, `gluster1` was also the client,
    so this issue was not possible.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 如果挂载的对等节点（`gluster1`）宕机，即使集群中的其他对等节点保持文件系统可用，客户端仍然无法访问分布式文件系统。在此方案中，`gluster1`
    同时也是客户端，因此这个问题不会发生。
- en: A GlusterFS distributed filesystem is normally accessed from outside the cluster,
    not from a trusted storage peer within the cluster. Mounting the distributed filesystem
    from one of the storage peers directly defeats the high availability of the cluster
    by making the client dependent on a single trusted peer instead of being dependent
    on the cluster as a whole.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: GlusterFS 分布式文件系统通常是从集群外部访问的，而不是从集群内受信存储对等节点访问。直接从某个存储对等节点挂载分布式文件系统会破坏集群的高可用性，因为它使客户端依赖于单个受信对等节点，而不是依赖整个集群。
- en: Using Keepalived to create a virtual filesystem endpoint
  id: totrans-350
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 Keepalived 创建虚拟文件系统端点
- en: The virtual IP address service Keepalived can be used to create a distributed
    filesystem endpoint that is kept alive by all peers of the trusted storage pool.
    The previous recipe, *Installing a high-availability load balancer*, shows how
    to install and configure Keepalived for use with the HA Proxy.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: Keepalived 提供的虚拟 IP 地址服务可以用于创建一个由所有受信任存储池节点维持活跃的分布式文件系统端点。前面的食谱，*安装高可用负载均衡器*，展示了如何安装和配置
    Keepalived，以便与 HA Proxy 一起使用。
- en: Keepalived can also be used with GlusterFS to create a virtual IP for accessing
    the distributed filesystem that will remain available so long as the distributed
    filesystem remains available.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: Keepalived 还可以与 GlusterFS 配合使用，创建一个虚拟 IP 地址，用于访问分布式文件系统，只要分布式文件系统保持可用，虚拟 IP
    也将保持可用。
- en: Using Keepalived, a virtual endpoint (IP address) is created for the distributed
    filesystem. Clients will mount the virtual endpoint of the filesystem instead
    of mounting the endpoint directly from a trusted storage peer.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Keepalived，会为分布式文件系统创建一个虚拟端点（IP 地址）。客户端将挂载文件系统的虚拟端点，而不是直接从受信任存储节点挂载端点。
- en: Even though the trusted storage peer currently serving the virtual filesystem
    endpoint may fail, the virtual endpoint provided by Keepalived will not fail;
    instead, another trusted storage peer will be selected to replace the peer that
    did fail. The virtual filesystem endpoint will remain alive no matter which trusted
    peer goes down.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 即使当前提供虚拟文件系统端点的受信任存储节点发生故障，Keepalived 提供的虚拟端点也不会失败；相反，系统会选择另一个受信任存储节点来替代发生故障的节点。不管哪个受信任节点发生故障，虚拟文件系统端点将始终保持活跃。
- en: To use Keepalived with this recipe, first enable (`=1`) the kernel parameter
    that permits listening for virtual IP addresses (`net.ipv4.ip_nonlocal_bind`)
    on each of the trusted storage peers in the cluster (`gluster1`, `gluster2`, `gluster3`,
    and `gluster4`).
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 要在本食谱中使用 Keepalived，首先启用（`=1`）允许监听虚拟 IP 地址（`net.ipv4.ip_nonlocal_bind`）的内核参数，适用于集群中的每个受信任存储节点（`gluster1`、`gluster2`、`gluster3`
    和 `gluster4`）。
- en: '[PRE38]'
  id: totrans-356
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Next, install the `keepalived` software distribution package using the `apt-get
    install` command.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，使用 `apt-get install` 命令安装 `keepalived` 软件包。
- en: '[PRE39]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Use a configuration for Keepalived that allows any of the trusted storage peers
    (`gluster1`, `gluster2`, `gluster3`, or `gluster4`) to take over the cluster's
    virtual IP address whenever the current peer serving the virtual IP address fails.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 使用一个 Keepalived 配置，使得任何一个受信任的存储节点（`gluster1`、`gluster2`、`gluster3` 或 `gluster4`）在当前提供虚拟
    IP 地址的节点发生故障时，能够接管集群的虚拟 IP 地址。
- en: '[PRE40]'
  id: totrans-360
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Finally, restart the Keepalived service.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，重启 Keepalived 服务。
- en: '[PRE41]'
  id: totrans-362
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Now, the virtual endpoint can be mounted instead of a trusted peer.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，虚拟端点可以被挂载，替代受信任节点。
- en: '[PRE42]'
  id: totrans-364
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: See also
  id: totrans-365
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见：
- en: '**GlusterFS** ([http://www.glusterfs.org/](http://www.glusterfs.org/)): GlusterFS
    is a scalable network filesystem. Using common off-the-shelf hardware, you can
    create large, distributed storage solutions for media streaming, data analysis,
    and other data and bandwidth-intensive tasks. GlusterFS is free and open source
    software.'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GlusterFS** ([http://www.glusterfs.org/](http://www.glusterfs.org/)): GlusterFS
    是一个可扩展的网络文件系统。通过使用常见的现成硬件，你可以创建大型分布式存储解决方案，适用于媒体流、数据分析及其他数据和带宽密集型任务。GlusterFS
    是免费且开源的软件。'
- en: '**GlusterFS** ([https://en.wikipedia.org/wiki/GlusterFS](https://en.wikipedia.org/wiki/GlusterFS)):
    This Wikipedia article describes the GlusterFS design.'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GlusterFS** ([https://en.wikipedia.org/wiki/GlusterFS](https://en.wikipedia.org/wiki/GlusterFS)):
    这篇维基百科文章描述了 GlusterFS 的设计。'
- en: Creating a supercomputer
  id: totrans-368
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建超级计算机
- en: This recipe turns four Raspberry Pis into a super computer using Apache Spark.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 本食谱将四台 Raspberry Pi 变成一台使用 Apache Spark 的超级计算机。
- en: Apache Spark is a fast and general engine for large-scale data processing. In
    this recipe, Apache Spark is installed on four Raspberry Pis that have been networked
    into a small computer cluster. The cluster is then used to demonstrate the speed
    of super computing by calculating the value of pi using a Monte Carlo algorithm.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Spark 是一个用于大规模数据处理的快速通用引擎。在本食谱中，Apache Spark 被安装在四台网络连接的小型 Raspberry
    Pi 计算机集群上。该集群将被用来展示超级计算机的速度，通过蒙特卡洛算法计算圆周率值。
- en: After completing this recipe, you will have a Raspberry Pi super computer.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 完成本食谱后，你将拥有一台 Raspberry Pi 超级计算机。
- en: Getting ready
  id: totrans-372
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'The following ingredients are required to create a supercomputer:'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 创建超级计算机需要以下配件：
- en: Four basic networking setups for the Raspberry Pi
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Raspberry Pi 的四种基本网络配置
- en: A high-speed network switch
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个高速网络交换机
- en: This recipe does not require the desktop GUI and could either be run from the
    text-based console or from within LXTerminal.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方法不需要桌面GUI，可以通过基于文本的控制台或者在LXTerminal中运行。
- en: With the Secure Shell server running on each Raspberry Pi, this recipe can be
    completed remotely using a Secure Shell client. Typically, a website is managed
    remotely.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个树莓派上运行安全Shell服务器后，可以使用安全Shell客户端远程完成这个方法。通常，网站会通过远程管理。
- en: All the Raspberry Pis should be connected directly to the same network switch.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 所有树莓派应直接连接到同一网络交换机。
- en: How to do it...
  id: totrans-379
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Perform the following steps to build a Raspberry Pi supercomputer:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤构建树莓派超级计算机：
- en: Log in to each Raspberry Pi and set its hostname. One Raspberry Pi will be the
    Spark master server, and the other three will be Spark slaves. Name the four Raspberry
    Pis `spark-master`, `spark-slave-a`, `spark-slave-b`, and `spark-slave-c`.
  id: totrans-381
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录到每个树莓派并设置其主机名。一个树莓派将作为Spark主服务器，另外三个将作为Spark从机。将四个树莓派命名为`spark-master`、`spark-slave-a`、`spark-slave-b`和`spark-slave-c`。
- en: Now, let's set up secure communication between master and slaves. Use the `ssh-keygen`
    command on `spark-master` to generate a pair of SSH keys. Press `<enter>` to accept
    the default file location (`/home/pi/.ssh/id_rsa`). Then, press `<enter>` twice
    to use an empty passphrase (the Spark automation requires an empty passphrase).
  id: totrans-382
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，设置主从机之间的安全通信。使用`spark-master`上的`ssh-keygen`命令生成一对SSH密钥。按`<enter>`接受默认文件位置（`/home/pi/.ssh/id_rsa`）。然后，按两次`<enter>`以使用空密码（Spark自动化要求为空密码）。
- en: '[PRE43]'
  id: totrans-383
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Use the `ssh-copy-id` command to copy the newly created public key from `spark-master`
    to each of the Spark slaves (`spark-slave-a`, `spark-slave-b`, and `spark-slave-c)`.
  id: totrans-384
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`ssh-copy-id`命令将新创建的公钥从`spark-master`复制到每个Spark从机（`spark-slave-a`，`spark-slave-b`，和`spark-slave-c`）。
- en: '[PRE44]'
  id: totrans-385
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Note
  id: totrans-386
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Repeat step *3* for each of the slaves: `spark-slave-a`, `spark-slave-b`, and
    `spark-slave-c`.'
  id: totrans-387
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对每个从机重复步骤*3*：`spark-slave-a`，`spark-slave-b`，和`spark-slave-c`。
- en: 'Note that a secure shell login (`ssh`) from `spark-master` to the slaves no
    longer requires a password for authentication:'
  id: totrans-388
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请注意，从`spark-master`到从机的安全shell登录（`ssh`）不再需要密码进行身份验证：
- en: '[PRE45]'
  id: totrans-389
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Now, it's about downloading the Apache Spark software distribution. Use a web
    browser to locate the correct Apache Spark software distribution package on the
    Apache Spark website's download page ([http://spark.apache.org/downloads.html](http://spark.apache.org/downloads.html)),
    which is shown in the following screenshot:![How to do it...](img/B04745_07_03.jpg)
  id: totrans-390
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，开始下载Apache Spark软件发行版。使用网页浏览器在Apache Spark官网的下载页面上找到正确的Apache Spark软件发行包（[http://spark.apache.org/downloads.html](http://spark.apache.org/downloads.html)），如下图所示：![如何操作...](img/B04745_07_03.jpg)
- en: 'On the download page, use the following drop-down options:'
  id: totrans-391
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下载页面上，使用以下下拉选项：
- en: '**Choose a Spark release:** **1.5.1 (Oct 02 2015)**'
  id: totrans-392
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**选择一个Spark版本：** **1.5.1（2015年10月2日）**'
- en: '**Choose a package type:** Pre-built for Hadoop 2.6 and later'
  id: totrans-393
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**选择软件包类型：** 为Hadoop 2.6及以后版本预构建'
- en: '**Choose a download type**: Select Apache Mirror'
  id: totrans-394
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**选择下载类型：** 选择Apache镜像'
- en: Once the correct choices have been made for **1**, **2**, and **3**, click on
    the link (`spark-1.5.1-bin-haddop2.6.tgz`) that appears at **4**. Download Spark.
  id: totrans-395
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在**1**、**2**和**3**的选择正确之后，点击在**4**处出现的链接（`spark-1.5.1-bin-haddop2.6.tgz`）。下载Spark。
- en: '![How to do it...](img/B04745_07_04.jpg)'
  id: totrans-396
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![如何操作...](img/B04745_07_04.jpg)'
- en: Note that the next web page displays the actual download link for the correct
    Apache Spark software distribution package ([http://www.eu.apache.org/dist/spark/spark-1.5.1/spark-1.5.1-bin-hadoop2.6.tgz](http://www.eu.apache.org/dist/spark/spark-1.5.1/spark-1.5.1-bin-hadoop2.6.tgz)).
  id: totrans-397
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请注意，下一网页显示了正确的Apache Spark软件发行包的实际下载链接（[http://www.eu.apache.org/dist/spark/spark-1.5.1/spark-1.5.1-bin-hadoop2.6.tgz](http://www.eu.apache.org/dist/spark/spark-1.5.1/spark-1.5.1-bin-hadoop2.6.tgz)）。
- en: 'Use the `wget` command on `spark-master` to download the Apache Spark software
    distribution page, as follows:'
  id: totrans-398
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`spark-master`上使用`wget`命令下载Apache Spark软件发行页面，如下所示：
- en: '[PRE46]'
  id: totrans-399
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Use the `tar` command to unpack the Apache Spark software distribution on each
    Raspberry Pi (`spark-master`, `spark-slave-a`, `spark-slave-b`, and `spark-slave-c`),
    as follows:'
  id: totrans-400
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`tar`命令在每个树莓派（`spark-master`，`spark-slave-a`，`spark-slave-b`和`spark-slave-c`）上解压Apache
    Spark软件发行版，如下所示：
- en: '[PRE47]'
  id: totrans-401
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Use the `tar` command to unpack the Apache Spark software distribution on each
    Raspberry Pi (`spark-master`, `spark-slave-a`, `spark-slave-b`, and `spark-slave-c`),
    as follows:'
  id: totrans-402
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`tar`命令在每个树莓派（`spark-master`，`spark-slave-a`，`spark-slave-b`和`spark-slave-c`）上解压Apache
    Spark软件发行版，如下所示：
- en: '[PRE48]'
  id: totrans-403
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Note
  id: totrans-404
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Repeat step *10* on each Raspberry Pi, namely `spark-master`, `spark-slave-a`,
    `spark-slave-b`, and `spark-slave-c`.
  id: totrans-405
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在每个树莓派上重复步骤 *10*，即 `spark-master`、`spark-slave-a`、`spark-slave-b` 和 `spark-slave-c`。
- en: 'Use the `mv` command to move the Apache Spark installation directory (`spark-1.5.1-bin-hadoop2.6`)
    to a more convenient location on each Raspberry Pi (`/opt/spark`), as follows:'
  id: totrans-406
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `mv` 命令将 Apache Spark 安装目录（`spark-1.5.1-bin-hadoop2.6`）移动到每个树莓派上的更方便的位置（`/opt/spark`），如下所示：
- en: '[PRE49]'
  id: totrans-407
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Now, configure the Spark master. Use the `cat` command on `spark-master` to
    create a list of slaves, as follows:'
  id: totrans-408
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，配置 Spark 主节点。在 `spark-master` 上使用 `cat` 命令创建一个从节点列表，如下所示：
- en: '[PRE50]'
  id: totrans-409
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Use the `scp` command on `spark-master` to copy the Spark execution environment
    configuration file (`spark-env.sh`) to each Spark slave (`spark-slave-a`, `spark-slave-b`,
    and `spark-slave-c`), as follows:'
  id: totrans-410
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `spark-master` 上使用 `scp` 命令将 Spark 执行环境配置文件（`spark-env.sh`）复制到每个 Spark 从节点（`spark-slave-a`、`spark-slave-b`
    和 `spark-slave-c`）中，如下所示：
- en: '[PRE51]'
  id: totrans-411
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Use the `scp` command on `spark-master` to copy the Spark execution environment
    configuration file (`spark-env.sh`) to each Spark slave (`spark-slave-a`, `spark-slave-b`,
    and `spark-slave-c`), as follows:'
  id: totrans-412
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `spark-master` 上使用 `scp` 命令将 Spark 执行环境配置文件（`spark-env.sh`）复制到每个 Spark 从节点（`spark-slave-a`、`spark-slave-b`
    和 `spark-slave-c`）中，如下所示：
- en: '[PRE52]'
  id: totrans-413
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Use the `echo` command on `spark-master` to append an additional memory constraint
    (`SPARK_DRIVER_MEMORY=512m`) to the execution environment (`spark-env.sh`) of
    the Spark master server (`spark-master`) so that enough memory remains free on
    the master server to run spark jobs, as follows:'
  id: totrans-414
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `spark-master` 上使用 `echo` 命令将额外的内存限制（`SPARK_DRIVER_MEMORY=512m`）添加到 Spark
    主服务器（`spark-master`）的执行环境（`spark-env.sh`）中，以确保主服务器上保留足够的内存来运行 Spark 任务，如下所示：
- en: '[PRE53]'
  id: totrans-415
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Use the `echo` command on `spark-master` to append the local IP address (`SPARK_LOCAL_IP`)
    to the execution environment (`spark-env.sh`). This reduces the warnings in the
    output from Spark jobs:'
  id: totrans-416
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `spark-master` 上使用 `echo` 命令将本地 IP 地址（`SPARK_LOCAL_IP`）添加到执行环境（`spark-env.sh`）中。这可以减少
    Spark 任务输出中的警告信息：
- en: '[PRE54]'
  id: totrans-417
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Use the `sed` command to change the logging level of Spark jobs from `INFO`
    (which produces a lot of informational output) to `WARN` (which produces a lot
    less output).
  id: totrans-418
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `sed` 命令将 Spark 任务的日志级别从 `INFO`（会生成大量信息性输出）更改为 `WARN`（生成的输出较少）。
- en: '[PRE55]'
  id: totrans-419
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: At this point, the Spark cluster is ready to start.
  id: totrans-420
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此时，Spark 集群已准备好启动。
- en: Note
  id: totrans-421
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The next steps calculate pi both with and without the Spark cluster so that
    the duration of the two calculation methods can be compared.
  id: totrans-422
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 接下来的步骤是分别使用 Spark 集群和不使用 Spark 集群计算 pi，以便对比这两种计算方法的时长。
- en: 'Now, calculate pi without using the Spark cluster. Use the `cat` command on
    `spark-master` to create a simple Python script to calculate pi without using
    the Spark cluster, as follows:'
  id: totrans-423
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，在不使用 Spark 集群的情况下计算 pi。在 `spark-master` 上使用 `cat` 命令创建一个简单的 Python 脚本来计算
    pi，而不使用 Spark 集群，如下所示：
- en: '[PRE56]'
  id: totrans-424
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: Use the `python` command on `spark-master` to run the script for calculating
    pi (`pi.py`) without a Spark cluster.
  id: totrans-425
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `spark-master` 上使用 `python` 命令运行计算 pi 的脚本（`pi.py`），而不使用 Spark 集群。
- en: '[PRE57]'
  id: totrans-426
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: Note that it took one Raspberry Pi (`spark-master`) more than 13 seconds (`13.430613`
    seconds) to calculate pi without using Spark.
  id: totrans-427
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意，使用一个树莓派（`spark-master`）计算 pi 时，没有使用 Spark 而花费了超过 13 秒（`13.430613` 秒）。
- en: 'Now, calculate pi using the Spark cluster. Use the `cat` command on `spark-master`
    to create a simple Python script that parallelizes the calculation of pi for use
    on the Spark cluster, as follows:'
  id: totrans-428
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用 Spark 集群计算 pi。在 `spark-master` 上使用 `cat` 命令创建一个简单的 Python 脚本，来并行化计算 pi
    并在 Spark 集群上使用，如下所示：
- en: '[PRE58]'
  id: totrans-429
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: Use the `start-all.sh` shell script on `spark-master` to start the Apache Spark
    cluster. Starting the cluster may take 30 seconds.
  id: totrans-430
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `spark-master` 上使用 `start-all.sh` 脚本启动 Apache Spark 集群。启动集群可能需要 30 秒。
- en: '[PRE59]'
  id: totrans-431
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: Use a web browser to view the status of the cluster by browsing to the cluster
    status page at `http://spark-master.local:8080/`.![How to do it...](img/B04745_07_05.jpg)
  id: totrans-432
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Web 浏览器查看集群的状态，访问集群状态页面 `http://spark-master.local:8080/`。![如何操作...](img/B04745_07_05.jpg)
- en: Wait until the Spark master server and all three slaves have started. Three
    worker IDs will be displayed on the status page when the cluster is ready to compute.
    Refresh the page, if necessary.
  id: totrans-433
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 等待 Spark 主服务器和所有三个从节点启动完毕。当集群准备好进行计算时，状态页面将显示三个工作节点 ID。如果需要，刷新页面。
- en: 'Submit the Python script (`pi-spark.py`) that is used to calculate pi to the
    Spark cluster, as follows:'
  id: totrans-434
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将用于计算 pi 的 Python 脚本（`pi-spark.py`）提交给 Spark 集群，如下所示：
- en: '[PRE60]'
  id: totrans-435
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: Notice that it took the Spark cluster less than a second (`0.720023 seconds`)
    to calculate pi. That's more than 185 times faster!!
  id: totrans-436
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请注意，Spark 集群计算圆周率时用了不到一秒钟（`0.720023秒`）。这比传统方法快了超过 185 倍！！
- en: The Raspberry Pi super computer is working!
  id: totrans-437
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 树莓派超级计算机正在工作！
- en: How it works...
  id: totrans-438
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: 'This recipe has the following six parts:'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 本食谱包含以下六个部分：
- en: Setting up secure communication between the master and slaves
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置主节点与从节点之间的安全通信
- en: Downloading the Apache Spark software distribution
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下载 Apache Spark 软件分发包
- en: Installing Apache Spark on each Raspberry Pi in the cluster
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在集群中的每个树莓派上安装 Apache Spark
- en: Configuring the Spark master
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置 Spark 主节点
- en: Calculating pi without using the Spark cluster
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在没有使用 Spark 集群的情况下计算圆周率
- en: Calculating pi using the Spark cluster
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Spark 集群计算圆周率
- en: The recipe begins by setting the hostnames of the four Raspberry Pi computers.
    One Raspberry Pi is selected as the Spark master (`spark-master`), the other three
    Raspberry Pis are the Spark slaves (`spark-slave-a`, `spark-slave-b`, and `spark-slave-c`).
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 本食谱从设置四台树莓派计算机的主机名开始。选择一台树莓派作为 Spark 主节点（`spark-master`），其他三台树莓派作为 Spark 从节点（`spark-slave-a`、`spark-slave-b`
    和 `spark-slave-c`）。
- en: Setting up secure communication between master and slaves
  id: totrans-447
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设置主节点与从节点之间的安全通信
- en: After the hostnames have been set, the `ssh-keygen` and `ssh-copy-id` commands
    are used to establish a secure communication link between the Spark master (`spark-master`)
    and each of its slaves (`spark-slave-a`, `spark-slave-b`, and `spark-slave-c`).
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 设置主机名后，使用 `ssh-keygen` 和 `ssh-copy-id` 命令来建立 Spark 主节点（`spark-master`）与每个从节点（`spark-slave-a`、`spark-slave-b`
    和 `spark-slave-c`）之间的安全通信连接。
- en: The `ssh-keygen` command is used to create a secure key pair (`/home/pi/.ssh/id_rsa`
    and `/home/pi/.ssh/id_rsa.pub`). The `ssh-copy-id` command is used to copy the
    public key (`id_rsa.pub`) from `spark-master` to each of the slaves.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: '`ssh-keygen` 命令用于创建一对安全密钥（`/home/pi/.ssh/id_rsa` 和 `/home/pi/.ssh/id_rsa.pub`）。`ssh-copy-id`
    命令用于将公钥（`id_rsa.pub`）从 `spark-master` 复制到每个从节点。'
- en: After the public key of `spark-master` has been copied to each slave, it is
    possible to log in from `spark-master` to each slave without using a password.
    Having a secure login from a master to a slave without a password is a requirement
    for the automation of the startup of the cluster.
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 在将 `spark-master` 的公钥复制到每个从节点后，可以在不使用密码的情况下，从 `spark-master` 登录到每个从节点。主节点到从节点的无密码安全登录是集群启动自动化的要求。
- en: Downloading the Apache Spark software distribution
  id: totrans-451
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 下载 Apache Spark 软件分发包
- en: The Apache Spark download page ([http://spark.apache.org/downloads.html](http://spark.apache.org/downloads.html))
    presents a number of choices that are used to determine the correct software distribution.
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Spark 下载页面（[http://spark.apache.org/downloads.html](http://spark.apache.org/downloads.html)）提供了多个选项，用于确定正确的软件分发包。
- en: This recipe uses the 1.5.1 (Oct 02 2015) release of Spark that has been pre-built
    for Hadoop 2.6 and later. Once the correct choices have been made, a link is presented
    (`spark-1.5.1-bin-hadoop2.6.tgz`), which leads to the actual download page.
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 本食谱使用的是 Spark 1.5.1（2015年10月2日发布）版本，该版本已经为 Hadoop 2.6 及更高版本预先构建。选择正确的选项后，将显示一个链接（`spark-1.5.1-bin-hadoop2.6.tgz`），点击该链接将跳转到实际的下载页面。
- en: The `wget` command is used to download the Spark software distribution from
    the actual download page to `spark-master` using the link presented on the actual
    download page ([http://www.us.apache.org/dist/spark/spark-1.5.1/spark-1.5.1-bin-hadoop2.6.tgz](http://www.us.apache.org/dist/spark/spark-1.5.1/spark-1.5.1-bin-hadoop2.6.tgz)).
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `wget` 命令通过实际下载页面提供的链接（[http://www.us.apache.org/dist/spark/spark-1.5.1/spark-1.5.1-bin-hadoop2.6.tgz](http://www.us.apache.org/dist/spark/spark-1.5.1/spark-1.5.1-bin-hadoop2.6.tgz)）将
    Spark 软件分发包下载到 `spark-master`。
- en: The software distribution has a size of 280 MB. It will take a while to download.
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 软件分发包的大小为 280 MB。下载需要一些时间。
- en: Once the Spark software distribution (`spark-1.5.1-bin-hadoop2.6.tgz`) is downloaded
    to `spark-master`, it is then copied using the `scp` command to the three slaves
    (`spark-slave-a`, `spark-slave-b`, and `spark-slave-c`).
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦 Spark 软件分发包（`spark-1.5.1-bin-hadoop2.6.tgz`）下载到 `spark-master`，然后使用 `scp`
    命令将其复制到三个从节点（`spark-slave-a`、`spark-slave-b` 和 `spark-slave-c`）。
- en: Installing Apache Spark on each Raspberry Pi in the cluster
  id: totrans-457
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在集群中的每个树莓派上安装 Apache Spark
- en: The `tar` command is use to unpack the Apache Spark software distribution (`spark-1.5.1-bin-hadoop2.6.tgz`)
    on each Raspberry Pi in the cluster (`spark-master`, `spark-slave-a`, `spark-slave-b`,
    and `spark-slave-c`).
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: '`tar`命令用于在集群中的每台树莓派（`spark-master`、`spark-slave-a`、`spark-slave-b`和`spark-slave-c`）上解压
    Apache Spark 软件包（`spark-1.5.1-bin-hadoop2.6.tgz`）。'
- en: After the software distribution has been unpacked in the home directory of the
    user, `pi`, it is moved by using the `mv` command to a more central location (`/opt/spark`).
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 在软件包被解压到用户的主目录`pi`中后，使用`mv`命令将其移动到一个更中心的位置（`/opt/spark`）。
- en: Configuring the Spark master
  id: totrans-460
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 配置 Spark 主节点
- en: The `cat` command is used to create a list of slaves (`/opt/spark/conf/slaves`).
    This list is used during the cluster startup to automatically start the slaves
    when `spark-master` is started. All the lines after the `cat` command up to the
    **end-of-data** (**EOD**) mark are copied to the list of slaves.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: '`cat`命令用于创建从节点列表（`/opt/spark/conf/slaves`）。该列表在集群启动时使用，用于在` spark-master`启动时自动启动从节点。`cat`命令后的所有行直到**数据结束**（**EOD**）标记都会被复制到从节点列表中。'
- en: The `echo` command is used to create the Spark runtime environment file (`spark-env.sh`
    under `/opt/spark/conf/`) with one environment variable (`SPARK_MASTER_IP`) that
    is set to the IP address of `spark-master` (`hostname –I`).
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: '`echo`命令用于创建 Spark 运行时环境文件（位于`/opt/spark/conf/`下的` spark-env.sh`），并设置一个环境变量（`SPARK_MASTER_IP`），该变量的值为`spark-master`的
    IP 地址（`hostname -I`）。'
- en: The Spark runtime environment configuration file, `spark-env.sh`, is then copied
    from the `spark-master` to each slave (`spark-slave-a`, `spark-slave-b`, and `spark-slave-c`).
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，将 Spark 运行时环境配置文件` spark-env.sh`从` spark-master`复制到每个从节点（`spark-slave-a`、`spark-slave-b`和`
    spark-slave-c`）。
- en: After the configuration file (`spark-env.sh`) has been copied to the slaves,
    two additional configuration parameters specific to `spark-master` are added to
    the file.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 配置文件（`spark-env.sh`）复制到从节点后，向文件中添加了两个特定于`spark-master`的额外配置参数。
- en: The `echo` command is used to append (`>>`) the `SPARK_DRIVER_MEMORY` parameter
    to the bottom of the configuration file. This parameter is used to limit the amount
    of memory used by the `spark-master` to `512m` (512 MB). This leaves room in the
    `spark-master` memory pool to run the Spark jobs.
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: '`echo`命令用于将`SPARK_DRIVER_MEMORY`参数追加（`>>`）到配置文件的底部。此参数用于限制`spark-master`使用的内存为`512m`（512
    MB）。这为`spark-master`的内存池留出了运行 Spark 作业的空间。'
- en: The `echo` command is also used to append the `SPARK_LOCAL_IP` parameter to
    the bottom of the configuration file (`spark-env.sh`). This parameter is set to
    the IP address of the `spark-master` (`hostname –I`). Setting this parameter eliminates
    some of the warning messages that occur when running the Spark jobs.
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: '`echo`命令还用于将`SPARK_LOCAL_IP`参数追加到配置文件（`spark-env.sh`）的底部。此参数设置为`spark-master`的
    IP 地址（`hostname -I`）。设置该参数可以消除运行 Spark 作业时出现的一些警告消息。'
- en: The `sed` command is used to modify the logging parameters of `spark-master`.
    The `log4j.properties` file is changed so that `INFO` messages are no longer displayed.
    Only warning messages (`WARN`) and error messages are displayed. This greatly
    reduces the output of the Spark jobs.
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: '`sed`命令用于修改`spark-master`的日志记录参数。`log4j.properties`文件被修改，以使`INFO`级别的消息不再显示，只有警告消息（`WARN`）和错误消息会显示。这大大减少了
    Spark 作业的输出。'
- en: At this point, the Spark cluster is fully configured and ready to start.
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，Spark 集群已完全配置，准备启动。
- en: Calculating pi without using the Spark cluster
  id: totrans-469
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 不使用 Spark 集群计算圆周率
- en: Before the Spark cluster is started, a simple Python script (`pi.py`) is created
    using the `cat` command to calculate pi without using the Spark cluster.
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 在启动 Spark 集群之前，使用`cat`命令创建一个简单的 Python 脚本（`pi.py`），用来在不使用 Spark 集群的情况下计算圆周率。
- en: This script (`pi.py`) uses the Monte Carlo method to estimate the value of pi
    by randomly generating 1 million data points and testing each data point for inclusion
    in a circle. The ratio of points inside the circle to the total number of points
    will be approximately equal to *Pi/4*.
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 这个脚本（`pi.py`）使用蒙特卡罗方法，通过随机生成100万个数据点，并测试每个数据点是否位于圆内，从而估算圆周率的值。位于圆内的点与总点数的比例将大约等于*Pi/4*。
- en: More information on calculating the value of Pi, including how to use the Monte
    Carlo method, can be found on Wikipedia ([https://en.wikipedia.org/wiki/Pi](https://en.wikipedia.org/wiki/Pi)).
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 有关计算圆周率（Pi）的更多信息，包括如何使用蒙特卡罗方法，可以在维基百科上找到 ([https://en.wikipedia.org/wiki/Pi](https://en.wikipedia.org/wiki/Pi))。
- en: The Python script that is used to estimate the value of pi takes more than 13
    seconds to run on a single standalone Raspberry Pi.
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 用于估算 pi 值的 Python 脚本在单个独立的 Raspberry Pi 上运行需要超过 13 秒。
- en: Calculating pi using the Spark cluster
  id: totrans-474
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 Spark 集群计算 pi
- en: Another Python script (`pi-spark.py`) is created using the `cat` command.
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个 Python 脚本（`pi-spark.py`）使用 `cat` 命令创建。
- en: This new script (`pi-spark.py`) uses the same Monte Carlo method to estimate
    the value of pi using 1 million random data points. However, this script uses
    the `SparkContext` (`sc`) to create a **resilient distributed dataset** (**RDD**)
    that parallelizes the million data points (`range( 1, n + 1 )`) so that they can
    be distributed among the slaves for the actual calculation (`f`).
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 这个新脚本（`pi-spark.py`）使用相同的蒙特卡洛方法，通过 100 万个随机数据点来估算 pi 值。然而，该脚本使用 `SparkContext`（`sc`）来创建一个
    **弹性分布式数据集**（**RDD**），并将这 100 万个数据点（`range(1, n + 1)`）并行化，使其可以分发到从节点进行实际计算（`f`）。
- en: After the script is created, the Spark cluster is started (`/opt/spark/sbin/start-all.sh`).
    The startup script (`start-all.sh`) uses the contents of the `/opt/conf/slaves`
    file to locate and start the Spark slaves (`spark-slave-a`, `spark-slave-b`, and
    `spark-slave-c`).
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本创建后，启动 Spark 集群（`/opt/spark/sbin/start-all.sh`）。启动脚本（`start-all.sh`）使用 `/opt/conf/slaves`
    文件中的内容来定位并启动 Spark 从节点（`spark-slave-a`、`spark-slave-b` 和 `spark-slave-c`）。
- en: A web browser is used to validate that all the slaves have started properly.
    The `spark-master` produces a small website (`http://spark-master.local:8080/`)
    that displays the status of the cluster. The Spark cluster's status page is not
    refreshed automatically, so you will need to continually refresh the page until
    all the workers have started.
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 使用网页浏览器验证所有从节点是否已正确启动。`spark-master` 会生成一个小型网站（`http://spark-master.local:8080/`），展示集群的状态。Spark
    集群的状态页面不会自动刷新，因此你需要不断刷新页面，直到所有工作节点启动完成。
- en: Each Spark slave is given a Worker ID when it connects to `spark-master`. You
    will need to wait until there are three workers before you can submit the Spark
    jobs, with one worker for each slave (`spark-slave-a`, `spark-slave-b`, and `spark-slave-c`).
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 每个 Spark 从节点在连接到 `spark-master` 时都会分配一个 Worker ID。你需要等待直到有三个工作节点启动，才能提交 Spark
    任务，每个从节点一个工作节点（`spark-slave-a`、`spark-slave-b` 和 `spark-slave-c`）。
- en: Once all the slaves (workers) have started, the `pi-spark.py` Python script
    can be submitted to the cluster using the `spark-submit` command.
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦所有从节点（工作节点）都已启动，就可以使用 `spark-submit` 命令将 `pi-spark.py` Python 脚本提交到集群。
- en: The `spark-submit` command passes two parameters, namely `$SPARK_MASTER_URL`
    and `24`, to the `pi-spark.py` script.
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: '`spark-submit` 命令传递了两个参数，即 `$SPARK_MASTER_URL` 和 `24`，给 `pi-spark.py` 脚本。'
- en: The value of the `SPARK_MASTER_URL` is used to configure (`SparkConf conf`)
    the location of the Spark master (`conf.setMaster( master )`).
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: '`SPARK_MASTER_URL` 的值用于配置（`SparkConf conf`）Spark 主节点的位置（`conf.setMaster(master)`）。'
- en: The second parameter of the `pi-spark.py` script (`24`) determines the number
    of compute partitions that are used to parallelize the calculations. Partitions
    divide the total number of calculations into compute groups (24 distinct groups).
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: '`pi-spark.py` 脚本的第二个参数（`24`）决定了用于并行计算的计算分区数。分区将总计算任务划分为计算组（24个独立的组）。'
- en: The number of partitions should be a factor of the number of available computer
    cores. Here, we are using 2 partitions for each available computer core (24 =
    2 x 12). There are twelve cores available—four cores in each of three Raspberry
    Pi slaves.
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 分区数应为可用计算核心数的因数。在这里，我们为每个可用计算核心使用 2 个分区（24 = 2 x 12）。共有 12 个核心——每个 Raspberry
    Pi 从节点有 4 个核心。
- en: The `SPARK_MASTER_URL` and `PATH` environment variables are updated to simplify
    the `spark-submit` command line.
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: '`SPARK_MASTER_URL` 和 `PATH` 环境变量已更新，以简化 `spark-submit` 命令行。'
- en: The `SPARK_MASTER_URL` is set to the IP address of the `spark-master` using
    the `hostname –I` command. The `tr` command is used to strip (`-d`) the trailing
    space (`[:space:]`) from the output of the `hostname –I` command.
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: '`SPARK_MASTER_URL` 使用 `hostname –I` 命令设置为 `spark-master` 的 IP 地址。`tr` 命令用来去除（`-d`）`hostname
    –I` 命令输出中的尾部空格（`[:space:]`）。'
- en: The location of the Spark command directory (`/opt/spark/bin`) is prepended
    to the front of the `PATH` environment variable so that the Spark commands can
    be used without requiring their complete path.
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: Spark 命令目录的位置（`/opt/spark/bin`）会被添加到 `PATH` 环境变量的前面，这样就可以在不需要完整路径的情况下使用 Spark
    命令。
- en: Submitting the `pi-spark.py` script to the cluster for calculation takes a few
    seconds. However, once the calculation is distributed among the workers (slaves),
    it takes less than a second (`0.720023` seconds) to estimate the value of pi.
    The Spark cluster is more than 185 times faster than a standalone Raspberry Pi.
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: 将`pi-spark.py`脚本提交到集群进行计算需要几秒钟。然而，一旦计算被分配到工作节点（从节点）上，估算π值的时间不到一秒钟（`0.720023`秒）。Spark集群的计算速度比单一的树莓派快超过185倍。
- en: The Raspberry Pi supercomputer is running!
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 树莓派超级计算机正在运行！
- en: There's more...
  id: totrans-490
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: This recipe only begins to explore the possibility of creating a supercomputer
    from low-cost Raspberry Pi computers. For Spark (and Hadoop, on which Spark is
    built), there are numerous packages for statistical calculation and data visualization.
    More information on supercomputing using Spark (and Hadoop) can be found on the
    Apache Software Foundation website ([http://www.apache.org](http://www.apache.org)).
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程仅开始探索使用低成本的树莓派计算机创建超级计算机的可能性。对于Spark（以及Spark构建之上的Hadoop），有许多用于统计计算和数据可视化的包。有关使用Spark（和Hadoop）进行超级计算的更多信息，可以在Apache软件基金会网站上找到([http://www.apache.org](http://www.apache.org))。
- en: See Also
  id: totrans-492
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: '**Apache Spark** ([http://spark.apache.org/](http://spark.apache.org/)): Apache
    Spark™ is a fast and general engine for large-scale data processing.'
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Apache Spark** ([http://spark.apache.org/](http://spark.apache.org/)): Apache
    Spark™ 是一个用于大规模数据处理的快速通用引擎。'
- en: '**Apache Hadoop (**[http://hadoop.apache.org/](http://hadoop.apache.org/)):
    The Apache™ Hadoop^® project develops open-source software for reliable, scalable,
    and distributed computing.'
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Apache Hadoop** ([http://hadoop.apache.org/](http://hadoop.apache.org/)):
    Apache™ Hadoop^®项目开发了用于可靠、可扩展和分布式计算的开源软件。'
- en: '**ssh-copy-id** ([http://manpages.debian.org/cgi-bin/man.cgi?query=ssh-copy-id](http://manpages.debian.org/cgi-bin/man.cgi?query=ssh-copy-id)):
    Uses locally available keys to authorize logins on a remote machine. The Debian
    man page for `ssh-copy-id` describes the command and its options.'
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ssh-copy-id** ([http://manpages.debian.org/cgi-bin/man.cgi?query=ssh-copy-id](http://manpages.debian.org/cgi-bin/man.cgi?query=ssh-copy-id)):
    使用本地可用的密钥来授权远程机器的登录。Debian的`ssh-copy-id`手册页面描述了该命令及其选项。'
- en: '**tr** ([http://manpages.debian.org/cgi-bin/man.cgi?query=tr](http://manpages.debian.org/cgi-bin/man.cgi?query=tr)):
    This is used to translate or delete characters. The Debian man page for tr describes
    the command and its options.'
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**tr** ([http://manpages.debian.org/cgi-bin/man.cgi?query=tr](http://manpages.debian.org/cgi-bin/man.cgi?query=tr)):
    用于翻译或删除字符。Debian的`tr`手册页面描述了该命令及其选项。'
- en: '**Monte Carlo methods for estimating pi** ([https://en.wikipedia.org/wiki/Pi#Monte_Carlo_methods](https://en.wikipedia.org/wiki/Pi#Monte_Carlo_methods)):
    This Wikipedia article on pi describes a number of ways to calculate pi, including
    the Monte Carlo method.'
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用于估算π值的蒙特卡洛方法** ([https://en.wikipedia.org/wiki/Pi#Monte_Carlo_methods](https://en.wikipedia.org/wiki/Pi#Monte_Carlo_methods)):
    这篇关于π的维基百科文章描述了多种计算π的方法，包括蒙特卡洛方法。'
