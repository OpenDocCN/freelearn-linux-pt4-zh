- en: Chapter 1. CoreOS Overview
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 第 1 章 CoreOS 概述
- en: CoreOS is a Container-optimized Linux-based operating system to deploy a distributed
    application across a cluster of nodes. Along with providing a secure operating
    system, CoreOS provides services such as `etcd` and `fleet` that simplify the
    Container-based distributed application deployment. This chapter will provide
    you with an overview of Microservices and distributed application development
    concepts along with the basics of CoreOS, Containers, and Docker. Microservices
    is a software application development style where applications are composed of
    small, independent services talking to each other with APIs. After going through
    the chapter, you will be able to appreciate the role of CoreOS and Containers
    in the Microservices architecture.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: CoreOS 是一个基于 Linux 的容器优化操作系统，用于在节点集群中部署分布式应用程序。除了提供一个安全的操作系统外，CoreOS 还提供如 `etcd`
    和 `fleet` 等服务，简化了基于容器的分布式应用程序部署。本章将为你提供微服务和分布式应用程序开发的概述，并介绍 CoreOS、容器和 Docker
    的基本概念。微服务是一种软件应用程序开发风格，应用程序由多个小型、独立的服务组成，这些服务通过 API 进行相互通信。通过本章的学习，你将能够理解 CoreOS
    和容器在微服务架构中的作用。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将覆盖以下主题：
- en: Distributed application development—an overview and components
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式应用程序开发——概述与组成部分
- en: Comparison of currently available minimalist Container-optimized OSes
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当前可用的最简化容器优化操作系统的比较
- en: Containers—technology and advantages
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器——技术与优势
- en: Docker—architecture and advantages
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker——架构与优势
- en: CoreOS—architecture and components
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CoreOS——架构与组件
- en: An overview of CoreOS components—`systemd`, `etcd`, `fleet`, `flannel`, and
    `rkt`
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CoreOS 组件概述——`systemd`、`etcd`、`fleet`、`flannel` 和 `rkt`
- en: Docker versus Rkt
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker 与 Rkt
- en: A workflow for distributed application development with Docker, Rkt, and CoreOS
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Docker、Rkt 和 CoreOS 的分布式应用程序开发工作流
- en: Distributed application development
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式应用程序开发
- en: 'Distributed application development involves designing and coding a microservice-based
    application rather than creating a monolithic application. Each standalone service
    in the microservice-based application can be created as a Container. Distributed
    applications existed even before Containers were available. Containers provide
    the additional benefit of isolation and portability to each individual service
    in the distributed application. The following diagram shows you an example of
    a microservice-based application spanning multiple hosts:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式应用程序开发涉及设计和编码基于微服务的应用程序，而不是创建单体应用程序。微服务架构中的每个独立服务都可以作为容器创建。分布式应用程序在容器出现之前就已经存在。容器为分布式应用程序中的每个独立服务提供了额外的隔离性和可移植性。下图展示了一个跨多个主机的基于微服务的应用程序示例：
- en: '![](img/00186.jpg)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00186.jpg)'
- en: Components of distributed application development
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式应用程序开发的组成部分
- en: 'The following are the primary components of distributed application development.
    This assumes that individual services of the distributed application are created
    as Containers:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是分布式应用程序开发的主要组成部分。这假设分布式应用程序的各个服务是作为容器创建的：
- en: Applications or microservices.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用程序或微服务。
- en: Cloud infrastructure—public (AWS, GCE, and Digital Ocean) or private.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云基础设施——公共（AWS、GCE 和 Digital Ocean）或私有。
- en: Base OS—CoreOS, Atomic, Rancher OS, and others.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基础操作系统——CoreOS、Atomic、Rancher OS 等。
- en: Distributed data store and service discovery—`etcd`, `consul`, and `Zookeeper`.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式数据存储和服务发现——`etcd`、`consul` 和 `Zookeeper`。
- en: Load balancer—NGINX and HAProxy.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 负载均衡器——NGINX 和 HAProxy。
- en: Container runtime—Docker, Rkt, and LXC.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器运行时——Docker、Rkt 和 LXC。
- en: Container orchestration—Fleet, Kubernetes, Mesos, and Docker Swarm.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器编排——Fleet、Kubernetes、Mesos 和 Docker Swarm。
- en: Storage—local or distributed storage. Some examples are GlusterFS and Ceph for
    cluster storage and AWS EBS for cloud storage. Flocker's upcoming storage driver
    plugin promises to work across different storage mechanisms.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存储——本地或分布式存储。一些例子包括用于集群存储的 GlusterFS 和 Ceph，以及用于云存储的 AWS EBS。Flocker 即将推出的存储驱动插件承诺可以跨不同的存储机制工作。
- en: Networking—using cloud-based networking such as AWS VPC, CoreOS Flannel, or
    Docker networking.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络——使用基于云的网络，如 AWS VPC、CoreOS Flannel 或 Docker 网络。
- en: Miscellaneous—Container monitoring (cadvisor, Sysdig, and Newrelic) and Logging
    (Spout and Logentries).
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 杂项——容器监控（cadvisor、Sysdig 和 Newrelic）和日志记录（Spout 和 Logentries）。
- en: An update strategy to update microservices, such as a rolling upgrade.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更新策略，如滚动升级，用于更新微服务。
- en: Advantages and disadvantages
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 优势与劣势
- en: 'The following are some advantages of distributed application development:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是分布式应用程序开发的一些优势：
- en: Application developers of each microservice can work independently. If necessary,
    different microservices can even have their own programming language.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个微服务的应用程序开发人员可以独立工作。如有必要，不同的微服务甚至可以使用各自的编程语言。
- en: Application component reuse becomes high. Different unrelated projects can use
    the same microservice.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用程序组件的复用性较高。不同的不相关项目可以使用相同的微服务。
- en: Each individual service can be horizontally scaled. CPU and memory usage for
    each microservice can be tuned appropriately.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个独立的服务可以进行横向扩展。每个微服务的 CPU 和内存使用可以适当调整。
- en: Infrastructure can be treated like cattle rather than a pet, and it is not necessary
    to differentiate between each individual infrastructure component.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基础设施可以像管理牲畜一样处理，而不是像宠物一样，且无需区分每个单独的基础设施组件。
- en: Applications can be deployed in-house or on a public, private, or hybrid cloud.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用程序可以部署在内部服务器或公共、私有或混合云中。
- en: 'The following are some problems associated with the microservices approach:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是微服务方法的一些问题：
- en: The number of microservices to manage can become huge and this makes it complex
    to manage the application.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理的微服务数量可能会非常庞大，这使得应用程序的管理变得复杂。
- en: Debugging can become difficult.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调试可能变得非常困难。
- en: Maintaining integrity and consistency is difficult so services must be designed
    to handle failures.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 维护完整性和一致性较为困难，因此服务必须设计为能够处理故障。
- en: Tools are constantly changing, so there is a need to stay updated with current
    technologies.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工具不断变化，因此需要保持与当前技术的更新。
- en: A minimalist Container-optimized OS
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 一个极简的容器优化操作系统
- en: 'This is a new OS category for developing distributed applications that has
    become popular in recent years. Traditional Linux-based OSes were bulky for Container
    deployment and did not natively provide the services that Containers need. The
    following are some common characteristics of a Container-optimized OS:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个新型操作系统类别，专为开发分布式应用程序而设计，近年来变得越来越流行。传统的基于 Linux 的操作系统对于容器部署来说过于庞大，且未能原生提供容器所需的服务。以下是一些容器优化操作系统的常见特点：
- en: The OS needs to be bare-minimal and fast to bootup
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作系统需要极简，并且启动速度快。
- en: It should have an automated update strategy
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应该有自动化的更新策略。
- en: Application development should be done using Containers
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用程序开发应该使用容器进行。
- en: Redundancy and clustering should be built-in
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应该内建冗余和集群功能
- en: The following table captures the comparison of features of four common Container-optimized
    OSes. Other OSes such as VMWare Photon and Mesos DCOS have not been included.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格展示了四种常见容器优化操作系统的特性比较。其他操作系统，如 VMWare Photon 和 Mesos DCOS，未被包括在内。
- en: '| Feature | CoreOS | Rancher OS | Atomic | Ubuntu snappy |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| 特性 | CoreOS | Rancher OS | Atomic | Ubuntu snappy |'
- en: '| Company | CoreOS | Rancher Labs | Red Hat | Canonical |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| 公司 | CoreOS | Rancher Labs | Red Hat | Canonical |'
- en: '| Containers | Docker and Rkt | Docker | Docker | Snappy packages and Docker
    |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| 容器 | Docker 和 Rkt | Docker | Docker | Snappy 包和 Docker |'
- en: '| Maturity | First release in 2013, relatively mature | First release in early
    2015, pretty new | First release in early 2015, pretty new | First release in
    early 2015, pretty new |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| 成熟度 | 2013 年首次发布，比较成熟 | 2015 年初首次发布，较新 | 2015 年初首次发布，较新 | 2015 年初首次发布，较新
    |'
- en: '| Service management | Systemd and Fleet | System docker manages system services
    and user docker manages user containers | Systemd | Systemd and Upstart |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| 服务管理 | Systemd 和 Fleet | System docker 管理系统服务，用户 docker 管理用户容器 | Systemd
    | Systemd 和 Upstart |'
- en: '| Tools | Etcd, fleet, and flannel | Rancher has tools for service discovery,
    load balancing, dns, storage, and networking | Flannel and other RedHat tools
    | Ubuntu tools |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| 工具 | Etcd、fleet 和 flannel | Rancher 提供服务发现、负载均衡、DNS、存储和网络的工具 | Flannel 和其他
    RedHat 工具 | Ubuntu 工具 |'
- en: '| Orchestration | Kubernetes and Tectonic | Rancher''s own orchestration and
    Kubernetes | Kubernetes. Atomic app, and Nulecule also used | Kubernetes and any
    other orchestration tool |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 编排 | Kubernetes 和 Tectonic | Rancher 自有编排和 Kubernetes | Kubernetes、Atomic
    应用和 Nulecule 也使用 | Kubernetes 和其他编排工具 |'
- en: '| Update | Automatic, uses A and B partitions | Automatic | Automatic, uses
    rpm-os-tree | Automatic |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| 更新 | 自动，使用 A 和 B 分区 | 自动 | 自动，使用 rpm-os-tree | 自动 |'
- en: '| Registry | Docker hub and Quay | Docker hub | Docker hub | Docker hub |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| 注册表 | Docker hub 和 Quay | Docker hub | Docker hub | Docker hub |'
- en: '| Debugging | Toolbox | Rancher''s own tools and external tools | RedHat tools
    | Ubuntu debug tools |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 调试 | 工具箱 | Rancher 自有工具和外部工具 | RedHat 工具 | Ubuntu 调试工具 |'
- en: '| Security | SELinux can be turned on | There is a plan to add SELinux and
    AppArmor support | SELinux enabled by default, additional security | AppArmor
    security profile can be used |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| 安全性 | SELinux 可以启用 | 有计划添加 SELinux 和 AppArmor 支持 | SELinux 默认启用，额外的安全性 |
    可以使用 AppArmor 安全配置文件 |'
- en: Containers
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 容器
- en: Containers do virtualization at the OS level while VMs do virtualization at
    the hardware level. Containers in a single host share the same kernel. As Containers
    are lightweight, hundreds of containers can run on a single host. In a microservices-based
    design, the approach taken is to split a single application into multiple small
    independent components and run each component as a Container. LXC, Docker, and
    Rkt are examples of Container runtime implementations.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 容器在操作系统级别进行虚拟化，而虚拟机在硬件级别进行虚拟化。容器在单个主机上共享相同的内核。由于容器是轻量级的，单个主机上可以运行数百个容器。在基于微服务的设计中，采取的方式是将一个应用拆分为多个小的独立组件，并将每个组件作为容器运行。LXC、Docker
    和 Rkt 是容器运行时实现的示例。
- en: Technology
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 技术
- en: 'The following are the two critical Linux kernel technologies that are used
    in Containers:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是容器中使用的两个关键 Linux 内核技术：
- en: 'Namespaces: They virtualize processes, networks, filesystems, users, and so
    on'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 命名空间：它们对进程、网络、文件系统、用户等进行虚拟化。
- en: 'cgroups: They limit the usage of the CPU, memory, and I/O per group of processes'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: cgroups：它们限制每组进程的 CPU、内存和 I/O 使用。
- en: Advantages
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 优势
- en: 'The following are some significant advantages of Containers:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是容器的一些主要优势：
- en: Each container is isolated from other Containers. There is no issue of shared
    package management, shared libraries, and so on.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个容器都与其他容器隔离。没有共享包管理、共享库等问题。
- en: Compared to a VM, Containers have smaller footprints and are faster to load
    and run.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与虚拟机相比，容器的占用空间更小，加载和运行速度更快。
- en: They provide an efficient usage of computing power.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们提供了高效的计算资源使用。
- en: They can work seamlessly across dev, test, and production. This makes Containers
    DevOps-friendly.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们可以在开发、测试和生产环境中无缝工作。这使得容器非常适合 DevOps。
- en: An overview of Docker architecture
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 架构概述
- en: 'Docker is a Container runtime implementation. Even though Containers were available
    for quite a long time, Docker revolutionized Container technology by making it
    easier to use. The following image shows you the main components of Docker (the
    Docker engine, Docker CLI, Docker REST, and Docker hub) and how they interact
    with each other:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 是一种容器运行时实现。尽管容器技术已经存在了相当长时间，但 Docker 通过使其更易于使用，彻底改变了容器技术。以下图片展示了 Docker
    的主要组件（Docker 引擎、Docker CLI、Docker REST 和 Docker Hub）及其相互之间的交互：
- en: '![](img/00192.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00192.jpg)'
- en: 'Following are some details on the Docker architecture:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 Docker 架构的一些细节：
- en: The Docker daemon runs in every host where Docker is installed and started.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker 守护进程在每个安装并启动 Docker 的主机上运行。
- en: Docker uses Linux kernel container facilities such as namespaces and cgroups
    through the libcontainer library.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker 通过 libcontainer 库使用 Linux 内核容器功能，如命名空间和 cgroups。
- en: The Docker client can run in the host machine or externally and it communicates
    with the Docker daemon using the REST interface. There is also a CLI interface
    that the Docker client provides.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker 客户端可以在主机机器或外部运行，并通过 REST 接口与 Docker 守护进程通信。Docker 客户端还提供 CLI 接口。
- en: The Docker hub is the repository for Docker images. Both private and public
    images can be hosted in the Docker hub repository.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker Hub 是 Docker 镜像的仓库。私有镜像和公共镜像都可以托管在 Docker Hub 仓库中。
- en: 'Dockerfile is used to create container images. The following is a sample Dockerfile
    that is used to create a Container that starts the Apache web service exposing
    port `80` to the outside world:'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dockerfile 用于创建容器镜像。以下是一个示例 Dockerfile，用于创建一个启动 Apache Web 服务并暴露 `80` 端口的容器：
- en: '![](img/00194.jpg)'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/00194.jpg)'
- en: The Docker platform as of release 1.9 includes orchestration tools such as Swarm,
    Compose, Kitematic, and Machine as well as native networking and storage solutions.
    Docker follows a batteries-included pluggable approach for orchestration, storage,
    and networking where a native Docker solution can be swapped with vendor plugins.
    For example, Weave can be used as an external networking plugin, Flocker can be
    used as an external storage plugin, and Kubernetes can be used as an external
    orchestration plugin. These external plugins can replace the native Docker solutions.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 截至版本 1.9，Docker 平台包括诸如 Swarm、Compose、Kitematic 和 Machine 等编排工具，以及本地网络和存储解决方案。Docker
    遵循“包含电池的可插拔”方式进行编排、存储和网络管理，其中本地 Docker 解决方案可以与厂商插件进行替换。例如，Weave 可以作为外部网络插件，Flocker
    可以作为外部存储插件，Kubernetes 可以作为外部编排插件。这些外部插件可以替代本地 Docker 解决方案。
- en: Advantages of Docker
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 的优势
- en: 'The following are some significant advantages of Docker:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 Docker 的一些显著优势：
- en: Docker has revolutionized Container packaging and tools around Containers and
    this has helped both application developers and infrastructure administrators
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker 革新了容器打包和围绕容器的工具，帮助了应用开发者和基础设施管理员。
- en: It is easier to deploy and upgrade individual containers
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署和升级单个容器更加容易。
- en: It is more suitable for the microservices architecture
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它更适合微服务架构。
- en: It works great across all Linux distributions as long as the kernel version
    is greater than or equal to 3.10
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它在所有 Linux 发行版上都能很好地运行，只要内核版本大于或等于 3.10。
- en: The Union filesystem makes it faster to download and keep different versions
    of container images
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 联合文件系统使得下载和保持不同版本的容器镜像更加快速。
- en: Container management tools such as Dockerfile, Docker engine CLI, Machine, Compose,
    and Swarm make it easy to manage containers
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器管理工具，如 Dockerfile、Docker 引擎 CLI、Machine、Compose 和 Swarm，使得容器管理更加简单。
- en: Docker provides an easy way to share Container images using public and private
    registry services
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker 提供了通过公共和私有注册表服务共享容器镜像的简单方法。
- en: CoreOS
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: CoreOS
- en: CoreOS belongs to the minimalist Container-optimized OS category. CoreOS is
    the first OS in this category and many new OSes have appeared recently in the
    same category. CoreOS's mission is to improve the security and reliability of
    the Internet. CoreOS is a pioneer in this space and its first alpha release was
    in July 2013\. A lot of developments have happened in the past two years in the
    area of networking, distributed storage, container runtime, authentication, and
    security. CoreOS is used by PaaS providers (such as Dokku and Deis), Web application
    development companies, and many enterprise and service providers developing distributed
    applications.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: CoreOS 属于极简主义容器优化操作系统类别。CoreOS 是这一类别中的第一个操作系统，最近许多新操作系统也出现在同一类别中。CoreOS 的使命是提高互联网的安全性和可靠性。CoreOS
    在这个领域是先驱，首次 alpha 版本发布于 2013 年 7 月。在过去两年中，网络、分布式存储、容器运行时、身份验证和安全性等领域发生了很多发展。CoreOS
    被 PaaS 提供商（如 Dokku 和 Deis）、Web 应用开发公司，以及许多开发分布式应用的企业和服务提供商使用。
- en: Properties
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 属性
- en: 'The following are some of the key CoreOS properties:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些 CoreOS 的关键属性：
- en: The kernel is very small and fast to bootup.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内核非常小，启动速度非常快。
- en: The base OS and all services are open sourced. Services can also be used standalone
    in non-CoreOS systems.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基础操作系统及所有服务都开源。服务也可以在非 CoreOS 系统中独立使用。
- en: No package management is provided by the OS. Libraries and packages are part
    of the application developed using Containers.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作系统不提供包管理。库和包是使用容器开发的应用程序的一部分。
- en: It enables secure, large server clusters that can be used for distributed application
    development.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它支持安全的大型服务器集群，可用于分布式应用开发。
- en: It is based on principles from the Google Chrome OS.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它基于 Google Chrome OS 的原则。
- en: Container runtime, SSH, and kernel are the primary components.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器运行时、SSH 和内核是主要组成部分。
- en: Every process is managed by systemd.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个进程都由 systemd 管理。
- en: Etcd, fleet, and flannel are all controller units running on top of the kernel.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Etcd、fleet 和 flannel 都是运行在内核之上的控制单元。
- en: It supports both Docker and Rkt Container runtime.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它同时支持 Docker 和 Rkt 容器运行时。
- en: Automatic updates are provided with A and B partitions.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动更新通过 A 和 B 分区提供。
- en: The Quay registry service can be used to store public and private Container
    images.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Quay 注册表服务可以用来存储公共和私有的容器镜像。
- en: CoreOS release channels (stable, beta, and alpha) are used to control the release
    cycle.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CoreOS 发布渠道（稳定版、测试版和 alpha 版）用于控制发布周期。
- en: Commercial products include the Coreupdate service (part of the commercially
    managed and enterprise CoreOS), Quay enterprise, and Tectonic (CoreOS + Kubernetes).
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 商业产品包括 Coreupdate 服务（商业管理和企业版 CoreOS 的一部分）、Quay 企业版和 Tectonic（CoreOS + Kubernetes）。
- en: It currently runs on x86 processors.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它目前运行在 x86 处理器上。
- en: Advantages
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 优势
- en: 'The following are some significant advantages of CoreOS:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 CoreOS 的一些显著优势：
- en: The kernel auto-update feature protects the kernel from security vulnerabilities.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内核自动更新功能可以保护内核免受安全漏洞的影响。
- en: The CoreOS memory footprint is very small.
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CoreOS 的内存占用非常小。
- en: The management of CoreOS machines is done at the cluster level rather than at
    an individual machine level.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CoreOS 机器的管理是在集群级别进行的，而不是在单个机器级别。
- en: It provides service-level (using systemd) and node-level (using fleet) redundancy.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它提供基于服务级别（使用 systemd）和节点级别（使用 fleet）的冗余。
- en: Quay provides you with a private and public Container repository. The repository
    can be used for both Docker and Rkt containers.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Quay 为您提供了私有和公共容器仓库。该仓库可用于 Docker 和 Rkt 容器。
- en: Fleet is used for basic service orchestration and Kubernetes is used for application
    service orchestration.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fleet 用于基本的服务编排，Kubernetes 用于应用服务编排。
- en: It is supported by all major cloud providers such as AWS, GCE, Azure, and DigitalOcean.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它得到 AWS、GCE、Azure 和 DigitalOcean 等主要云服务提供商的支持。
- en: Majority of CoreOS components are open sourced and the customer can choose the
    combination of tools that is necessary for their specific application.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大多数 CoreOS 组件是开源的，客户可以选择适合其特定应用程序所需的工具组合。
- en: Supported platforms
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 支持的平台
- en: The following are the official and community-supported CoreOS platforms. This
    is not an exhaustive list.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是官方和社区支持的 CoreOS 平台。这不是完整列表。
- en: Note
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: For exhaustive list of CoreOS supported platforms, please refer to this link
    ([https://coreos.com/os/docs/latest/](https://coreos.com/os/docs/latest/)).
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 若要查看 CoreOS 支持的平台的完整列表，请参考此链接（[https://coreos.com/os/docs/latest/](https://coreos.com/os/docs/latest/)）。
- en: 'The platforms that are officially supported are as follows:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是官方支持的平台：
- en: Cloud platforms such as AWS, GCE, Microsoft Azure, DigitalOcean, and OpenStack
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云平台如 AWS、GCE、Microsoft Azure、DigitalOcean 和 OpenStack
- en: Bare metal with PXE
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PXE 无盘启动
- en: Vagrant
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vagrant
- en: 'The platforms that are community-supported are as follows:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是社区支持的平台：
- en: CloudStack
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CloudStack
- en: VMware
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: VMware
- en: CoreOS components
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: CoreOS 组件
- en: The following are the CoreOS core components and CoreOS ecosystem. The ecosystem
    can become pretty large if automation, management, and monitoring tools are included.
    These have not been included here.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 CoreOS 核心组件和 CoreOS 生态系统。如果包括自动化、管理和监控工具，生态系统可能会变得非常庞大，这些内容未在此列出。
- en: 'Core components: Kernel, systemd, etcd, fleet, flannel, and rkt'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 核心组件：内核、systemd、etcd、fleet、flannel 和 rkt
- en: 'CoreOS ecosystem: Docker and Kubernetes'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CoreOS 生态系统：Docker 和 Kubernetes
- en: 'The following image shows you the different layers in the CoreOS architecture:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了 CoreOS 架构中的不同层次：
- en: '![](img/00197.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00197.jpg)'
- en: Kernel
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 内核
- en: 'CoreOS uses the latest Linux kernel in its distribution. The following screenshot
    shows the Linux kernel version running in the CoreOS stable release 766.3.0:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: CoreOS 在其发行版中使用最新的 Linux 内核。以下截图显示了在 CoreOS 稳定版 766.3.0 中运行的 Linux 内核版本：
- en: '![](img/00199.jpg)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00199.jpg)'
- en: Systemd
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: Systemd
- en: 'Systemd is an init system used by CoreOS to start, stop, and manage processes.
    SysVinit is one of the oldest init systems. The following are some of the common
    init systems used in the Unix world:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: Systemd 是 CoreOS 使用的初始化系统，用于启动、停止和管理进程。SysVinit 是最古老的初始化系统之一。以下是 Unix 世界中常用的一些
    init 系统：
- en: 'Systemd: CoreOS and RedHat'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Systemd：CoreOS 和 RedHat
- en: 'Upstart: Ubuntu'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Upstart：Ubuntu
- en: 'Supervisord: The Python world'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Supervisord：Python 世界
- en: 'The following are some of the common functionality performed by an init system:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些 init 系统执行的常见功能：
- en: It is the first process to start
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它是第一个启动的进程
- en: It controls the ordering and execution of all the user processes
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它控制所有用户进程的顺序和执行
- en: It takes care of restarting processes if they die or hang
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它负责在进程死掉或挂起时重新启动它们
- en: It takes care of process ownership and resources
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它负责进程所有权和资源管理
- en: 'The following are some specifics of systemd:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 systemd 的一些具体细节：
- en: Every process in systemd runs in one cgroup and this includes forked processes.
    If the systemd service is killed, all the processes associated with the service,
    including forked processes, are killed. This also provides you with a nice way
    to control resource usage. If we run a Container in systemd, we can control the
    resource usage even if the container contains multiple processes. Additionally,
    systemd takes care of restarting containers that die if we specify the `restart`
    option in systemd.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: systemd中的每个进程都运行在一个cgroup中，包括派生的进程。如果systemd服务被终止，所有与该服务相关的进程，包括派生的进程，都会被终止。这也为你提供了控制资源使用的良好方法。如果我们在systemd中运行容器，我们可以控制资源使用，即使容器包含多个进程。此外，如果我们在systemd中指定了`restart`选项，systemd会自动重启死掉的容器。
- en: Systemd units are run and controlled on a single machine.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Systemd单元是在单台机器上运行和控制的。
- en: These are some systemd unit types—service, socket, device, and mount.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些是一些systemd单元类型——服务、套接字、设备和挂载。
- en: The `Service` type is the most common type and is used to define a service with
    its dependencies. The `Socket` type is used to expose services to the external
    world. For example, `docker.service` exposes external connectivity to the Docker
    engine through `docker.socket`. Sockets can also be used to export logs to external
    machines.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Service`类型是最常见的类型，用于定义带有依赖项的服务。`Socket`类型用于将服务暴露给外部世界。例如，`docker.service`通过`docker.socket`将外部连接暴露给Docker引擎。套接字还可以用来将日志导出到外部机器。'
- en: The `systemctl` CLI can be used to control Systemd units.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`systemctl`命令行工具可以用来控制Systemd单元。'
- en: Systemd units
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: Systemd单元
- en: The following are some important systemd units in a CoreOS system.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是CoreOS系统中的一些重要systemd单元。
- en: Etcd2.service
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: Etcd2.service
- en: 'The following is an example `etcd2.service` unit file:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是`etcd2.service`单元文件的示例：
- en: '![](img/00201.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00201.jpg)'
- en: 'The following are some details about the etcd2 service unit file:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些关于etcd2服务单元文件的细节：
- en: All units have the `[Unit]` and `[Install]` sections. There is a type-specific
    section such as `[Service]` for service units.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有单元都有`[Unit]`和`[Install]`部分。还有一个类型特定的部分，例如服务单元的`[Service]`。
- en: The `Conflicts` option notifies that either `etcd` or `etcd2` can run, but not
    both.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Conflicts`选项表示`etcd`或`etcd2`可以运行，但不能同时运行。'
- en: The `Environment` option specifies the environment variables to be used by `etcd2`.
    The `%m` unit specifier allows the machine ID to be taken automatically based
    on where the service is running.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Environment`选项指定`etcd2`将使用的环境变量。`%m`单元说明符允许根据服务运行的位置自动获取机器ID。'
- en: The `ExecStart` option specifies the executable to be run.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ExecStart`选项指定要运行的可执行文件。'
- en: The `Restart` option specifies whether the service can be restarted. The `Restartsec`
    option specifies the time interval after which the service should be restarted.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Restart`选项指定服务是否可以重启。`Restartsec`选项指定服务重启的时间间隔。'
- en: '`LimitNoFILE` specifies the file count limit.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LimitNoFILE`指定文件数限制。'
- en: The `WantedBy` option in the `Install` section specifies the group to which
    this service belongs. The grouping mechanism allows systemd to start up groups
    of processes at the same time.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Install`部分中的`WantedBy`选项指定此服务所属的组。分组机制允许systemd同时启动一组进程。'
- en: Fleet.service
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: Fleet.service
- en: 'The following is an example of the `fleet.service` unit file:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是`fleet.service`单元文件的示例：
- en: '![](img/00203.jpg)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00203.jpg)'
- en: In the preceding unit file, we can see two dependencies for `fleet.service.`
    `etcd.Service` and `etcd2.service` are specified as dependencies as Fleet depends
    on them to communicate between fleet agents in different nodes. The `fleet.socket`
    socket unit is also specified as a dependency as it is used by external clients
    to talk to Fleet.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的单元文件中，我们可以看到`fleet.service`有两个依赖项。`etcd.Service`和`etcd2.service`被指定为依赖项，因为Fleet依赖它们来在不同节点的Fleet代理之间进行通信。`fleet.socket`套接字单元也被指定为依赖项，因为它被外部客户端用来与Fleet通信。
- en: Docker.service
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: Docker.service
- en: 'The Docker service consists of the following components:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: Docker服务由以下组件组成：
- en: '`Docker.service`: This starts the Docker daemon'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Docker.service`：此项启动Docker守护进程。'
- en: '`Docker.socket`: This allows communication with the Docker daemon from the
    CoreOS node'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Docker.socket`：此项允许CoreOS节点与Docker守护进程进行通信。'
- en: '`Docker-tcp.socket`: This allows communication with the Docker daemon from
    external hosts with port `2375` as the listening port'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Docker-tcp.socket`：此项允许与Docker守护进程进行通信，外部主机使用端口`2375`作为监听端口。'
- en: 'The following `docker.service` unit file starts the Docker daemon:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是启动Docker守护进程的`docker.service`单元文件：
- en: '![](img/00205.jpg)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00205.jpg)'
- en: 'The following `docker.socket` unit file starts the local socket stream:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 以下 `docker.socket` 单元文件启动本地套接字流：
- en: '![](img/00208.jpg)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00208.jpg)'
- en: Tip
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: Downloading the example code
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 下载示例代码
- en: You can download the example code files from your account at [http://www.packtpub.com](http://www.packtpub.com)
    for all the Packt Publishing books you have purchased. If you purchased this b
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从 [http://www.packtpub.com](http://www.packtpub.com) 下载示例代码文件，适用于你购买的所有 Packt
    Publishing 图书。如果你购买了这本书...
- en: 'The following `docker-tcp.socket` unit file sets up a listening socket for
    remote client communication:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 以下 `docker-tcp.socket` 单元文件设置了一个用于远程客户端通信的监听套接字：
- en: '![](img/00212.jpg)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00212.jpg)'
- en: The `docker ps` command uses `docker.socket` and `docker -H tcp://127.0.0.1:2375
    ps` uses `docker-tcp.socket` unit to communicate with the Docker daemon running
    in the local system.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '`docker ps` 命令使用 `docker.socket`，而 `docker -H tcp://127.0.0.1:2375 ps` 使用 `docker-tcp.socket`
    单元与本地系统中运行的 Docker 守护进程进行通信。'
- en: The procedure to start a simple systemd service
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 启动简单 systemd 服务的过程
- en: 'Let''s start a simple `hello1.service` unit that runs a Docker busybox container,
    as shown in the following image:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们启动一个简单的 `hello1.service` 单元，该单元运行一个 Docker busybox 容器，如下图所示：
- en: '![](img/00215.jpg)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00215.jpg)'
- en: 'The following are the steps to start `hello1.service`:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是启动 `hello1.service` 的步骤：
- en: Copy `hello1.service` as sudo to `/etc/systemd/system`.
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `hello1.service` 复制为 sudo 到 `/etc/systemd/system`。
- en: 'Enable the service:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启用服务：
- en: '`sudo systemctl enable /etc/systemd/system/hello1.service`'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`sudo systemctl enable /etc/systemd/system/hello1.service`'
- en: 'Start `hello1.service`:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动 `hello1.service`：
- en: '`sudo systemctl start hello1.service`'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`sudo systemctl start hello1.service`'
- en: 'This creates the following link:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建以下链接：
- en: '`core@core-01 /etc/systemd/system/multi-user.target.wants $ ls -la``lrwxrwxrwx 1 root root   34 Aug 12 13:25 hello1.service -> /etc/systemd/system/hello1.service`'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '`core@core-01 /etc/systemd/system/multi-user.target.wants $ ls -la``lrwxrwxrwx
    1 root root   34 Aug 12 13:25 hello1.service -> /etc/systemd/system/hello1.service`'
- en: 'Now, we can see the status of `hello1.service`:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以查看 `hello1.service` 的状态：
- en: '![](img/00219.jpg)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00219.jpg)'
- en: In the preceding output, we can see that the service is in the active state.
    At the end, we can also see `stdout` where the echo output is logged.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的输出中，我们可以看到服务处于活动状态。最后，我们还可以看到 `stdout`，其中记录了回显输出。
- en: 'Let''s look at the running Docker containers:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看正在运行的 Docker 容器：
- en: '![](img/00223.jpg)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00223.jpg)'
- en: Note
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: When starting Docker Containers with systemd, it is necessary to avoid using
    the `-d` option as it prevents the Container process to be monitored by systemd.
    More details can be found at [https://coreos.com/os/docs/latest/getting-started-with-docker.html](https://coreos.com/os/docs/latest/getting-started-with-docker.html).
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用 systemd 启动 Docker 容器时，需要避免使用 `-d` 选项，因为它会阻止容器进程被 systemd 监控。更多详情请参考 [https://coreos.com/os/docs/latest/getting-started-with-docker.html](https://coreos.com/os/docs/latest/getting-started-with-docker.html)。
- en: Demonstrating systemd HA
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 演示 systemd 高可用性（HA）
- en: 'In the `hello1.service` created, we specified two options:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建的 `hello1.service` 中，我们指定了两个选项：
- en: '`Restart=always RestartSec=30s`'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '`Restart=always RestartSec=30s`'
- en: This means that the service should be restarted after 30 seconds in case the
    service exits for some reason.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着如果服务由于某种原因退出，服务将在 30 秒后重启。
- en: 'Let''s stop the Docker `hello1` container:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们停止 Docker `hello1` 容器：
- en: '![](img/00226.jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00226.jpg)'
- en: 'Service gets restarted automatically after 30 seconds, as shown in the following
    screenshot:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 服务在 30 秒后自动重启，如下图所示：
- en: '![](img/00229.jpg)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00229.jpg)'
- en: 'The following screenshot shows you that the `hello1` container is running again.
    From the Container status output, we can see that the container is up only for
    a minute:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了 `hello1` 容器再次运行。从容器状态输出中，我们可以看到容器仅运行了一分钟：
- en: '![](img/00233.jpg)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00233.jpg)'
- en: 'We can also confirm the service restarted from the systemd logs associated
    with that service. In the following output, we can see that the service exited
    and restarted after 30 seconds:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以从与该服务相关的 systemd 日志中确认服务已重启。在以下输出中，我们可以看到服务退出并在 30 秒后重启：
- en: '![](img/00236.jpg)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00236.jpg)'
- en: Etcd
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: Etcd
- en: Etcd is a distributed key-value store used by all machines in the CoreOS cluster
    to read/write and exchange data. Etcd uses the Raft consensus algorithm ([https://raft.github.io/](https://raft.github.io/))
    to maintain a highly available cluster. Etcd is used to share configuration and
    monitoring data across CoreOS machines and for doing service discovery. All other
    CoreOS services such as Fleet and Flannel use etcd as a distributed database.
    Etcd can also be used as a standalone outside CoreOS. In fact, many complex distributed
    application projects such as Kubernetes and Cloudfoundry use etcd for their distributed
    key-value store. The `etcdctl` utility is the CLI frontend for etcd.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: Etcd 是由 CoreOS 集群中所有机器使用的分布式键值存储，用于读写和交换数据。Etcd 使用 Raft 共识算法（[https://raft.github.io/](https://raft.github.io/)）来维护高可用性集群。Etcd
    用于跨 CoreOS 机器共享配置和监控数据，并进行服务发现。所有其他 CoreOS 服务（如 Fleet 和 Flannel）都使用 etcd 作为分布式数据库。Etcd
    也可以作为独立于 CoreOS 外部的服务使用。事实上，许多复杂的分布式应用项目，如 Kubernetes 和 Cloudfoundry，都使用 etcd
    作为它们的分布式键值存储。`etcdctl` 实用程序是 etcd 的 CLI 前端。
- en: The following are two sample use cases of etcd.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 etcd 的两个示例用例。
- en: 'Service discovery: Service discovery can be used to communicate service connectivity
    details across containers. Let''s take an example WordPress application with a
    WordPress application container and MySQL database container. If one of the machines
    has a database container and wants to communicate its service IP address and port
    number, it can use etcd to write the relevant key and data; the WordPress container
    in another host can use the key value to write to the appropriate database.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务发现：服务发现可用于在容器之间传递服务连接详细信息。让我们以 WordPress 应用为例，其中包含 WordPress 应用容器和 MySQL 数据库容器。如果某台机器有一个数据库容器，并希望通信其服务
    IP 地址和端口号，它可以使用 etcd 写入相关键和数据；另一台主机上的 WordPress 容器可以使用键值来写入相应的数据库。
- en: 'Configuration sharing: The Fleet master talks to Fleet agents using etcd to
    decide which node in the cluster will execute the Fleet service unit.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置共享：Fleet 主节点使用 etcd 与 Fleet 代理通信，以决定集群中的哪个节点将执行 Fleet 服务单元。
- en: Etcd discovery
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: Etcd 发现
- en: The members in the cluster discover themselves using either a static approach
    or dynamic approach. In the static approach, we need to mention the IP addresses
    of all the neighbors statically in every node of the cluster. In the dynamic approach,
    we use the discovery token approach where we get a distributed token from a central
    etcd server and use this in all members of the cluster so that the members can
    discover each other.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 集群成员使用静态方法或动态方法自行发现。在静态方法中，我们需要在集群的每个节点中静态地列出所有邻居的 IP 地址。在动态方法中，我们使用发现令牌方法，从中央
    etcd 服务器获取分布式令牌，并在集群的所有成员中使用此令牌，以便成员可以互相发现。
- en: 'Get a distributed token as follows:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 获取分布式令牌如下：
- en: '`curl https://discovery.etcd.io/new?size=<size>`'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '`curl https://discovery.etcd.io/new?size=<size>`'
- en: 'The following is an example of getting a discovery token for a cluster size
    of three:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是获取集群大小为三的发现令牌的示例：
- en: '![](img/00239.jpg)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00239.jpg)'
- en: The discovery token feature is hosted by CoreOS and is implemented as an etcd
    cluster as well.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 发现令牌功能由 CoreOS 托管，并作为 etcd 集群实现。
- en: Cluster size
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 集群大小
- en: It is preferable to have an odd-sized etcd cluster as it gives a better failure
    tolerance. The following table shows the majority count and failure tolerance
    for common cluster sizes up to five. With a cluster size of two, we cannot determine
    majority.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 最好将 etcd 集群大小设置为奇数，因为这样可以提供更好的容错性。以下表格显示了常见集群大小（最多五个）的大多数计数和容错性。集群大小为二时，我们无法确定大多数。
- en: '| Cluster size | Majority | Failure tolerance |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| 集群大小 | 大多数 | 容错性 |'
- en: '| 1 | 1 | 0 |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1 | 0 |'
- en: '| 3 | 2 | 1 |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 2 | 1 |'
- en: '| 4 | 3 | 1 |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 3 | 1 |'
- en: '| 5 | 3 | 2 |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 3 | 2 |'
- en: The Majority count tells us the number of nodes that is necessary to have a
    working cluster, and failure tolerance tells us the number of nodes that can fail
    and still keep the cluster operational.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数计数告诉我们需要多少节点才能使集群正常工作，而容错性告诉我们可以故障多少节点仍然保持集群运行。
- en: Etcd cluster details
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: Etcd 集群详细信息
- en: 'The following screenshot shows the Etcd member list in a 3 node CoreOS cluster:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了一个 3 节点 CoreOS 集群中的 Etcd 成员列表：
- en: '![](img/00242.jpg)'
  id: totrans-237
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00242.jpg)'
- en: We can see that there are three members that are part of the etcd cluster with
    their machine ID, machine name, IP address, and port numbers used for etcd server-to-server
    and client-to-server communication.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到有三个成员作为 etcd 集群的一部分，具有它们的机器 ID、机器名称、IP 地址以及用于 etcd 服务器间和客户端间通信的端口号。
- en: 'The following output shows you the etcd cluster health:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 以下输出展示了etcd集群的健康状况：
- en: '![](img/00245.jpg)'
  id: totrans-240
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00245.jpg)'
- en: Here, we can see that all three members of the etcd cluster are healthy.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到etcd集群的所有三个成员都是健康的。
- en: 'The following output shows you etcd statistics with the cluster leader:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 以下输出展示了带有集群领导者的etcd统计信息：
- en: '![](img/00248.jpg)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00248.jpg)'
- en: We can see that the member ID matches with the leader ID, `41419684c778c117`.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，成员ID与领导者ID匹配，`41419684c778c117`。
- en: 'The following output shows you etcd statistics with the cluster member:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 以下输出展示了带有集群成员的etcd统计信息：
- en: '![](img/00251.jpg)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00251.jpg)'
- en: Simple set and get operations using etcd
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 使用etcd进行简单的设置和获取操作
- en: 'In the following example, we will set the `/message1` key to the `Book1` value
    and then later retrieve the value of the `/message1` key:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例中，我们将`/message1`键设置为`Book1`值，然后稍后检索`/message1`键的值：
- en: '![](img/00255.jpg)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00255.jpg)'
- en: Fleet
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: Fleet
- en: Fleet is a cluster manager/scheduler that controls service creation at the cluster
    level. Like systemd being the init system for a node, Fleet serves as the init
    system for a cluster. Fleet uses etcd for internode communication.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: Fleet是一个集群管理器/调度器，用于控制集群级别的服务创建。就像systemd是节点的初始化系统一样，Fleet是集群的初始化系统。Fleet使用etcd进行节点间通信。
- en: The Fleet architecture
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: Fleet架构
- en: 'The following image shows you the components of the Fleet architecture:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像展示了Fleet架构的组件：
- en: '![](img/00051.jpg)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00051.jpg)'
- en: Fleet uses master, slave model with Fleet Engine playing master role and Fleet
    agent playing slave role. Fleet engine is responsible for scheduling Fleet units
    and Fleet agent is responsible for executing the units as well as reporting the
    status back to the Fleet engine.
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fleet采用主从模型，其中Fleet引擎扮演主角色，Fleet代理扮演从角色。Fleet引擎负责调度Fleet单元，而Fleet代理负责执行单元并将状态报告回Fleet引擎。
- en: One master engine is elected among the CoreOS cluster using etcd.
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在CoreOS集群中，使用etcd选举出一个主引擎。
- en: When the user starts a Fleet service, each agent bids for that service. Fleet
    uses a very simple `least-loaded` scheduling algorithm to schedule the unit to
    the appropriate node. Fleet units also consist of metadata that is useful to control
    where the unit runs with respect to the node property as well as based on other
    services running on that particular node.
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当用户启动Fleet服务时，每个代理都会竞标该服务。Fleet使用一种非常简单的`least-loaded`调度算法，将单元调度到合适的节点。Fleet单元还包含元数据，这些元数据有助于控制单元如何基于节点属性以及在特定节点上运行的其他服务来调度。
- en: The Fleet agent processes the unit and gives it to systemd for execution.
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fleet代理处理单元并将其交给systemd执行。
- en: If any node dies, a new Fleet engine is elected and the scheduled units in that
    node are rescheduled to a new node. Systemd provides HA at the node level; Fleet
    provides HA at the cluster level.
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果某个节点出现故障，将选举出一个新的Fleet引擎，并将该节点中的调度单元重新调度到新的节点。Systemd提供了节点级别的高可用性（HA）；Fleet提供了集群级别的高可用性。
- en: Considering that CoreOS and Google are working closely on the Kubernetes project,
    a common question that comes up is the role of Fleet if Kubernetes is going to
    do container orchestration. Fleet is typically used for the orchestration of critical
    system services using systemd while Kubernetes is used for application container
    orchestration. Kubernetes is composed of multiple services such as the kubelet
    server, API server, scheduler, and replication controller and they all run as
    Fleet units. For smaller deployments, Fleet can also be used for application orchestration.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到CoreOS和Google在Kubernetes项目中密切合作，一个常见的问题是，如果Kubernetes负责容器编排，那么Fleet的角色是什么？Fleet通常用于使用systemd编排关键系统服务，而Kubernetes用于应用程序容器的编排。Kubernetes由多个服务组成，如kubelet服务器、API服务器、调度器和复制控制器，它们都作为Fleet单元运行。对于较小的部署，Fleet也可以用于应用程序编排。
- en: A Fleet scheduling example
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 一个Fleet调度示例
- en: 'The following is a three-node CoreOS cluster with some metadata present for
    each node:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个包含一些元数据的三节点CoreOS集群：
- en: '![](img/00054.jpg)'
  id: totrans-263
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00054.jpg)'
- en: A global unit example
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 一个全局单元示例
- en: A global unit executes the same service unit on all the nodes in the cluster.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 一个全局单元在集群中的所有节点上执行相同的服务单元。
- en: 'The following is a sample `helloglobal.service`:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个示例`helloglobal.service`：
- en: '`[Unit] Description=My Service After=docker.service [Service] TimeoutStartSec=0
    ExecStartPre=-/usr/bin/docker kill hello ExecStartPre=-/usr/bin/docker rm hello
    ExecStartPre=/usr/bin/docker pull busybox ExecStart=/usr/bin/docker run --name hello busybox /bin/sh -c "while true; do echo Hello World; sleep 1; done"
    ExecStop=/usr/bin/docker stop hello [X-Fleet] Global=true`'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '`[Unit] Description=My Service After=docker.service [Service] TimeoutStartSec=0
    ExecStartPre=-/usr/bin/docker kill hello ExecStartPre=-/usr/bin/docker rm hello
    ExecStartPre=/usr/bin/docker pull busybox ExecStart=/usr/bin/docker run --name
    hello busybox /bin/sh -c "while true; do echo Hello World; sleep 1; done" ExecStop=/usr/bin/docker
    stop hello [X-Fleet] Global=true`'
- en: 'Let''s execute the unit as follows:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们按如下方式执行单元：
- en: '![](img/00057.jpg)'
  id: totrans-269
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00057.jpg)'
- en: 'We can see that the same service is started on all three nodes:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到相同的服务在所有三台节点上启动：
- en: '![](img/00059.jpg)'
  id: totrans-271
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00059.jpg)'
- en: Scheduling based on metadata
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 基于元数据的调度
- en: 'Let''s say that we have a three-node CoreOS cluster with the following metadata:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个三节点CoreOS集群，具有以下元数据：
- en: Node1 (compute=web, rack=rack1)
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Node1（compute=web，rack=rack1）
- en: Node2 (compute=web, rack=rack2)
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Node2（compute=web，rack=rack2）
- en: Node3 (compute=db, rack=rack3)
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Node3（compute=db，rack=rack3）
- en: We have used the `compute` metadata to identity the type of machine as `web`
    or `db`. We have used the `rack` metadata to identify the rack number. Fleet metadata
    for a node can be specified in the Fleet section of the `cloud-config`.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了`compute`元数据来标识机器类型为`web`或`db`。我们使用了`rack`元数据来标识机架编号。节点的Fleet元数据可以在`cloud-config`的Fleet部分中指定。
- en: Let's start a web service and database service with each having its corresponding
    metadata and see where they get scheduled.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们启动一个Web服务和一个数据库服务，每个服务都有相应的元数据，看看它们会被调度到哪里。
- en: 'This is the web service:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 这是Web服务：
- en: '`[Unit] Description=Apache web server service After=etcd.service After=docker.service  [Service]
    TimeoutStartSec=0 KillMode=none EnvironmentFile=/etc/environment ExecStartPre=-/usr/bin/docker kill nginx
    ExecStartPre=-/usr/bin/docker rm nginx ExecStartPre=/usr/bin/docker pull nginx
    ExecStart=/usr/bin/docker run --name nginx -p ${COREOS_PUBLIC_IPV4}:8080:80 nginx
    ExecStop=/usr/bin/docker stop nginx  [X-Fleet] MachineMetadata=compute=web`'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '`[Unit] Description=Apache web server service After=etcd.service After=docker.service
    [Service] TimeoutStartSec=0 KillMode=none EnvironmentFile=/etc/environment ExecStartPre=-/usr/bin/docker
    kill nginx ExecStartPre=-/usr/bin/docker rm nginx ExecStartPre=/usr/bin/docker
    pull nginx ExecStart=/usr/bin/docker run --name nginx -p ${COREOS_PUBLIC_IPV4}:8080:80
    nginx ExecStop=/usr/bin/docker stop nginx [X-Fleet] MachineMetadata=compute=web`'
- en: 'This is the database service:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 这是数据库服务：
- en: '`[Unit] Description=Redis DB service After=etcd.service After=docker.service  [Service]
    TimeoutStartSec=0 KillMode=none EnvironmentFile=/etc/environment ExecStartPre=-/usr/bin/docker kill redis
    ExecStartPre=-/usr/bin/docker rm redis ExecStartPre=/usr/bin/docker pull redis
    ExecStart=/usr/bin/docker run --name redis redis ExecStop=/usr/bin/docker stop redis  [X-Fleet]
    MachineMetadata=compute=db`'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '`[Unit] Description=Redis DB service After=etcd.service After=docker.service
    [Service] TimeoutStartSec=0 KillMode=none EnvironmentFile=/etc/environment ExecStartPre=-/usr/bin/docker
    kill redis ExecStartPre=-/usr/bin/docker rm redis ExecStartPre=/usr/bin/docker
    pull redis ExecStart=/usr/bin/docker run --name redis redis ExecStop=/usr/bin/docker
    stop redis [X-Fleet] MachineMetadata=compute=db`'
- en: 'Let''s start the services using Fleet:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用Fleet启动服务：
- en: '![](img/00061.jpg)'
  id: totrans-284
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00061.jpg)'
- en: As we can see, `nginxweb.service` got started on `Node1` and `nginxdb.service`
    got started on `Node3`. This is because `Node1` and `Node2` were of the `web`
    type and `Node3` was of the `db` type.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，`nginxweb.service`在`Node1`上启动，`nginxdb.service`在`Node3`上启动。这是因为`Node1`和`Node2`是`web`类型，而`Node3`是`db`类型。
- en: Fleet HA
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: Fleet高可用
- en: When any of the nodes has an issue and does not respond, Fleet automatically
    takes care of scheduling the service units to the next appropriate machine.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 当任何一个节点出现问题并且没有响应时，Fleet会自动处理将服务单元调度到下一个合适的机器上。
- en: 'From the preceding example, let''s reboot `Node1`, which has `nginxweb.service`.
    The service gets scheduled to `Node2` and not to `Node3` because Node2 has the
    `web` metadata:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的例子来看，让我们重启`Node1`，它有`nginxweb.service`。该服务被调度到`Node2`而不是`Node3`，因为Node2有`web`元数据：
- en: '![](img/00064.jpg)'
  id: totrans-289
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00064.jpg)'
- en: In the preceding output, we can see that `nginxweb.service` is rescheduled to
    `Node2` and that `Node1` is not visible in the Fleet cluster.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的输出中，我们可以看到`nginxweb.service`被重新调度到`Node2`，而`Node1`在Fleet集群中不可见。
- en: Flannel
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: Flannel
- en: Flannel uses an Overlay network to allow Containers across different hosts to
    talk to each other. Flannel is not part of the base CoreOS image. This is done
    to keep the CoreOS image size minimal. When Flannel is started, the flannel container
    image is retrieved from the Container image repository. The Docker daemon is typically
    started after the Flannel service so that containers can get the IP address assigned
    by Flannel. This represents a chicken-and-egg problem as Docker is necessary to
    download the Flannel image. The CoreOS team has solved this problem by running
    a master Docker service whose only purpose is to download the Flannel container.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: Flannel使用覆盖网络使不同主机上的容器能够相互通信。Flannel不是基础CoreOS镜像的一部分，这是为了保持CoreOS镜像的最小化。当Flannel启动时，Flannel容器镜像会从容器镜像仓库中获取。通常，Docker守护进程在Flannel服务之后启动，以便容器能够获取Flannel分配的IP地址。这就出现了一个先有鸡还是先有蛋的问题，因为Docker是必要的，以便下载Flannel镜像。CoreOS团队通过运行一个主Docker服务来解决这个问题，这个服务的唯一目的是下载Flannel容器。
- en: 'The following image shows you how Flannel agents in each node communicate using
    etcd:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像展示了每个节点中的Flannel代理如何使用etcd进行通信：
- en: '![](img/00069.jpg)'
  id: totrans-294
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00069.jpg)'
- en: 'The following are some Flannel internals:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些Flannel的内部实现：
- en: Flannel runs without a central server and uses etcd for communication between
    the nodes.
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Flannel在没有中央服务器的情况下运行，使用etcd进行节点之间的通信。
- en: 'As part of starting Flannel, we need to supply a configuration file that contains
    the IP subnet to be used for the cluster as well as the backend protocol method
    (such as UDP and VXLAN). The following is a sample configuration that specifies
    the subnet range and backend protocol as UDP:'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在启动Flannel时，我们需要提供一个配置文件，该文件包含集群要使用的IP子网以及后端协议方法（例如UDP和VXLAN）。以下是一个指定子网范围和后端协议为UDP的示例配置：
- en: '![](img/00071.jpg)'
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/00071.jpg)'
- en: Each node in the cluster requests an IP address range for containers created
    in that host and registers this IP range with etcd.
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集群中的每个节点都会请求为该主机上创建的容器分配一个IP地址范围，并将该IP范围注册到etcd。
- en: As every node in the cluster knows the IP address range allocated for every
    other node, it knows how to reach containers created on any node in the cluster.
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于集群中的每个节点都知道为其他节点分配的IP地址范围，因此它知道如何访问集群中任何节点上创建的容器。
- en: When containers are created, containers get an IP address in the range allocated
    to the node.
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当容器被创建时，容器会获得分配给该节点的IP地址范围内的一个IP地址。
- en: When Containers need to talk across hosts, Flannel does the encapsulation based
    on the backend encapsulation protocol chosen. Flannel, in the destination node,
    de-encapsulates the packet and hands it over to the Container.
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当容器需要跨主机通信时，Flannel会根据选择的后端封装协议进行封装。Flannel在目标节点中解封装数据包并将其交给容器。
- en: By not using port-based mapping to talk across containers, Flannel simplifies
    Container-to-Container communication.
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过不使用基于端口的映射来进行容器间通信，Flannel简化了容器之间的通信。
- en: 'The following image shows the data path for Container-to-Container communication
    using Flannel:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像展示了使用Flannel进行容器到容器通信的数据路径：
- en: '![](img/00075.jpg)'
  id: totrans-305
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00075.jpg)'
- en: A Flannel service unit
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 一个Flannel服务单元
- en: 'The following is an example of a flannel service unit where we set the IP range
    for the flannel network as `10.1.0.0/16`:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个flannel服务单元的示例，我们将flannel网络的IP范围设置为`10.1.0.0/16`：
- en: '![](img/00079.jpg)'
  id: totrans-308
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00079.jpg)'
- en: 'In a three-node etcd cluster, the following is a sample output that shows the
    Container IP address range picked by each node. Each node requests an IP range
    with a 24-bit mask. `10.1.19.0/24` is picked by node A, `10.1.3.0/24` is picked
    by node B, and `10.1.62.0/24` is picked by node C:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个三节点etcd集群中，以下是一个示例输出，显示每个节点选定的容器IP地址范围。每个节点请求一个24位掩码的IP范围。`10.1.19.0/24`由节点A选择，`10.1.3.0/24`由节点B选择，`10.1.62.0/24`由节点C选择：
- en: '![](img/00083.jpg)'
  id: totrans-310
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00083.jpg)'
- en: Rkt
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: Rkt
- en: 'Rkt is the Container runtime developed by CoreOS. Rkt does not have a daemon
    and is managed by systemd. Rkt uses the Application Container image (ACI) image
    format, which is according to the APPC specification ([https://github.com/appc/spec](https://github.com/appc/spec)).
    Rkt''s execution is split into three stages. This approach was taken so that some
    of the stages can be replaced by a different implementation if needed. Following
    are details on the three stages of Rkt execution:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: Rkt是CoreOS开发的容器运行时。Rkt没有守护进程，由systemd进行管理。Rkt使用应用程序容器镜像（ACI）格式，遵循APPC规范（[https://github.com/appc/spec](https://github.com/appc/spec)）。Rkt的执行分为三个阶段。采取这种方法是为了在需要时能够用不同的实现替换某些阶段。以下是Rkt执行的三个阶段的详细信息：
- en: 'Stage 0:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 阶段0：
- en: This is the first stage of Container execution. This stage does image discovery,
    retrieval and sets up filesystem for stages 1 and 2.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 这是容器执行的第一阶段。该阶段进行镜像发现、检索，并为第 1 和第 2 阶段设置文件系统。
- en: 'Stage 1:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 第 1 阶段：
- en: This stage sets up the execution environment for containers like Container namespace,
    cgroups using the filesystem setup by stage 0.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 该阶段设置容器的执行环境，如容器命名空间、使用第 0 阶段设置的文件系统中的 cgroups。
- en: 'Stage 2:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 第 2 阶段：
- en: This stage executes the Container using execution environment setup by stage
    1 and filesystem setup by stage 0.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 该阶段使用第 1 阶段设置的执行环境和第 0 阶段设置的文件系统来执行容器。
- en: As of release 0.10.0, Rkt is still under active development and is not ready
    for production.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 从 0.10.0 版本开始，Rkt 仍在积极开发中，尚未准备好用于生产环境。
- en: The CoreOS cluster architecture
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: CoreOS 集群架构
- en: Nodes in the CoreOS cluster are used to run critical CoreOS services such as
    etcd, fleet, Docker, systemd, flannel, and journald as well as application containers.
    It is important to avoid using the same host to run critical services as well
    as application containers so that there is no resource contention for critical
    services. This kind of scheduling can be achieved using the Fleet metadata to
    separate the core machines and worker machines. The following are two cluster
    approaches.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: CoreOS 集群中的节点用于运行关键的 CoreOS 服务，如 etcd、fleet、Docker、systemd、flannel 和 journald，以及应用容器。为了避免关键服务和应用容器之间的资源争用，重要的是避免在同一主机上同时运行关键服务和应用容器。可以通过使用
    Fleet 元数据来分离核心机器和工作机器，从而实现这种调度。以下是两种集群方法。
- en: The development cluster
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 开发集群
- en: 'The following image shows a development cluster with three CoreOS nodes:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像展示了一个包含三台 CoreOS 节点的开发集群：
- en: '![](img/00088.jpg)'
  id: totrans-324
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00088.jpg)'
- en: To try out CoreOS and etcd, we can start with a single-node cluster. With this
    approach, there is no need to have dynamic discovery of cluster members. Once
    this works fine, we can expand the cluster size to three or five to achieve redundancy.
    The static or dynamic discovery approach can be used to discover CoreOS members.
    As CoreOS critical services and application containers run in the same cluster,
    there could be resource contention in this approach.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 为了试用 CoreOS 和 etcd，我们可以从一个单节点集群开始。使用这种方法，不需要动态发现集群成员。一旦它工作正常，我们可以将集群规模扩展到三台或五台，以实现冗余。可以使用静态或动态发现方法来发现
    CoreOS 成员。由于 CoreOS 的关键服务和应用容器运行在同一个集群中，这种方法可能会出现资源争用问题。
- en: The production cluster
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 生产集群
- en: 'The following image shows a production cluster with a three-node master cluster
    and five-node worker cluster:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像展示了一个生产集群，包含三节点主集群和五节点工作集群：
- en: '![](img/00090.jpg)'
  id: totrans-328
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00090.jpg)'
- en: We can have a three or five-node master cluster to run critical CoreOS services
    and then have a dynamic worker cluster to run application Containers. The master
    cluster will run etcd, fleet, and other critical services. In worker nodes, etcd
    will be set up to proxy to master nodes so that worker nodes can use master nodes
    for etcd communication. Fleet, in worker nodes, will also be set up to use etcd
    in master nodes.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以拥有一个三节点或五节点的主集群来运行关键的 CoreOS 服务，然后有一个动态的工作集群来运行应用容器。主集群将运行 etcd、fleet 和其他关键服务。在工作节点中，etcd
    将被设置为代理到主节点，以便工作节点可以通过主节点进行 etcd 通信。在工作节点中，fleet 也将设置为使用主节点中的 etcd。
- en: Docker versus Rkt
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 与 Rkt
- en: As this is a controversial topic, I will try to give a neutral stand here.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是一个有争议的话题，我会尽量保持中立。
- en: History
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 历史
- en: 'CoreOS team started the Rkt project because of the following reasons:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: CoreOS 团队启动了 Rkt 项目，原因如下：
- en: Container interoperability issue needed to be addressed since Docker runtime
    was not fully following the Container manifest specification
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于 Docker 运行时没有完全遵循容器清单规范，容器互操作性问题需要解决
- en: Getting Docker to run under systemd had some issues because of Docker running
    as the daemon
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 systemd 下运行 Docker 遇到了一些问题，因为 Docker 作为守护进程运行。
- en: Container image discovery and image signing required improvements
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器镜像发现和镜像签名需要改进
- en: Security model for Containers needed to be improved
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要改进容器的安全模型
- en: APPC versus OCI
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: APPC 与 OCI
- en: APPC ([https://github.com/appc/spec](https://github.com/appc/spec)) and OCI
    ([https://github.com/opencontainers/specs](https://github.com/opencontainers/specs))
    define Container standards.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: APPC ([https://github.com/appc/spec](https://github.com/appc/spec)) 和 OCI ([https://github.com/opencontainers/specs](https://github.com/opencontainers/specs))
    定义了容器标准。
- en: 'The APPC specification is primarily driven by CoreOS along with a few other
    community members. The APPC specification defines the following:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: APPC 规范主要由 CoreOS 和少数其他社区成员推动。APPC 规范定义了以下内容：
- en: 'Image format: Packaging and signing'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像格式：打包和签名
- en: 'Runtime: How to execute the Container'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行时：如何执行容器
- en: 'Naming and Sharing: Automatic discovery'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 命名和共享：自动发现
- en: APPC is implemented by Rkt, Kurma, Jetpack, and others.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: Rkt、Kurma、Jetpack 等实现了 APPC。
- en: 'OCI ([https://www.opencontainers.org/](https://www.opencontainers.org/)) is
    an open container initiative project started in April 2015 and has members from
    all major companies including Docker and CoreOS. Runc is an implementation of
    OCI. The following image shows you how APPC, OCI, Docker, and Rkt are related:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: OCI ([https://www.opencontainers.org/](https://www.opencontainers.org/)) 是一个自
    2015 年 4 月启动的开放容器倡议项目，其成员包括 Docker 和 CoreOS 等各大公司。Runc 是 OCI 的一个实现。以下图片展示了 APPC、OCI、Docker
    和 Rkt 的关系：
- en: '![](img/00111.jpg)'
  id: totrans-346
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00111.jpg)'
- en: The current status
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 当前状态
- en: Based on the latest developments, there is consensus among the community to
    having a common container specification called the Open Container Specification.
    Anyone can develop a Container runtime based on this specification. This will
    allow Container images to be interoperable. Docker, Rkt, and Odin are examples
    of Container runtime.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 根据最新的发展，社区普遍一致认为应当有一个称为开放容器规范的通用容器规范。任何人都可以基于此规范开发容器运行时。这将允许容器镜像具备互操作性。Docker、Rkt
    和 Odin 都是容器运行时的示例。
- en: The original APPC container specification proposed by CoreOS covers four different
    elements of container management—packaging, signing, naming (sharing the container
    with others), and runtime. As per the latest CoreOS blog update ([https://coreos.com/blog/making-sense-of-standards.html](https://coreos.com/blog/making-sense-of-standards.html)),
    APPC and OCI will intersect only on runtime and APPC will continue to focus on
    image format, signing, and distribution. Runc is an implementation of OCI and
    Docker uses Runc.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: CoreOS 最初提出的 APPC 容器规范涵盖了容器管理的四个不同元素——打包、签名、命名（与他人共享容器）和运行时。根据最新的 CoreOS 博客更新（[https://coreos.com/blog/making-sense-of-standards.html](https://coreos.com/blog/making-sense-of-standards.html)），APPC
    和 OCI 仅在运行时上交汇，而 APPC 将继续专注于图像格式、签名和分发。Runc 是 OCI 的一个实现，Docker 使用了 Runc。
- en: Differences between Docker and Rkt
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 和 Rkt 之间的区别
- en: 'Following are some differences between Docker and Rkt Container runtimes:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 Docker 和 Rkt 容器运行时之间的一些区别：
- en: 'Docker uses LibContainer APIs to access the Linux kernel Container functionality
    while Rkt uses the Systemd-nspawn API to access the Linux kernel Container functionality.
    The following image illustrates this:'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker 使用 LibContainer API 访问 Linux 内核容器功能，而 Rkt 使用 Systemd-nspawn API 访问 Linux
    内核容器功能。以下图片说明了这一点：
- en: '![](img/00098.jpg)'
  id: totrans-353
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/00098.jpg)'
- en: Docker requires a daemon to manage Container images, remote APIs, and Container
    processes. Rkt is daemonless and Container resources are managed by systemd. This
    makes Rkt integrate better with init systems such as systemd and upstart.
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker 需要一个守护程序来管理容器镜像、远程 API 和容器进程。Rkt 是无守护程序的，容器资源由 systemd 管理。这使得 Rkt 更好地集成到像
    systemd 和 upstart 这样的初始化系统中。
- en: Docker has a complete platform to manage containers such as Machine, Compose,
    and Swarm. CoreOS will use some of its own tools such as Flannel for the Networking
    and combines it with tools such as Kubernetes for Orchestration.
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker 拥有一套完整的平台来管理容器，如 Machine、Compose 和 Swarm。CoreOS 则会使用一些自己的工具，如 Flannel
    用于网络，同时结合像 Kubernetes 这样的工具进行编排。
- en: Docker is pretty mature and production-ready as compared to Rkt. As of the Rkt
    release 0.10.0, Rkt is not yet ready for production.
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相比于 Rkt，Docker 已经相当成熟并且可以用于生产。截至 Rkt 0.10.0 版本发布时，Rkt 还未准备好用于生产。
- en: For the Container image registry, Docker has the Docker hub and Rkt has Quay.
    Quay also has Docker images.
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于容器镜像注册表，Docker 使用 Docker Hub，Rkt 使用 Quay。Quay 也有 Docker 镜像。
- en: CoreOS is planning to support both Docker and Rkt and users will have a choice
    to use the corresponding Container runtime for their applications.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: CoreOS 计划同时支持 Docker 和 Rkt，用户可以选择使用相应的容器运行时来运行他们的应用程序。
- en: A workflow for distributed application development with Docker and CoreOS
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Docker 和 CoreOS 进行分布式应用开发的工作流程
- en: 'The following is a typical workflow to develop microservices using Docker and
    CoreOS:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是使用 Docker 和 CoreOS 开发微服务的典型工作流程：
- en: Select applications that need to be containerized. This could be greenfield
    or legacy applications. For legacy applications, reverse engineering might be
    required to split the monolithic application and containerize the individual components.
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择需要容器化的应用程序。这可以是绿色领域（greenfield）应用程序，也可以是遗留应用程序。对于遗留应用程序，可能需要进行逆向工程，以拆分单体应用并容器化各个组件。
- en: Create a Dockerfile for each microservice. The Dockerfile defines how to create
    the Container image from the base image. Dockerfile itself could be source-controlled.
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为每个微服务创建一个 Dockerfile。Dockerfile 定义了如何从基础镜像创建容器镜像。Dockerfile 本身可以进行版本控制。
- en: Split the stateless and stateful pieces of the application. For stateful applications,
    a storage strategy needs to be decided.
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将应用程序的无状态部分与有状态部分分离。对于有状态应用程序，需要决定存储策略。
- en: Microservices need to talk to each other and some of the services should be
    reachable externally. Assuming that basic network connectivity between services
    is available, services can talk to each other either statically by defining a
    service name to IP address and port number mapping or by using service discovery
    where services can dynamically discover and talk to each other.
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微服务之间需要互相通信，其中一些服务应能够对外访问。假设服务之间的基本网络连接可用，服务可以通过静态方式通过定义服务名称与 IP 地址及端口号的映射来进行通信，或者通过使用服务发现机制，在该机制中，服务可以动态发现并互相通信。
- en: Docker container images need to be stored in a private or public repository
    so that they can be shared among development, QA, and production teams.
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker 容器镜像需要存储在私有或公有仓库中，以便开发、QA 和生产团队可以共享。
- en: The application can be deployed in a private or public cloud. An appropriate
    infrastructure has to be selected based on the business need.
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用程序可以部署在私有云或公有云中。必须根据业务需求选择合适的基础设施。
- en: Select the CoreOS cluster size and cluster architecture. It's better to make
    infrastructure dynamically scalable.
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择 CoreOS 集群的大小和架构。最好使基础设施具有动态可扩展性。
- en: Write CoreOS unit files for basic services such as etcd, fleet, and flannel.
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为基本服务（如 etcd、fleet 和 flannel）编写 CoreOS 单元文件。
- en: Finalize a storage strategy—local versus distributed versus cloud.
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定存储策略——本地、分布式或云存储。
- en: For orchestration of smaller applications, fleet can be used. For complex applications,
    the Kubernetes kind of Orchestration solution will be necessary.
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于较小应用程序的编排，可以使用 fleet。对于复杂的应用程序，将需要 Kubernetes 这类编排解决方案。
- en: For production clusters, appropriate monitoring, logging, and upgrading strategies
    also need to be worked out.
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于生产集群，还需要制定合适的监控、日志记录和升级策略。
- en: Summary
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we covered the basics of CoreOS, Containers, and Docker and
    how they help in distributed application development and deployment. These technologies
    are under active development and will revolutionize and create a new software
    development and distribution model. We will explore each individual topic in detail
    in the following chapters. In the next chapter, we will cover how to set up the
    CoreOS development environment in Vagrant as well as in a public cloud.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们介绍了 CoreOS、容器和 Docker 的基础知识，以及它们如何帮助分布式应用程序的开发和部署。这些技术仍在积极开发中，将彻底改变并创造一种新的软件开发和分发模式。我们将在接下来的章节中详细探讨每个主题。在下一章中，我们将介绍如何在
    Vagrant 和公有云中设置 CoreOS 开发环境。
- en: References
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'APPC specification: [https://github.com/appc/spec/blob/master/SPEC.md](https://github.com/appc/spec/blob/master/SPEC.md)'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'APPC 规范: [https://github.com/appc/spec/blob/master/SPEC.md](https://github.com/appc/spec/blob/master/SPEC.md)'
- en: 'OCI specification: [https://github.com/opencontainers/specs](https://github.com/opencontainers/specs)'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'OCI 规范: [https://github.com/opencontainers/specs](https://github.com/opencontainers/specs)'
- en: 'CoreOS documentation: [https://coreos.com/docs/](https://coreos.com/docs/)'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'CoreOS 文档: [https://coreos.com/docs/](https://coreos.com/docs/)'
- en: 'Docker documentation: [https://docs.docker.com/](https://docs.docker.com/)'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Docker 文档: [https://docs.docker.com/](https://docs.docker.com/)'
- en: Further reading and tutorials
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步阅读和教程
- en: 'A blog on the minimalist operating system: [https://blog.docker.com/2015/02/the-new-minimalist-operating-systems/](https://blog.docker.com/2015/02/the-new-minimalist-operating-systems/)
    and [https://blog.codeship.com/container-os-comparison/](https://blog.codeship.com/container-os-comparison/)'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '有关极简操作系统的博客: [https://blog.docker.com/2015/02/the-new-minimalist-operating-systems/](https://blog.docker.com/2015/02/the-new-minimalist-operating-systems/)
    和 [https://blog.codeship.com/container-os-comparison/](https://blog.codeship.com/container-os-comparison/)'
- en: 'Container basics: [http://www.slideshare.net/jpetazzo/anatomy-of-a-container-namespaces-cgroups-some-filesystem-magic-linuxcon](http://www.slideshare.net/jpetazzo/anatomy-of-a-container-namespaces-cgroups-some-filesystem-magic-linuxcon)'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器基础：[http://www.slideshare.net/jpetazzo/anatomy-of-a-container-namespaces-cgroups-some-filesystem-magic-linuxcon](http://www.slideshare.net/jpetazzo/anatomy-of-a-container-namespaces-cgroups-some-filesystem-magic-linuxcon)
- en: 'An introduction to Docker: [https://www.youtube.com/watch?v=Q5POuMHxW-0](https://www.youtube.com/watch?v=Q5POuMHxW-0)'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker 入门：[https://www.youtube.com/watch?v=Q5POuMHxW-0](https://www.youtube.com/watch?v=Q5POuMHxW-0)
- en: 'Mesos overview: [https://www.youtube.com/watch?v=gVGZHzRjvo0](https://www.youtube.com/watch?v=gVGZHzRjvo0)'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mesos 概述：[https://www.youtube.com/watch?v=gVGZHzRjvo0](https://www.youtube.com/watch?v=gVGZHzRjvo0)
- en: 'The CoreOS presentation: [http://www.slideshare.net/RichardLister/core-os](http://www.slideshare.net/RichardLister/core-os)'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CoreOS 演示：[http://www.slideshare.net/RichardLister/core-os](http://www.slideshare.net/RichardLister/core-os)
- en: 'DigitalOcean CoreOS tutorials: [https://www.digitalocean.com/community/tags/coreos?type=tutorials](https://www.digitalocean.com/community/tags/coreos?type=tutorials)'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DigitalOcean CoreOS 教程：[https://www.digitalocean.com/community/tags/coreos?type=tutorials](https://www.digitalocean.com/community/tags/coreos?type=tutorials)
- en: 'Microservices'' characteristics: [http://martinfowler.com/articles/microservices.html](http://martinfowler.com/articles/microservices.html)'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微服务的特点：[http://martinfowler.com/articles/microservices.html](http://martinfowler.com/articles/microservices.html)
- en: 'The Docker daemon issue: [http://www.ibuildthecloud.com/blog/2014/12/03/is-docker-fundamentally-flawed/](http://www.ibuildthecloud.com/blog/2014/12/03/is-docker-fundamentally-flawed/)
    and [https://github.com/ibuildthecloud/systemd-docker](https://github.com/ibuildthecloud/systemd-docker)'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker 守护进程问题：[http://www.ibuildthecloud.com/blog/2014/12/03/is-docker-fundamentally-flawed/](http://www.ibuildthecloud.com/blog/2014/12/03/is-docker-fundamentally-flawed/)
    和 [https://github.com/ibuildthecloud/systemd-docker](https://github.com/ibuildthecloud/systemd-docker)
