- en: Chapter 9. Mesos Big Data Frameworks 2
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第9章：Mesos 大数据框架 2
- en: This chapter is a guide to deploying important big data storage frameworks,
    such as Cassandra, the Elasticsearch-Logstash-Kibana (ELK) stack, and Kafka, on
    Mesos.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍如何在 Mesos 上部署重要的大数据存储框架，如 Cassandra、Elasticsearch-Logstash-Kibana（ELK）堆栈和
    Kafka。
- en: Cassandra on Mesos
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Cassandra 在 Mesos 上的使用
- en: This section will introduce Cassandra and explain how to set up Cassandra on
    Mesos while also discussing the problems commonly encountered during the setup
    process.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将介绍 Cassandra，并解释如何在 Mesos 上部署 Cassandra，同时讨论在设置过程中常遇到的问题。
- en: Introduction to Cassandra
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Cassandra 介绍
- en: '**Cassandra** is an open source, scalable NoSQL database that is fully distributed
    with no single point of failure and is highly performant for most standard use
    cases. It is both horizontally as well as vertically scalable. **Horizontal scalability**
    or **scale-out solution** involves adding more nodes with commodity hardware to
    the existing cluster while **vertical scalability** or **scale-up solution** means
    adding more CPU and memory resources to a node with specialized hardware.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '**Cassandra** 是一个开源、可扩展的 NoSQL 数据库，完全分布式且没有单点故障，对于大多数标准使用案例具有高性能。它既支持横向扩展也支持纵向扩展。**横向扩展**
    或 **扩展解决方案** 涉及通过添加更多的普通硬件节点来扩展现有集群，而 **纵向扩展** 或 **扩展升级解决方案** 则意味着通过为节点添加更多的 CPU
    和内存资源来使用专用硬件。'
- en: Cassandra was developed by Facebook engineers to address the inbox search use
    case and was inspired by Google Bigtable, which served as the foundation for its
    storage model, and Amazon DynamoDB, which was the foundation of its distribution
    model. It was open sourced in 2008 and became an Apache top-level project in early
    2010\. It provides a query language called **Cassandra Query Language** or **CQL**,
    which has a SQL-like syntax, to communicate with the database.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Cassandra 是由 Facebook 工程师开发的，旨在解决收件箱搜索的使用案例，灵感来自 Google Bigtable（它为 Cassandra
    的存储模型提供了基础）以及 Amazon DynamoDB（它为 Cassandra 的分布式模型提供了基础）。Cassandra 于 2008 年开源，并在
    2010 年初成为 Apache 顶级项目。它提供了一种名为 **Cassandra 查询语言** 或 **CQL** 的查询语言，语法类似 SQL，用于与数据库进行通信。
- en: 'Cassandra provides various capabilities, such as:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Cassandra 提供了多种功能，例如：
- en: High performance
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高性能
- en: Continuous uptime (no single point of failure)
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 持续的正常运行时间（无单点故障）
- en: Ease of use
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 易用性
- en: Data replication and distribution across datacenters
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据在数据中心之间的复制和分发
- en: Instead of using a traditional master-slave or sharded design, Cassandra's architecture
    uses an elegant and simple **ring design** without any masters. This allows it
    to provide all the features and benefits listed earlier.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Cassandra 的架构采用优雅且简洁的 **环形设计**，没有任何主节点，而不是使用传统的主从或分片设计。这使得它能够提供前述所有特性和优势。
- en: 'The Cassandra Ring Design diagram is shown as follows (source: [www.planetcassandra.org](http://www.planetcassandra.org)):'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Cassandra 环形设计图如下所示（来源：[www.planetcassandra.org](http://www.planetcassandra.org)）：
- en: '![Introduction to Cassandra](img/B05186_09_00.jpg)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![Cassandra 介绍](img/B05186_09_00.jpg)'
- en: A large number of companies use Cassandra in production, including Apple, Instagram,
    eBay, Spotify, Comcast, and Netflix among others.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 许多公司在生产环境中使用 Cassandra，包括 Apple、Instagram、eBay、Spotify、Comcast 和 Netflix 等公司。
- en: 'Cassandra is best used when you need:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Cassandra 最适用于以下场景：
- en: No single failure point
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无单点故障
- en: Real-time writes
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实时写入
- en: Flexibility
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 灵活性
- en: Horizontal scaling
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 横向扩展
- en: Reliability
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可靠性
- en: A clearly defined table schema in a NoSQL environment
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 NoSQL 环境中拥有明确定义的表结构
- en: 'Some of the common use cases are as follows:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些常见的使用场景：
- en: Storing, managing, and performing analysis on data generated by messaging applications
    (Instagram and Comcast, among others, use Cassandra for this purpose)
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存储、管理以及对由消息应用程序生成的数据进行分析（Instagram 和 Comcast 等公司都使用 Cassandra 来处理这类数据）
- en: Storing data patterns for the detection of fraudulent activity
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存储用于检测欺诈活动的数据模式
- en: Storing user-selected and curated items (shopping cart, playlists, and so on)
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存储用户选择和策划的项目（购物车、播放列表等）
- en: Recommendation and personalization
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推荐和个性化
- en: '**Performance benchmark**'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**性能基准**'
- en: 'The following performance benchmark conducted by an independent database firm
    showed that for mixed operational and analytical workloads, Cassandra was far
    superior to other open source NoSQL technologies (source: [www.datastax.com](http://www.datastax.com)):'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 以下由独立数据库公司进行的性能基准测试显示，对于混合的操作和分析工作负载，Cassandra 明显优于其他开源 NoSQL 技术（来源：[www.datastax.com](http://www.datastax.com)）：
- en: '![Introduction to Cassandra](img/B05186_09_01.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![Cassandra 介绍](img/B05186_09_01.jpg)'
- en: Setting up Cassandra on Mesos
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在Mesos上设置Cassandra
- en: This section covers the process of deploying Cassandra on top of Mesos. The
    recommended way of deploying Cassandra on Mesos is through Marathon. At the time
    of writing this book, Cassandra on Mesos is in an experimental stage, and the
    configuration described here might change in future releases.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了在Mesos上部署Cassandra的过程。推荐的Cassandra在Mesos上的部署方式是通过Marathon。在编写本书时，Cassandra在Mesos上的配置仍处于实验阶段，此处描述的配置可能在未来的版本中发生变化。
- en: 'The Mesosphere team has already packaged the necessary JAR files and the Cassandra
    executor in a tarball that can be directly submitted to Mesos through Marathon
    with the following JSON code:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Mesosphere团队已经将所需的JAR文件和Cassandra执行器打包在一个tar包中，可以通过以下JSON代码直接提交给Mesos并通过Marathon运行：
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Edit the JSON code by pointing `MESOS_ZK` and any other parameters that you
    need to change accordingly, save this JSON code in `cassandra-mesos.json`, and
    then submit it to Marathon with the following command:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 编辑JSON代码，指向`MESOS_ZK`及任何其他需要更改的参数，将此JSON代码保存为`cassandra-mesos.json`，然后通过以下命令将其提交给Marathon：
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Once submitted, the framework will bootstrap itself. We also need to expand
    the port ranges managed by each Mesos node to include the standard Cassandra ports.
    We can pass the port ranges as resources when starting the process.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦提交，框架将自我引导。我们还需要扩展每个Mesos节点管理的端口范围，以包括标准的Cassandra端口。我们可以在启动过程中将端口范围作为资源传递。
- en: 'Here''s an example:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个示例：
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Cassandra on Mesos provides a REST endpoint to tune the setup. We can access
    this endpoint on port `18080` by default (unless changed).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: Mesos上的Cassandra提供了一个REST端点，用于调整设置。我们可以通过默认端口`18080`访问此端点（除非已更改）。
- en: An advanced configuration guide
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高级配置指南
- en: 'As mentioned previously, Cassandra on Mesos takes in runtime configuration
    through environment variables. We can use the following environment variables
    to bootstrap the configuration of the framework. After the initial run, the configurations
    are read from the framework state stored in ZooKeeper:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，Mesos上的Cassandra通过环境变量接受运行时配置。我们可以使用以下环境变量来引导框架的配置。在初始运行后，配置会从ZooKeeper中存储的框架状态中读取：
- en: '[PRE3]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Here are some references:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些参考资料：
- en: '[https://github.com/mesosphere/cassandra-mesos](https://github.com/mesosphere/cassandra-mesos)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://github.com/mesosphere/cassandra-mesos](https://github.com/mesosphere/cassandra-mesos)'
- en: '[http://mesosphere.github.io/cassandra-mesos/](http://mesosphere.github.io/cassandra-mesos/)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://mesosphere.github.io/cassandra-mesos/](http://mesosphere.github.io/cassandra-mesos/)'
- en: The Elasticsearch-Logstash-Kibana (ELK) stack on Mesos
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Mesos上的Elasticsearch-Logstash-Kibana（ELK）栈
- en: This section will introduce the **Elasticsearch-Logstash-Kibana** (**ELK**)
    stack and explain how to set it up on Mesos while also discussing the problems
    commonly encountered during the setup process.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将介绍**Elasticsearch-Logstash-Kibana**（**ELK**）栈，并解释如何在Mesos上设置它，同时讨论在设置过程中常见的问题。
- en: Introduction to Elasticsearch, Logstash, and Kibana
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Elasticsearch、Logstash和Kibana简介
- en: The ELK stack, a combination of **Elasticsearch**, **Logstash**, and **Kibana**,
    is an end-to-end solution for **log analytics**. Elasticsearch provides search
    capabilities, Logstash is a log management software, while Kibana serves as the
    visualization layer. The stack is commercially backed by a company called **Elastic**.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ELK栈，**Elasticsearch**、**Logstash**和**Kibana**的组合，是一个端到端的**日志分析**解决方案。Elasticsearch提供搜索功能，Logstash是日志管理软件，而Kibana作为可视化层。该栈由名为**Elastic**的公司提供商业支持。
- en: Elasticsearch
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Elasticsearch
- en: 'Elasticsearch is a Lucene-based open source distributed search engine designed
    for high scalability and fast search query response time. It simplifies the usage
    of Lucene, a highly performant search engine library, by providing a powerful
    REST API on top. Some of the important concepts in Elasticsearch are highlighted
    as follows:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Elasticsearch是一个基于Lucene的开源分布式搜索引擎，旨在实现高可扩展性和快速的搜索查询响应时间。它通过提供一个强大的REST API来简化Lucene的使用，Lucene是一个高性能的搜索引擎库。以下是Elasticsearch中的一些重要概念：
- en: '**Document**: This is a JSON object stored in an index'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文档**：这是存储在索引中的一个JSON对象'
- en: '**Index**: This is a document collection'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**索引**：这是一个文档集合'
- en: '**Type**: This is a logical partition of an index representing a category of
    documents'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**类型**：这是一个表示文档类别的索引逻辑分区'
- en: '**Field**: This is a key-value pair within a document'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**字段**：这是文档中的一个键值对'
- en: '**Mapping**: This is used to map every field with its datatype'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**映射**：用于将每个字段与其数据类型进行映射'
- en: '**Shard**: This is the physical location where an index''s data is stored (the
    data is stored on one primary shard and copied on a set of replica shards)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Shard**：这是存储索引数据的物理位置（数据存储在一个主分片上，并复制到一组副本分片上）'
- en: Logstash
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Logstash
- en: 'This is a tool to collect and process the log events generated by a wide variety
    of systems. It includes a rich set of input and output connectors to ingest the
    logs and make them available for analysis. Some of its important features are:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个收集和处理由各种系统生成的日志事件的工具。它包括一组丰富的输入和输出连接器，用于获取日志并使其可供分析。一些重要功能包括：
- en: The ability to convert logs to a common format for the ease of use
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将日志转换为通用格式以便于使用的能力
- en: The ability to process multiple log formats, including custom ones
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理多种日志格式的能力，包括自定义格式
- en: A rich set of input and output connectors
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 丰富的输入和输出连接器集
- en: Kibana
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kibana
- en: 'This is an Elasticsearch-based data visualization tool with a wide variety
    of charting and dashboarding capabilities. It is powered by the data stored in
    the Elasticsearch indexes and is entirely developed using HTML and JavaScript.
    Some of its most important features are:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个基于Elasticsearch的数据可视化工具，具有多种图表和仪表板功能。它依赖于存储在Elasticsearch索引中的数据，完全使用HTML和JavaScript开发。其一些最重要的功能包括：
- en: A graphical user interface for dashboard construction
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于仪表板构建的图形用户界面
- en: A rich set of charts (map, pie charts, histograms, and so on)
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 丰富的图表集（地图、饼图、直方图等）
- en: The ability to embed charts in user applications
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将图表嵌入用户应用程序的能力
- en: The ELK stack data pipeline
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ELK栈数据管道
- en: 'Take a look at the following diagram (source: *Learning ELK Stack* by Packt
    Publishing):'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下图示（来源：*Learning ELK Stack*，Packt出版社）：
- en: '![The ELK stack data pipeline](img/B05186_09_02.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![ELK栈数据管道](img/B05186_09_02.jpg)'
- en: In a standard ELK stack pipeline, logs from various application servers are
    transported through Logstash to a central indexer module. This indexer then transmits
    the output to an Elasticsearch cluster, where it can be queried directly or visualized
    in a dashboard by leveraging Kibana.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在标准ELK栈管道中，各种应用程序服务器的日志通过Logstash传输到中央索引模块。该索引模块随后将输出传输到Elasticsearch集群，在那里可以直接查询或通过Kibana在仪表板中进行可视化。
- en: Setting up Elasticsearch-Logstash-Kibana on Mesos
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在Mesos上设置Elasticsearch-Logstash-Kibana
- en: This section explains how to set up Elasticsearch, Logstash, and Kibana on top
    of Mesos. We will first take a look at how to set up Elasticsearch on top of Mesos
    followed by Logstash and Kibana.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 本节解释如何在Mesos上设置Elasticsearch、Logstash和Kibana。我们将首先介绍如何在Mesos上设置Elasticsearch，然后是Logstash和Kibana。
- en: Elasticsearch on Mesos
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Mesos上的Elasticsearch
- en: 'We will use Marathon to deploy Elasticsearch, and this can be done in two ways:
    through the Docker image, which is highly recommended, and through `elasticsearch-mesos
    jar`. Both are explained in the following section.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用Marathon来部署Elasticsearch，这可以通过两种方式完成：通过Docker镜像（强烈推荐），以及通过`elasticsearch-mesos
    jar`。这两种方式将在以下部分进行解释。
- en: 'We can use the following Marathon file to deploy Elasticsearch on top of Mesos.
    It uses the Docker image:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下Marathon文件将Elasticsearch部署到Mesos上。它使用Docker镜像：
- en: '[PRE4]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Ensure that `zookeeper-node` is changed to the address of the ZooKeeper node
    that you have on the cluster. We can save this to an `elasticsearch.json` file
    and then deploy it on Marathon with the following command:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 确保将`zookeeper-node`更改为集群中ZooKeeper节点的地址。我们可以将其保存到`elasticsearch.json`文件，并通过以下命令在Marathon上部署：
- en: '[PRE5]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'As mentioned before, we can also use the JAR file to deploy Elasticsearch on
    top of Mesos with the following Marathon file:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们也可以使用JAR文件通过以下Marathon文件将Elasticsearch部署到Mesos上：
- en: '[PRE6]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'In both cases, the `JAVA_OPTS` environment variable is required, and if it''s
    not set, it will cause problems with the Java heap space. We can save this as
    `elasticsearch.json` and submit it to Marathon with the following command:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，都需要`JAVA_OPTS`环境变量，如果没有设置，可能会导致Java堆内存空间的问题。我们可以将其保存为`elasticsearch.json`文件，并通过以下命令提交给Marathon：
- en: '[PRE7]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Both Docker image and the JAR file take in the following command-line arguments,
    similar to the `--zookeeperMesosUrl` argument:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: Docker镜像和JAR文件都需要以下命令行参数，类似于`--zookeeperMesosUrl`参数：
- en: '[PRE8]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Logstash on Mesos
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Mesos上的Logstash
- en: This section explains how to run Logstash on top of Mesos. Once Logstash is
    deployed on the cluster, any program that runs on Mesos can log an event that
    is then passed by Logstash and sent to a central log location.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍如何在 Mesos 上运行 Logstash。Logstash 部署到集群后，任何在 Mesos 上运行的程序都可以记录事件，事件随后通过 Logstash
    被传递并发送到中央日志位置。
- en: 'We can run Logstash as a Marathon application and deploy it on top of Mesos
    with the following Marathon file:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将 Logstash 作为 Marathon 应用程序运行，并通过以下 Marathon 文件在 Mesos 上部署：
- en: '[PRE9]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Here, we used the Docker image for deployment, the configurations of which
    can be changed according to your cluster specification. Save the preceding file
    as `logstash.json` and submit it to Marathon with the following command:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用了用于部署的 Docker 镜像，其配置可以根据您的集群规格进行更改。将前面的文件保存为 `logstash.json` 并使用以下命令提交给
    Marathon：
- en: '[PRE10]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Logstash on Mesos configurations
  id: totrans-93
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Mesos 上的 Logstash 配置
- en: 'Logstash and Elasticsearch are tested with the Mesos version 0.25.0 and later.
    We need to add Logstash to the list of roles on every Mesos master machine. This
    can be done with the following command:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: Logstash 和 Elasticsearch 经 Mesos 版本 0.25.0 及更高版本测试。我们需要将 Logstash 添加到每个 Mesos
    主节点的角色列表中。这可以通过以下命令完成：
- en: '[PRE11]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'If the purpose of Logstash is to monitor `syslog` (a message logging standard),
    then we need to add the TCP and UDP port `514` to the resources list in every
    Mesos node in the cluster. This can be done by adding the following entry in the
    `/etc/mesos-slave/resources` file:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 Logstash 的目的是监控 `syslog`（一种消息日志标准），则需要在集群中每个 Mesos 节点的资源列表中添加 TCP 和 UDP 端口
    `514`。可以通过在 `/etc/mesos-slave/resources` 文件中添加以下条目来实现：
- en: '[PRE12]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'To monitor `collectd`, we need to add the TCP and UDP port `25826` to the resources
    for the Logstash role by adding the following line to the `/etc/mesos-slave/resources`
    file:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 要监控 `collectd`，我们需要通过在 `/etc/mesos-slave/resources` 文件中添加以下行来将 TCP 和 UDP 端口
    `25826` 添加到 Logstash 角色的资源中：
- en: '[PRE13]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Kibana on Mesos
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kibana 在 Mesos 上
- en: If we run Kibana on Mesos, then each instance of Kibana will run as a Docker
    image in the Mesos cluster. For each instance of Elasticsearch, one or more instances
    of Kibana can be deployed to serve the users.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在 Mesos 上运行 Kibana，那么每个 Kibana 实例将作为 Docker 镜像在 Mesos 集群中运行。对于每个 Elasticsearch
    实例，可以部署一个或多个 Kibana 实例来为用户提供服务。
- en: 'We can clone Kibana on the Mesos project from the following repository:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从以下代码库克隆 Mesos 项目上的 Kibana：
- en: '[PRE14]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Build the project with the following command:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令构建项目：
- en: '[PRE15]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This will generate the Kibana JAR file (`kibana.jar`).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成 Kibana JAR 文件（`kibana.jar`）。
- en: 'Once `kibana.jar` is generated, we can deploy it with the following command:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦 `kibana.jar` 文件生成，我们可以使用以下命令进行部署：
- en: '[PRE16]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Here, `-zk` represents the ZooKeeper URI and the `-es` points to the Elasticsearch
    endpoint, which we deployed in the previous section. Set them accordingly.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`-zk` 代表 ZooKeeper URI，`-es` 指向我们在前一节中部署的 Elasticsearch 端点。请根据需要设置它们。
- en: 'The following command-line options are also supported by the `kibana.jar` file:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '`kibana.jar` 文件还支持以下命令行选项：'
- en: '| Short keyword | Keyword | Definition |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 短关键词 | 关键词 | 定义 |'
- en: '| --- | --- | --- |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| `-zk` | -`zookeeper` | This is the Mesos ZooKeeper URL (Required) |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| `-zk` | `-zookeeper` | 这是 Mesos ZooKeeper 的 URL（必需） |'
- en: '| `-di` | `-dockerimage` | This is the name of the Docker image to be used
    (The default is `kibana`) |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| `-di` | `-dockerimage` | 这是要使用的 Docker 镜像名称（默认值为 `kibana`） |'
- en: '| `-v` | `-version` | This is the version of the Kibana Docker image to be
    used (The default is `latest`) |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| `-v` | `-version` | 这是要使用的 Kibana Docker 镜像的版本（默认值为 `latest`） |'
- en: '| `-mem` | `-requiredMem` | This is the amount of memory (in MB) to be allocated
    to a single Kibana instance (The default is `128`) |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| `-mem` | `-requiredMem` | 这是分配给单个 Kibana 实例的内存量（单位：MB，默认值为 `128`） |'
- en: '| `-cpu` | `-requiredCpu` | This is the amount of CPUs to allocate to a single
    Kibana instance (The default is `0.1`) |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| `-cpu` | `-requiredCpu` | 这是分配给单个 Kibana 实例的 CPU 数量（默认值为 `0.1`） |'
- en: '| `-disk` | `-requiredDisk` | This is the amount of disk space (in MB) to be
    allocated to a single Kibana instance (The default is `25`) |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| `-disk` | `-requiredDisk` | 这是分配给单个 Kibana 实例的磁盘空间量（单位：MB，默认值为 `25`） |'
- en: '| `-es` | `-elasticsearch` | These are the URLs of Elasticsearch to start a
    Kibana for at startup |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| `-es` | `-elasticsearch` | 这些是启动时用于启动 Kibana 的 Elasticsearch URL |'
- en: 'Here are some references:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些参考资料：
- en: '[http://mesos-elasticsearch.readthedocs.org/en/latest/#elasticsearch-mesos-framework](http://mesos-elasticsearch.readthedocs.org/en/latest/#elasticsearch-mesos-framework)'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://mesos-elasticsearch.readthedocs.org/en/latest/#elasticsearch-mesos-framework](http://mesos-elasticsearch.readthedocs.org/en/latest/#elasticsearch-mesos-framework)'
- en: '[https://github.com/mesos/logstash](https://github.com/mesos/logstash)'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://github.com/mesos/logstash](https://github.com/mesos/logstash)'
- en: '[https://github.com/mesos/kibana](https://github.com/mesos/kibana)'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://github.com/mesos/kibana](https://github.com/mesos/kibana)'
- en: Kafka on Mesos
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kafka on Mesos
- en: This section will introduce Kafka and explain how to set it up on Mesos while
    also discussing the problems commonly encountered during the setup process.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将介绍Kafka，并解释如何在Mesos上进行设置，同时讨论在设置过程中常见的问题。
- en: Introduction to Kafka
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kafka简介
- en: 'Kafka is a distributed publish-subscribe messaging system designed for speed,
    scalability, reliability, and durability. Some of the key terms used in Kafka
    are given as follows:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka是一个分布式发布-订阅消息系统，旨在提供速度、可扩展性、可靠性和耐久性。Kafka中使用的一些关键术语如下所示：
- en: '**Topics**: These are the categories where message feeds are maintained by
    Kafka'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主题**：这些是Kafka维护消息流的类别。'
- en: '**Producers**: These are the upstream processes that send messages to a particular
    Kafka topic'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生产者**：这些是上游进程，它们将消息发送到特定的Kafka主题。'
- en: '**Consumers**: These are the downstream processes that listen to the incoming
    messages in a topic and process them as per requirements'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**消费者**：这些是下游进程，它们监听主题中传入的消息，并根据要求处理它们。'
- en: '**Broker**: Each node in a Kafka cluster is called a broker'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代理**：Kafka集群中的每个节点称为代理。'
- en: 'Take a look at the following high-level diagram of Kafka (source: [http://kafka.apache.org/documentation.html#introduction](http://kafka.apache.org/documentation.html#introduction)):'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 请查看以下Kafka的高层次示意图（来源：[http://kafka.apache.org/documentation.html#introduction](http://kafka.apache.org/documentation.html#introduction)）：
- en: '![Introduction to Kafka](img/B05186_09_03.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![Kafka介绍](img/B05186_09_03.jpg)'
- en: 'A partitioned log is maintained by the Kafka cluster for every topic, which
    looks similar to the following (source: [http://kafka.apache.org/documentation.html#intro_topics](http://kafka.apache.org/documentation.html#intro_topics)):'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka集群为每个主题维护一个分区日志，类似于以下内容（来源：[http://kafka.apache.org/documentation.html#intro_topics](http://kafka.apache.org/documentation.html#intro_topics)）：
- en: '![Introduction to Kafka](img/B05186_09_04.jpg)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![Kafka介绍](img/B05186_09_04.jpg)'
- en: Use cases of Kafka
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kafka的使用案例
- en: 'Some important uses of Kafka are described here:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 这里描述了一些Kafka的重要用途：
- en: '**Website activity tracking**: Site activity events, such as page views and
    user searches, can be sent by the web application to Kafka topics. Downstream
    processing systems can then subscribe to these topics and consume the messages
    for batch analytics, monitoring, real-time dashboarding, and other such use cases.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**网站活动跟踪**：网站活动事件，例如页面浏览和用户搜索，可以由Web应用程序发送到Kafka主题。下游处理系统可以订阅这些主题并消费消息，用于批量分析、监控、实时仪表盘等用例。'
- en: '**Log aggregation**: Kafka is used as an alternative to traditional log aggregation
    systems. Physical log files can be collected from various services and pushed
    to different Kafka topics, where different consumers can read and process them.
    File details are abstracted by Kafka, which enables faster processing and support
    for a variety of data sources.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**日志聚合**：Kafka作为传统日志聚合系统的替代方案。可以从各种服务收集物理日志文件并推送到不同的Kafka主题，在那里不同的消费者可以读取和处理它们。Kafka抽象了文件细节，从而实现了更快的处理并支持多种数据源。'
- en: '**Stream processing**: Frameworks, for instance Spark Streaming, can consume
    data from a Kafka topic, process it as per requirements, and then publish the
    processed output to a different Kafka topic, where this output can, in turn, be
    consumed by other applications.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**流处理**：框架，例如Spark Streaming，可以从Kafka主题中消费数据，按照要求处理，然后将处理后的输出发布到另一个Kafka主题，在那里该输出可以被其他应用程序消费。'
- en: Setting up Kafka
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kafka设置
- en: 'Before installing Kafka on Mesos, make sure the following applications are
    available on the machine:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在Mesos上安装Kafka之前，确保机器上已安装以下应用程序：
- en: Java version 7 or later ([http://openjdk.java.net/install/](http://openjdk.java.net/install/))
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Java版本7或更高版本（[http://openjdk.java.net/install/](http://openjdk.java.net/install/)）
- en: Gradle ([http://gradle.org/installation](http://gradle.org/installation))
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gradle（[http://gradle.org/installation](http://gradle.org/installation)）
- en: 'We can clone and build the Kafka on Mesos project from the following repository:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从以下仓库克隆并构建Kafka on Mesos项目：
- en: '[PRE17]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We will also require the Kafka executor, which can be downloaded with the following
    command:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要Kafka执行器，可以通过以下命令下载：
- en: '[PRE18]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We will also need to set the following environment variable to point to the
    `libmesos.so` file:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要设置以下环境变量，以指向`libmesos.so`文件：
- en: '[PRE19]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Once these are set, we can use the `kafka-mesos.sh` script to launch and configure
    Kafka on top of Mesos. Before doing so, we need to create the `kafka-mesos.properties`
    file with the following contents:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦这些设置好，我们可以使用`kafka-mesos.sh`脚本在Mesos上启动并配置Kafka。在此之前，我们需要创建`kafka-mesos.properties`文件，其内容如下：
- en: '[PRE20]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This file can be used to configure the scheduler (`kafka-mesos.sh`) if we don''t
    need to pass the arguments to the scheduler all the time. The scheduler supports
    the following command-line arguments:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们不希望每次都将参数传递给调度器，可以使用该文件来配置调度器（`kafka-mesos.sh`）。调度器支持以下命令行参数：
- en: '| Option | Description |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| 选项 | 描述 |'
- en: '| --- | --- |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `--api` | This is the API URL—for example, `http://master:7000`. |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| `--api` | 这是API URL，例如`http://master:7000`。 |'
- en: '| `--bind-address` | This is the scheduler bind address (such as master, `0.0.0.0`,
    `192.168.50.*`, and `if:eth1`). The default is `all`. |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| `--bind-address` | 这是调度器绑定地址（例如master，`0.0.0.0`，`192.168.50.*`，以及`if:eth1`）。默认值是`all`。
    |'
- en: '| `--debug <Boolean>` | This is the debug mode. The default is `false`. |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| `--debug <Boolean>` | 这是调试模式。默认值是`false`。 |'
- en: '| `--framework-name` | This is the framework name. The default is `kafka`.
    |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| `--framework-name` | 这是框架名称。默认值是`kafka`。 |'
- en: '| `--framework-role` | This is the framework role. The default is `*`. |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| `--framework-role` | 这是框架角色。默认值是`*`。 |'
- en: '| `--framework-timeout` | This is the framework timeout (30s, 1m, or 1h). The
    default is `30d`. |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| `--framework-timeout` | 这是框架超时时间（30s、1m或1h）。默认值是`30d`。 |'
- en: '| `--jre` | This is the JRE zip file (`jre-7-openjdk.zip`). The default is
    `none`. |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| `--jre` | 这是JRE压缩文件（`jre-7-openjdk.zip`）。默认值是`none`。 |'
- en: '| `--log` | This is the log file to use. The default is `stdout`. |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| `--log` | 这是要使用的日志文件。默认值是`stdout`。 |'
- en: '| `--master` | These are the master connection settings. Some examples are:`-
    master:5050``- master:5050,master2:5050``- zk://master:2181/mesos``- zk://username:password@master:2181``-
    zk://master:2181,master2:2181/mesos` |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| `--master` | 这些是主连接设置。一些示例如下：`- master:5050` `- master:5050,master2:5050`
    `- zk://master:2181/mesos` `- zk://username:password@master:2181` `- zk://master:2181,master2:2181/mesos`
    |'
- en: '| `--principal` | This is the principal (username) used to register the framework.
    The default is `none`. |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| `--principal` | 这是用于注册框架的主体（用户名）。默认值是`none`。 |'
- en: '| `--secret` | This is the secret (password) used to register the framework.
    The default is `none`. |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| `--secret` | 这是用于注册框架的密码（密码）。默认值是`none`。 |'
- en: '| `--storage` | This is the storage for the cluster state. Some examples are:`-
    file:kafka-mesos.json``- zk:/kafka-mesos`The default is `file:kafka-mesos.json`.
    |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| `--storage` | 这是集群状态的存储位置。一些示例如下：`- file:kafka-mesos.json` `- zk:/kafka-mesos`
    默认值是`file:kafka-mesos.json`。 |'
- en: '| `--user` | This is the Mesos user to run tasks. The default is `none`. |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| `--user` | 这是运行任务的Mesos用户。默认值是`none`。 |'
- en: '| `--zk` | This is Kafka `zookeeper.connect`. Some examples are:`- master:2181``-
    master:2181,master2:2181` |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| `--zk` | 这是Kafka的`zookeeper.connect`。一些示例如下：`- master:2181` `- master:2181,master2:2181`
    |'
- en: 'Now, we can use the scheduler to run a Kafka scheduler via the following commands
    listed:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用调度器通过以下命令运行Kafka调度器：
- en: '[PRE21]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The next thing we need to do is to start up one Kafka broker with the default
    settings. This can be done via the following command:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要做的事情是以默认设置启动一个Kafka代理。这可以通过以下命令完成：
- en: '[PRE22]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'At this point, our Kafka cluster will have one broker that is not yet started.
    We can verify this with the following command:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们的Kafka集群将有一个代理尚未启动。我们可以通过以下命令验证这一点：
- en: '[PRE23]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We can now start this broker with the following command:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以使用以下命令启动这个代理：
- en: '[PRE24]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: If the preceding output is shown, then our broker is ready to produce and consume
    messages. We can now test this setup with `kafkacat`.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 如果显示上面的输出，则我们的代理已经准备好生成和消费消息。我们现在可以使用`kafkacat`来测试这个设置。
- en: 'The `kafkacat` can be installed on the system with the following command:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '`kafkacat`可以通过以下命令安装到系统中：'
- en: '[PRE25]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Now that we have pushed the test to the broker, we can read it back with the
    following command:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经将测试推送到代理上，我们可以通过以下命令将其读取回来：
- en: '[PRE26]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Now, let''s take a look at how we can add more brokers to the cluster at once.
    Run the following:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看一下如何一次性向集群添加更多代理。运行以下命令：
- en: '[PRE27]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The preceding command adds three `kafka` brokers to the cluster with the following
    output:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的命令将会向集群添加三个`kafka`代理，输出如下：
- en: '[PRE28]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'We can start all the three brokers at once with the following command:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过以下命令一次性启动所有三个代理：
- en: '[PRE29]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'If we need to change the location of the Kafka logs where the data is stored,
    we need to first stop the particular broker and then update the location with
    the following commands:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们需要更改Kafka日志存储数据的位置，我们需要首先停止特定代理，然后使用以下命令更新位置：
- en: '[PRE30]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Once done, we can start the broker back up with the following command:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，我们可以使用以下命令重新启动代理：
- en: '[PRE31]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Kafka logs management
  id: totrans-193
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kafka日志管理
- en: 'We can get the last 100 lines of the logs (`stdout` -default or `stderr`) of
    any broker in the cluster with the following command:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过以下命令获取集群中任何代理的日志的最后100行（`stdout` - 默认或`stderr`）：
- en: '[PRE32]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'If we need to read from the `stderr` file, then we will use the following command:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们需要从`stderr`文件读取，则可以使用以下命令：
- en: '[PRE33]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We can read any file in the `kafka-*/log/` directory by passing on the filename
    to the `--name` option. For example, if we need to read `server.log`, then it
    can be read with the following command:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过将文件名传递给`--name`选项来读取`kafka-*/log/`目录中的任何文件。例如，如果我们需要读取`server.log`，可以使用以下命令：
- en: '[PRE34]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Also, if we need to read more numbers of lines from the log, it can be read
    using the `--lines` option, as follows:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果我们需要从日志中读取更多行数，可以使用`--lines`选项，方法如下：
- en: '[PRE35]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: An advanced configuration guide
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高级配置指南
- en: 'The following are the configuration options available while *adding* broker(s)
    to the cluster:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是在集群中*添加*代理时可用的配置选项：
- en: '[PRE36]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'We will now take a look at the options that are available when starting the
    broker(s):'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看一下启动代理时可用的选项：
- en: '[PRE37]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The following are the configuration options available while *updating* broker(s)
    in the cluster:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是在集群中*更新*代理时可用的配置选项：
- en: '[PRE38]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The following are the configuration options available while stopping broker(s)
    in the cluster:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是在集群中停止代理时可用的配置选项：
- en: '[PRE39]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The following are the configuration options available while adding a topic
    to the broker(s) in the cluster:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是在集群中向代理添加主题时可用的配置选项：
- en: '[PRE40]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: The reference for this is [https://github.com/mesos/kafka](https://github.com/mesos/kafka).
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 参考资料：[https://github.com/mesos/kafka](https://github.com/mesos/kafka)。
- en: Summary
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This chapter introduced the reader to some important big data storage frameworks
    such as Cassandra, the ELK stack, and Kafka and covered topics such as the setup,
    configuration, and management of these frameworks on a distributed infrastructure
    using Mesos.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了如Cassandra、ELK堆栈和Kafka等一些重要的大数据存储框架，并涵盖了如何在分布式基础设施上使用Mesos进行这些框架的设置、配置和管理等主题。
- en: I hope that this book has armed you with all the resources that you require
    to effectively manage the complexities of today's modern datacenter requirements.
    By following the detailed step-by-step guides to deploy a Mesos cluster using
    the DevOps tool of your choice, you should now be in a position to handle the
    system administration requirements of your organization smoothly.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望本书已经为您提供了管理当今现代数据中心需求复杂性的所有资源。通过遵循使用您选择的DevOps工具部署Mesos集群的详细分步指南，您现在应该能够顺利处理组织的系统管理需求。
