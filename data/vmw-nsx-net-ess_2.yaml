- en: Chapter 2.  NSX Architecture
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2章. NSX架构
- en: 'In this chapter, we will have a high-level discussion on NSX architecture.
    To properly install and configure NSX, we should understand the core components
    that are involved in the NSX solution. By the end of this chapter, we will have
    a good understanding of the following aspects:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将对NSX架构进行高层次的讨论。为了正确安装和配置NSX，我们应该了解涉及到NSX解决方案的核心组件。到本章结束时，我们将对以下方面有一个较为清晰的理解：
- en: Network planes
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络平面
- en: NSX core components
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NSX核心组件
- en: Identifying controller roles
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定控制器角色
- en: The controller cluster
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 控制器集群
- en: VXLAN architecture
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: VXLAN架构
- en: Introducing network planes
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍网络平面
- en: 'In a traditional switch/router, routing and packet forwarding is ideally done
    on the same device. What does this mean? Let''s take a classic example of configuring
    a router. We might configure SSH for managing the router and later configure routing
    protocols to exchange the routes with its neighbors. All these common tasks are
    done specifically on the same hardware device. So, in a nutshell, each and every
    router will take a forwarding decision based on the configuration of routers.
    The power of software-defined networking is decoupling the forwarding and control
    plane functionality to a centralized device called a controller and the end result
    is the controller maintaining the forwarding information and taking decisions
    rather than going via hop by hop in the traditional way. As shown in the following
    figure, the three functional planes of a network are the management plane, the
    control plane, and the data plane:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统的交换机/路由器中，路由和数据包转发通常是在同一设备上完成的。这意味着什么呢？我们可以举一个配置路由器的经典例子。我们可能会配置SSH来管理路由器，然后再配置路由协议与其邻居交换路由。这些常见任务都是在同一硬件设备上完成的。因此，简而言之，每个路由器都会根据路由器的配置做出转发决策。软件定义网络的优势在于将转发平面和控制平面功能解耦到一个集中式设备，称为控制器，最终的结果是控制器维护转发信息并做出决策，而不是像传统方式那样逐跳转发。如图所示，网络的三个功能平面分别是管理平面、控制平面和数据平面：
- en: '![Introducing network planes](img/image_02_001.jpg)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![介绍网络平面](img/image_02_001.jpg)'
- en: 'The three functional planes of a network are explained as follows:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 网络的三个功能平面解释如下：
- en: '**Management plane**: The management plane is a straightforward concept: a
    slice of software through which we will make changes and configure network devices,
    and protocols such as SSH and SNMP are used to access and monitor them.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管理平面**：管理平面是一个直观的概念：通过这块软件切片，我们可以进行变更并配置网络设备，使用如SSH和SNMP等协议来访问和监控这些设备。'
- en: '**Control plane**: The classic example for the control plane is learning routes
    and making decisions based on routing algorithms. However, control plane functionality
    is not limited to learning routes. The control plane also helps in pairing with
    vendor-specific devices, and secures control plane access such as SSH and Telnet.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**控制平面**：控制平面的经典示例是学习路由并基于路由算法做出决策。然而，控制平面功能不仅限于学习路由。控制平面还帮助与特定厂商的设备进行配对，并保护控制平面的访问，如SSH和Telnet。'
- en: '**Data plane**: Data plane traffic is traditionally performed in dedicated
    hardware devices by consuming a little bit of compute resources. Primarily, the
    data plane is focused on data forwarding tasks.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据平面**：数据平面流量通常由专用硬件设备执行，消耗少量计算资源。数据平面主要关注数据转发任务。'
- en: I know most of us will be wondering why we are discussing network planes here.
    Network planes are DNA in the NSX world and we have all three planes which make
    the network virtualization layer.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我知道我们大多数人可能会想，为什么在这里讨论网络平面。网络平面是NSX世界中的DNA，三种平面共同构成了网络虚拟化层。
- en: NSX vSphere components
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: NSX vSphere组件
- en: 'NSX uses the management plane, control plane, and data plane models. The components
    are represented diagrammatically in the following diagram:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: NSX使用管理平面、控制平面和数据平面模型。组件在下图中以示意图的形式展示：
- en: '![NSX vSphere components](img/image_02_002.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![NSX vSphere组件](img/image_02_002.jpg)'
- en: The management plane
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 管理平面
- en: The management plane contains the NSX Manager and vCenter Server. It is important
    to know that each NSX Manager should be registered with only one vCenter Server.
    The NSX Manager provides a management UI and API for NSX. We will be discussing
    NSX Manager and vCenter Server integration during NSX Manager installation and
    configuration modules. Once the integration is done, NSX Manager can be managed
    from a vSphere web client, which acts as a single pane of glass for configuring
    and securing the vSphere infrastructure. Immediate benefit is network administrators
    no longer need to switch between multiple management consoles. All network services
    can be configured and monitored from a single interface.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 管理平面包含NSX Manager和vCenter Server。需要了解的是，每个NSX Manager应只注册一个vCenter Server。NSX
    Manager为NSX提供管理UI和API。我们将在NSX Manager安装和配置模块中讨论NSX Manager与vCenter Server的集成。一旦集成完成，NSX
    Manager可以通过vSphere Web客户端进行管理，vSphere Web客户端作为一个单一的管理界面，用于配置和保护vSphere基础设施。即时的好处是，网络管理员不再需要在多个管理控制台之间切换。所有网络服务都可以通过单一界面进行配置和监控。
- en: The control plane
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 控制平面
- en: 'The control plane primarily consists of NSX Controllers and the control VM,
    which allows us to perform distributed routing. The control plane also allows
    multicast-free VXLAN networks, which was a limitation in earlier vCloud networking
    and security versions. Controllers maintain ARP, VTEP (VXLAN tunnel endpoint),
    and MAC table. The NSX logical router control virtual machine and VMware NSX Controller
    are virtual machines that are deployed by VMware NSX Manager. The **User World
    Agent** (**UWA**) is composed of the ntcpad and vsfwd daemons on the ESXi host.
    Communication related to NSX between the NSX Manager instance or the NSX Controller
    instances and the ESXi host happen through the UWA. NSX Controller clusters are
    deployed in ODD number fashion and the maximum number of supported controllers
    is three. Since every controller in a control cluster is active at the same time,
    it ensures that the control plane is intact even if there is a controller failure.
    Controllers talk to each other to be in sync through a secured SSL channel. Controllers
    use a slicing technology to divide the workload among other controllers. Have
    a look at the following figure, which is a three-node controller cluster, in which
    slicing technology is dividing the workload across the controllers:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 控制平面主要由NSX控制器和控制虚拟机组成，允许我们执行分布式路由。控制平面还支持无组播的VXLAN网络，这是早期vCloud网络与安全版本的一个限制。控制器维护ARP、VTEP（VXLAN隧道端点）和MAC表。NSX逻辑路由器控制虚拟机和VMware
    NSX控制器是由VMware NSX Manager部署的虚拟机。**用户世界代理**（**UWA**）由ESXi主机上的ntcpad和vsfwd守护进程组成。NSX
    Manager实例或NSX控制器实例与ESXi主机之间的NSX相关通信通过UWA进行。NSX控制器集群以奇数个方式部署，最大支持的控制器数量为三。由于控制集群中的每个控制器同时处于活动状态，它确保即使某个控制器发生故障，控制平面仍然完好。控制器之间通过安全的SSL通道进行同步通信。控制器使用切片技术在控制器之间分配工作负载。请看下面的图，它是一个三节点控制器集群，其中切片技术在控制器之间分配工作负载：
- en: '![The control plane](img/B03244_02_03.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![控制平面](img/B03244_02_03.jpg)'
- en: 'It is important to understand that there are two types of applications running
    on each of these controllers:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要理解在每个控制器上运行着两种类型的应用程序：
- en: '**VXLAN**: Enables extension of a Layer-2 IP subnet anywhere in the fabric,
    irrespective of the physical network design.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**VXLAN**：使得可以在网络中任何地方扩展一个二层IP子网，而不受物理网络设计的限制。'
- en: '**Logical router**: Routing between IP subnets can be done in a logical space
    without traffic touching the physical router. This routing is performed directly
    in the hypervisor kernel with minimal CPU/memory overhead. This functionality
    provides an optimal data path for routing traffic within the virtual infrastructure.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**逻辑路由器**：在逻辑空间内可以进行IP子网之间的路由，而无需流量经过物理路由器。这种路由直接在虚拟机监控程序内核中执行，并且CPU/内存开销最小。这一功能为在虚拟基础设施中路由流量提供了最佳的数据路径。'
- en: The functionality of these applications is to learn and populate controller
    tables, and also distribute learned routes to underlying ESXi hosts. Lastly, the
    control plane and data plane configuration will be intact even during the failure
    of a management plane-this is the real power of software-defined networking.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这些应用程序的功能是学习并填充控制器表格，同时将学习到的路由分发给底层的ESXi主机。最后，即使管理平面发生故障，控制平面和数据平面的配置仍然保持完整——这就是软件定义网络的真正力量。
- en: Three-node controller clusters
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 三节点控制器集群
- en: 'In a large-scale distributed system with *n* number of servers, it is extremely
    difficult to ensure that one specific server can perform a write operation to
    a database or that only one server is the master that processes all writes. The
    fundamental problem is we do not have a simple way through which process execution
    can be done. How do we resolve this? All we need is to promote one server as master,
    and have some consensus with other servers. Paxos is a distributed consensus protocol
    published in 1989\. The algorithm also ensures we have a leader election whenever
    there is a server failure. Paxos distinguishes the roles of proposer, acceptor,
    and learner, where a process (server/node) can play one or more roles simultaneously.
    The following are a few vendors who are using the Paxos algorithm extensively
    for the same reason:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个大规模的分布式系统中，有 *n* 个服务器时，确保一个特定的服务器能够对数据库执行写操作，或确保只有一个服务器是处理所有写操作的主服务器，是极其困难的。根本问题在于我们没有一个简单的方式来执行进程。我们如何解决这个问题呢？我们只需要提升一个服务器为主服务器，并与其他服务器达成共识。Paxos
    是一个分布式共识协议，发布于 1989 年。该算法还确保每当服务器发生故障时，我们会进行领导者选举。Paxos 区分了提议者、接受者和学习者的角色，其中一个进程（服务器/节点）可以同时扮演一个或多个角色。以下是一些广泛使用
    Paxos 算法的厂商，原因相同：
- en: VMware NSX Controller uses a Paxos-based algorithm within an NSX Controller
    cluster
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: VMware NSX 控制器在 NSX 控制器集群中使用基于 Paxos 的算法
- en: Amazon Web Services uses the Paxos algorithm extensively to power its platform
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 亚马逊 Web 服务广泛使用 Paxos 算法为其平台提供支持
- en: Nutanix implements the Paxos algorithm to ensure strict consistency is maintained
    in cassandara (for storing cluster metadata)
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nutanix 实现了 Paxos 算法，以确保在 Cassandra（用于存储集群元数据）中保持严格的一致性
- en: Apache Mesos uses the Paxos algorithm for its replicated log coordination
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Apache Mesos 使用 Paxos 算法进行其复制日志协调
- en: Google uses the Paxos algorithm for providing the Chubby lock service for loosely
    coupled distributed systems
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Google 使用 Paxos 算法为松耦合的分布式系统提供 Chubby 锁服务
- en: The Windows fabric used by many of the Azure services makes use of the Paxos
    algorithm for replication between nodes in a cluster
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 许多 Azure 服务使用的 Windows fabric 利用 Paxos 算法实现集群节点之间的复制
- en: NSX Controllers are deployed in a three-node clustered fashion to ensure we
    are getting the highest level of resiliency since the controllers are running
    a fault-tolerant, distributed consensus algorithm called **Paxos**.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 为确保获取最高级别的可靠性，NSX 控制器以三节点集群的方式进行部署，因为控制器运行的是一种容错的分布式共识算法，称为**Paxos**。
- en: Controller roles
  id: totrans-36
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 控制器角色
- en: 'The NSX Controller provides the control plane functions for routing and logical
    switching functions. Each controller node is running a set of roles that defines
    the type of task the controller node can run. There are total of five roles running
    in a controller node; they are as follows:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: NSX 控制器提供路由和逻辑交换功能的控制平面功能。每个控制器节点运行一组角色，这些角色定义了控制器节点可以执行的任务类型。一个控制器节点总共运行五个角色，它们如下所示：
- en: API
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: API
- en: Persistence server
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 持久化服务器
- en: Logical manager
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑管理器
- en: Switch manager
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 交换机管理器
- en: Directory server
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目录服务器
- en: While each of these roles needs a different master, it is important to understand
    that the leader is the responsible controller for allocating the tasks to other
    controllers.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然每个角色需要不同的主节点，但重要的是要理解领导者是负责将任务分配给其他控制器的控制器。
- en: 'The following figure depicts the responsibilities of various roles:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示描述了各个角色的职责：
- en: '![Controller roles](img/B03244_02_04-1024x783.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![控制器角色](img/B03244_02_04-1024x783.jpg)'
- en: 'As we know, three node controllers form a control cluster. We will have a look
    at the role election per controller. Each role has a master controller node and
    only if a master controller node for a given role fails there would be a cluster-wide
    election for a new master role. This is one of the prime reasons a three-node
    cluster is a must in an enterprise environment, to avoid any split-brain situation
    which might eventually end up with data inconsistencies and the whole purpose
    of the control plane would be defeated. In the following figure, we have a three-node
    control cluster running and each controller is running a master role:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所知，三个节点控制器组成一个控制集群。我们将查看每个控制器的角色选举。每个角色都有一个主控制器节点，只有当某个给定角色的主控制器节点失败时，才会进行全集群范围的选举来选出新的主角色。这是三节点集群在企业环境中必不可少的主要原因之一，以避免出现分脑情况，这可能最终导致数据不一致，从而破坏整个控制平面的目的。在下图中，我们有一个正在运行的三节点控制集群，每个控制器都在运行主角色：
- en: '**Controller 1**: Directory server master role running'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**控制器 1**：目录服务器主角色正在运行'
- en: '**Controller 2**: Persistence server master role running'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**控制器 2**：持久性服务器主角色正在运行'
- en: '**Controller 3**: API and switch manager master role running'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**控制器 3**：API 和交换机管理主角色正在运行'
- en: '![Controller roles](img/image_02_005.jpg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![Controller roles](img/image_02_005.jpg)'
- en: The data plane
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据平面
- en: 'NSX logical switches, ESXi hypervisor, distributed switches, and NSX edge devices
    are all data plane components. Once the management plane is up and running, we
    can deploy control plane and data plane software and components. Behind the scenes,
    these three **VMware Installation Bundles** (**VIB**) get pushed to the underlying
    ESXi hypervisor:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: NSX 逻辑交换机、ESXi 虚拟化服务器、分布式交换机和 NSX 边缘设备都是数据平面组件。一旦管理平面启动并运行，我们就可以部署控制平面和数据平面软件及组件。在幕后，这三个
    **VMware 安装包**（**VIB**）会被推送到底层的 ESXi 虚拟化服务器上：
- en: VXLAN VIB
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: VXLAN VIB
- en: Distributed routing VIB
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分布式路由 VIB
- en: Distributed firewall VIB
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分布式防火墙 VIB
- en: Up to now, we have discussed the management, control, and data plane components
    in the NSX world; in the upcoming modules, we will have a closer look at the installation
    part and design specification for each layer.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经讨论了 NSX 世界中的管理平面、控制平面和数据平面组件；在接下来的模块中，我们将更详细地了解每一层的安装部分和设计规范。
- en: Overlay networks
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 覆盖网络
- en: 'A virtual network which is built on top of a physical network is called an
    overlay network. Does that sound familiar by any chance? Most enterprise environments
    would have used VPN technology for securing private or public networks, which
    is an IP-over-IP overlay technology. However, it is very important to understand
    that not all overlay networks are built on top of IP networks. The real question
    is, why do we require an overlay network ? As we can see from the following figure,
    we have two data centers and each of these data centers is following a spine-leaf
    topology. Flexible workload placement and virtual machine mobility, along with
    strong multitenancy for each tenant, are common asks in a virtualized infrastructure:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在物理网络之上构建的虚拟网络称为覆盖网络。这听起来熟悉吗？大多数企业环境会使用 VPN 技术来保护私有或公共网络，这是一种 IP-over-IP 的覆盖技术。然而，重要的是要理解，并非所有的覆盖网络都是建立在
    IP 网络之上的。真正的问题是，为什么我们需要覆盖网络？如以下图所示，我们有两个数据中心，每个数据中心都遵循一个 spine-leaf 拓扑结构。在虚拟化基础设施中，灵活的工作负载部署和虚拟机迁移能力，以及为每个租户提供强大的多租户性，都是常见的需求：
- en: '![Overlay networks](img/B03244_02_06.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![Overlay networks](img/B03244_02_06.jpg)'
- en: VXLAN, MPLS, NVGRE, VPN, and OTV are some of the classic examples of network-based
    overlays. Let's go back to the roots of server virtualization. Server virtualization
    virtualizes a physical server and allows multiple virtual machines to run on top
    of it with its own compute and storage resources. Now, each virtual machine might
    be having one or more than one MAC address, which eventually increases the MAC
    table in the network. Added to that, VM mobility forces the broadcast domains
    to grow. The traditional way of segmenting a network would be with the help of
    VLAN. As per the 802.1q standard, a VLAN tag is a 12-bit space providing a maximum
    of 4,096 VLANS. This is not a feasible solution in current multi tenant cloud
    environments wherein multiple machines reside on the same server and network isolation
    is required and workloads keep spiking, which demands a few VLANs to be provisioned
    for future growth and VLAN sprawl continues to happen based on workload mobility.
    Overlay networks alleviate this problem by providing Layer 2 connectivity independent
    of physical networks. We all know new technologies solve a lot of problems; however,
    there will always be challenges associated with them. Guess how difficult it will
    be for a network administrator to troubleshoot an overlay network! Trust me, when
    the mapping between the overlay network and physical network is crystal clear,
    it is extremely easy to perform troubleshooting. An NSX-VXLAN-based overlay network
    is a host-based overlay network which uses a UDP-based VXLAN encapsulation.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: VXLAN、MPLS、NVGRE、VPN 和 OTV 是一些经典的基于网络的覆盖网络例子。让我们回到服务器虚拟化的根源。服务器虚拟化将一台物理服务器虚拟化，并允许多个虚拟机在其上运行，每个虚拟机拥有自己的计算和存储资源。现在，每个虚拟机可能拥有一个或多个
    MAC 地址，这最终会增加网络中的 MAC 表。加之，虚拟机的迁移迫使广播域扩展。传统的网络划分方式通常依赖于 VLAN。根据802.1q标准，VLAN标签是一个12位的空间，最多可以提供4,096个VLAN。对于当前的多租户云环境来说，这并不是一个可行的解决方案，因为在这些环境中，多个虚拟机可能驻留在同一台服务器上，需要网络隔离，而工作负载不断波动，这要求为未来增长配置多个VLAN，且VLAN蔓延问题会基于工作负载的迁移而持续发生。覆盖网络通过提供独立于物理网络的第二层连接来缓解这个问题。我们都知道，新技术解决了许多问题；然而，它们总是伴随挑战。你能想象一个网络管理员在排查覆盖网络时会遇到多大的困难吗？相信我，当覆盖网络和物理网络之间的映射非常清晰时，故障排除会变得异常简单。基于NSX-VXLAN的覆盖网络是一种基于主机的覆盖网络，使用基于UDP的VXLAN封装。
- en: The VLAN packet
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: VLAN数据包
- en: 'Before trying to understand VXLAN, let''s go back to the fundamentals of a
    VLAN packet. How does  tagging work in a VLAN packet? It''s very simple concept:
    4 bytes are inserted into the Ethernet header field (IEEE), which are a combination
    of a 2-byte **Tag Protocol Identifier** (**TPID**) and 2 bytes of **Tag Control
    Information** (**TCI**). The priority field is a 3-bit field that allows information
    priority to be encoded in the overall frame, 0 being the lowest priority and 8
    the highest value. CFI is typically a bit used for compatibility between Ethernet
    and token ring networks and if the value is 0, those are Ethernet switches. Last
    but not the least, we have the VLAN field - VID:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在尝试理解VXLAN之前，让我们回到VLAN数据包的基本概念。VLAN数据包中的标记是如何工作的？其实很简单：4个字节被插入到以太网头字段（IEEE），这4个字节由2字节的**标签协议标识符**（**TPID**）和2字节的**标签控制信息**（**TCI**）组成。优先级字段是一个3位字段，允许信息的优先级被编码到整个数据帧中，0表示最低优先级，8表示最高优先级。CFI通常是一个用于以太网和令牌环网络之间兼容性的位，如果值为0，则说明是以太网交换机。最后但同样重要的是，我们有VLAN字段——VID：
- en: '![The VLAN packet](img/B03244_02_07.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![VLAN数据包](img/B03244_02_07.jpg)'
- en: The act of creating a VLAN on a switch involves defining a set of switch ports,
    and end devices get connected to these ports. They all become part of that VLAN
    domain which eventually stops a broadcast not to be forwarded to another set of
    VLANs. I know whatever we have discussed so far is something which we will have
    heard in every networking class. This is just a repetition to ensure we never
    forget it. Now we can move on and discuss VXLAN.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在交换机上创建VLAN的过程涉及定义一组交换机端口，并将终端设备连接到这些端口。它们都会成为该VLAN域的一部分，最终会阻止广播转发到另一组VLAN。到目前为止，我们讨论的内容应该是我们在每一门网络课程中都会听到的内容。这只是为了确保我们永远不会忘记这些基本知识。现在我们可以继续讨论VXLAN了。
- en: A VXLAN overview
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: VXLAN概述
- en: 'VXLAN is a technology developed by vendors such as Arista, VMware, Cisco, and
    Broadcom. Each of these VXLAN networks is called a logical switch (virtual wires
    in vCloud network security solution) and they are identified by a 24-bit segment-ID.
    In this way, customers can create up to 16 million VXLAN networks. **Virtual Tunnel
    End Points** (**VTEPs**) are the endpoints that encapsulate and de-encapsulate
    the VXLAN frames. Let''s understand a few key terminologies in VXLAN; and we will
    discuss VXLAN frames after that:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: VXLAN 是由 Arista、VMware、Cisco 和 Broadcom 等厂商开发的一项技术。每个 VXLAN 网络称为逻辑交换机（在 vCloud
    网络安全解决方案中为虚拟线路），它们通过 24 位的段-ID 进行标识。通过这种方式，客户可以创建最多 1600 万个 VXLAN 网络。**虚拟隧道终端节点**（**VTEP**）是封装和解封装
    VXLAN 帧的端点。接下来我们将了解 VXLAN 中的一些关键术语；之后我们将讨论 VXLAN 帧：
- en: '**VXLAN VIB**: VXLAN VIB or VMkernel modules are pushed to an underlying hypervisor
    during ESXi host preparation from NSX Manager.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**VXLAN VIB**：VXLAN VIB 或 VMkernel 模块在 ESXi 主机准备过程中由 NSX Manager 推送到底层虚拟化管理程序。'
- en: '**Vmknic adapter**: Virtual adapter is responsible for sending ARP, DHCP, and
    multicast join messages. Yes, there would be an IP assigned (static/dynamic) to
    vmknic from the VTEP IP pool, which is one of the prerequisites for VXLAN configuration.
    NSX supports multiple VXLAN vmknics per host for uplink load balancing features.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Vmknic 适配器**：虚拟适配器负责发送 ARP、DHCP 和组播加入消息。是的，会从 VTEP IP 池分配一个 IP（静态或动态）给 vmknic，这是
    VXLAN 配置的前提条件之一。NSX 支持每个主机多个 VXLAN vmknic 以实现上行链路负载均衡功能。'
- en: '**VXLAN port group**: VXLAN port group is preconfigured during host preparation
    and it includes components and features such as NIC teaming policy, VLAN, and
    other NIC details.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**VXLAN 端口组**：VXLAN 端口组在主机准备过程中预先配置，包括 NIC 聚合策略、VLAN 和其他 NIC 详细信息等组件和功能。'
- en: '**VTEP proxy**: VTEP proxy is a VTEP that forwards VXLAN traffic to its local
    segment from another VTEP in a remote segment. NSX uses three modes of VXLAN:
    unicast, multicast, and hybrid. In unicast mode, VXLAN VTEP proxy is called UTEP
    and in hybrid mode, it is called MTEP.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**VTEP 代理**：VTEP 代理是一个 VTEP，它将 VXLAN 流量从另一个 VTEP 在远程段转发到本地段。NSX 使用三种 VXLAN
    模式：单播、组播和混合模式。在单播模式下，VXLAN VTEP 代理称为 UTEP，在混合模式下称为 MTEP。'
- en: '**VNI**: **VXLAN Network Identifier** (**VNI**) or segment ID is similar to
    VLAN-bit field; however, VNI is a 24-bit address that gets added to a VXLAN frame.
    This is one of the most critical elements in VXLAN frames, since it uniquely identifies
    the VXLAN network just as a VLAN ID identifies a VLAN network. VNI numbers start
    with 5000.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**VNI**：**VXLAN 网络标识符**（**VNI**）或段 ID 类似于 VLAN 位字段；然而，VNI 是一个 24 位的地址，添加到 VXLAN
    帧中。VNI 是 VXLAN 帧中的关键元素之一，因为它像 VLAN ID 唯一标识 VLAN 网络一样，唯一标识 VXLAN 网络。VNI 的编号从 5000
    开始。'
- en: '**Transport zones**: Transport zones are basically a cluster or a group of
    clusters which define a VXLAN boundary or domain. Transport zones can be local
    or universal for multi VC deployment based on NSX design.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**传输区**：传输区基本上是定义 VXLAN 边界或域的集群或集群组。根据 NSX 设计，传输区可以是本地的或是多 VC 部署的通用区域。'
- en: The VXLAN frame
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VXLAN 帧
- en: 'The following are the main components of the VXLAN frame along with the figure:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 VXLAN 帧的主要组成部分及其图示：
- en: '**Outer Ethernet header (L2 header)**: The destination MAC in the outer Ethernet
    header can be a next hop router MAC or destination VTEP MAC addresses and the
    source outer MAC address will be the source VTEP MAC address.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**外部以太网头（L2 头）**：外部以太网头中的目标 MAC 地址可以是下一个跳跃路由器的 MAC 地址或目标 VTEP 的 MAC 地址，而源外部
    MAC 地址将是源 VTEP 的 MAC 地址。'
- en: '**Outer IP header (L3 header)**: Respective VTEP source and destination IP
    will be populated in the outer IP header.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**外部 IP 头（L3 头）**：相应的 VTEP 源 IP 和目标 IP 将被填充到外部 IP 头中。'
- en: '**Outer UDP header (L4 header)**: The outer UDP header is a combination of
    source port and destination port. IANA has assigned the value `4789` for UDP;
    however, the VMware NSX default UDP port is `8472.` So it is important to allow
    port `8472` in physical/virtual firewall devices for VXLAN traffic.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**外部 UDP 头（L4 头）**：外部 UDP 头由源端口和目标端口组成。IANA 为 UDP 指定了值 `4789`，但 VMware NSX
    默认的 UDP 端口是 `8472`。因此，允许在物理/虚拟防火墙设备中开放端口 `8472` 以支持 VXLAN 流量是非常重要的。'
- en: '**VXLAN header**: This is an 8-byte field which will have the VXLAN flag value,
    segment-ID, and reserved field:'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**VXLAN 头**：这是一个 8 字节的字段，包含 VXLAN 标志位、段-ID 和保留字段：'
- en: '![The VXLAN frame](img/image_02_008.jpg)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![VXLAN 帧](img/image_02_008.jpg)'
- en: Since we have discussed the VXLAN packet format, let's move on and check the
    inner Ethernet frame.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经讨论了 VXLAN 数据包格式，接下来让我们继续查看内部以太网帧。
- en: The inner Ethernet frame
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内部以太网帧
- en: 'The following are the main components of the inner Ethernet frame along with
    the figure:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是内层以太网帧的主要组成部分以及对应的图示：
- en: '**Frame Check Sequence (FCS)**: FCS is a field at the end of the frame which
    is used to store the **cyclic redundancy check** (**CRC**) information. CRC is
    an algorithm which will run each time a frame is built, based on the data in the
    frame. When a receiving host receives the frame and runs the CRC, the answer should
    be the same. If not, the frame is discarded.'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**帧校验序列（FCS）**：FCS是帧末尾的一个字段，用于存储**循环冗余检验**（**CRC**）信息。CRC是一种算法，每次构建帧时都会运行，根据帧中的数据进行计算。当接收主机接收到帧并运行CRC时，结果应该是相同的。如果不同，帧将被丢弃。'
- en: '**Ethernet payload**: The length of a frame is very important, whether it is
    maximum or minimum frame size. The Ethernet payload field is a length field delimiting
    the length of the packet.'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**以太网有效载荷**：帧的长度非常重要，无论是最大帧还是最小帧大小。以太网有效载荷字段是一个长度字段，用于限定数据包的长度。'
- en: '**Inner source MAC address**: The inner source MAC address will be the MAC
    address of the virtual machine which is connected to the VXLAN network.'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**内层源MAC地址**：内层源MAC地址将是连接到VXLAN网络的虚拟机的MAC地址。'
- en: '**Outer destination MAC address**: The outer destination MAC address will be
    the MAC address of the destination virtual machine. Pause for a moment: what if
    a virtual machine doesn''t know the destination virtual machine MAC? There is
    no rocket science here. All it does is a traditional broadcast, `ff:ff:ff:ff:ff:ff`
    (destination MAC), which is the broadcast address, and addresses every network
    adapter in the network and later this complete L2 frame will get encapsulated
    with the VXLAN frame before leaving the hypervisor host.'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**外部目标MAC地址**：外部目标MAC地址将是目标虚拟机的MAC地址。稍等一下：如果虚拟机不知道目标虚拟机的MAC地址该怎么办？这里并没有什么复杂的原理。它所做的只是一个传统的广播，`ff:ff:ff:ff:ff:ff`（目标MAC），这是广播地址，会广播到网络中的每个网络适配器，稍后这个完整的L2帧会在离开虚拟化主机之前被封装上VXLAN帧。'
- en: The life of a VXLAN packet
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VXLAN数据包的生命周期
- en: If we need to understand how a sequence of packets from a source machine reaches
    the destination in a unicast, multicast, or broadcast domain, all we do is a simple
    packet walk. In the following example, if **VM-A** is communicating with **VM-B**
    for the first time in a VXLAN domain, how is the encapsulation and de-encapsulation
    process happening?
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们需要了解一系列数据包从源主机如何到达目的地，无论是在单播、多播还是广播域中，我们只需进行一个简单的数据包过程。在以下示例中，如果**VM-A**第一次在VXLAN域中与**VM-B**通信，封装和解封装过程是如何进行的？
- en: 'The following diagram shows you how:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了如何操作：
- en: '![The life of a VXLAN packet](img/image_02_009.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![VXLAN数据包的生命周期](img/image_02_009.jpg)'
- en: 'Let us now go through the steps one by one:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们逐步了解这些步骤：
- en: VM A-192.168.1.1, MAC- A on ESXi host A generates a broadcast frame (Layer 2
    broadcast frame)
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: VM A-192.168.1.1，MAC-A在ESXi主机A上生成一个广播帧（Layer 2广播帧）。
- en: VTEP A on host A encapsulates the broadcast frame into UDP header with the destination
    IP as multicast/unicast IP based on VXLAN replication modes (Layer 2 header gets
    encapsulated with VXLAN header)
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 主机A上的VTEP A将广播帧封装到UDP头部，目标IP根据VXLAN复制模式（单播/多播IP）而定（Layer 2头部被封装进VXLAN头部）。
- en: Note
  id: totrans-94
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意：
- en: We will certainly have a discussion on VXLAN replication modes in [Chapter 4](ch04.html
    "Chapter 4. NSX Virtual Networks and Logical Router"), *NSX Virtual Networks and
    Logical Routing*.
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将在[第4章](ch04.html "第4章. NSX虚拟网络与逻辑路由器")中详细讨论VXLAN复制模式，*NSX虚拟网络与逻辑路由*。
- en: The physical network delivers the packet to the host, because it was part of
    either the multicast group or unicast IP that we have defined during VXLAN replication
    modes.
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 物理网络将数据包传递给主机，因为它是我们在VXLAN复制模式中定义的多播组或单播IP的一部分。
- en: VTEP B on ESXi host B will look at the VXLAN header (24-bit) and if matches
    with the VTEP table entries, it removes the VXLAN encapsulation header and delivers
    the Layer 2 packet to the virtual machine.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 主机B上的VTEP B将查看VXLAN头（24位），如果与VTEP表条目匹配，则移除VXLAN封装头，并将Layer 2数据包传递给虚拟机。
- en: The preceding four steps mentioned are a simple packet walk on how virtual machines
    communicate in a VXLAN network. However, I haven't explained about ARP suppression
    and VTEP table learning because I want to explain that during NSX virtual networks
    and logical router.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 上述四个步骤是一个简单的数据包过程，展示了虚拟机如何在VXLAN网络中通信。然而，我还没有解释ARP抑制和VTEP表学习的内容，因为我希望在NSX虚拟网络和逻辑路由器部分来进行讲解。
- en: Think for a minute and check in which scenario there won't be any encapsulation
    and de-encapsulation even though virtual machines are connected to a VXLAN network.
    No brainteasers here. If both the virtual machines are residing on same ESXi host
    and same VXLAN network, all it does is traditional Layer 2 learning and there
    is no encapsulation or de-encapsulation. These are very important points to note
    since it would ease a lot of troubleshooting issues when virtual machine to virtual
    machine communication is not happening due to VXLAN/physical network issues. I'm
    sure we have done such troubleshooting in vSphere environments.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 思考一下，检查在什么情况下，即使虚拟机连接到VXLAN网络，也不会发生任何封装和解封装。这里没有脑筋急转弯。如果两台虚拟机位于同一个ESXi主机和相同的VXLAN网络上，它所做的仅是传统的二层学习，并没有封装或解封装。这些是非常重要的点，因为当由于VXLAN/物理网络问题导致虚拟机间无法通信时，能够帮助我们解决很多故障排除问题。我相信我们在vSphere环境中已经做过这样的故障排除。
- en: Summary
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: We began the chapter with a brief introduction of NSX core components and looked
    at the management, control, and data plane components. We then discussed the NSX
    Manager and the NSX Controller clusters, which was followed by a VXLAN architecture
    overview discussion where we looked at the VLAN and VXLAN packet followed by a
    simple packet walk. Now we are familiar with the core components and their functionality.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们以简要介绍NSX核心组件开始本章，并查看了管理、控制和平面组件。接着，我们讨论了NSX Manager和NSX Controller集群，随后进行了VXLAN架构概述讨论，我们分析了VLAN和VXLAN数据包，并进行了简单的数据包步进。现在我们已经熟悉了核心组件及其功能。
- en: In the next chapter, we will discuss NSX Manager installation and configuration.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将讨论NSX Manager的安装和配置。
