- en: Chapter 9. OpenStack Integration with Containers and CoreOS
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 第 9 章 OpenStack 与容器和 CoreOS 的集成
- en: OpenStack is an open source cloud operating system for managing public and private
    clouds. It is a pretty mature technology that is supported by the majority of
    the vendors and is used in a wide variety of production deployments. Running CoreOS
    in the OpenStack environment will give OpenStack users a Container-based Micro
    OS to deploy their distributed applications. Having Container orchestration integrated
    with OpenStack gives OpenStack users a single management solution to manage VMs
    and Containers. There are multiple projects ongoing in OpenStack currently to
    integrate Container management and Container networking with OpenStack.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: OpenStack 是一个开源云操作系统，用于管理公共云和私有云。它是一项相当成熟的技术，得到了大多数供应商的支持，并被广泛应用于各种生产部署中。在 OpenStack
    环境中运行 CoreOS 将为 OpenStack 用户提供一个基于容器的微型操作系统，以便部署他们的分布式应用。容器编排与 OpenStack 的集成为
    OpenStack 用户提供了一个统一的管理解决方案，用于管理虚拟机和容器。目前，OpenStack 中有多个项目正在进行，以将容器管理和容器网络与 OpenStack
    集成。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涉及以下内容：
- en: An overview of OpenStack
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenStack 概述
- en: Running CoreOS in OpenStack
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 OpenStack 中运行 CoreOS
- en: Options to run Containers in OpenStack—the Nova Docker driver, Heat Docker plugin,
    and Magnum
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 OpenStack 中运行容器的选项——Nova Docker 驱动、Heat Docker 插件和 Magnum
- en: Container networking using OpenStack Kuryr and Neutron
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 OpenStack Kuryr 和 Neutron 进行容器网络连接
- en: An overview of OpenStack
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: OpenStack 概述
- en: Just like an OS for a desktop or server manages the resources associated with
    it, a cloud OS manages the resources associated with the cloud. Major cloud resources
    are compute, storage, and network. Compute includes servers and hypervisors associated
    with the servers that allows VM creation. Storage includes the local storage,
    Storage Area Network (SAN), and object storage.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 就像桌面或服务器操作系统管理与之相关的资源一样，云操作系统管理与云相关的资源。主要的云资源包括计算、存储和网络。计算包括服务器和与服务器相关的虚拟化管理程序，这些允许虚拟机的创建。存储包括本地存储、存储区域网络（SAN）和对象存储。
- en: Network includes vlans, firewalls, load balancers, and routers. A cloud OS is
    also responsible for other infrastructure-related items such as image management,
    authentication, security, billing, and so on. A cloud OS also provides some automated
    characteristics such as elasticity, a self service provisioning model, and others.
    Currently, the most popular open source cloud OS in the market is OpenStack. OpenStack
    has a lot of momentum going for it along with a great industry backing.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 网络包括 VLAN、火墙、负载均衡器和路由器。云操作系统还负责其他基础设施相关的项目，如镜像管理、身份验证、安全、计费等。云操作系统还提供一些自动化特性，如弹性、自助式配置模型等。目前，市场上最流行的开源云操作系统是
    OpenStack。OpenStack 得到了极大的支持，并且拥有强大的行业背书。
- en: 'The following are some key OpenStack services:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些关键的 OpenStack 服务：
- en: 'Nova: Compute'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Nova: 计算'
- en: 'Swift: Object storage'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Swift: 对象存储'
- en: 'Cinder: Block storage'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Cinder: 块存储'
- en: 'Neutron: Networking'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Neutron: 网络'
- en: 'Glance: Image management'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Glance: 镜像管理'
- en: 'Keystone: Authentication'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Keystone: 身份验证'
- en: 'Heat: Orchestration'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Heat: 编排'
- en: 'Ceilometer: Metering'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ceilometer: 计量'
- en: 'Horizon: Web interface'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Horizon: Web 界面'
- en: OpenStack can be downloaded from [https://wiki.openstack.org/wiki/Get_OpenStack](https://wiki.openstack.org/wiki/Get_OpenStack).
    It is pretty complex to install OpenStack as there are multiple components involved.
    Similar to Linux distributions provided by Linux vendors, there are multiple vendors
    offering OpenStack distributions. The best way to try out OpenStack is using Devstack
    ([http://devstack.org/](http://devstack.org/)). Devstack offers a scripted approach
    to install and can be installed on a laptop or VM. Devstack can be used to create
    a single-node cluster or multi-node cluster.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: OpenStack 可以从 [https://wiki.openstack.org/wiki/Get_OpenStack](https://wiki.openstack.org/wiki/Get_OpenStack)
    下载。由于涉及多个组件，安装 OpenStack 是相当复杂的。类似于 Linux 供应商提供的 Linux 发行版，多个供应商也提供 OpenStack
    发行版。尝试 OpenStack 的最佳方式是使用 Devstack ([http://devstack.org/](http://devstack.org/))。Devstack
    提供了一种脚本化的安装方式，可以在笔记本或虚拟机上安装。Devstack 可用于创建单节点集群或多节点集群。
- en: CoreOS on OpenStack
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: CoreOS 在 OpenStack 上
- en: CoreOS can be run as a VM on OpenStack. CoreOS OpenStack images are available
    for alpha, beta, and stable versions.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: CoreOS 可以作为虚拟机在 OpenStack 上运行。CoreOS 的 OpenStack 镜像适用于 alpha、beta 和稳定版本。
- en: Here, I have described the procedure to install CoreOS on OpenStack running
    in the Devstack environment. The procedure is based on the CoreOS OpenStack documentation
    ([https://coreos.com/os/docs/latest/booting-on-openstack.html](https://coreos.com/os/docs/latest/booting-on-openstack.html)).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我描述了在 Devstack 环境中运行的 OpenStack 上安装 CoreOS 的过程。该过程基于 CoreOS OpenStack 文档（[https://coreos.com/os/docs/latest/booting-on-openstack.html](https://coreos.com/os/docs/latest/booting-on-openstack.html)）。
- en: 'The following is a summary of the steps:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是步骤的总结：
- en: Get OpenStack Kilo running in Devstack. In my case, I installed Devstack in
    the Ubuntu 14.04 VM.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Devstack 中获取运行的 OpenStack Kilo。在我的例子中，我在 Ubuntu 14.04 虚拟机中安装了 Devstack。
- en: Set up the keys for authentication and a security group for SSH access.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置身份验证的密钥和 SSH 访问的安全组。
- en: Set up external network access and DNS for the VM. This is necessary as the
    CoreOS nodes need to discover each other using the token service.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为虚拟机设置外部网络访问和 DNS。这是必要的，因为 CoreOS 节点需要通过令牌服务相互发现。
- en: Download the appropriate CoreOS image and upload to OpenStack using the Glance
    service.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载适当的 CoreOS 镜像并使用 Glance 服务上传到 OpenStack。
- en: Get a discovery token and update it in the user data configuration file.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取发现令牌并在用户数据配置文件中更新它。
- en: Start CoreOS instances using custom user data specifying necessary services
    to be started and the number of instances to be started.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用自定义用户数据启动 CoreOS 实例，指定需要启动的服务以及要启动的实例数量。
- en: Get OpenStack Kilo running in Devstack
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 获取 Devstack 中运行的 OpenStack Kilo
- en: 'The following blog covers the procedure in detail:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 以下博客详细介绍了该过程：
- en: '[https://sreeninet.wordpress.com/2015/02/21/openstack-juno-install-using-devstack/](https://sreeninet.wordpress.com/2015/02/21/openstack-juno-install-using-devstack/)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://sreeninet.wordpress.com/2015/02/21/openstack-juno-install-using-devstack/](https://sreeninet.wordpress.com/2015/02/21/openstack-juno-install-using-devstack/)'
- en: 'This is the `local.conf` file that I used:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我使用的`local.conf`文件：
- en: '`[[local|localrc]] DEST=/opt/stack  # Logging LOGFILE=$DEST/logs/stack.sh.log
    VERBOSE=True SCREEN_LOGDIR=$DEST/logs/screen OFFLINE=True  # HOST #EDITME HOST_IP=<EDITME>  # Networking
    FIXED_RANGE=10.0.0.0/24 disable_service n-net enable_service q-svc enable_service q-agt
    enable_service q-dhcp enable_service q-meta enable_service q-l3 #ml2 Q_PLUGIN=ml2
    Q_AGENT=openvswitch # vxlan Q_ML2_TENANT_NETWORK_TYPE=vxlan  # Credentials ADMIN_PASSWORD=openstack
    MYSQL_PASSWORD=openstack RABBIT_PASSWORD=openstack SERVICE_PASSWORD=openstack
    SERVICE_TOKEN=tokentoken  #scheduler enable_service n-sch SCHEDULER=nova.scheduler.chance.ChanceScheduler  #vnc
    enable_service n-novnc enable_service n-cauth`'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '`[[local|localrc]] DEST=/opt/stack  # 日志 LOGFILE=$DEST/logs/stack.sh.log VERBOSE=True
    SCREEN_LOGDIR=$DEST/logs/screen OFFLINE=True  # 主机 #EDITME HOST_IP=<EDITME>  #
    网络 FIXED_RANGE=10.0.0.0/24 disable_service n-net enable_service q-svc enable_service
    q-agt enable_service q-dhcp enable_service q-meta enable_service q-l3 #ml2 Q_PLUGIN=ml2
    Q_AGENT=openvswitch # vxlan Q_ML2_TENANT_NETWORK_TYPE=vxlan  # 凭证 ADMIN_PASSWORD=openstack
    MYSQL_PASSWORD=openstack RABBIT_PASSWORD=openstack SERVICE_PASSWORD=openstack
    SERVICE_TOKEN=tokentoken  # 调度器 enable_service n-sch SCHEDULER=nova.scheduler.chance.ChanceScheduler  #
    vnc enable_service n-novnc enable_service n-cauth`'
- en: Setting up keys and a security group
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 设置密钥和安全组
- en: 'The following are the commands that I used to create a keypair and to expose
    port SSH and ICMP port of the VM:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我用来创建密钥对并暴露虚拟机 SSH 和 ICMP 端口的命令：
- en: '`nova keypair-add heattest > ~/Downloads/heattest.pem``nova secgroup-add-rule default icmp -1 -1 0.0.0.0/0``nova secgroup-add-rule default tcp 1 65535 0.0.0.0/0`'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '`nova keypair-add heattest > ~/Downloads/heattest.pem``nova secgroup-add-rule
    default icmp -1 -1 0.0.0.0/0``nova secgroup-add-rule default tcp 1 65535 0.0.0.0/0`'
- en: Setting up external network access
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 设置外部网络访问
- en: 'The first command sets up the NAT rule for VM external access and the second
    command sets up a DNS server:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 第一条命令设置虚拟机外部访问的 NAT 规则，第二条命令设置 DNS 服务器：
- en: '`sudo iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE``neutron subnet-update  <subnet> --dns-nameservers list=true <dns address>`'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '`sudo iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE``neutron subnet-update  <subnet>
    --dns-nameservers list=true <dns address>`'
- en: (Find `<subnet>` using `nova subnet-list` and `<dns address>` from the running
    host machine).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: （使用`nova subnet-list`查找`<subnet>`，并从运行的主机获取`<dns address>`）。
- en: Download the CoreOS image and upload to Glance
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 下载 CoreOS 镜像并上传到 Glance
- en: 'The following command is used to download the latest alpha image and upload
    to OpenStack glance:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令用于下载最新的 alpha 镜像并上传到 OpenStack glance：
- en: '`wget http://alpha.release.core-os.net/amd64-usr/current/coreos_production_openstack_image.img.bz2``bunzip2 coreos_production_openstack_image.img.bz2``glance image-create --name CoreOS \``  --container-format bare \``  --disk-format qcow2 \``  --file coreos_production_openstack_image.img \``  --is-public True`'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '`wget http://alpha.release.core-os.net/amd64-usr/current/coreos_production_openstack_image.img.bz2``bunzip2
    coreos_production_openstack_image.img.bz2``glance image-create --name CoreOS \``  --container-format
    bare \``  --disk-format qcow2 \``  --file coreos_production_openstack_image.img
    \``  --is-public True`'
- en: 'The following is the `glance image-list` output and we can see the CoreOS image
    uploaded to Glance:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 `glance image-list` 输出，我们可以看到 CoreOS 镜像已上传至 Glance：
- en: '![](img/00231.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00231.jpg)'
- en: Updating the user data to be used for CoreOS
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 更新用于 CoreOS 的用户数据
- en: I had some issues using the default user data to start CoreOS because there
    were issues with CoreOS determining the system IP. I raised a case ([https://groups.google.com/forum/#!topic/coreos-user/STmEU6FGRB4](https://groups.google.com/forum/#!topic/coreos-user/STmEU6FGRB4))
    and the CoreOS team provided a sample user data where IP addresses are determined
    using a script inside the user data.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我在使用默认用户数据启动 CoreOS 时遇到了一些问题，因为 CoreOS 在确定系统 IP 时遇到问题。我提出了一个案例（[https://groups.google.com/forum/#!topic/coreos-user/STmEU6FGRB4](https://groups.google.com/forum/#!topic/coreos-user/STmEU6FGRB4)），CoreOS
    团队提供了一个示例用户数据，其中通过用户数据内的脚本来确定 IP 地址。
- en: 'The following is the user data that I used:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我使用的用户数据：
- en: '`#cloud-config  write_files:   - path: /tmp/ip.sh     permissions: 0755     content: |
          #!/bin/sh       get_ipv4() {           IFACE="${1}"            local ip
              while [ -z "${ip}" ]; do               ip=$(ip -4 -o addr show dev "${IFACE}" scope global | gawk ''{split ($4, out, "/"); print out[1]}'')
                  sleep .1           done            echo "${ip}"       }       echo "IPV4_PUBLIC=$(get_ipv4 eth0)" > /run/metadata
          echo "IPV4_PRIVATE=$(get_ipv4 eth0)" >> /run/metadata  coreos:   units:
        - name: populate-ips.service       command: start       runtime: true       content: |
            [Service]         Type=oneshot         ExecStart=/tmp/ip.sh     - name: etcd2.service
          command: start       runtime: true       drop-ins:         - name: custom.conf
              content: |             [Unit]             Requires=populate-ips.service
                After=populate-ips.service              [Service]             EnvironmentFile=/run/metadata
                ExecStart=             ExecStart=/usr/bin/etcd2 --initial-advertise-peer-urls=http://${IPV4_PRIVATE}:2380 --listen-peer-urls=http://${IPV4_PRIVATE}:2380 --listen-client-urls=http://0.0.0.0:2379 --advertise-client-urls=http://${IPV4_PUBLIC}:2379 --discovery=https://discovery.etcd.io/0cbf57ced1c56ac028af8ce7e32264ba
        - name: fleet.service       command: start`'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '`#cloud-config  write_files:   - path: /tmp/ip.sh    permissions: 0755    content:
    |      #!/bin/sh      get_ipv4() {          IFACE="${1}"           local ip          while
    [ -z "${ip}" ]; do              ip=$(ip -4 -o addr show dev "${IFACE}" scope global
    | gawk ''{split ($4, out, "/"); print out[1]}'')              sleep .1          done           echo
    "${ip}"      }      echo "IPV4_PUBLIC=$(get_ipv4 eth0)" > /run/metadata      echo
    "IPV4_PRIVATE=$(get_ipv4 eth0)" >> /run/metadata  coreos:   units:     - name:
    populate-ips.service       command: start       runtime: true       content: |         [Service]         Type=oneshot         ExecStart=/tmp/ip.sh     -
    name: etcd2.service       command: start       runtime: true       drop-ins:         -
    name: custom.conf           content: |             [Unit]             Requires=populate-ips.service             After=populate-ips.service              [Service]             EnvironmentFile=/run/metadata             ExecStart=             ExecStart=/usr/bin/etcd2
    --initial-advertise-peer-urls=http://${IPV4_PRIVATE}:2380 --listen-peer-urls=http://${IPV4_PRIVATE}:2380
    --listen-client-urls=http://0.0.0.0:2379 --advertise-client-urls=http://${IPV4_PUBLIC}:2379
    --discovery=https://discovery.etcd.io/0cbf57ced1c56ac028af8ce7e32264ba     - name:
    fleet.service       command: start`'
- en: 'The preceding user data does the following:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 上述用户数据执行了以下操作：
- en: The `populate-ips.service` unit file is used to update the IP address. It reads
    the IP manually and updates `/run/metadata` with the IP address.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`populate-ips.service` 单元文件用于更新 IP 地址。它手动读取 IP 并将其更新到 `/run/metadata`。'
- en: The discovery token is updated so that nodes can discover each other.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更新发现令牌，以便节点可以相互发现。
- en: Etcd2 service is started using the IP address set in `/run/metadata`.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Etcd2 服务通过在 `/run/metadata` 中设置的 IP 地址启动。
- en: Fleet service is started using fleet unit file.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fleet 服务使用 fleet 单元文件启动。
- en: 'The following command is used to start two CoreOS instances using the preceding
    user data:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令用于使用上述用户数据启动两个 CoreOS 实例：
- en: '`nova boot \``--user-data ./user-data1.yaml \``--image 8ae5223c-1742-47bf-9bb3-873374e61a64 \``--key-name heattest \``--flavor m1.coreos \``--num-instances 2 \``--security-groups default coreos`'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '`nova boot \``--user-data ./user-data1.yaml \``--image 8ae5223c-1742-47bf-9bb3-873374e61a64
    \``--key-name heattest \``--flavor m1.coreos \``--num-instances 2 \``--security-groups
    default coreos`'
- en: Note
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'Note: For the CoreOS instance, I have used a custom flavor `m1.coreos` with
    1 vcpu, 2 GB memory, and 10 GB hard disk. If these resource requirements are not
    met, instance creation will fail.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：对于 CoreOS 实例，我使用了一个自定义规格 `m1.coreos`，配置为 1 vcpu、2 GB 内存和 10 GB 硬盘。如果这些资源要求没有满足，实例创建将失败。
- en: 'Let''s look at the list of VMs. We can see the two CoreOS instances in the
    following image:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看虚拟机的列表。我们可以在以下图片中看到两个 CoreOS 实例：
- en: '![](img/00232.jpg)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00232.jpg)'
- en: 'The following command shows the CoreOS version running in OpenStack:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令显示了在 OpenStack 中运行的 CoreOS 版本：
- en: '![](img/00234.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00234.jpg)'
- en: 'The following command shows the etcd member list:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令显示 etcd 成员列表：
- en: '![](img/00235.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00235.jpg)'
- en: 'The following command shows the fleet machines showing the two CoreOS nodes:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令显示了显示两个 CoreOS 节点的舰队机器：
- en: '![](img/00237.jpg)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00237.jpg)'
- en: OpenStack and Containers
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: OpenStack 和容器
- en: Even though OpenStack has supported VMs and baremetal for quite some time, Containers
    are pretty new to OpenStack. The initial focus in OpenStack was to extend VM Orchestration
    to also manage Containers. The Nova Docker driver and Heat Docker plugin are examples
    of this. This was not widely adopted as some of the Container functionality was
    missing in this approach. The OpenStack Magnum project addresses some of the limitations
    and manages Containers as a first-class citizen like a VM.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 OpenStack 已经支持虚拟机（VM）和裸金属（baremetal）一段时间，但容器对 OpenStack 来说还是相对较新的概念。OpenStack
    最初的重点是将虚拟机编排扩展到容器管理。Nova Docker 驱动程序和 Heat Docker 插件就是这种方法的例子。但由于这种方式缺少了一些容器功能，它并没有得到广泛采用。OpenStack
    Magnum 项目解决了一些局限性，并将容器作为一种类虚拟机的第一类公民来管理。
- en: The Nova Docker driver
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: Nova Docker 驱动程序
- en: Nova typically manages VMs. In this approach, the Nova driver is extended to
    spawn Docker Containers.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: Nova 通常用于管理虚拟机。在这种方法中，Nova 驱动程序被扩展以启动 Docker 容器。
- en: 'The following diagram describes the architecture:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表描述了架构：
- en: '![](img/00238.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00238.jpg)'
- en: 'The following are some notes on the architecture:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是关于架构的一些说明：
- en: Nova is configured to use the Nova Docker driver for Containers
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nova 已配置为使用 Nova Docker 驱动程序来管理容器。
- en: The Nova Docker driver talks to the Docker daemon using the REST API
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nova Docker 驱动程序通过 REST API 与 Docker 守护进程进行通信。
- en: Docker images are imported to Glance and the Nova Docker driver uses these images
    to spawn Containers
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker 镜像被导入到 Glance 中，Nova Docker 驱动程序使用这些镜像来启动容器。
- en: The Nova Docker driver is not present in the mainstream OpenStack installation
    and has to be installed separately.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: Nova Docker 驱动程序并不包含在主流的 OpenStack 安装中，必须单独安装。
- en: Installing the Nova Driver
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 安装 Nova 驱动程序
- en: In the following example, we will cover the installation and usage of the Nova
    Docker driver to create Containers.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们将介绍 Nova Docker 驱动程序的安装和使用方法来创建容器。
- en: 'The following is a summary of the steps:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是步骤摘要：
- en: You need to have a Ubuntu 14.04 VM.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你需要有一个 Ubuntu 14.04 虚拟机。
- en: Install Docker.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装 Docker。
- en: Install the Nova docker plugin.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装 Nova Docker 插件。
- en: Do the stacking of Devstack.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行 Devstack 堆叠。
- en: Install nova-docker rootwrap filters.
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装 nova-docker rootwrap 过滤器。
- en: Create Docker images and export to Glance.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建 Docker 镜像并导出到 Glance。
- en: Spawn Docker containers from Nova.
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 Nova 启动 Docker 容器。
- en: Installing Docker
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 安装 Docker
- en: 'The following is the Docker version running in my system after the Docker installation:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是在我系统中 Docker 安装后运行的 Docker 版本：
- en: '![](img/00240.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00240.jpg)'
- en: Install the Nova Docker plugin
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 安装 Nova Docker 插件
- en: 'Use the following command to install the plugin:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令安装插件：
- en: '`git clone -b stable/kilo https://github.com/stackforge/nova-docker.git``cd nova-docker``sudo pip install .`'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '`git clone -b stable/kilo https://github.com/stackforge/nova-docker.git``cd
    nova-docker``sudo pip install .`'
- en: 'The following is the Docker driver version after installation:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是安装后的 Docker 驱动程序版本：
- en: '![](img/00241.jpg)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00241.jpg)'
- en: The Devstack installation
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: Devstack 安装
- en: 'I have used a stable Kilo release with the following `local.conf`. This sets
    up Nova to use the Docker driver:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用了稳定的 Kilo 版本，并配有以下 `local.conf`。这将配置 Nova 使用 Docker 驱动程序：
- en: '`[[local|localrc]] # HOST HOST_IP=<EDITME>  ADMIN_PASSWORD=openstack DATABASE_PASSWORD=$ADMIN_PASSWORD
    RABBIT_PASSWORD=$ADMIN_PASSWORD SERVICE_PASSWORD=$ADMIN_PASSWORD SERVICE_TOKEN=super-secret-admin-token
    VIRT_DRIVER=novadocker.virt.docker.DockerDriver  # Logging VERBOSE=True DEST=$HOME/stack
    SCREEN_LOGDIR=$DEST/logs/screen SERVICE_DIR=$DEST/status DATA_DIR=$DEST/data LOGFILE=$DEST/logs/stack.sh.log
    LOGDIR=$DEST/logs OFFLINE=false  # Networking FIXED_RANGE=10.0.0.0/24  # This enables Neutron
    disable_service n-net enable_service q-svc enable_service q-agt enable_service q-dhcp
    enable_service q-l3 enable_service q-meta  # Introduce glance to docker images
    [[post-config|$GLANCE_API_CONF]] [DEFAULT] container_formats=ami,ari,aki,bare,ovf,ova,docker  # Configure nova to use the nova-docker driver
    [[post-config|$NOVA_CONF]] [DEFAULT] compute_driver=novadocker.virt.docker.DockerDriver`'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '`[[local|localrc]] # HOST HOST_IP=<EDITME> ADMIN_PASSWORD=openstack DATABASE_PASSWORD=$ADMIN_PASSWORD
    RABBIT_PASSWORD=$ADMIN_PASSWORD SERVICE_PASSWORD=$ADMIN_PASSWORD SERVICE_TOKEN=super-secret-admin-token
    VIRT_DRIVER=novadocker.virt.docker.DockerDriver  # Logging VERBOSE=True DEST=$HOME/stack
    SCREEN_LOGDIR=$DEST/logs/screen SERVICE_DIR=$DEST/status DATA_DIR=$DEST/data LOGFILE=$DEST/logs/stack.sh.log
    LOGDIR=$DEST/logs OFFLINE=false  # Networking FIXED_RANGE=10.0.0.0/24  # This
    enables Neutron disable_service n-net enable_service q-svc enable_service q-agt
    enable_service q-dhcp enable_service q-l3 enable_service q-meta  # Introduce glance
    to docker images [[post-config|$GLANCE_API_CONF]] [DEFAULT] container_formats=ami,ari,aki,bare,ovf,ova,docker  #
    Configure nova to use the nova-docker driver [[post-config|$NOVA_CONF]] [DEFAULT]
    compute_driver=novadocker.virt.docker.DockerDriver`'
- en: 'For installing the nova-docker rootwrap filters run the following command:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装nova-docker rootwrap过滤器，请运行以下命令：
- en: '`sudo cp nova-docker/etc/nova/rootwrap.d/docker.filters \``  /etc/nova/rootwrap.d/`'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '`sudo cp nova-docker/etc/nova/rootwrap.d/docker.filters \``  /etc/nova/rootwrap.d/`'
- en: 'For uploading the Docker image to Glance run the following command:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 要将Docker镜像上传到Glance，请运行以下命令：
- en: '`docker save nginx |  glance image-create --is-public=True --container-format=docker --disk-format=raw --name nginx`'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '`docker save nginx | glance image-create --is-public=True --container-format=docker
    --disk-format=raw --name nginx`'
- en: 'Let''s look at the Glance image list; we can see the nginx container image:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们查看Glance镜像列表；我们可以看到nginx容器镜像：
- en: '![](img/00243.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00243.jpg)'
- en: 'Now, let''s create the nginx container:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们创建nginx容器：
- en: '`nova boot --flavor m1.small --image nginx nginxtest`'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '`nova boot --flavor m1.small --image nginx nginxtest`'
- en: 'Let''s look at the Nova instances:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看Nova实例：
- en: '![](img/00244.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00244.jpg)'
- en: 'We can also see the running Container using the Docker native command:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用Docker原生命令查看正在运行的容器：
- en: '![](img/00246.jpg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00246.jpg)'
- en: The Heat Docker plugin
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: Heat Docker插件
- en: 'The following are some of the items that the Nova Docker driver cannot do currently:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是Nova Docker驱动当前无法完成的某些操作：
- en: Passing environment variables
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 传递环境变量
- en: Linking containers
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器链接
- en: Specifying volumes
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指定卷
- en: Orchestrating and scheduling the containers
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编排和调度容器
- en: These missing functionalities are important and unique for Containers. The Heat
    Docker plugin solves these problems partially, except for the orchestration part.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这些缺失的功能对于容器来说非常重要且独特。Heat Docker插件部分解决了这些问题，除了编排部分。
- en: 'The following diagram shows the Heat Docker orchestration architecture:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示展示了Heat Docker编排架构：
- en: '![](img/00247.jpg)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00247.jpg)'
- en: 'The following are some notes on the architecture:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些关于架构的说明：
- en: Heat uses the Heat Docker plugin to talk to Docker. The Docker plugin uses the
    REST API to talk to the Docker engine.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Heat使用Heat Docker插件与Docker进行通信。Docker插件通过REST API与Docker引擎进行交互。
- en: There is no direct interaction of Heat with the Docker registry.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Heat与Docker注册表之间没有直接交互。
- en: Using the Heat orchestration script, we can use all the features of the Docker
    engine. The disadvantage of this approach is that there is no direct integration
    of Docker with other OpenStack modules.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Heat编排脚本，我们可以使用Docker引擎的所有功能。此方法的缺点是没有将Docker与其他OpenStack模块直接集成。
- en: Installing the Heat plugin
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 安装Heat插件
- en: I used the procedure at [https://sreeninet.wordpress.com/2015/06/14/openstack-and-docker-part-2/](https://sreeninet.wordpress.com/2015/06/14/openstack-and-docker-part-2/)
    and [https://github.com/MarouenMechtri/Docker-containers-deployment-with-OpenStack-Heat](https://github.com/MarouenMechtri/Docker-containers-deployment-with-OpenStack-Heat)
    to do the OpenStack Heat Docker plugin integration with OpenStack Icehouse.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用了[https://sreeninet.wordpress.com/2015/06/14/openstack-and-docker-part-2/](https://sreeninet.wordpress.com/2015/06/14/openstack-and-docker-part-2/)和[https://github.com/MarouenMechtri/Docker-containers-deployment-with-OpenStack-Heat](https://github.com/MarouenMechtri/Docker-containers-deployment-with-OpenStack-Heat)中的步骤，将OpenStack
    Heat与OpenStack Icehouse中的Docker插件进行了集成。
- en: Using the Heat plugin, we can spawn Docker containers either in the localhost
    or VM created by OpenStack.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Heat插件，我们可以在本地主机或由OpenStack创建的虚拟机上启动Docker容器。
- en: I have used a Ubuntu 14.04 VM with Icehouse installed using Devstack. I used
    the procedure in the preceding links to install the Heat Docker plugin.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用的是安装了Icehouse的Ubuntu 14.04虚拟机，通过Devstack进行配置。我按照前述链接中的程序安装了Heat Docker插件。
- en: 'The following command output shows that the Heat plugin is successfully installed
    in the localhost:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令输出显示Heat插件在本地主机中安装成功：
- en: '`$ heat resource-type-list | grep Docker``| DockerInc::Docker::Container     `'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '`$ heat resource-type-list | grep Docker``| DockerInc::Docker::Container     `'
- en: 'The following is a heat template file to spawn the nginx container in the localhost:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个Heat模板文件，用于在本地主机中启动nginx容器：
- en: '`heat_template_version: 2013-05-23 description: >   Heat template to deploy Docker containers to an existing host
    resources:   nginx-01:     type: DockerInc::Docker::Container     properties:
          image: nginx       docker_endpoint: ''tcp://192.168.56.102:2376''`'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '`heat_template_version: 2013-05-23 description: >   Heat模板，用于将Docker容器部署到现有主机
    resources:   nginx-01:     type: DockerInc::Docker::Container     properties:
          image: nginx       docker_endpoint: ''tcp://192.168.56.102:2376''`'
- en: We have specified the endpoint as the localhost IP address and Docker engine
    port number.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已将端点指定为本地主机的IP地址和Docker引擎端口号。
- en: 'The following command is used to create the Container using the preceding heat
    template:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令用于使用前述Heat模板创建容器：
- en: '`heat stack-create -f ~/heat/docker_temp.yml nginxheat1`'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '`heat stack-create -f ~/heat/docker_temp.yml nginxheat1`'
- en: 'The following output shows that the heat stack installation is complete:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 以下输出显示Heat堆栈安装已完成：
- en: '`$ heat stack-list``+--------------------------------------+---------------+-----------------+----------------------+``| id                                   | stack_name    | stack_status    | creation_time        |``+--------------------------------------+---------------+-----------------+----------------------+``| d878d8c1-ce17-4f29-9203-febd37bd8b7d | nginxheat1    | CREATE_COMPLETE | 2015-06-14T13:27:54Z |``+--------------------------------------+---------------+-----------------+----------------------`'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '`$ heat stack-list``+--------------------------------------+---------------+-----------------+----------------------+``|
    id                                   | stack_name    | stack_status    | creation_time        |``+--------------------------------------+---------------+-----------------+----------------------+``|
    d878d8c1-ce17-4f29-9203-febd37bd8b7d  | nginxheat1    | CREATE_COMPLETE | 2015-06-14T13:27:54Z  |``+--------------------------------------+---------------+-----------------+----------------------`'
- en: 'The following output shows the successful running container in the localhost:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 以下输出显示容器在本地主机中的成功运行：
- en: '`$ docker -H :2376 ps``CONTAINER ID        IMAGE               COMMAND                CREATED             STATUS              PORTS               NAMES``624ff5de9240        nginx:latest        "nginx -g ''daemon of   2 minutes ago       Up 2 minutes        80/tcp, 443/tcp     trusting_pasteur   `'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '`$ docker -H :2376 ps``CONTAINER ID        IMAGE               COMMAND                CREATED             STATUS              PORTS               NAMES``624ff5de9240        nginx:latest        "nginx
    -g ''daemon of   2 minutes ago       Up 2 minutes        80/tcp, 443/tcp     trusting_pasteur   `'
- en: We can use the Heat plugin approach to run Containers on OpenStack VMs by changing
    the endpoint IP address from the localhost to the VM's IP address.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过将端点IP地址从本地主机更改为虚拟机的IP地址，使用Heat插件方法在OpenStack虚拟机上运行容器。
- en: Magnum
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: Magnum
- en: With Nova Driver and Heat Orchestration, Containers were not a first-class citizen
    in OpenStack and Container specifics were not easy to manage with these approaches.
    Magnum is a generic Container management solution being developed in OpenStack
    to manage Docker as well as other Container technologies. Magnum supports Kubernetes,
    Docker Swarm, and Mesos for Orchestration currently. Other orchestration solutions
    will be added in the future. Magnum supports Docker Containers currently. The
    architecture allows it to support other Container runtime such as Rkt in the future.
    Magnum is still in the early stages and is available as a beta feature in the
    OpenStack Liberty release.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在Nova驱动程序和Heat编排的情况下，容器在OpenStack中并不是一等公民，且这些方法并不容易管理容器的特性。Magnum是OpenStack中正在开发的通用容器管理解决方案，用于管理Docker及其他容器技术。Magnum目前支持Kubernetes、Docker
    Swarm和Mesos进行编排。未来将添加其他编排解决方案。Magnum目前支持Docker容器。该架构允许其未来支持其他容器运行时，如Rkt。Magnum仍处于早期阶段，并在OpenStack
    Liberty版本中作为测试功能提供。
- en: The Magnum architecture
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: Magnum架构
- en: 'The following diagram shows the different layers in Magnum:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了Magnum中的不同层次：
- en: '![](img/00249.jpg)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00249.jpg)'
- en: 'The following are some notes on the Magnum architecture:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是关于Magnum架构的一些说明：
- en: The Magnum client talks to the Magnum API server, which in turn talks to the
    Magnum conductor. The Magnum conductor is responsible for interacting with Kubernetes,
    Docker Swarm, and Heat.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Magnum 客户端与 Magnum API 服务器进行通信，后者再与 Magnum conductor 通信。Magnum conductor 负责与
    Kubernetes、Docker Swarm 和 Heat 进行交互。
- en: Heat takes care of interacting with other OpenStack modules such as Nova, Neutron,
    Keystone, and Glance.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Heat 负责与其他 OpenStack 模块（如 Nova、Neutron、Keystone 和 Glance）进行交互。
- en: Nova is used to create nodes in the Bay and they can run different Micro OSes
    such as CoreOS and Atomic.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nova 用于在 Bay 中创建节点，这些节点可以运行不同的微型操作系统，如 CoreOS 和 Atomic。
- en: 'OpenStack Magnum uses the following constructs:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: OpenStack Magnum 使用以下构件：
- en: 'Bay model: This is a cluster definition that describes properties of the cluster,
    such as the node flavor, node OS, and orchestration engine to be used. The following
    is an example bay model template that uses the node flavor as `m1.small`, fedora
    atomic as the base OS for the node, and Kubernetes as the orchestration engine:'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bay 模型：这是一个集群定义，描述集群的属性，例如节点规格、节点操作系统以及使用的编排引擎。以下是一个示例 Bay 模型模板，使用 `m1.small`
    作为节点规格，fedora atomic 作为节点的基础操作系统，并使用 Kubernetes 作为编排引擎：
- en: '`magnum baymodel-create --name k8sbaymodel \``                       --image-id fedora-21-atomic-5 \``                       --keypair-id testkey \``                       --external-network-id public \``                       --dns-nameserver 8.8.8.8 \``                       --flavor-id m1.small \``                       --docker-volume-size 5 \``                       --network-driver flannel \``                       --coe kubernetes`'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`magnum baymodel-create --name k8sbaymodel \``           --image-id fedora-21-atomic-5
    \``           --keypair-id testkey \``           --external-network-id public
    \``           --dns-nameserver 8.8.8.8 \``           --flavor-id m1.small \``           --docker-volume-size
    5 \``           --network-driver flannel \``           --coe kubernetes`'
- en: 'Bay: Bays are instantiated based on the bay model with the number of nodes
    necessary in Bay.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bay：Bays 是基于 Bay 模型实例化的，包含 Bay 中所需数量的节点。
- en: 'Nodes, Pods, and Containers: Nodes are the individual VM instances. Pods are
    a collection of containers that share common properties and are scheduled together.
    Containers run within a Pod.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点、Pod 和容器：节点是单独的虚拟机实例。Pod 是一组共享共同属性并一起调度的容器。容器在 Pod 内运行。
- en: 'The following diagram shows the relationship between the Bay model, Bay, Node,
    Pod, and Container:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示显示了 Bay 模型、Bay、节点、Pod 和容器之间的关系：
- en: '![](img/00250.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00250.jpg)'
- en: 'The following are the advantages of using OpenStack Magnum versus a native
    orchestration solution such as Kubernetes:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是使用 OpenStack Magnum 与本地编排解决方案（如 Kubernetes）相比的优势：
- en: For customers who are already using OpenStack, this provides an integrated solution.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于已经使用 OpenStack 的客户，Magnum 提供了一个集成的解决方案。
- en: OpenStack provides multitenancy at all layers. This can be extended for Containers
    as well.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenStack 在所有层级提供多租户功能。这一功能也可以扩展到容器。
- en: OpenStack Magnum allows interaction with other OpenStack modules such as Neutron,
    Keystone, Glance, Swift, and Cinder. Some of these integrations are planned for
    the future.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenStack Magnum 允许与其他 OpenStack 模块（如 Neutron、Keystone、Glance、Swift 和 Cinder）进行交互。其中一些集成计划在未来实现。
- en: VMs and Containers have different purposes and most likely, they will coexist.
    OpenStack with the Magnum project provides you with an orchestration solution
    covering both VMs and Containers and this makes it very attractive.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虚拟机和容器有不同的用途，它们很可能会共存。OpenStack 与 Magnum 项目提供了一个涵盖虚拟机和容器的编排解决方案，这使得它非常具有吸引力。
- en: Installing Magnum
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 安装 Magnum
- en: 'Magnum can be installed using the procedure at [https://github.com/openstack/magnum/blob/master/doc/source/dev/quickstart.rst](https://github.com/openstack/magnum/blob/master/doc/source/dev/quickstart.rst).
    The following is a summary of the steps:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: Magnum 可以通过以下过程进行安装：[https://github.com/openstack/magnum/blob/master/doc/source/dev/quickstart.rst](https://github.com/openstack/magnum/blob/master/doc/source/dev/quickstart.rst)。以下是步骤的总结：
- en: Create the OpenStack development environment with Devstack enabling the Magnum
    service.
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Devstack 创建 OpenStack 开发环境，并启用 Magnum 服务。
- en: By default, the Fedora Atomic image gets downloaded to Glance as part of the
    Devstack installation. If the CoreOS image is necessary, we need to download it
    manually to Glance.
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 默认情况下，Fedora Atomic 镜像会在 Devstack 安装过程中下载到 Glance。如果需要 CoreOS 镜像，我们需要手动将其下载到
    Glance。
- en: Create a Bay model. A Bay model is like a template with a specific set of parameters
    using which multiple bays can be created. In the Bay model, we can specify the
    Bay type (currently supported Bay types are Kubernetes and Swarm), base image
    type (currently supported base images are Fedora Atomic and CoreOS), networking
    model (Flannel), instance size, and so on.
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个 Bay 模型。Bay 模型类似于一个模板，具有一组特定的参数，可以用来创建多个 Bay。在 Bay 模型中，我们可以指定 Bay 类型（当前支持的
    Bay 类型有 Kubernetes 和 Swarm）、基础镜像类型（当前支持的基础镜像有 Fedora Atomic 和 CoreOS）、网络模型（Flannel）、实例大小等。
- en: Create a Bay using the Bay model as a template. While creating a Bay, we can
    specify the number of nodes that need to be created. Node is a VM on top of which
    the base image is installed.
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Bay 模型作为模板创建 Bay。在创建 Bay 时，我们可以指定需要创建的节点数。节点是安装基础镜像的虚拟机。
- en: Deploy Containers using either Kubernetes or Swarm on top of the created Bay.
    Kubernetes or Swarm will take care of scheduling the Containers among the different
    nodes in the Bay.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Kubernetes 或 Swarm 部署容器，并将其部署在创建的 Bay 上。Kubernetes 或 Swarm 会负责将容器调度到 Bay
    中的不同节点。
- en: Note
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: 'Note: It is recommended that you avoid running Magnum in a VM. It is necessary
    to have a beefy machine as each Fedora instance requires at least 1 or 2 GB of
    RAM and 8 GB of hard disk space.'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意：建议避免在虚拟机中运行 Magnum。每个 Fedora 实例至少需要 1 或 2 GB 的内存和 8 GB 的硬盘空间，因此需要一台性能较强的机器。
- en: Container networking using OpenStack Kuryr
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 OpenStack Kuryr 进行容器网络配置
- en: In this section, we will cover how Container networking can be done with OpenStack
    Neutron using the OpenStack Kuryr project.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍如何使用 OpenStack Kuryr 项目通过 OpenStack Neutron 实现容器网络配置。
- en: OpenStack Neutron
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: OpenStack Neutron
- en: 'OpenStack Neutron provides the networking functionality for OpenStack clusters.
    The following are some properties of OpenStack Neutron:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: OpenStack Neutron 为 OpenStack 集群提供网络功能。以下是 OpenStack Neutron 的一些属性：
- en: Neutron provides networking as an API service with backends or plugins doing
    the implementation
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Neutron 通过 API 服务提供网络功能，后端或插件负责实现具体功能。
- en: Neutron can be used for baremetal networking as well as VM networking
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Neutron 可用于裸金属网络以及虚拟机网络。
- en: Basic Neutron constructs are Neutron network, Port, Subnet, and Router
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Neutron 的基本构件包括 Neutron 网络、端口、子网和路由器。
- en: Common Neutron backends are OVS, OVN, and Linux bridge
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 常见的 Neutron 后端包括 OVS、OVN 和 Linux 桥接。
- en: Neutron also provides advanced networking services such as load balancing as
    a service, Firewall as a service, Routing as a service, and VPN as a service
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Neutron 还提供了高级网络服务，如负载均衡服务、防火墙服务、路由服务和 VPN 服务。
- en: Containers and networking
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 容器与网络
- en: We covered the details of Container networking in the earlier chapters. Some
    of the common technologies used were Flannel, Docker Libnetwork, Weave, and Calico.
    Most of these technologies use the Overlay network to provide Container networking.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在前面的章节中已详细介绍了容器网络配置的内容。常用的一些技术包括 Flannel、Docker Libnetwork、Weave 和 Calico。这些技术大多数使用
    Overlay 网络来提供容器网络。
- en: OpenStack Kuryr
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: OpenStack Kuryr
- en: The goal of OpenStack Kuryr is to use Neutron to provide Container networking.
    Considering that Neutron is a mature technology, Kuryr aims to leverage the Neutron
    effort and make it easy for OpenStack users to adopt the Container technology.
    Kuryr is not a networking technology by itself; it aims to act as a bridge between
    Container networking and VM networking and enhancing Neutron to provide missing
    Container networking pieces.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: OpenStack Kuryr 的目标是通过 Neutron 提供容器网络。考虑到 Neutron 是一个成熟的技术，Kuryr 旨在利用 Neutron
    的努力，使 OpenStack 用户能够轻松采用容器技术。Kuryr 本身不是一种网络技术；它的目标是充当容器网络与虚拟机网络之间的桥梁，并增强 Neutron
    以提供缺失的容器网络功能。
- en: 'The following diagram shows you how Docker can be used with Neutron and where
    Kuryr fits in:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示展示了 Docker 如何与 Neutron 配合使用，以及 Kuryr 的作用：
- en: '![](img/00253.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00253.jpg)'
- en: 'The following are some notes on the Kuryr architecture:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些关于 Kuryr 架构的说明：
- en: Kuryr is implemented as the Docker libnetwork plugin. Container networking calls
    are mapped by Kuryr to appropriate Neutron API calls.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kuryr 作为 Docker libnetwork 插件实现。容器网络调用通过 Kuryr 映射到相应的 Neutron API 调用。
- en: Neutron uses OVN, Midonet, and Dragonflow as backends to implement the Neutron
    calls.
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Neutron 使用 OVN、Midonet 和 Dragonflow 作为后端来实现 Neutron 调用。
- en: 'The following are some advantages of OpenStack Kuryr:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 OpenStack Kuryr 的一些优点：
- en: It provides a common networking solution for both VMs and Containers.
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它为虚拟机和容器提供统一的网络解决方案。
- en: With Magnum and Kuryr together, Containers and VMs can have a common Orchestration.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过 Magnum 和 Kuryr，容器和虚拟机可以共享同一个编排系统。
- en: Considering that the Neutron technology is already mature, Containers can leverage
    all the Neutron functionalities.
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 考虑到 Neutron 技术已经成熟，容器可以利用所有 Neutron 功能。
- en: With default Container networking, there is a double encapsulation problem when
    Containers are deployed over a VM. Container networking does the first level of
    encapsulation and VM networking does the next level of encapsulation. This can
    cause performance overhead. With Kuryr, the double encapsulation problem can be
    avoided because Containers and VMs share the same network.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在默认的容器网络配置下，当容器部署在虚拟机上时，会出现双重封装问题。容器网络执行第一层封装，虚拟机网络执行下一层封装。这可能会导致性能开销。使用Kuryr，可以避免双重封装问题，因为容器和虚拟机共享同一网络。
- en: Kuryr can integrate well with other OpenStack components to provide a complete
    Container solution with built-in multitenant support.
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kuryr 可以与其他 OpenStack 组件良好集成，提供内置多租户支持的完整容器解决方案。
- en: 'The following table shows the mapping between the Neutron and Libnetwork abstraction:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格显示了 Neutron 和 Libnetwork 抽象之间的映射：
- en: '| Neutron | Libnetwork |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| Neutron | Libnetwork |'
- en: '| Neutron network | Network |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| Neutron 网络 | 网络 |'
- en: '| Port | Endpoint |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| 端口 | 端点 |'
- en: '| Subnet | IPAM |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| 子网 | IP管理 |'
- en: '| Plugin API (plug/unplug) | Plugin API (Join/leave) |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| 插件 API (插入/拔出) | 插件 API (加入/离开) |'
- en: 'The following diagram shows you how Kuryr can provide a common networking solution
    for Containers, VMs, and bare metal:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表展示了 Kuryr 如何为容器、虚拟机和裸金属提供共同的网络解决方案：
- en: '![](img/00254.jpg)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00254.jpg)'
- en: 'The following image shows you where Kuryr fits in with Magnum and Container
    orchestration projects:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像展示了 Kuryr 在 Magnum 和容器编排项目中的作用：
- en: '![](img/00256.jpg)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00256.jpg)'
- en: The current state and roadmap of Kuryr
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: Kuryr的当前状态和发展路线
- en: 'The Kuryr project is pretty new, and the Mitaka release will be the first OpenStack
    release with Kuryr support. The following are the ongoing and future work items
    with Kuryr:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: Kuryr 项目相当新，Mitaka 版本将是首个支持 Kuryr 的 OpenStack 版本。以下是与 Kuryr 相关的正在进行和未来的工作项目：
- en: Adding missing Container features to Neutron, such as Port forwarding, resource
    tagging, and service discovery.
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向 Neutron 添加缺失的容器功能，例如端口转发、资源标记和服务发现。
- en: Handling the nested container issue by integrating VM and Container networking.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过整合虚拟机和容器网络，解决嵌套容器问题。
- en: Better integration with OpenStack Magnum and Kolla projects.
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更好地与 OpenStack Magnum 和 Kolla 项目集成。
- en: Current integration is focused on Docker. There are integration plans with the
    Kubernetes networking model.
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当前集成主要集中在 Docker。也有与 Kubernetes 网络模型的集成计划。
- en: Summary
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we covered how Containers and CoreOS integrate with OpenStack.
    As CoreOS allows only applications running as Containers inside it, the OpenStack
    integration with CoreOS becomes more useful if OpenStack supports Container Orchestration.
    Even though the Nova driver and Heat plugin add Container support in OpenStack,
    the Magnum project seems like the correct solution treating Containers as a first-class
    citizen in OpenStack. We also covered how OpenStack Neutron can be used to provide
    Container networking using the Kuryr project. OpenStack Container integration
    is relatively new and there is still a lot of work ongoing to complete this integration.
    Managing VMs and Containers using single orchestration software gives tighter
    integration and eases the management and debugging capabilities. In the next chapter,
    we will cover CoreOS troubleshooting and debugging.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，我们讨论了容器和 CoreOS 如何与 OpenStack 集成。由于 CoreOS 只允许以容器的形式运行应用程序，因此如果 OpenStack
    支持容器编排，OpenStack 与 CoreOS 的集成将更加有用。尽管 Nova 驱动程序和 Heat 插件已经在 OpenStack 中添加了对容器的支持，但
    Magnum 项目似乎是正确的解决方案，将容器视为 OpenStack 中的第一类公民。我们还讨论了如何通过 Kuryr 项目，利用 OpenStack Neutron
    提供容器网络。OpenStack 容器集成相对较新，仍有很多工作正在进行，以完成这一集成。使用单一的编排软件来管理虚拟机和容器，可以实现更紧密的集成，并简化管理和调试能力。在下一章中，我们将介绍
    CoreOS 的故障排除和调试。
- en: References
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Magnum: [https://wiki.openstack.org/wiki/Magnum](https://wiki.openstack.org/wiki/Magnum)'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Magnum: [https://wiki.openstack.org/wiki/Magnum](https://wiki.openstack.org/wiki/Magnum)'
- en: 'Magnum developer quick start: [https://github.com/openstack/magnum/blob/master/doc/source/dev/dev-quickstart.rst](https://github.com/openstack/magnum/blob/master/doc/source/dev/dev-quickstart.rst)'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Magnum 开发者快速入门: [https://github.com/openstack/magnum/blob/master/doc/source/dev/dev-quickstart.rst](https://github.com/openstack/magnum/blob/master/doc/source/dev/dev-quickstart.rst)'
- en: 'CoreOS on OpenStack: [https://coreos.com/os/docs/latest/booting-on-openstack.html](https://coreos.com/os/docs/latest/booting-on-openstack.html)'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'CoreOS 在 OpenStack 上: [https://coreos.com/os/docs/latest/booting-on-openstack.html](https://coreos.com/os/docs/latest/booting-on-openstack.html)'
- en: 'The OpenStack Docker driver: [https://wiki.openstack.org/wiki/Docker](https://wiki.openstack.org/wiki/Docker)'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'OpenStack Docker 驱动程序: [https://wiki.openstack.org/wiki/Docker](https://wiki.openstack.org/wiki/Docker)'
- en: 'Installing Nova-docker with OpenStack: [http://blog.oddbit.com/2015/02/11/installing-novadocker-with-devstack/](http://blog.oddbit.com/2015/02/11/installing-novadocker-with-devstack/)'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '在 OpenStack 上安装 Nova-docker: [http://blog.oddbit.com/2015/02/11/installing-novadocker-with-devstack/](http://blog.oddbit.com/2015/02/11/installing-novadocker-with-devstack/)'
- en: 'OpenStack and Docker driver: [https://sreeninet.wordpress.com/2015/06/14/openstack-and-docker-part-1/](https://sreeninet.wordpress.com/2015/06/14/openstack-and-docker-part-1/)'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'OpenStack 和 Docker 驱动程序: [https://sreeninet.wordpress.com/2015/06/14/openstack-and-docker-part-1/](https://sreeninet.wordpress.com/2015/06/14/openstack-and-docker-part-1/)'
- en: 'OpenStack and Docker with Heat and Magnum: [https://sreeninet.wordpress.com/2015/06/14/openstack-and-docker-part-2/](https://sreeninet.wordpress.com/2015/06/14/openstack-and-docker-part-2/)'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'OpenStack 和 Docker 与 Heat 和 Magnum: [https://sreeninet.wordpress.com/2015/06/14/openstack-and-docker-part-2/](https://sreeninet.wordpress.com/2015/06/14/openstack-and-docker-part-2/)'
- en: 'The OpenStack Heat plugin for Docker: [https://github.com/MarouenMechtri/Docker-containers-deployment-with-OpenStack-Heat](https://github.com/MarouenMechtri/Docker-containers-deployment-with-OpenStack-Heat)'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'OpenStack Heat 插件用于 Docker: [https://github.com/MarouenMechtri/Docker-containers-deployment-with-OpenStack-Heat](https://github.com/MarouenMechtri/Docker-containers-deployment-with-OpenStack-Heat)'
- en: 'OpenStack Kuryr: [https://github.com/openstack/kuryr](https://github.com/openstack/kuryr)'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'OpenStack Kuryr: [https://github.com/openstack/kuryr](https://github.com/openstack/kuryr)'
- en: 'OpenStack Kuryr background: [https://galsagie.github.io/sdn/openstack/docker/kuryr/neutron/2015/08/24/kuryr-part1/](https://galsagie.github.io/sdn/openstack/docker/kuryr/neutron/2015/08/24/kuryr-part1/)'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'OpenStack Kuryr 背景: [https://galsagie.github.io/sdn/openstack/docker/kuryr/neutron/2015/08/24/kuryr-part1/](https://galsagie.github.io/sdn/openstack/docker/kuryr/neutron/2015/08/24/kuryr-part1/)'
- en: Further reading and tutorials
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步阅读和教程
- en: 'Private Cloud Dream Stack - OpenStack + CoreOS + Kubernetes: [https://www.openstack.org/summit/vancouver-2015/summit-videos/presentation/private-cloud-dream-stack-openstack-coreos-kubernetes](https://www.openstack.org/summit/vancouver-2015/summit-videos/presentation/private-cloud-dream-stack-openstack-coreos-kubernetes)'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '私有云梦之堆栈 - OpenStack + CoreOS + Kubernetes: [https://www.openstack.org/summit/vancouver-2015/summit-videos/presentation/private-cloud-dream-stack-openstack-coreos-kubernetes](https://www.openstack.org/summit/vancouver-2015/summit-videos/presentation/private-cloud-dream-stack-openstack-coreos-kubernetes)'
- en: 'Magnum OpenStack presentations: [https://www.youtube.com/watch?v=BM6nFH7G8Vc](https://www.youtube.com/watch?v=BM6nFH7G8Vc)
    and [https://www.youtube.com/watch?v=_ZbebTIaS7M](https://www.youtube.com/watch?v=_ZbebTIaS7M)'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Magnum OpenStack 演示: [https://www.youtube.com/watch?v=BM6nFH7G8Vc](https://www.youtube.com/watch?v=BM6nFH7G8Vc)
    和 [https://www.youtube.com/watch?v=_ZbebTIaS7M](https://www.youtube.com/watch?v=_ZbebTIaS7M)'
- en: 'Kuryr OpenStack presentations: [https://www.openstack.org/summit/tokyo-2015/videos/presentation/connecting-the-dots-with-neutron-unifying-network-virtualization-between-containers-and-vms](https://www.openstack.org/summit/tokyo-2015/videos/presentation/connecting-the-dots-with-neutron-unifying-network-virtualization-between-containers-and-vms)
    and [https://www.youtube.com/watch?v=crVi30bgOt0](https://www.youtube.com/watch?v=crVi30bgOt0)'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kuryr OpenStack 演示: [https://www.openstack.org/summit/tokyo-2015/videos/presentation/connecting-the-dots-with-neutron-unifying-network-virtualization-between-containers-and-vms](https://www.openstack.org/summit/tokyo-2015/videos/presentation/connecting-the-dots-with-neutron-unifying-network-virtualization-between-containers-and-vms)
    和 [https://www.youtube.com/watch?v=crVi30bgOt0](https://www.youtube.com/watch?v=crVi30bgOt0)'
